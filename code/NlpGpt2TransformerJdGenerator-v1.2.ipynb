{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NlpGpt2TransformerJdGenerator-v1.2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"g2eKaN11uAXZ"},"source":["Import GPT-*2* Transformer and set global parameters"]},{"cell_type":"code","metadata":{"id":"9UkmmLHbXewP"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Oc15KZg2yDT"},"source":["!pip install tensorflow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUIdwlItt1jP","executionInfo":{"elapsed":17359,"status":"ok","timestamp":1617811755953,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"},"user_tz":-330},"outputId":"5316e4d0-2778-4819-c191-ef735019b779"},"source":["!pip install -q gpt-2-simple\n","%tensorflow_version 1.x\n","import tensorflow as tf\n","import gpt_2_simple as gpt2\n","from datetime import datetime\n","from google.colab import files\n","\n","file_name_1 = \"jd_roles_responsibility_corpus_v1.txt\"\n","file_name_2 = \"jd_skills_corpus_v1.1.txt\"\n","file_name_3 = \"jd_company_corpus_v1.txt\"\n","run_name_1 = 'fine_tuning_run_1'\n","run_name_2 = 'fine_tuning_run_2'\n","run_name_3 = 'fine_tuning_run_3'\n","model_size = '355M'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g9VHkTOjyrG0"},"source":["def mount():\n","   gpt2.mount_gdrive()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"if_WIr23Pn6K"},"source":["Manage Tensorflow Sessions"]},{"cell_type":"code","metadata":{"id":"eGJ3gGxcQxcL"},"source":["def initsess():\n","  tf.reset_default_graph()\n","  tf.global_variables_initializer()\n","  return tf.Session() "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4YVQD9DC3Xlu"},"source":["def getsess(sess):    \n","    if sess._closed:\n","      tf.reset_default_graph()\n","      sess = gpt2.start_tf_sess()\n","      tf.global_variables_initializer()\n","    return sess    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oEVPINcYOoHw"},"source":["def resetsess(sess):    \n","   sess = gpt2.reset_session(sess)\n","   return sess"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tTJSx8c0wh9E"},"source":["Load a Custom Pretrained Model with Saved Checkpoints"]},{"cell_type":"code","metadata":{"id":"fXe3WdISsrJu"},"source":["def load_trained_randr_model():\n","    sess = initsess()\n","    #mount()\n","    gpt2.copy_checkpoint_from_gdrive(run_name=run_name_1)\n","    sess = resetsess(sess)\n","    gpt2.load_gpt2(sess, run_name=run_name_1)\n","    return True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SFm3TmMWWkxR"},"source":["def load_trained_skils_model():\n","    sess = initsess()\n","    #mount()\n","    gpt2.copy_checkpoint_from_gdrive(run_name=run_name_2)\n","    sess = resetsess(sess)\n","    gpt2.load_gpt2(sess, run_name=run_name_2)\n","    return True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rfuGPr6B81I"},"source":["def load_trained_company_model():\n","    sess = initsess()\n","   #mount()\n","    gpt2.copy_checkpoint_from_gdrive(run_name=run_name_3)\n","    sess = resetsess(sess)\n","    gpt2.load_gpt2(sess, run_name=run_name_3)\n","    return True"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mxz1kRJfwvZh"},"source":["Fine tune the model"]},{"cell_type":"code","metadata":{"id":"oACJjtLlssYz"},"source":["def model_train(model_trained):\n","  if not model_trained :  \n","      sess = initsess()\n","      gpt2.download_gpt2(model_name=\"355M\")\n","      mount()\n","      #gpt2.copy_file_from_gdrive(file_name_1)\n","      #gpt2.copy_file_from_gdrive(file_name_2)\n","      gpt2.copy_file_from_gdrive(file_name_3)\n","\n","      #gpt2.copy_checkpoint_from_gdrive(run_name=run_name_1)\n","      #gpt2.copy_checkpoint_from_gdrive(run_name=run_name_2)\n","      #gpt2.copy_checkpoint_from_gdrive(run_name=run_name_3)\n","\n","      #sess = resetsess(sess)\n","\n","      #gpt2.finetune(sess,\n","      #              dataset=file_name_1,\n","      #              model_name=model_size,\n","      #              steps=200,\n","      #              restore_from='fresh',\n","      #              run_name = run_name_1,\n","      #              print_every=10,\n","      #              sample_every=50,\n","      #              save_every=50)\n","                  # , learning_rate=.00003)\n","      #gpt2.copy_checkpoint_to_gdrive(run_name_1)             \n","\n","      #sess = resetsess(sess)\n","      #gpt2.finetune(sess,\n","      #              dataset=file_name_2,\n","      #              model_name=model_size,\n","      #              steps=200,\n","      #              restore_from='fresh',\n","      #              run_name = run_name_2,\n","      #              print_every=10,\n","      #              sample_every=50,\n","      #              save_every=50)\n","                  # , learning_rate=.00003)\n","      #gpt2.copy_checkpoint_to_gdrive(run_name_2)\n","\n","      sess = resetsess(sess)\n","      gpt2.finetune(sess,\n","                     dataset=file_name_3,\n","                     model_name=model_size,\n","                     steps=200,\n","                     restore_from='fresh',\n","                     run_name = run_name_3,\n","                     print_every=10,\n","                     sample_every=50,\n","                     save_every=50)\n","                  # , learning_rate=.00003)\n","      gpt2.copy_checkpoint_to_gdrive(run_name_3)\n","  else:\n","      load_trained_model()\n","  return True    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YWcETercDRoS"},"source":["Call model_train to train model"]},{"cell_type":"code","metadata":{"id":"mEJYNg_ODN6D"},"source":["model_train(False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YzxehOHlTbjH"},"source":["Load the Custom Pretrained Model "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFU0XZ-LPiiy","executionInfo":{"elapsed":52882,"status":"ok","timestamp":1617811857968,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"},"user_tz":-330},"outputId":"23e4a421-da3b-4c21-ae6f-5871d1a0b0be"},"source":[" load_trained_randr_model()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading checkpoint checkpoint/fine_tuning_run_1/model-253\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_1/model-253\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"5qXA2GGhxfzS"},"source":["Generate Job Description given input"]},{"cell_type":"code","metadata":{"id":"d95R8n_zCN-N"},"source":["def model_generate(input, run_name):\n","  sess = initsess()\n","  gpt2.load_gpt2(sess, run_name=run_name)\n","  return gpt2.generate(sess, run_name=run_name, temperature=.7, length=100, prefix=input, top_k=40, nsamples=1, batch_size=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hC7B2uqfyPrb","executionInfo":{"elapsed":43952,"status":"ok","timestamp":1617811910586,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"},"user_tz":-330},"outputId":"e08bd49c-91d4-43bc-a055-6b8f8c8c7fea"},"source":["input = \"You combine strong analysis with synthesis abilities\"\n","model_generate(input, \"fine_tuning_run_1\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading checkpoint checkpoint/fine_tuning_run_1/model-253\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_1/model-253\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","You combine strong analysis with synthesis abilities to build an understanding of the underlying structure, and how to exploit it to generate new products and improve the way we measure performance.Demonstrated experience building and building complex data solutions in a distributed, data-intensive environment.Ability to analyze large data sets to understand the performance, reliability, and impact of the analytics tools and processes.Experience working in a data analytics environment, preferably in the U.S. or in other advanced markets.Demonstrated ability to apply advanced statistical and/or machine\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"A4OgTqZeTX7z","outputId":"d8fa207d-6f7d-4904-e01a-ce566744457d"},"source":[" load_trained_company_model()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading checkpoint checkpoint/fine_tuning_run_3/model-200\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_3/model-200\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"id":"qP86IZICIEp0"},"source":["  load_trained_company_model()\n","  load_trained_randr_model()\n","  load_trained_skils_model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VpWM0iKcTcri","executionInfo":{"elapsed":43740,"status":"ok","timestamp":1617810589193,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"},"user_tz":-330},"outputId":"4ec6fd60-4ea2-4bd8-b66d-9bbd9618465a"},"source":["input = \"ABOUT EXPRESS SCRIPTS\"\n","model_generate(input, \"fine_tuning_run_3\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading checkpoint checkpoint/fine_tuning_run_3/model-200\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_3/model-200\n","ABOUT EXPRESS SCRIPTS INC.\n","\n","Express Scripts is the leading provider of enterprise data processing solutions across the globe and an equal opportunity employer.Our mission is to empower each other through a culture of innovation, education, and fun., \n","\n","About Express Scripts\n","\n","Express Scripts (NYSE: ESB), a leading global consulting firm, offers a comprehensive approach to business analysis and strategy with a focus on user-centered solutions.We are committed to the principle of equal employment opportunity for all employees and to\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ovjB6ymqzaCa","executionInfo":{"elapsed":9823,"status":"ok","timestamp":1617812024740,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"},"user_tz":-330},"outputId":"38d4b645-d5cc-44bc-a2f7-23f7fab3d5ff"},"source":["!pip install pydantic"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (1.8.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LFbkpkQLlGdq"},"source":["from pydantic import BaseModel\n","\n","class LstmJdGenerator(BaseModel):\n","  seedText: str\n","  skills: str\n","  company: str"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_WLp6FMkiAT"},"source":["#Install colabcode and fastapi\n","!pip install colabcode\n","!pip install fastapi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21Kswv_DkqNW","executionInfo":{"elapsed":1714,"status":"ok","timestamp":1617812051825,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"},"user_tz":-330},"outputId":"12f3c2c3-dbd9-4321-b285-78faff21affb"},"source":["#import libraries for loading saved model, fast api, colabcode\n","import tensorflow as tf\n","from tensorflow import keras\n","from colabcode import ColabCode\n","from fastapi import FastAPI\n","from keras.models import load_model\n","\n","import logging\n","from fastapi import FastAPI\n","\n","app=FastAPI(title=\"NlpJdGeneratorAPI\", description=\"NLP based LSTM model Job Description Generator\")\n","\n","#initializing logging\n","my_logger = logging.getLogger()\n","my_logger.setLevel(logging.DEBUG)\n","logging.basicConfig(level=logging.DEBUG, filename='logs.log')\n","\n","#Initalize lstml model to load and model file path\n","lstm_model_loaded = None\n","model_path = '/content/drive/MyDrive/nlp-job-generator/app/main/resources/models/lstm/lstm_model.h5'\n","max_sequence_length = 1000\n","\n","@app.on_event(\"startup\")\n","#Returns a compiled model identical to the saved after trained\n","def load_saved_model():\n","  #load_trained_company_model()\n","  #load_trained_randr_model()\n","  #load_trained_skils_model()\n","\n","@app.post(\"/api\")\n","async def getJobDescription(inputData:LstmJdGenerator):\n","  try:\n","    print(inputData)\n","    #my_logger.debug(\"inputData:\", inputData)\n","\n","    prediction = model_generate(\"ABOUT EXPRESS SCRIPTS\", \"fine_tuning_run_3\")\n","    #prediction += \"\\n\"\n","    #prediction = model_generate(inputData.seedText, \"fine_tuning_run_1\")\n","    #prediction += \"\\n\"\n","    #prediction += model_generate(inputData.skills, \"fine_tuning_run_2\")\n","   \n","    my_logger.debug(\"prediction:\", prediction)\n","    print(prediction)\n","\n","    return {\"job_description\" : prediction}\n","  except:\n","    my_logger.error(\"Someting went wrong!\")\n","    return {\"prediction\": \"error\"}"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1k58c5KplkqX","outputId":"e44f68d7-19c3-41e3-837c-e3fd0954beae"},"source":["from colabcode import ColabCode\n","from fastapi import FastAPI\n","cc = ColabCode(port=1200, code=False, authtoken=\"1qhOBp2p5qxw80yQipxR0JHwMbl_5choeHxGXkp6HVXZ66hTh\")\n","cc.run_app(app=app)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Public URL: NgrokTunnel: \"http://4c4015d558e0.ngrok.io\" -> \"http://localhost:1200\"\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:     Started server process [1898]\n","INFO:     Waiting for application startup.\n"],"name":"stderr"},{"output_type":"stream","text":["Loading checkpoint checkpoint/fine_tuning_run_3/model-200\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_3/model-200\n","Loading checkpoint checkpoint/fine_tuning_run_1/model-253\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_1/model-253\n","Loading checkpoint checkpoint/fine_tuning_run_2/model-245\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_2/model-245\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:     Application startup complete.\n","INFO:     Uvicorn running on http://127.0.0.1:1200 (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:     2409:4071:e1e:defb:b14f:45da:a1ef:54c7:0 - \"GET /docs HTTP/1.1\" 200 OK\n","INFO:     2409:4071:e1e:defb:b14f:45da:a1ef:54c7:0 - \"GET /openapi.json HTTP/1.1\" 200 OK\n","seedText='string' skills='string' company='string'\n","Loading checkpoint checkpoint/fine_tuning_run_3/model-200\n","INFO:tensorflow:Restoring parameters from checkpoint/fine_tuning_run_3/model-200\n","ABOUT EXPRESS SCRIPTS, INC. 2017 is shaping up to be a big year for Express Scripts.Our mission is to help our clients transform their organizations by offering cutting edge analytics and data science capabilities to improve the way they communicate, operate and collaborate.We're an Equal Opportunity/Affirmative Action employer., All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, veteran status, or protected veteran status.]\"As a Data Scientist, you will be\n"],"name":"stdout"},{"output_type":"stream","text":["--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/logging/__init__.py\", line 1025, in emit\n","    msg = self.format(record)\n","  File \"/usr/lib/python3.7/logging/__init__.py\", line 869, in format\n","    return fmt.format(record)\n","  File \"/usr/lib/python3.7/logging/__init__.py\", line 608, in format\n","    record.message = record.getMessage()\n","  File \"/usr/lib/python3.7/logging/__init__.py\", line 369, in getMessage\n","    msg = msg % self.args\n","TypeError: not all arguments converted during string formatting\n","Call stack:\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 199, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 189, in _handle_events\n","    handler_func(fileobj, events)\n","  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 451, in _handle_events\n","    self._handle_recv()\n","  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n","    self._run_callback(callback, msg)\n","  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 434, in _run_callback\n","    callback(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n","    return self.dispatch_shell(stream, msg)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n","    handler(stream, idents, msg)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n","    user_expressions, allow_stdin)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n","    interactivity=interactivity, compiler=compiler, result=result)\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n","    if self.run_code(code, result):\n","  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-18-0ad66f9f0248>\", line 4, in <module>\n","    cc.run_app(app=app)\n","  File \"/usr/local/lib/python3.7/dist-packages/colabcode/code.py\", line 118, in run_app\n","    uvicorn.run(app, host=\"127.0.0.1\", port=self.port, workers=workers)\n","  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/main.py\", line 386, in run\n","    server.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/server.py\", line 48, in run\n","    loop.run_until_complete(self.serve(sockets=sockets))\n","  File \"/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\", line 92, in run_until_complete\n","    self._run_once()\n","  File \"/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\", line 132, in _run_once\n","    handle._run()\n","  File \"/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\", line 201, in run\n","    ctx.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.7/dist-packages/nest_asyncio.py\", line 159, in step\n","    step_orig(task, exc)\n","  File \"/usr/lib/python3.7/asyncio/tasks.py\", line 249, in __step\n","    result = coro.send(None)\n","  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/protocols/http/h11_impl.py\", line 394, in run_asgi\n","    result = await app(self.scope, self.receive, self.send)\n","  File \"/usr/local/lib/python3.7/dist-packages/uvicorn/middleware/proxy_headers.py\", line 45, in __call__\n","    return await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.7/dist-packages/fastapi/applications.py\", line 199, in __call__\n","    await super().__call__(scope, receive, send)\n","  File \"/usr/local/lib/python3.7/dist-packages/starlette/applications.py\", line 111, in __call__\n","    await self.middleware_stack(scope, receive, send)\n","  File \"/usr/local/lib/python3.7/dist-packages/starlette/middleware/errors.py\", line 159, in __call__\n","    await self.app(scope, receive, _send)\n","  File \"/usr/local/lib/python3.7/dist-packages/starlette/exceptions.py\", line 71, in __call__\n","    await self.app(scope, receive, sender)\n"],"name":"stderr"},{"output_type":"stream","text":["None\n","INFO:     2409:4071:e1e:defb:b14f:45da:a1ef:54c7:0 - \"POST /api HTTP/1.1\" 200 OK\n"],"name":"stdout"},{"output_type":"stream","text":["  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 566, in __call__\n","    await route.handle(scope, receive, send)\n","  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 227, in handle\n","    await self.app(scope, receive, send)\n","  File \"/usr/local/lib/python3.7/dist-packages/starlette/routing.py\", line 41, in app\n","    response = await func(request)\n","  File \"/usr/local/lib/python3.7/dist-packages/fastapi/routing.py\", line 202, in app\n","    dependant=dependant, values=values, is_coroutine=is_coroutine\n","  File \"/usr/local/lib/python3.7/dist-packages/fastapi/routing.py\", line 148, in run_endpoint_function\n","    return await dependant.call(**values)\n","  File \"<ipython-input-17-a986f19704f5>\", line 42, in getJobDescription\n","    my_logger.debug(\"prediction:\", prediction)\n","Message: 'prediction:'\n","Arguments: (None,)\n"],"name":"stderr"}]}]}