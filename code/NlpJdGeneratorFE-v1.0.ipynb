{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of Capstone_Job_description_generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ha7QHtRpm-ay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dajb1moAilMs"
      },
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ko2dpgDQijle"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "\n",
        "import re\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loV0Cbodf_lL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM_cOBR_5gx-"
      },
      "source": [
        "###### Data Clean\n",
        "- Parse words\n",
        "- Remove all special characters\n",
        "- Cleaned formatting\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVtNyFPG5gx_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c198cdda-86eb-4ed1-bd27-40b03cd0e050"
      },
      "source": [
        "# Loading dataset using Pandas DataFrame.\n",
        "df = pd.read_csv('indeed_job_dataset_200.csv')\n",
        "type (df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcyXjaN97VDE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6-KJdqp5gyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da7ed5d-dd44-4b5a-d246-fcdb501de9e0"
      },
      "source": [
        "# Check to data shape, Total number of columns and row.\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5714, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA2i8jaTjc5v",
        "outputId": "c736fb3e-4a82-45cb-c0a3-2dd0f71ebe74"
      },
      "source": [
        "df['Description'].head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [<p><b>POSITION SUMMARY</b></p>, <p>\\r\\r\\nThe ...\n",
              "1    [<p><b>What do we need?</b></p>, <ul><li>\\r\\r\\...\n",
              "Name: Description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7KH8TJO5gyC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "49f0d5ab-488a-417b-b9d7-6e6dbb929ba6"
      },
      "source": [
        "pd.set_option('display.max_columns', 43)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Job_Title</th>\n",
              "      <th>Link</th>\n",
              "      <th>Queried_Salary</th>\n",
              "      <th>Job_Type</th>\n",
              "      <th>Skill</th>\n",
              "      <th>No_of_Skills</th>\n",
              "      <th>Company</th>\n",
              "      <th>No_of_Reviews</th>\n",
              "      <th>No_of_Stars</th>\n",
              "      <th>Date_Since_Posted</th>\n",
              "      <th>Description</th>\n",
              "      <th>Location</th>\n",
              "      <th>Company_Revenue</th>\n",
              "      <th>Company_Employees</th>\n",
              "      <th>Company_Industry</th>\n",
              "      <th>python</th>\n",
              "      <th>sql</th>\n",
              "      <th>machine learning</th>\n",
              "      <th>r</th>\n",
              "      <th>hadoop</th>\n",
              "      <th>tableau</th>\n",
              "      <th>sas</th>\n",
              "      <th>spark</th>\n",
              "      <th>java</th>\n",
              "      <th>Others</th>\n",
              "      <th>CA</th>\n",
              "      <th>NY</th>\n",
              "      <th>VA</th>\n",
              "      <th>TX</th>\n",
              "      <th>MA</th>\n",
              "      <th>IL</th>\n",
              "      <th>WA</th>\n",
              "      <th>MD</th>\n",
              "      <th>DC</th>\n",
              "      <th>NC</th>\n",
              "      <th>Other_states</th>\n",
              "      <th>Consulting and Business Services</th>\n",
              "      <th>Internet and Software</th>\n",
              "      <th>Banks and Financial Services</th>\n",
              "      <th>Health Care</th>\n",
              "      <th>Insurance</th>\n",
              "      <th>Other_industries</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=6a105f495c36a...</td>\n",
              "      <td>&lt;80000</td>\n",
              "      <td>data_scientist</td>\n",
              "      <td>['SAP', 'SQL']</td>\n",
              "      <td>2</td>\n",
              "      <td>Express Scripts</td>\n",
              "      <td>3301.0</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[&lt;p&gt;&lt;b&gt;POSITION SUMMARY&lt;/b&gt;&lt;/p&gt;, &lt;p&gt;\\r\\r\\nThe ...</td>\n",
              "      <td>MO</td>\n",
              "      <td>More than $10B (USD)</td>\n",
              "      <td>10,000+</td>\n",
              "      <td>Health Care</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=86afd561ea8c6...</td>\n",
              "      <td>&lt;80000</td>\n",
              "      <td>data_scientist</td>\n",
              "      <td>['Machine Learning', 'R', 'SAS', 'SQL', 'Python']</td>\n",
              "      <td>5</td>\n",
              "      <td>Money Mart Financial Services</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>[&lt;p&gt;&lt;b&gt;What do we need?&lt;/b&gt;&lt;/p&gt;, &lt;ul&gt;&lt;li&gt;\\r\\r\\...</td>\n",
              "      <td>TX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Data Scientist</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=e0aad317e6d45...</td>\n",
              "      <td>&lt;80000</td>\n",
              "      <td>data_scientist</td>\n",
              "      <td>['Data Mining', 'Data Management', 'R', 'SAS',...</td>\n",
              "      <td>9</td>\n",
              "      <td>comScore</td>\n",
              "      <td>62.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>[&lt;ul&gt;&lt;li&gt;Validate, analyze, and conduct statis...</td>\n",
              "      <td>OR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Graduate Studies Program - Data Scientist</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...</td>\n",
              "      <td>&lt;80000</td>\n",
              "      <td>data_scientist</td>\n",
              "      <td>['Certified Internal Auditor']</td>\n",
              "      <td>1</td>\n",
              "      <td>Central Intelligence Agency</td>\n",
              "      <td>158.0</td>\n",
              "      <td>4.3</td>\n",
              "      <td>30.0</td>\n",
              "      <td>[&lt;p&gt;Full time&lt;/p&gt;, &lt;p&gt;Washington, DC metro are...</td>\n",
              "      <td>DC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Government</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Data Scientist I</td>\n",
              "      <td>https://www.indeed.com/rc/clk?jk=fec647775a21e...</td>\n",
              "      <td>&lt;80000</td>\n",
              "      <td>data_scientist</td>\n",
              "      <td>['Statistical Software', 'Time Management', 'R...</td>\n",
              "      <td>7</td>\n",
              "      <td>Federal Reserve Bank of Dallas</td>\n",
              "      <td>495.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>30.0</td>\n",
              "      <td>[&lt;ul&gt;&lt;li&gt;Assist in consultations with business...</td>\n",
              "      <td>TX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Less than 10,000</td>\n",
              "      <td>Banks and Financial Services</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                  Job_Title  \\\n",
              "0           0                             Data Scientist   \n",
              "1           1                             Data Scientist   \n",
              "2           2                             Data Scientist   \n",
              "3           3  Graduate Studies Program - Data Scientist   \n",
              "4           4                           Data Scientist I   \n",
              "\n",
              "                                                Link Queried_Salary  \\\n",
              "0  https://www.indeed.com/rc/clk?jk=6a105f495c36a...         <80000   \n",
              "1  https://www.indeed.com/rc/clk?jk=86afd561ea8c6...         <80000   \n",
              "2  https://www.indeed.com/rc/clk?jk=e0aad317e6d45...         <80000   \n",
              "3  https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...         <80000   \n",
              "4  https://www.indeed.com/rc/clk?jk=fec647775a21e...         <80000   \n",
              "\n",
              "         Job_Type                                              Skill  \\\n",
              "0  data_scientist                                     ['SAP', 'SQL']   \n",
              "1  data_scientist  ['Machine Learning', 'R', 'SAS', 'SQL', 'Python']   \n",
              "2  data_scientist  ['Data Mining', 'Data Management', 'R', 'SAS',...   \n",
              "3  data_scientist                     ['Certified Internal Auditor']   \n",
              "4  data_scientist  ['Statistical Software', 'Time Management', 'R...   \n",
              "\n",
              "   No_of_Skills                         Company  No_of_Reviews  No_of_Stars  \\\n",
              "0             2                 Express Scripts         3301.0          3.3   \n",
              "1             5   Money Mart Financial Services            NaN          NaN   \n",
              "2             9                        comScore           62.0          3.5   \n",
              "3             1     Central Intelligence Agency          158.0          4.3   \n",
              "4             7  Federal Reserve Bank of Dallas          495.0          4.1   \n",
              "\n",
              "   Date_Since_Posted                                        Description  \\\n",
              "0                1.0  [<p><b>POSITION SUMMARY</b></p>, <p>\\r\\r\\nThe ...   \n",
              "1               15.0  [<p><b>What do we need?</b></p>, <ul><li>\\r\\r\\...   \n",
              "2                1.0  [<ul><li>Validate, analyze, and conduct statis...   \n",
              "3               30.0  [<p>Full time</p>, <p>Washington, DC metro are...   \n",
              "4               30.0  [<ul><li>Assist in consultations with business...   \n",
              "\n",
              "  Location       Company_Revenue Company_Employees  \\\n",
              "0       MO  More than $10B (USD)           10,000+   \n",
              "1       TX                   NaN               NaN   \n",
              "2       OR                   NaN               NaN   \n",
              "3       DC                   NaN               NaN   \n",
              "4       TX                   NaN  Less than 10,000   \n",
              "\n",
              "               Company_Industry  python  sql  machine learning  r  hadoop  \\\n",
              "0                   Health Care       0    1                 0  0       0   \n",
              "1                           NaN       1    1                 1  1       0   \n",
              "2                           NaN       1    1                 0  1       0   \n",
              "3                    Government       0    0                 0  0       0   \n",
              "4  Banks and Financial Services       0    0                 0  1       0   \n",
              "\n",
              "   tableau  sas  spark  java  Others  CA  NY  VA  TX  MA  IL  WA  MD  DC  NC  \\\n",
              "0        0    0      0     0       1   0   0   0   0   0   0   0   0   0   0   \n",
              "1        0    1      0     0       0   0   0   0   1   0   0   0   0   0   0   \n",
              "2        0    1      0     0       1   0   0   0   0   0   0   0   0   0   0   \n",
              "3        0    0      0     0       1   0   0   0   0   0   0   0   0   1   0   \n",
              "4        1    0      0     0       1   0   0   0   1   0   0   0   0   0   0   \n",
              "\n",
              "   Other_states  Consulting and Business Services  Internet and Software  \\\n",
              "0             1                                 0                      0   \n",
              "1             0                                 0                      0   \n",
              "2             1                                 0                      0   \n",
              "3             0                                 0                      0   \n",
              "4             0                                 0                      0   \n",
              "\n",
              "   Banks and Financial Services  Health Care  Insurance  Other_industries  \n",
              "0                             0            1          0                 0  \n",
              "1                             0            0          0                 0  \n",
              "2                             0            0          0                 0  \n",
              "3                             0            0          0                 1  \n",
              "4                             1            0          0                 0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEYZJZD85gyC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ff3979-83bb-4d96-dc20-78f85b870ca5"
      },
      "source": [
        "# Get the summary of DataFrame.\n",
        "list(df.columns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Unnamed: 0',\n",
              " 'Job_Title',\n",
              " 'Link',\n",
              " 'Queried_Salary',\n",
              " 'Job_Type',\n",
              " 'Skill',\n",
              " 'No_of_Skills',\n",
              " 'Company',\n",
              " 'No_of_Reviews',\n",
              " 'No_of_Stars',\n",
              " 'Date_Since_Posted',\n",
              " 'Description',\n",
              " 'Location',\n",
              " 'Company_Revenue',\n",
              " 'Company_Employees',\n",
              " 'Company_Industry',\n",
              " 'python',\n",
              " 'sql',\n",
              " 'machine learning',\n",
              " 'r',\n",
              " 'hadoop',\n",
              " 'tableau',\n",
              " 'sas',\n",
              " 'spark',\n",
              " 'java',\n",
              " 'Others',\n",
              " 'CA',\n",
              " 'NY',\n",
              " 'VA',\n",
              " 'TX',\n",
              " 'MA',\n",
              " 'IL',\n",
              " 'WA',\n",
              " 'MD',\n",
              " 'DC',\n",
              " 'NC',\n",
              " 'Other_states',\n",
              " 'Consulting and Business Services',\n",
              " 'Internet and Software',\n",
              " 'Banks and Financial Services',\n",
              " 'Health Care',\n",
              " 'Insurance',\n",
              " 'Other_industries']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-YOz_0C5gyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0e21eef-2d56-4acf-9a1f-79b3621dd7c1"
      },
      "source": [
        "#Get the dataFrame info\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5715 entries, 0 to 5714\n",
            "Data columns (total 43 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   Unnamed: 0                        5715 non-null   int64  \n",
            " 1   Job_Title                         5715 non-null   object \n",
            " 2   Link                              5715 non-null   object \n",
            " 3   Queried_Salary                    5715 non-null   object \n",
            " 4   Job_Type                          5715 non-null   object \n",
            " 5   Skill                             5483 non-null   object \n",
            " 6   No_of_Skills                      5715 non-null   int64  \n",
            " 7   Company                           5611 non-null   object \n",
            " 8   No_of_Reviews                     4753 non-null   float64\n",
            " 9   No_of_Stars                       4753 non-null   float64\n",
            " 10  Date_Since_Posted                 5611 non-null   float64\n",
            " 11  Description                       5413 non-null   object \n",
            " 12  Location                          5463 non-null   object \n",
            " 13  Company_Revenue                   2017 non-null   object \n",
            " 14  Company_Employees                 3199 non-null   object \n",
            " 15  Company_Industry                  3826 non-null   object \n",
            " 16  python                            5715 non-null   int64  \n",
            " 17  sql                               5715 non-null   int64  \n",
            " 18  machine learning                  5715 non-null   int64  \n",
            " 19  r                                 5715 non-null   int64  \n",
            " 20  hadoop                            5715 non-null   int64  \n",
            " 21  tableau                           5715 non-null   int64  \n",
            " 22  sas                               5715 non-null   int64  \n",
            " 23  spark                             5715 non-null   int64  \n",
            " 24  java                              5715 non-null   int64  \n",
            " 25  Others                            5715 non-null   int64  \n",
            " 26  CA                                5715 non-null   int64  \n",
            " 27  NY                                5715 non-null   int64  \n",
            " 28  VA                                5715 non-null   int64  \n",
            " 29  TX                                5715 non-null   int64  \n",
            " 30  MA                                5715 non-null   int64  \n",
            " 31  IL                                5715 non-null   int64  \n",
            " 32  WA                                5715 non-null   int64  \n",
            " 33  MD                                5715 non-null   int64  \n",
            " 34  DC                                5715 non-null   int64  \n",
            " 35  NC                                5715 non-null   int64  \n",
            " 36  Other_states                      5715 non-null   int64  \n",
            " 37  Consulting and Business Services  5715 non-null   int64  \n",
            " 38  Internet and Software             5715 non-null   int64  \n",
            " 39  Banks and Financial Services      5715 non-null   int64  \n",
            " 40  Health Care                       5715 non-null   int64  \n",
            " 41  Insurance                         5715 non-null   int64  \n",
            " 42  Other_industries                  5715 non-null   int64  \n",
            "dtypes: float64(3), int64(29), object(11)\n",
            "memory usage: 1.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rSeKNzokIDx",
        "outputId": "f191501a-69a1-4831-9992-15554cdf9288"
      },
      "source": [
        "#Removing Duplicates\n",
        "\n",
        "df = df.drop_duplicates(subset=['Job_Title','Job_Type','Description','Location'])\n",
        "print(df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5355, 43)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5zCcyp9lNLf",
        "outputId": "0f8ac7b0-5eea-435b-bfbd-5cadb226e37d"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                            1\n",
              "Job_Title                             1\n",
              "Link                                  1\n",
              "Queried_Salary                        1\n",
              "Job_Type                              1\n",
              "Skill                                11\n",
              "No_of_Skills                          1\n",
              "Company                               1\n",
              "No_of_Reviews                        27\n",
              "No_of_Stars                          27\n",
              "Date_Since_Posted                     1\n",
              "Description                          17\n",
              "Location                              1\n",
              "Company_Revenue                     151\n",
              "Company_Employees                   105\n",
              "Company_Industry                     62\n",
              "python                                1\n",
              "sql                                   1\n",
              "machine learning                      1\n",
              "r                                     1\n",
              "hadoop                                1\n",
              "tableau                               1\n",
              "sas                                   1\n",
              "spark                                 1\n",
              "java                                  1\n",
              "Others                                1\n",
              "CA                                    1\n",
              "NY                                    1\n",
              "VA                                    1\n",
              "TX                                    1\n",
              "MA                                    1\n",
              "IL                                    1\n",
              "WA                                    1\n",
              "MD                                    1\n",
              "DC                                    1\n",
              "NC                                    1\n",
              "Other_states                          1\n",
              "Consulting and Business Services      1\n",
              "Internet and Software                 1\n",
              "Banks and Financial Services          1\n",
              "Health Care                           1\n",
              "Insurance                             1\n",
              "Other_industries                      1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt2rFlZK-ozn",
        "outputId": "3903b405-7195-4932-b274-128d6787d26b"
      },
      "source": [
        "#Skills and Description are important parameters in the model,hence there shouldnt be any null value for these feartures\n",
        "#Before we detect the skills from description , we need to standardize the description features\n",
        "import re as re\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "#Converting the Descrition feature into String type\n",
        "df['Description']=df['Description'].apply(str)\n",
        "#Removing tags from description\n",
        "def remove_tags(string) :\n",
        "  #Convert to lower case\n",
        "  string = string.lower()\n",
        "  #Remove Special Characters\n",
        "  result = re.sub('(\\\\d|\\\\W)+','',string)\n",
        "  #Remove Tags\n",
        "  result = result = re.sub('<.*?>','',string)\n",
        "  result = result.replace('\\r','')\n",
        "  result = result.replace('\\n','')\n",
        "  result = result.strip()\n",
        "  return result\n",
        "df['Description'] = df['Description'].apply(lambda cw : remove_tags(cw))\n",
        "df['Description'].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [position summary, the business analyst role i...\n",
              "1    [what do we need?, you to have an amazing pers...\n",
              "2    [validate, analyze, and conduct statistical an...\n",
              "3    [full time, washington, dc metro area, startin...\n",
              "4    [assist in consultations with business partner...\n",
              "Name: Description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "jfoVTFck-xjw",
        "outputId": "7d6241a8-be22-4a5b-de9d-0b9d9e7361c1"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "stop = stopwords.words('english')\n",
        "df['Description'].apply(lambda x: [item for item in x if item not in stop])\n",
        "\n",
        "# remove words less than three letters\n",
        "#df['Description'].apply(lambda x :[word for word in text if len(word) >= 3]\n",
        "docs = df['Description']\n",
        "#instantiate CountVectorizer() \n",
        "cv=CountVectorizer(max_df=0.95,max_features=10000,ngram_range=(1,3)) \n",
        " \n",
        "# this steps generates word counts for the words in your docs \n",
        "word_count_vector=cv.fit_transform(docs)\n",
        "word_count_vector.shape "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-117-545e57e61cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'averaged_perceptron_tagger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# remove words less than three letters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-545e57e61cd4>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'averaged_perceptron_tagger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# remove words less than three letters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWnOc83NkFxt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "23bc9dbc-705c-480c-eb35-9ed3834ef9b2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "stop = stopwords.words('english')\n",
        "df['Description'].apply(lambda x: [item for item in x if item not in stop])\n",
        "\n",
        "# remove words less than three letters\n",
        "#DataFrame['Description'].apply(lambda x :[word for word in text if len(word) >= 3]\n",
        "docs = df['Description']\n",
        "#instantiate CountVectorizer() \n",
        "cv=CountVectorizer(max_df=0.95,max_features=10000,ngram_range=(1,3)) \n",
        " \n",
        "# this steps generates word counts for the words in your docs \n",
        "word_count_vector=cv.fit_transform(docs)\n",
        "word_count_vector.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-0c152929e858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'averaged_perceptron_tagger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# remove words less than three letters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-118-0c152929e858>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'averaged_perceptron_tagger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Description'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# remove words less than three letters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egxMzo3x-4hQ"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
        "tfidf_transformer.fit(word_count_vector)\n",
        "\n",
        "# print idf values \n",
        "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
        " \n",
        "# sort ascending \n",
        "df_idf.sort_values(by=['idf_weights'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls_mnAGs_J4J"
      },
      "source": [
        "#words = [w for w in words if not w in stopwords.words(\"english\")]\n",
        "#words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGjmjzJP5gyE"
      },
      "source": [
        "def clean_text(raw):\n",
        "    try:\n",
        "        # Remove new line.\n",
        "        raw = raw.replace('\\r', '')\n",
        "        raw = raw.replace('\\n', '')\n",
        "        \n",
        "        # Remove brackets.\n",
        "        raw = raw.replace('[', '')\n",
        "        raw = raw.replace(']', '')\n",
        "        raw = raw.replace(')', '')\n",
        "        raw = raw.replace('(', '')\n",
        "        \n",
        "        # Remove html tags.\n",
        "        clean_html = re.compile('<.*?>')\n",
        "        clean_text = re.sub(clean_html, ' ', raw)\n",
        "        \n",
        "        # Remove duplicate whitespace.\n",
        "        clean_text = re.sub(\" +\", \" \", clean_text) \n",
        "        \n",
        "        # Stripping first and last white space.\n",
        "        clean_text = clean_text.strip()\n",
        "        \n",
        "        # Remove multiple commas.\n",
        "        clean_text = re.sub(\" , \", \", \", clean_text) \n",
        "        \n",
        "        # Remove the extra comma after a period\n",
        "        clean_text = clean_text.replace('.,', '.')\n",
        "        \n",
        "        # using try and except due to Nan in the column\n",
        "    except:\n",
        "        clean_text = np.nan\n",
        "        \n",
        "    return clean_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egvces_A5gyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af32969-cedc-4557-c230-7aec03220608"
      },
      "source": [
        "df_desc = df_desc.apply(clean_text)\n",
        "df_desc\n",
        "#df_desc.iloc[876]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                         NaN\n",
              "Job_Title                          NaN\n",
              "Link                               NaN\n",
              "Queried_Salary                     NaN\n",
              "Job_Type                           NaN\n",
              "Skill                              NaN\n",
              "No_of_Skills                       NaN\n",
              "Company                            NaN\n",
              "No_of_Reviews                      NaN\n",
              "No_of_Stars                        NaN\n",
              "Date_Since_Posted                  NaN\n",
              "Description                        NaN\n",
              "Location                           NaN\n",
              "Company_Revenue                    NaN\n",
              "Company_Employees                  NaN\n",
              "Company_Industry                   NaN\n",
              "python                             NaN\n",
              "sql                                NaN\n",
              "machine learning                   NaN\n",
              "r                                  NaN\n",
              "hadoop                             NaN\n",
              "tableau                            NaN\n",
              "sas                                NaN\n",
              "spark                              NaN\n",
              "java                               NaN\n",
              "Others                             NaN\n",
              "CA                                 NaN\n",
              "NY                                 NaN\n",
              "VA                                 NaN\n",
              "TX                                 NaN\n",
              "MA                                 NaN\n",
              "IL                                 NaN\n",
              "WA                                 NaN\n",
              "MD                                 NaN\n",
              "DC                                 NaN\n",
              "NC                                 NaN\n",
              "Other_states                       NaN\n",
              "Consulting and Business Services   NaN\n",
              "Internet and Software              NaN\n",
              "Banks and Financial Services       NaN\n",
              "Health Care                        NaN\n",
              "Insurance                          NaN\n",
              "Other_industries                   NaN\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBmB3NrMiio2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1Nw68XS5gyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8eb4319-b8ef-4620-a263-4448ccdf4fbf"
      },
      "source": [
        "# Total number of null value.\n",
        "df_desc.isna().sum()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJz_6WZ0jq8Y",
        "outputId": "58a34519-ef3f-498f-e1e5-19f92478d1ae"
      },
      "source": [
        "df['Description'].head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [position summary, the business analyst role i...\n",
              "1    [what do we need?, you to have an amazing pers...\n",
              "Name: Description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE_0g2R05gyG"
      },
      "source": [
        "# Total number of missing /null value 302\n",
        "df_desc = pd.DataFrame(df_desc)\n",
        "df_desc.dropna(inplace = True)\n",
        "df_desc.reset_index(inplace = True, drop = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLQuKtjN5gyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b7d904-8177-4815-bd01-b4b5b186cdb6"
      },
      "source": [
        "df_desc.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Description    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUmGp1OCkfIk",
        "outputId": "821b19fc-40b2-48d9-c3b4-ee2dbfce4c2b"
      },
      "source": [
        "df['Description'].head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [<p><b>POSITION SUMMARY</b></p>, <p>\\r\\r\\nThe ...\n",
              "1    [<p><b>What do we need?</b></p>, <ul><li>\\r\\r\\...\n",
              "Name: Description, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQMOhvHqlSis",
        "outputId": "7a7e1e69-0561-40b2-cb2b-4ed1fac94bf0"
      },
      "source": [
        "df.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 246 entries, 0 to 251\n",
            "Data columns (total 43 columns):\n",
            " #   Column                            Non-Null Count  Dtype  \n",
            "---  ------                            --------------  -----  \n",
            " 0   Unnamed: 0                        245 non-null    float64\n",
            " 1   Job_Title                         245 non-null    object \n",
            " 2   Link                              245 non-null    object \n",
            " 3   Queried_Salary                    245 non-null    object \n",
            " 4   Job_Type                          245 non-null    object \n",
            " 5   Skill                             235 non-null    object \n",
            " 6   No_of_Skills                      245 non-null    float64\n",
            " 7   Company                           245 non-null    object \n",
            " 8   No_of_Reviews                     219 non-null    float64\n",
            " 9   No_of_Stars                       219 non-null    float64\n",
            " 10  Date_Since_Posted                 245 non-null    float64\n",
            " 11  Description                       229 non-null    object \n",
            " 12  Location                          245 non-null    object \n",
            " 13  Company_Revenue                   95 non-null     object \n",
            " 14  Company_Employees                 141 non-null    object \n",
            " 15  Company_Industry                  184 non-null    object \n",
            " 16  python                            245 non-null    float64\n",
            " 17  sql                               245 non-null    float64\n",
            " 18  machine learning                  245 non-null    float64\n",
            " 19  r                                 245 non-null    float64\n",
            " 20  hadoop                            245 non-null    float64\n",
            " 21  tableau                           245 non-null    float64\n",
            " 22  sas                               245 non-null    float64\n",
            " 23  spark                             245 non-null    float64\n",
            " 24  java                              245 non-null    float64\n",
            " 25  Others                            245 non-null    float64\n",
            " 26  CA                                245 non-null    float64\n",
            " 27  NY                                245 non-null    float64\n",
            " 28  VA                                245 non-null    float64\n",
            " 29  TX                                245 non-null    float64\n",
            " 30  MA                                245 non-null    float64\n",
            " 31  IL                                245 non-null    float64\n",
            " 32  WA                                245 non-null    float64\n",
            " 33  MD                                245 non-null    float64\n",
            " 34  DC                                245 non-null    float64\n",
            " 35  NC                                245 non-null    float64\n",
            " 36  Other_states                      245 non-null    float64\n",
            " 37  Consulting and Business Services  245 non-null    float64\n",
            " 38  Internet and Software             245 non-null    float64\n",
            " 39  Banks and Financial Services      245 non-null    float64\n",
            " 40  Health Care                       245 non-null    float64\n",
            " 41  Insurance                         245 non-null    float64\n",
            " 42  Other_industries                  245 non-null    float64\n",
            "dtypes: float64(32), object(11)\n",
            "memory usage: 84.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sf1IA1wo5gyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3f5f33-a85b-4fc4-a0b1-8ea86acc0e29"
      },
      "source": [
        "# Convert all to lower case and split words\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#df_desc['lower_description'] = df_desc.Description.str.lower()\n",
        "lower_case = df_desc.Description.str.lower()  # Convert to lower case\n",
        "words = lower_case.str.split()               # Split into words\n",
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [position, summary,, the, business, analyst, r...\n",
              "1      [what, do, we, need?,, you, to, have, an, amaz...\n",
              "2      [validate,, analyze,, and, conduct, statistica...\n",
              "3      [full, time,, washington,, dc, metro, area,, s...\n",
              "4      [assist, in, consultations, with, business, pa...\n",
              "                             ...                        \n",
              "224    [innovate., collaborate., shine., lighthouse, ...\n",
              "225    [company:, arvato, digital, services, llc, -, ...\n",
              "226    [innovate., collaborate., shine., lighthouse, ...\n",
              "227    [innovate., collaborate., shine., lighthouse, ...\n",
              "228    [implement, large-scale, data, ecosystems, inc...\n",
              "Name: Description, Length: 229, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfokdpeUA8Pg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXPXaLb3Arv2"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFyfZhrQAqnd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTSAzMUSpJh_",
        "outputId": "47ad4db1-410a-4e9b-ad8e-16f9cf8ed64a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOh52_2g5gyI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef789aa-b22c-41f0-8777-443c4be977f2"
      },
      "source": [
        "# Remove english stop words\n",
        "\n",
        "## import nltk\n",
        "# nltk.download()\n",
        "\n",
        "from nltk.corpus import stopwords # Import the stop word list\n",
        "test = stopwords.words(\"english\")\n",
        "test\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyO3nbD55gyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e390f833-3264-47a0-e9d5-02f6f38e588d"
      },
      "source": [
        "import re  # For preprocessing\n",
        "import pandas as pd  # For data handling\n",
        "from time import time  # To time our operations\n",
        "from collections import defaultdict  # For word frequency\n",
        "import spacy  # For preprocessing\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "#print(df.dtypes)\n",
        "print(df['Description'].dtypes)\n",
        "sent = [str(row).split() for row in df['Description']]\n",
        "#print (sent)\n",
        "phrases = Phrases(sent, min_count=30, progress_per=10000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-krdYHZMAUV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZw17hkeC6gF",
        "outputId": "bd355009-5ee7-4032-e60b-9c05652ca30c"
      },
      "source": [
        "sentences = sent #bigram[sent]\n",
        "word_freq = defaultdict(int)\n",
        "for s in sentences:\n",
        "    for i in s:\n",
        "        word_freq[i] += 1\n",
        "len(word_freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11911"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGPiGUi6C9en",
        "outputId": "9eb8416f-a10e-481f-a2b2-c6512ea35fb8"
      },
      "source": [
        "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'to', 'the', 'of', 'in', 'a', 'data', 'with', 'or', 'for']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8fwid39C__2"
      },
      "source": [
        "import multiprocessing\n",
        "from gensim.models import Word2Vec\n",
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMLKN0jSDZJ6"
      },
      "source": [
        "w2v_model = Word2Vec(min_count=20,\n",
        "                     window=2,\n",
        "                     size=300,\n",
        "                     sample=6e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=cores-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rzc9urXDbtk",
        "outputId": "fb2d80c3-d85e-42c6-a156-4a13ac120b22"
      },
      "source": [
        "t = time()\n",
        "w2v_model.build_vocab(sentences, progress_per=10000)\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.0 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2bu9sj1Dd0A",
        "outputId": "d2c09253-3377-493e-f300-6427eefe381b"
      },
      "source": [
        "t = time()\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 0.05 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs1IS_1-DgUm",
        "outputId": "91f96b36-d882-473a-9d1a-784e90cec0d6"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"machine\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('statistical', 0.9955878257751465),\n",
              " ('learning,', 0.9953383207321167),\n",
              " ('modeling,', 0.9907042980194092),\n",
              " ('programming', 0.9903129935264587),\n",
              " ('knowledge', 0.9897602200508118),\n",
              " ('learning', 0.9890963435173035),\n",
              " ('using', 0.9877902865409851),\n",
              " ('regression,', 0.98774254322052),\n",
              " ('language', 0.9869343638420105),\n",
              " ('such', 0.9831910133361816)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnC2zCcGDm4T",
        "outputId": "e8177cdd-aa08-48ef-a769-f03f1b94c812"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"communication\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('written', 0.999154806137085),\n",
              " ('excellent', 0.9981745481491089),\n",
              " ('skills', 0.9975196719169617),\n",
              " ('presentation', 0.9975178241729736),\n",
              " ('applications,', 0.9973074197769165),\n",
              " ('concepts', 0.9972285032272339),\n",
              " ('strong', 0.9970403909683228),\n",
              " ('models,', 0.9969161152839661),\n",
              " ('verbal', 0.996904730796814),\n",
              " ('common', 0.9966981410980225)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7bSFkx6Dm7Z",
        "outputId": "03abaa89-edb0-4004-ed91-7f742290a69f"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"data\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('modeling', 0.9856635332107544),\n",
              " ('analytics', 0.9828342795372009),\n",
              " ('complex', 0.9811112284660339),\n",
              " ('statistical', 0.9743896722793579),\n",
              " ('using', 0.9727662801742554),\n",
              " ('knowledge', 0.9709545373916626),\n",
              " ('cleaning,', 0.9696717262268066),\n",
              " ('models', 0.9668748378753662),\n",
              " ('unstructured', 0.9662361741065979),\n",
              " ('modeling,', 0.9650071263313293)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E0a3j9dDzEe",
        "outputId": "5f6dd2ae-b23c-4d82-dbdb-1d5a005505c4"
      },
      "source": [
        "w2v_model.wv.most_similar(positive=[\"build\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('product', 0.9990051984786987),\n",
              " ('across', 0.997504711151123),\n",
              " ('improve', 0.9972037076950073),\n",
              " ('capabilities', 0.9967969655990601),\n",
              " ('internal', 0.9960457682609558),\n",
              " ('support', 0.9953798651695251),\n",
              " ('client', 0.9950597882270813),\n",
              " ('identify', 0.9942275881767273),\n",
              " ('projects', 0.9940832853317261),\n",
              " ('new', 0.9939902424812317)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    }
  ]
}