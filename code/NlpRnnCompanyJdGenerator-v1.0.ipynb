{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"NlpRnnCompanyJdGenerator-v1.0.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"p2C_hirsYgtR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617903969657,"user_tz":-330,"elapsed":1304,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"8462ead4-1537-4df9-8c23-55584b676ef1"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ceAkTIkUY1SG","executionInfo":{"status":"ok","timestamp":1617903975329,"user_tz":-330,"elapsed":3026,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}}},"source":["from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing.text import Tokenizer\n","from keras.callbacks import EarlyStopping\n","from keras.models import Sequential\n","import keras.utils as ku \n","\n","# set seeds for reproducability\n","from tensorflow import random\n","from numpy.random import seed\n","random.set_seed(2)\n","seed(1)\n","import pandas as pd\n","import numpy as np\n","import string, os \n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","warnings.simplefilter(action='ignore', category=FutureWarning)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"mb1DKCRWYguv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617903998672,"user_tz":-330,"elapsed":1610,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"db2b1762-dc5f-4bcd-f91d-d927153d2925"},"source":["#Configuration parameters\n","\n","#Add header in the company-corpus\n","headers = [\"Description\"]\n","\n","#Number of rows to be selected from corpus    \n","nrows=1000 #for testing set 100, but actually it should be 1000\n","\n","#corpus file path\n","corpus_file_path = '/content/drive/MyDrive/nlp-job-generator/app/main/resources/data/jd_company_corpus_v1.0.csv'\n","   \n","all_headlines = pd.read_csv(corpus_file_path, names = headers, sep = '\\t',nrows = nrows)       \n","\n","#Print lenght of all headlines from corpus\n","len(all_headlines)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"EDMDDSJDYgvr","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1617904002486,"user_tz":-330,"elapsed":1085,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"892255d4-1446-4bc4-c0a0-84d8e06a717d"},"source":["all_headlines"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Description</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Learn more about Splunk careers and how you ca...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>The Data Scientist role involves working on al...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Experience using one or more advanced analytic...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Experience with one or more data storage and m...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Demonstrates the ability to transform ambiguou...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>995</th>\n","      <td>Partner with your product and development peer...</td>\n","    </tr>\n","    <tr>\n","      <th>996</th>\n","      <td>Manage testing and debugging of analytics/tagg...</td>\n","    </tr>\n","    <tr>\n","      <th>997</th>\n","      <td>Assist in reporting and ad-hoc analysis of dat...</td>\n","    </tr>\n","    <tr>\n","      <th>998</th>\n","      <td>Assist peer groups in the development of, and ...</td>\n","    </tr>\n","    <tr>\n","      <th>999</th>\n","      <td>Qualifications,</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1000 rows × 1 columns</p>\n","</div>"],"text/plain":["                                           Description\n","0    Learn more about Splunk careers and how you ca...\n","1    The Data Scientist role involves working on al...\n","2    Experience using one or more advanced analytic...\n","3    Experience with one or more data storage and m...\n","4    Demonstrates the ability to transform ambiguou...\n","..                                                 ...\n","995  Partner with your product and development peer...\n","996  Manage testing and debugging of analytics/tagg...\n","997  Assist in reporting and ad-hoc analysis of dat...\n","998  Assist peer groups in the development of, and ...\n","999                                   Qualifications, \n","\n","[1000 rows x 1 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"4TtpCXt6Ygv1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617904012050,"user_tz":-330,"elapsed":1549,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"ec1c486e-4555-474d-d9ba-ee7caa56c4f4"},"source":["#List description text from corpus\n","corpus_header = \"Description\"\n","description_texts = list(set(all_headlines[corpus_header]))\n","print (\"Description Text:\\n\")\n","print (description_texts)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Description Text:\n","\n","['Must have a minimum of 5 years‚Äô experience with large-scale data manipulation, analytic tools, and data visualization', 'MS in Applied Mathematics, Statistics, or Computer Science - PhD desired', 'Strong research interest and experience with design of experiments, randomized control trials, and inference, particularly aspects of high throughput testing such as multiple hypothesis testing, sequential testing, robustness, data mining of experiments, ', 'Experience with clickstream tools including Adobe Analytics / Omniture, Google Analytics or Optimizely', 'Masters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable, ', '2+ years of experience with one or more scripting or scientific languages, including Python, R, C++ or Java', 'Common NLP techniques, such as, ', 'Working knowledge of Tableau ‚Äì a plus', 'SQL', 'Experience to analyze data to identify deliverables, gaps, and inconsistencies]\"', 'Retrieve and analyze data from cloud storage', 'Strong analytical and problem solving skills', 'Experience with recommender, or search/ranking systems', 'Qualifications:, ', 'Bachelor‚Äôs degree in Computer Science, Engineering, Statistics or equivalent', 'Leverage experience to apply elements of the Cross-Industry Standard Process for Data Mining (CRISP-DM)', 'Educate and coach both clients and team members on machine learning knowledge, practical mathematical modeling, simulation and optimization in multiple analytics platform, BENEFITS, ibm.com/employment/us/benefits/', 'is deliriously customer-focused', 'Ability to program in an object-oriented language, including Java or C++ and Python', \"As a Solutions Architect with a core focus on Machine Learning (ML), you'll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.Experience with Starcraft II and PySC2, and OpenAI Gym a plus.Additionally, the analyst will be called upon to work directly with school leaders to interpret and act on their data, and to collaborate across all departments within the organization., \", 'Support the public use of available software', ', **US Citizen or Green Card Holder only**]\"', 'Requisition ID: 25608, For Benefits Information, click http://hrweb.mit.edu/benefits, MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.\"[Analyze information from various sources to identify options and communicate recommendations', 'Ability to interpret results and disseminate results to a non-technical audience', 'CODE @ MIT 2016: A/B Testing in a Changing World', 'Use infrastructure as code to build, deploy, operate, and maintain big data analytics infrastructure', 'Experience with data analytics tools and technologies across data (Google Analytics, Omniture, SQL, R, SAS, Python), visualization (Tableau, QlikView, or PowerBI))', '[Position Overview:, \\n\\nThe Climate Corporation‚Äôs mission is to help the world‚Äôs farmers sustainably increase their productivity with digital tools.Cloud Computing Experience (e.g AWS, Google Cloud, Azure)., Experience with AWS and Google Cloud Platform.Reporting to the Director of Data Management and working closely with the numerous stakeholders on both the Program and Development teams, the individual in this role is responsible for understanding our schema inside and out; understanding our existing data; understanding the universe of available data; and ultimately for turning data into reliable, trustworthy stories for all levels within the organization., Reporting (50%):, Produce reports on-demand for C-level, program, and development staff\\nReactively and proactively provide analytics from Google Analytics\\nRepresent reports visually using tools like Google Data Studio or others\\nBe innovative and at-times experimental about sharing data using various clever means to keep the stories interesting\\nSummarize and translate analytics\\nTease out trends in the data that might not be immediately obvious\\nWork with teams in each region to understand unique trends; facilitate sharing of best practices for data use across organization\\nKeep abreast of advances in analytics and data visualization\\nOccasionally attend relevant events, meetups, and conferences\\nBe forward-thinking - critical thinking about data is key![Data Engineer Consultant, ', 'Creating automated anomaly detection systems and constant tracking of its performance', 'NRG is seeking an Analyst, Data Analytics with excellent analytical and interpersonal skills to join our Asset Integration team in NRG‚Äôs Asset-Backed Demand Response (ABDR) business.\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA, ', 'Learn more at zscaler.com or follow us on Twitter @zscaler.Differentiate the offering and the people working on it through the depth and breadth of expert skills', '[Design, construct, install, test and maintain highly scalable data management systems\\nBring structure to large, disparate sources of data ranging from highly structured market data through to fully unstructured text\\nBuild high-performance algorithms, prototypes, predictive models and proof of concepts\\nDesign and structure a research environment flexible enough for creative research whilst stable enough to generate investment ideas\\nIntegrate new data management technologies and software engineering tools into existing structures\\nRecommend ways to improve data reliability, efficiency and quality\\nCollaborate with data analysts and modelers on project goals, Python\\nDatabase architectures and storage structures (Parquet)\\nHadoop-based technologies (Spark, HDFS)\\nAnalytics workbenches (Jupyter, AWS Sagemaker, Domino Data Lab)\\nData mining, statistical analysis and machine learning (Pandas, Keras)\\nDocker containers\\nAWS and Google Cloud, Creative Problem-Solving: Approaching data organization challenges with a clear eye on what is important; employing the right approach/methods to make the maximum use of time and human resources.Experience with using web analytics tools such as Google Analytics.While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \\n\\nFacebook\\n\\nTwitter\\n\\nLinkedIn\\n\\nGoogle\\n\\nMore]', 'Delivering solutions to customers including vision workshop, Proof of Concepts / Proof of Value and production implementation.\"[', 'Provide analysis to Management Team, cross-network meetings, and other collaborative structures', '- Familiarity with web analytics platforms such as Adobe Analytics, Google Analytics, etc., ', '[\\nDesign, develop, automate, monitor and maintain Extract Transform Load (ETL) data movement applications using our preferred ETL tools and techniques.You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.a huge plus., Career Path, We hire Data Engineers at our Associate to Director career stages., Available locations, Arlington; Atlanta; Chicago; Newport Beach, CA; San Luis Obispo, CA; Sydney; Toronto]', 'Be a contributing member of a scrum team that voluntarily accepts work', 'Leverage a variety of tools and approaches to solve complex business objectives, from Statistical Natural Language Processing, Information Retrieval/Extraction, Machine Learning/ Deep Learning, Image Processing, Rules Engines, Knowledge Graphs and Semantic Search', 'A relevant university degree in a quantitative field such as Mathematics, Statistics, Business or Economics., ', 'Demonstrated organizational skills and customer focus]\"', 'Proficient with Excel Tables and Pivot tables', \"For over 17 years, we‚Äôve worked with a simple philosophy: help the connected world move more smoothly, seamlessly and productively.Interact cross-functionally with a wide variety of leaders and teams, and work closely with Engineers and Product Managers to identify opportunities for design and to assess improvements for Google products.We're providing users around the world with great search results every day, but at Google, great just isn't good enough., 6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\", 'Conducting ad hoc deep dives to understand root cause of issues', ']\"', '[We are looking for you - dynamic, best-in-class talent - to join the Initiative team as a Senior Analyst, Analytics.In addition to troubleshooting on the customer side, we work with Sales, Product and Engineering teams within Google to develop better tools and services to improve our products based on the evolving needs of our users.Are you self-motivated and have a passion for analytics, search and display advertising, and advanced campaign management?, \\n\\nPureCars is looking for an analytics-driven Digital Analytics Analyst to plan, implement, and analyze digital marketing campaigns in Google Analytics / Analytics 360 across our customers.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Familiar with popular machine learning and artificial intelligence packages provided by Amazon AWS, Microsoft or Google (such as Azure, Sagemaker, GCP).Hadoop, Spark or Vertica) is required\\n\\nMinimum of 1-2 years implementing solutions in a cloud environment (AWS, Azure or Google) Prior experience mentoring & leading technical teams of junior data scientists where you were responsible for providing project estimates for your work stream and assigning tasks to other team members\\n\\nExcellent written and oral communication skills; must be capable of effectively articulating technical concepts to non-technical audiences\\n\\nMust have an undergraduate (BS) or postgraduate (MS/Ph.D.)Experience with Dataflow, Google PubSub or other queuing software beneficial\\n\\nGood experience of parsing data formats such as XML/JSON and using 3rd party API‚Äôs\\n\\nExperience with Curl / similar beneficial\\n\\nSolid Python programming skills.Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud Platform.Google drive suite services (Google Docs, Google Sheets, etc.).Experience working across functions and influencing teams\\n\\nContinuous improvement mindset\\n\\nExperience with data modeling tools (e.g., SAP PA, Python, R, SAS, MS-Azure)\\n\\nExperience with business intelligence and data visualization tools (such as from Power BI, Google Analytics, Tableau, Domo, Qlikview)\\n\\nData integration experience including extract, transform, load (ETL) processes\\n\\nExperience with databases and complex data queries\\n\\nGreenbelt certified\\n\\nStrong organizational skills\\n\\nSelf-motivated and independent\\n\\nExcellent oral and written communication skills\\n\\nAbility to work in a rapidly changing environment\\n\\n, Location: St. Paul, MN\\n\\n, Sales Territory: N/A\\n\\n, Travel: May include up to 10% domestic/international\\n\\n, Relocation: Is not authorized\\n\\n, Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).]Need to be close to a major airport', 'INFORMS 2015: Can I Take a Peek?Connect with NRG Energy on Facebook and follow us on Twitter @nrgenergy., ', ', Work with clients across many levels: C-Level, Vice-President, IT, Analytics and Business Users', '2+ years of Python experience, Extensive knowledge and understanding of research and analysis', 'At least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling', 'Experience with Google Cloud Platform or Amazon Web Services', 'Experience with pulling reports and data out of DFP', 'Minimum of ten years of experience leading teams of at least ten data scientists, engineers, and other data & analytics professionals, including business development, requirements gathering, people development, and quality management using analytics and software development processes for natural language processing, machine learning on unstructured data, and/or information retrieval; Multidisciplinary backgrounds', '[Dell provides the technology that transforms the way we all work and live.Preferably including DoubleClick, Google Analytics, AdWords and Google Tag-Manager and stream data into environments such as BigQuery\\n\\nResponsible for the management of multiple processes and applications, performance reporting and error checking\\n\\nResponsible for the management of all data created within client applications, the structure of data held and the views of data created\\n\\nResponsible for recommending the correct technologies to be used and in the most cost effective manner\\n\\nResponsible for the design and creation of data led strategies which provide clients with opportunities to leverage their data for greater insight or performance\\n\\nProvide thought leadership with regards to best practice and use of the google cloud platform, \\n\\nBS Degree\\n\\nData Engineering/ BI Development/ Data Warehousing experience.[', '2-3 years of experience in statistical and database languages (e.g., Python, R, advanced SQL)', '[Position Description, Work closely with merchants to define objectives and design appropriate analytics solutionsApply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand consumersDevelop analytical models to drive analytics insightsLead small and participate in large data analytics project teamsParticipate in the continuous improvement of data science and analyticsPresent data insights and recommendations to key stakeholdersProvide and support the implementation of business solutionsModel compliance with company policies and support company mission, values, and standards of ethics and integrity, \\n\\nMinimum Qualifications, \\n\\nBachelor of Science and 5 years data science experience OR Master of Science and 3 years data science experience., \\n\\nAdditional Preferred Qualifications, 5 years‚Äô experience in predictive modeling and large data analysis5 years‚Äô experience with statistical programming languages (for example, R, SAS)5 years‚Äô experience with SQL and relational databases (for example, DB2, Oracle, SQL Server)Expert in any scripting language (Python, PHP, Perl, etc.For more information visit our website and follow GoodData on Twitter and LinkedIn., \\n\\n\\nJOB DESCRIPTION, \\n\\nAs a key member of our Consulting team within Professional Services, The Solutions Engineer will be the data engineer that helps guide our customers through their data product implementation.[Science and Technology on a Mission!, ', 'Qualifications, ', 'Serves as a data steward, ensuring accurate and timely data capture, ', 'Experience with a general-purpose programming language (C++, C#, Java, javascript) is a plus', 'Strong analytical skills with high attention to detail and accuracy', 'Friendly, fun, conscientious, curious and out-of-the box mindset', 'Demonstrated experience with SQL', 'Experience with Analytics across social channels and tactics (i.e., Facebook, Instagram, Twitter, Pinterest, Social Retargeting)', '[EBSCO Information Services (EIS) provides a complete and optimized research solution comprised of e-journals, e-books, and research databases ‚Äî all combined with the most powerful discovery service to support the information needs and maximize the research experience of our end-users.[Define database physical structure and functional capabilities, security, back-up, and recovery specifications.Install database systems by developing flowcharts; applying optimum access techniques; coordinating installation actions; document actions.Map data elements from client systems to target application for ingestion and processingMaintain database performance by identifying and resolving production and application development problems; calculating optimum values for parameters; evaluating, integrating, and installing new releases; completing maintenance; answering user questions., Bachelors degree and 5 years total relevant experience or equivalentAt least 3 years‚Äô experience as Data Analyst.As per TO2 of the contract, one of the discriminating factors for selecting the deployment architecture alternative shall be:Data acquisition, data processing and data lifecycle managementThe contractor should be able understand the selected alternative for data architecture, and help in mapping data from SSA systems to the IBM Counter Fraud Management Solution (ICFM) in the pre-production and production environments.Good communication skills, and problem solving abilities., Do you have what it takes to be mission critical?, ', 'Enjoy getting your hands dirty in day-to-day tasks and working in ambiguous environments', 'Strong oral/written communication skills', 'Interest and ability to make fundamental advances in ML', '[Job Summary, External Role / Title: Big Data Engineer - AWS & Hadoop, Internal Role / Title: Technology Architect, Job ID: 32890BR, Work Locations: Across cities in USA., Wanted: Global Innovators to Help Us Build Tomorrow‚Äôs Enterprise, As a Technology Architect, you will provide top-notch solution design and implementations; assist in defining scope and sizing of work; develop Proof of Concepts, innovate in solution development, solve problems and support Infosys brand., Locations for this position can be most cities in US.Experience in Python, Scala, Java, C, C++ or R is required', 'Review the work of others to provide design or programming recommendations and guide work to completion', ', 2 years of experience as a data analyst or business data analyst', 'Expert-level development experience in Java & Scala', 'Instagram', 'Implement Amazon Cloud (AWS) services for data connectors, ELT, data cleansing, data summarization, and automated data QA', 'Design and analyze A/B user tests and marketplace experiments, often in partnership with product managers', '2+ years of experience with Big Data programming technologies, including Hadoop, Spark, MapReduce, Accumulo, Cassandra, HBase, R, Mahout, Pig, or Hive', \"[Google's projects, like our users, span the globe and require managers to keep the big picture in focus while being able to dive into the unique engineering challenges we face daily.Continuous Monitoring of A/B Tests, \\n\\nCODE @ MIT 2016: A/B Testing in a Changing World, \\n\\nINFORMS 2015: Can I Take a Peek?You are a fast-learner and self-driven performer, who feels comfortable in a start-up environment, where everything needs to be built up from scratch., \\n\\nGoogle's mission is to organize the world's information and make it universally accessible and useful.Mentor others in using analytics tools\\n\\nEvaluate and enhance existing reports and dashboards\\n\\nDefine and document business requirements for new metrics and reports\\n\\nEnsure accuracy and integrity of data and reporting applications through detailed analysis, efficient coding, writing clear documentation processes, identifying and resolving problems as they arise\\n\\nReview and write complex SQL queries and develop stored procedures and functions in SQL\\n\\nPerform ongoing monitoring and refinement of reports and BI solutions\\n\\nAbility to work effectively within competing deadlines with minimal guidance\\n\\nInteract professionally and collaborate with a diverse group including executives, managers, and subject matter experts, 4 or more years of quality experience using SQL Server, SSRS, SSAS, Azure, and SSIS\\n\\nStrong knowledge of relational and multi-dimensional database architecture\\n\\nExperience creating and maintaining documentation following standard creation and change control processes\\n\\nProficient oral and written communication skills\\n\\nAbility to lead a meeting and present to small audiences\\n\\nExperience integrating Power BI into web applications]\", ', 3-5 years of data science/software development experience', ', Twitter has a very data-driven culture and experimentation is at the center of product decisions.Other duties as assigned., Minimum Qualifications:', 'Experience producing both tactical and strategic analytic products and briefing senior level managers', 'Understanding user behavior with great visualization and analysis tools, ', 'Support the operationalizing of robust data quality assurance within data infrastructure', 'Coordinate with backend engineering team to analyze data in order to improve the quality and consistency of our data', 'Self-directed, detail & team oriented with highly developed problem solving and analytical skills', 'Strong research interest and experience with design of experiments, randomized control trials, and inference, particularly aspects of high throughput testing such as multiple hypothesis testing, sequential testing, robustness, data mining of experiments', 'Some of the teams‚Äô projects include:, ', 'ESSENTIAL JOB FUNCTIONS:, ', 'Analyze and interpret data into thoughtful market strategy', 'Data Warehousing: BigQuery, Google Storage', 'At least 2 years of hands-on experience using complex machine learning methods and algorithms such neural net, deep learning and collaborative filtering', 'Proficient knowledge of Power Pivot, Power Query, and Power', ', Qualifications:', 'Experience with Vertica, Splunk and Hadoop, an asset.You listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation.thought leadership, articles, talks, competitions, certifications)', 'Analyzes large data sets and use programming languages such as Python, R, IBM SPSS Modeler to develop statistical and optimization models to drive business solutions.Knowledge of distributed systems as it pertains to data storage and computing', \"[gTech‚Äôs Product and Tools Operations team (gPTO) leverages deep user, operational, and technical insights to innovate Google's Ads products into customer experiences that are so intuitive (or automated) that they require no support at all.Google Analytics), data visualization tools (i.e.PostgreSQL, MongoDB)\\n\\nAptitude for problem solving\\n\\nStrong quantitative analysis skills\\n\\nExcellent written and spoken communication skills\\n\\nGood presentation skills\\n\\nTrack record of learning new skills and putting them to use immediately\\n\\nHunger for continued learning\\n\\nSense of ownership and pride in your performance and that of the company\\n\\n, Things That Will Impress Us\\n\\n, Experience with eCommerce, Magento Commerce, and/or Magento BI\\n\\nKnowledge of Google Analytics\\n\\nExperience with data analysis\\n\\nCustomer-facing experience\\n\\n, At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists .Deep product knowledge and understanding of Microsoft Azure, AWS, Google Cloud., \\nGreat team: Founded by successful veterans of Yahoo, Zynga, and eBay\\nHuge market: Disrupting a massive, growing $35+ billion market for CRMs\\nFunding: Raised $53M for our Series C from top-tier investors like Norwest Venture Partners\\nOur CRM has been awarded: G2Crowd #1 in Customer Satisfaction Summer Rankings, Google Best New Tech Partner of the Year\\nImpact: A fun, transparent, and exciting start-up culture that empowers its people to make a huge impact.You are a communicative person that values building strong relationships with colleagues and multiple stakeholders, and have the ability to explain complex topics in simple terms., Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\\nData visualization (such as Tableau, Qlik, D3, ggplot)\\nExperience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google‚Äôs Cloud Platform\\nExperience training and tuning statistical and machine learning models with libraries/frameworks such as sci-kit learn, tensorflow, pytorch or similar\\nFamiliarity with experimentation and A/B testing\\n]\", 'Experience building tools and automated processes to extract, clean, and distill data in a procedural language of your choice such as Python, Julia or R', ', REQUIRED EDUCATION AND EXPERIENCE:, ', 'Experience working with at least one of the following technologies (Spark, Kafka, Akka)', 'Working knowledge of basic financial concepts: P&L, margins, pricing, etc.\"[', ', Experience with QA/NLP', 'Expertise in statistical packages such as SPSS, SAS, or R', \", THE SIMONS FOUNDATION'S DIVERSITY COMMITMENT\", 'BA or BS degree in Statistics, Mathematics, CS, or EE', 'Outstanding organizational skills and dedication to quality and integrity', 'Learning on the Fly - Learns quickly when facing new problems, relentless learner, open to change, improves, enjoys challenges and finding solutions', 'PhD in Statistics or a closely related field, or 5+ years of equivalent industry experience in A/B testing and digital experimentation', 'detail oriented', 'Explore correlation and regression models in data sets', 'PhD or MS in quantitative discipline - Statistics, Physics, Math, Engineering, Economics, Econometrics, Data Science, Computer Science, Operations Research ‚Äì highly preferred', 'Demonstrated ability to coach and teach others', 'Experience with statistical analysis, modeling and simulation', 'Working with evolving Hadoop and Spark technologies', 'Probably at least one additional programming language / computational programming environment; e.g., R, Matlab, C++, etc', 'Writing client-facing reports and contributing to proposal work', 'access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', '1+ year of entry-level experience or academic training in data science, advanced analytics, and/or statistical modeling (regression, ANOVA, validation techniques, etc.)\"[', 'Data-informed decision making with rigorous split testing.How will Google Cloud and Atos‚Äô global partnership work together to deliver secure hybrid Cloud, machine learning, and collaboration solutions to the enterprise?You will be working with internal customers in all departments (marketing, finance, operations and customer service) to dig into data insights and develop operation and business metrics using a wide range of tools (Redshift, Looker, Tableau, etc)., ', \", Master's degree in Analytics, Mathematics, Physics, Computer and Information Science, or Engineering\", 'Big data technologies such as Hive, Hadoop, MapReduce, PIG, Google BigQuery, Oozie, etc.Experience with Java, SQL and NoSQL databases, data analytics (such as pattern recognition & change detection) is highly desired., ', 'High attention to detail and ability to manage multiple, competing priorities simultaneously', '[Data Scientist - Defense & Intelligence, \\n\\nElder Research Inc. is a recognized leader in predictive analytics and data science.with Flask\\n\\nExperience in test automation and ensuring data quality across multiple datasets used for analytical purposes\\n\\nExperience with Lambda Architecture or other Big Data architectural best practices\\n\\nA graduate degree in Computer Science or similar discipline\\n\\nCommit code to open source projects\\n\\nExperience with test automation and continuous delivery, \\n\\nExperience with Tableau\\n\\nExperience with Machine Learning\\n\\nHave worked with Data Scientists]', '5 - 7 years in Data Visualization', 'Identify, analyze, and interpret trends and correlation in large data sets', 'Excellent verbal, written, and interpersonal communication skills', 'Support and clarify direction in times of change to minimize confusion or disruption to business processes', 'Plan and manage projects; anticipate and mitigate risk, document decisions, manage change, ', '[Data Scientist - Marketing Analytics, \\n\\nSan Francisco, CA, \\n\\n$130,000-$150,000, \\n\\nTHE COMPANY, \\n\\nThis emerging Direct to Consumer eCommerce brand is looking to add a Data Scientist (Marketing Analytics focused) to the team.Experience using Google Analytics, Google Tag Manager, and implementing scripts\\n\\n\\nExperience with utilizing and working with various data visualization tools\\n\\n\\nExperience with various media api platforms such as Google Analytics/Adwords, Facebook, Linkedin etc\\n\\n\\nExperience with design and development of reporting tools and\\n\\n\\nExperience developing various forecasting and analytical models utilizing tools such as Excel\\n\\n\\nExperience managing out-sourced vendors\\n, 4-year degree from an accredited institution in Marketing or equivalent discipline OR appropriate combination of experience and education, \\n\\nMinimum of 3 years‚Äô experience serving in a data analyst capacity in marketing, finance, mathematics etc., \\n\\nExperience using Google Analytics, Google Tag Manager, and implementing scripts, \\n\\nExperience with utilizing and working with various data visualization tools, \\n\\nExperience with various media api platforms such as Google Analytics/Adwords, Facebook, Linkedin etc, \\n\\nExperience with design and development of reporting tools and, \\n\\nExperience developing various forecasting and analytical models utilizing tools such as Excel, \\n\\nExperience managing out-sourced vendors, Supervisory Responsibilities, None., Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.Hadoop, Cloudera, Horton Works, IBM Insights, MongoDB, Spark, Storm, HDFS, HBase, Accumulo, HIVE, PIG, SQL, Cassandra, Kafka and equivalents.Knowledge of server-less infrastructure beneficial\\n\\nAbility to scope a project based on a technical brief and work with the DevOps and QA teams to provide a detailed project plan including:, \\n\\nData Flow Diagrams for process flow\\n\\nDatabase Schemas & Normalisation\\n\\nRecommended software / plugins / architecture\\n\\nScalable environment architecture suggestions\\n\\nHosting, storage, load balancing and caching suggestions\\n\\nPerformance considerations\\n\\nSecurity considerations\\n\\nAssumptions & Exclusions\\n\\nA complete and accurate estimate for the project, \\n\\nAbility to assess new business and respond with a full list of targeted questions to ensure accurate estimates are created\\n\\nAbility to research solutions to technical problems\\n\\nExperience scheduling/automating scripts\\n\\nExperience with streaming data beneficial\\n\\nExperience on Linux command line and Bash scripting\\n\\nExperience with Git/GitHub\\n\\nExperience with Amazon/Google Cloud services.Requirements:, Expertise in Deep Learning and NLP\\n\\nExperience with software engineering best practices\\n\\nMS or PhD in machine learning or equivalent work experience, Desired:, Experience using big data platforms such as Spark or Hadoop, Experience using big data platforms such as Spark or Hadoop]', \"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.Cortex is the central ML/AI team with the goal to build an ML platform and provide deep ML expertise to support our internal customers, while advancing ML inside & outside Twitter., \\n\\nIn particular, the ML Extended Environment team (MLX) in Cortex is focused on unifying & advancing recommendation systems.Work effectively with clients to align Google Marketing Platform attribution and analytic solutions with key organizational challenges and develop value-based roadmaps to solve client business issues on a continuous and repeatable basis.We are looking for sharp, disciplined, and self-motivated individuals who have a passion for utilizing the cloud solutions from Amazon Web Services, Microsoft Azure, and Google Cloud Platform to solve real business problems for our customers., \\n\\nResponsibilities:, \\n\\nWork as part of a team, to design and develop cloud data solutions.[Raytheon is an Equal Opportunity/Affirmative Action employer., QUALIFICATIONS:\\n\\n, Advanced Degree (Ph.D. preferred) with a focus on Analytics, Statistical Sciences, Operations Research, Economics, Finance or a related Business quantitative discipline\\n\\n5+ years of real world analytical solution building experience\\n\\nData mining technical knowledge and skills including: decision trees, multivariate analysis, segmentation modeling, factor analysis, regression analysis, forecasting, and machine learning\\n\\nExpertise in R, SAS Enterprise Miner, or IBM SPSS Modeler or other analytical software\\n\\nIntellectual curiosity and commitment to teaching data analytics concepts to others\\n\\nExperience in leading and developing data science teams a plus\\n\\n, Qualifications:\\n\\n, Company Overview:\\n\\n, Our success comes from strategically placing you in the most suitable role.Familiarity with Big Data tools such as Splunk, Hadoop, Spark, etc.[Overall 8+ Years of experience in IT industryAtleast 4 years experience in SplunkVery good knowledge and working experience in Big Data Hadoop / No SQL3+ years' experience with Splunk in developing text mining use casesIntegrating Splunk with Big Data Hadoop for log storageIntegration with variety of external data sourcesThe ability to design Splunk reports and dashboards using complex data elementsFamiliarity of a Web Based application environmentLinux shell scripting/Regex experience would be highly preferableSplunk certifications is a plus.]Improve the data stack using the latest and greatest innovations in Google's internal and external Google Cloud Platform stack.Experience writing and executing complex SQL queries\\n\\nExperience managing and optimizing SQL databases\\n\\nExperience with development in one or more of the following Python, R, Scala, SQL\\n\\nExperience with data processing frameworks and data warehouses such as Hadoop, Spark, Redshift\\n\\n\\nBonus points for:\\n\\nExperience working with healthcare data\\n\\nExperience with Looker, Tableau and other BI tools\\n\\nExperience with DataBricks analysis platform\\n\\nExperience with building and operating data pipelines\\n\\nExperience with machine learning]\", 'Knowledge of clinical data standards and ontologies including ICD, SNOMED, UMLS, etc.Identify opportunities to use data to drive enhanced business decision making and promote a data-driven culture', ', Alternate Location: United States : Baytown, Texas || United States : Clinton, New Jersey || United States : Hugoton, Kansas, ExxonMobil is an Equal Opportunity Employer.The Transformation team helps the CSG leadership to define the near- and long-term strategy for Dell‚Äôs worldwide PC business., ', 'Publish and maintain a Data Dictionary, ', 'Experience with Kafka and Yarn or Mesos', 'Experience with Spark, Hive and Kafka', 'Serve as POC to partner with Ops & CS teams to review service issues and customer make good programs', 'Self-starter with a bias for action; can make things happen in a fast-paced, dynamic environment', '3+ years of experience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services', 'Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly; Work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)', 'Bachelor‚Äôs degree, related advanced degree a plus', 'Relevant professional experience with an emphasis on Retail or Digital Commerce Business', 'Excellent communication and presentation skills to senior leadership', '- Demonstrated record of 1-3 years in customer data, analytics, and reporting function with emphasis on marketing, business intelligence, and data mining, ', 'Experience working in the Salesforce environment, understanding business products, journey flow and terminology', 'Monitor, validate and maintain data pipelines to ensure consistent performance', 'Create a robust system of revenue reporting', 'Bayesian vs Frequentist Statistics https://blog.optimizely.com/2015/03/04/bayesian-vs-frequentist-statistics/, ', ', ExxonMobil is an Equal Opportunity Employer.Maintenance and improvement of created platforms and/or models', 'Experience with designing and setting up relational databases', ', CV', 'Ensure continuous improvement in quality of data and deliverables, ', 'Experience with source control and dependency management software, including Git or Maven', 'Experience implementing ETL processes in Big Data analytical solutions using a variety of sources (Text, databases, JSON, XML, etc..)', 'The ability to work collaboratively acting as a subject matter expert within a team environment to help define and meet measurement criteria and goals', 'In-depth knowledge of vendor software integration and interaction patterns', \"[Located in Pleasanton, this predictive analytics start-up that uses machine learning models and their client's CRM data to provide sales and marketing insights is looking for a hands-on contractor with expertise in Hadoop and Java to join their team for up to 18 months., In this role, you'll be working very hands-on with both the Hadoop and Spark ecosystems, Java, and Google's Cloud Platform to support the big name clients of this company.[Responsible for following the defined agile development processes including attending the required meetings with contribution towards the successful completion of the sprints..Collaborates with product management and customer delivery teams to ensure product requirements are clear on what customers expect and what the delivery teams should set as the right expectations with the customers.Communicate rigorously within the squad on goals, ongoing progress, milestones, and any issues.Support and follow the overall product architects, delivery architects, to drive and establish the architecture decisions and designs for the product.Leverage the DevOps team to ensure product can be automatically built, deployed, and tested using a CI/CD pipelines across all of the release cycles from dev to production.Mentor and develop required skills of other junior product developers., Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.Experience applying machine learning and predictive analytic techniques to large, complex data sets specializing in event data processingExperience with Machine Learning frameworksExpert in coding hands on in Python and RExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processingProven ability to develop resilient code (best practice error handling) that performs and scales for large enterprise needsDeep expertise in developing REST-based API's (json/yaml), Micro-services with RDBMS and NoSQLBachelor's degree in Computer Science or equivalent with specialization Machine Learning, Understanding of Public and Private Cloud Provider services, usage and delivery paradigmsWorking knowledge of cloud technologies and architectures, including Virtualization, APIs, Micro-services and Containers.5+ years experience delivering enterprise-class cognitive applications2+ years experience developing in Python and modern web-based languagesExcellent verbal and written communication abilities: must effectively communicate with technical and non-technical teamsHigh attention to detail and proven track record in taking ownership, driving results and moving with speed to implement ideas in a fast-paced online environmentWillingness to roll up your sleeves and do whatever is necessaryAbility to process and manage multiple priorities, Ph.D or Masters in Computer Science/Artificial Intelligence with specialization in Machine Learning.Knowledge of IT Service Management and IT Operations Management processes, tools and technologiesKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment modelsExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storageExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.,  Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.If you‚Äôre searching for a company that‚Äôs dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment ‚Äì apply now., \", ', Lead strategy discussions and help to design and develop a solution that meets clients goals and outcomes', 'The ideal candidate will demonstrate:, ', 'What you‚Äôll do:, ', 'Batch and Stream Processing with Beam, Data Bricks, Dataflow, Kinesis, BigTable', 'At least 5 years of experience in project management for external consulting engagements', '[The Curbside Engineering team is looking for highly motivated engineers to help build the next generation mobile commerce platform., \\n\\nAs part of a dynamic team environment you will:, Architect and develop processing pipelines that convert data to useful information consumed by internal and external processesDevelop web services that make data available in real-time for in-product applicationsBuild monitoring and debugging tools to analyze the data pipelinesDesign data schemas and manage operational scalability of data modelsCollaborate with product to build new features and infrastructureMentor junior engineers and provide technical leadership within the development teamParticipate in code reviews and write unit, integration and load tests as necessary, \\n\\nRequirements, Demonstrated proficiency in Python, Clojure, Java or GoHands-on experience with Big Data technologies (e.g Hadoop, Hive, HBase, Spark, Kafka, Storm, Cassandra, Columnar Databases or Graph Databases)Track record working with data from multiple sources ‚Äì willingness to dig-in and understand the data and to leverage creative thinking to deliver resultsStrong database fundamentals including SQL, performance and schema designExperience with cloud computing platforms like AWS, Google Cloud or Microsoft AzureKnowledge of the tooling for deployment, monitoring and site reliabilityAbility to work well in a team environment and be able to effectively drive cross-team solutions that have complex dependencies and requirementsExcellent communication and problem solving skills, MS or BS in Computer Science or related technical field or equivalent practical experience5+ years of industry experience working on building scalable ETL pipelines, data warehousing and schema modeling, \\n\\nPreferred Qualifications, Functional programming experience, All your information will be kept confidential according to EEO guidelines.]The types of things you‚Äôll do:', 'Provide access to data through dashboards to empower your team, and look for opportunity to automate insights through alerting and anomaly detection, ', ', Data Engineering/Data Wrangling', 'Expert proficiency in python and web analytics tools including Omniture and Google Analytics', 'Database Testing', '2+ years of design, implementation and governance experience with Artificial Intelligence, Natural Language Processing or Machine Learning architecture', 'Ability to work closely with people of various quantitative and qualitative backgrounds', 'Lawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE).[Engages with Google fellows, local Goodwill¬Æ team members, GII colleagues and other subject matter experts to coordinate implementation of the Google-supported Goodwill Impact Data Collaboration (IDC).Facilitates work on mission impact systems from implementation and enhancement.Prepares effective oral and written communications and materials to support alignment, collaboration and learning.Provides technical training to internal project team members and Goodwill member users.]degree in Computer Science, Electrical/Chemical/Mechanical Engineering, Applied Mathematics, Statistics or other related scientific discipline', 'Bring new and innovative ideas to the table to help us become the best in the world at sharing insights with our clients; source new business intelligence tools like Tableau, Looker, Periscope, etc.Cloud: Google Cloud(BigQuery/ML Engine/Google Dataflow/Google Dataproc, etc.)Statistics (Bayesian methods, experimental design, causal inference)', ', ', '3+ years of experience or equivalent in conducting quantitative research, analysis and modeling, preferably at a start-up, ', 'Self-motivated and directed fast learner', '[\\nEstablish Life Science Analytics prototype platform ‚Äì Guiding the effort to produce a first prototype of the life sciences Analytics platform, in collaboration with other members of the team (biostatisticians and clinical data analysts) developing and embedding the first data science packages leveraging HealthCatalyst data for Life Science Analytics into a more generalizable framework that can be re-utilized and re-deployed to solve other similar problems, leveraging Google Datalab platform/Jupyter Notebooks.You have a deep industry understanding of the digital advertising industry, Google‚Äôs ad product suite, and a passion for using data in storytelling., Google‚Äôs Global Partnerships team works with a wide range of partners to bring the best of Google to power their business.Experience developing scalable and automated data pipelines\\nMachine learning experience in Python and/or R\\nExperience with one or more cloud environments (AWS, Google Cloud Platform, Azure or other platforms)\\nPractical knowledge applying analytical techniques such as time series regression, decision trees, segmentation, clustering, response modeling and factor analysis to real-world data.Strong autonomy and team player, \\n\\nPreferred Qualifications, \\n\\nExperience with Google Cloud Platform (such as BigQuery, Compute Engine, Data Flow, ..)\\n\\nExperience with relational (SQL) and NoSQL Databases\\n\\nExperience with developing products deployed to production\\n\\nExperience in developing Search, Recommendation, Visual and/or Language applications, 50%-Design and develop algorithms and models to use against large datasets to create business insights\\n\\n20%-Establish scalable, efficient processes for large scale data analyses, model development and model implementation\\n\\n20%-Present analysis and resulting recommendations to senior management; Leverage data to present a compelling business case to optimize investments and operations\\n\\n10%-Communicate and educate technical and non-technical employees on analytics and data-driven decision making, This position reports to Director of Data Science, or Sr.Research mindset with bias towards action - able to structure a project from idea to experimentation to prototype to implementation\\n\\nIndependence, great communication, and amazing follow-through - you aggressively tackle your work and love the responsibility of being individually empowered, \\n\\nBackground in Machine Learning, Statistics, Operations Research, Operations Management, Econometrics, or similar\\n\\nExperience in software engineering]', 'PhD in Statistics or a closely related field, or 5+ years of equivalent industry experience in A/B testing and digital experimentation, ', 'Knowledge of relevant statistical measures, including confidence intervals, significance of error measurements, and development and evaluation data sets', 'Partner with your product and development peers to develop processes to improve audience data capture and improve data collection capabilities', 'Solid training in probability and statistics', '[\\nExperience with machine learning algorithms and development on Cloud platforms\\nExperience with Python, R, and Java\\nAbility to manipulate, integrate, and analyze large and complex data sets using SQL and no-SQL database platforms\\nAbility to provide non-technical users with data-driven tools for implementing machine learning into workflows, as needed\\nBA or BS degree\\n, \\nExperience with health data sets, including electronic health records, clinical data, and claims data a plus\\nExperience with developing machine learning, deep learning or natural language processing unstructured text data\\nExperience with leading technical project teams\\nMA or MS degree\\n]', '[Providing actionable reporting on how our users are engaging with our productsBringing data thinking to our projects by attaching metrics to our processesMaintaining, improving, and scaling our internal processes and learnings around data thinking, collecting and, reporting, Measurement Strategy: Define problems and solutions and attach metrics (KPIs) or other views of data that reflect how those problems can be being solvedSpecifications: Designing the specification for event tags (Segment.io, Mixpanel, Google Analytics) fired from the front end/back end, or queries that can enable those metrics or views of data to be calculatedReporting: Design and build a dashboard that displays those metrics and continues to iterate through ad-hoc reporting and meetings with stakeholders, Consume and report on external data sets, primarily logs (i.e., Sumo Logic)Consult and build business intelligence dashboards that are part of our products shipped to customers (Birst or Infor Business Intelligence), and work with the team to build a corporate-wide design system for these dashboardsAssist in non-quant researchContribute to storytelling, UX and product strategy, \\n\\nWe are looking for an engineer or data wizard first, a data analyst second, and designer as a value-add., Bachelor‚Äôs degree in Engineering or computer scienceAbility to rapidly execute against building data models and dashboards.Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc...\\n, Lead the design, implementation, and operation of a state-of-the-art ‚Äúbig data‚Äù analytics approach which is scalable and innovative in the way it extracts, manages and analyzes data\\nRoughly 65% thought leadership and management and 35% hands-on working with data\\nAssemble the right team, ask the right questions, and avoid mistakes that could derail a data science project.Follow us on LinkedIn, Youtube and Twitter.]Work with Business SMEs and Analysts to understand functional requirements and interact with other cross-functional teams to support their work to architect, design, develop, and test the solution., Ability to work seamlessly with complex data models and data relationships', 'Occasional travel to other office locations may be necessary', '5 - 7 years in Large Datasets', 'Computational Neuroscience modeling experiences', 'Experience with one or more data storage and manipulation technology:Hadoop, Azure Data Lake', 'Learn more about Splunk careers and how you can become a part of our journey!, ', ', Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.Lab employees and external candidates may be considered for these positions., About Us, ', 'Experience using one or more of the following software packages: scikit-learn, numpy, pandas, jupyter, matplotlib, scipy, nltk, spacy, keras, tensorflow', \"[Data Scientist - 23258, \\n\\nData Science - USA Tampa, Florida, \\n\\nThe Nielsen Company is the largest global measurement company in the world with unique measurement technologies, assets, and data that make it one of the most interesting and challenging places for a measurement or data scientist to work.And our teams are dedicated to helping our customers ‚Äî developers, small and large businesses, educational institutions and government agencies ‚Äî see the benefits of our technology come to life., Facilitate deep technical discussions with customers, partners, and Googlers.Employees have the opportunity to gain invaluable experience and make a significant impact on the business outcomes of our clients and our company., \\n\\nOver the past years, Maven Wave has received the following awards and accolades:, \\n\\nGoogle Cloud North America Services Partner of the Year, 2018\\n\\n#21 Best Workplaces in Chicago, FORTUNE, 2018\\n\\nGreat Place To Work Certification, Great Place to Work, 2017 & 2018\\n\\nFast Fifty, Crain's Chicago Business, 2014, 2015, 2016, 2017, 2018\\n\\n101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR), 2014, 2015, 2016, 2017, 2018\\n\\nTop Google Cloud Partner, Clutch, 2017\\n\\nFastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine, 2016, 2017\\n\\nTop IT Services Companies, Clutch, 2015\\n\\nGoogle Global Rising Star Partner of the Year 2015, \\n\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.You'll continuously explore and experiment with our advanced suite of products, partner tools, and third party applications to build and deploy cloud solutions that address customer use cases, all the while sharing valuable feedback with our product teams as you develop complex architectures, standard methodologies, and key strategies., \\n\\nGoogle Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.You will have the opportunity to analyze large datasets in a collaborative team work environment providing daily challenges and ongoing learning., Hallmark‚Äôs Data Scientist perform data analyses to derive insight, patterns and correlations from Hallmark's big data that includes vast amounts of consumer data, store data, product sales data, and other relevant data.Led by scientific experts from MIT, Harvard, Mayo Clinic and UCSD, and successful drug developers, informaticians, and company builders, Engine is working on multiple programs and therapeutic areas and growing rapidly across US and Asia., The Bioinformatics & Data Scientist will analyze multi-dimensional biological and genomics data, enhance algorithms and develop novel methods for the utilization in Engine‚Äôs analytics platform that combines advanced system biology analytics with genomics data science and machine learning for accelerated drug discovery and biomarker identification.Experience with Google Suite (Docs, Sheets, Slides, etc.We also implement metrics to track the impact of new product experiments and more generally find ways to make very large scale data approachable to guide our decisions., Twitter has very large and complex datasets.Experience with integration, and analysis of data from multiple sources using tools like: Hive, Impala, Rstudio, Splunk, etc.[At Google, we work at lightning speed.Then I have the right opportunity for you!, \", ', Experience', 'The Data Science team at Twitter is at the intersection of all this data and strives to make it actionable to all business units around Twitter.Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, 3+ years of mathematical predictive algorithm development utilizing large-scale multivariate datasets in a business environment', 'Experience and/or interest in designing and building Artificial intelligence solutions using third party API‚Äôs such as Microsoft Azure, Amazon Machine Learning, Google ML, IBM Watson etc', 'you grok data and revel in analyzing it', 'Proficiency in Adobe Omniture, Conviva, Microstrategy, and other analytics tools preferred', '3 - 5 years in Predictive Modeling', \"[\\nBachelors' degree in relevant field\\n3+ years of experience with data analysis and data interpretation with Army and/or DOD data sources\\nApplicant must be a U.S. citizen and have an active SECRET security clearance\\n, \\nExperience with Oracle and Microsoft Suite of software applications, highly desired\\nProject Management Institute Professional (PMP), a plus\\n]\", 'Exposure to cloud based technologies like Google Cloud Platform, AWS., A few reasons why this is the #BestJobEver, ', 'Support schools and network leaders in launching tools and analyzing data within tools to make evidence-based decisions', 'Assist in reporting and ad-hoc analysis of data with performance teams', 'Ability to code from Python/R to Java/Scala/Spark', 'Ability to be client facing (strong written and oral communication skills)', 'Experience writing automation code in Python/R/AppScripts etc., ', 'is self-driven, actively looks for ways to contribute, and knows how to get things done', 'A strong understanding of advanced analytic techniques, particularly related to measuring consumer & business outcomes in a digital commerce setting', 'Experience in reporting on customer insights and LTV analysis, ', '2 + years of experience using quantitative machine learning techniques', 'MA or MS degree a plus', 'has great communication and reasoning skills, including the ability to make a strong case for technology choices, Basic Qualifications:, Bachelor‚Äôs degree or Military ExperienceAt least 1+ years‚Äô experience with leading big data technologies such as Spark, Cassandra, Hadoop, HDFS, PostgreSQL, Redshift, and MongoDBAt least 2 years of professional experience with data engineering concepts, ', '[Serves as site coordinator for one or more of the following database tools:\\n\\nTruven/IBM-Watson Care Discovery Advantage Solution\\n\\n3M Encompass/360 MD analytics\\nClinovations HCC/HHS Program\\n\\nPEPPERreports\\nExecutive Health Resources Exchange/OptumInsights\\nVizient HIIN\\n\\nEpic electronic health record database\\nCollects and reports data for organizational clinical performance improvement initiatives\\nObtains listing of patients for clinical analysis, reviews charts, and reports data trends and analysis\\nPerforms download of reports and site-specific outcomes\\nCoordinates with other organizational analysts and CPSL Programs Managers to insure consistency between database tools, to the extent that definition and exclusion variations allow\\nPrepares and distributes reports as directed utilizing various software presentation tools\\nEducates physicians and other staff on current and updated database definitions\\nServes as a resource person in the development, maintenance, and troubleshooting of assigned database initiatives\\nPerforms data collection, analysis, and presentation, as directed, on various performance improvement activities within the CPSL\\nPerforms analysis of ‚Äúoutliers‚Äù as directed\\nAttends clinical meetings as directed\\nParticipates in regular phone/webex conferences to keep up-to-date on issues\\nUpdates CPSL dashboard for assigned database functions\\nSupports respective managers for designated program development accreditation responsibilities\\n, Truven/IBM-Watson Care Discovery Advantage Solution\\n\\n3M Encompass/360 MD analytics\\nClinovations HCC/HHS Program\\n\\nPEPPERreports\\nExecutive Health Resources Exchange/OptumInsights\\nVizient HIIN\\n\\nEpic electronic health record database\\n]', 'Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.Expert in Google Analytics and Tag Manager: you‚Äôll need to be able to manage, maintain and advance the analytics stack, and also be able to turn requests from marketing or product office into actionable implementation plans, then manage the process and valide the implementation.Eligible candidates are recent PhDs within five years of the month of the degree award at time of hire date., About Us, ', '[Qualys is seeking a Data Analyst with experience in financial systems and data management and interest in helping automate reporting and financial analysis.Self-motivated, work well both independently and as part of an agile team., \\n\\nPreferred Experience:, \\n\\nMaster‚Äôs degree required in a quantitative discipline such as Mathematics, Statistics, Economics, Engineering, Operations Research, Computer Science\\n\\nPreferred experience with console development for current platforms\\n\\nHave a clear understanding of Big Data tools mainly being Splunk, Hadoop, and Spark\\n\\nExperience with Visualization tools and platforms., \\n\\nCrystal Dynamics is an EOE and M/F/D/V employer.]Through analyzing large volume of data both from Twitter users and Twitter advertisers, you‚Äôll help Twitter grow revenue globally and in scale., ', 'All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check.Transition data storage to Cloud environments (Google or Azure).Deep understanding of relational database technologies and database development techniques, Experience working in a version-controlled (Git) development environment is strongly preferred', 'Must have an undergraduate (BS) or postgraduate (MS/Ph.D.)Fluent in multiple technologies such as with Python, Azure ML, IBM SPSS Modeler, R or comparable technologies required.Our vibrant and diverse international community of nearly 250 publishing brands and imprints include Ballantine Bantam Dell, Berkley, Clarkson Potter, Crown, DK, Doubleday, Dutton, Grosset & Dunlap, Little Golden Books, Knopf, Modern Library, Pantheon, Penguin Books, Penguin Press, Penguin Random House Audio, Penguin Young Readers, Portfolio, Puffin, Putnam, Random House, Random House Children‚Äôs Books, Riverhead, Ten Speed Press, Viking, and Vintage, among others.Work with data and analytics experts to strive for greater functionality in our data systems., ', 'SAS, R, Python, SPSS or related, Referral Bonus Level: 3]\"', 'Experience with managing, cleaning and normalizing large, multi-dimensional datasets', \"[You yearn to be part of cutting edge, high profile projects and are motivated by delivering world-class solutions on an aggressive scheduleYou are not intimidated by challenges, thrive under pressure, passionate about your craft, and focused on delivering exceptional resultsYou love to learn new technologies and mentor junior analysts to raise the bar on your teamPassionate about intuitive and engaging user interfaces, as well as new/emerging concepts and techniques, Develop sustainable data driven solutions with new data technologies to meet the needs of our organization and business customersBuild robust end-to-end systems with an eye on the long term maintenance and support of the applicationLeverage reusable code modules to solve problems across the team and organizationHandle multiple functions / roles for the projects / Agile teamsWork with established standards across the team and organizationUnderstand complex multi-tier, multi-platform systemsContribute to building a framework of a significant complexityWork with internal team of data engineers (both full-time associates and/or third party resources), At least 5 years coding, or at least 5 years experience in data warehousing or at least 5 years in unstructured data environmentsAt least 2 years experience in Azure cloud technologies AzureAt least 2 years experience in big data technologies (Cassandra, , HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, Zookeeper, or similar)2+ years of experience with Agile engineering practices\\n, 1+ years experience in Azure cloud technologies AWS, MapR, Cloudera, Google Cloud5+ years experience with NoSQL implementation (Mongo, Cassandra, etc.The Google AI Residency Program will have 3 start dates over the course of 5 months, from June to October 2019.Ability to accurately forecast volume and/or track and complete the specific project to meaningful deadlines\\n, Web analytics tool (Adobe Site Catalyst or Google 360 Premium),\\nCRM platform\\nLoyalty platform\\nA/B testing platform\\nEmail marketing platform (SalesForce Marketing Cloud is preferable)\\n, CAREER DEVELOPMENT\\n\\n, The role can advance depending on the individual‚Äôs passions and interests.Atos operates under the brands Atos, Atos Consulting, Atos Worldgrid, Bull, Canopy, Unify and Worldline., \\n\\nPlease follow this link, Atos.net page, to learn more about the new Global Partnership with Google Cloud and Atos!, Responsibilities Include:, \\n\\nProvide creative solutions to marketplace problems using data driven approach, both in short and long term\\n\\nDeliver robust and scalable solutions to improve Users' and advertisers' experience on Bing\\n\\nWork closely with various feature teams, evaluating the feature impact on Bing marketplace\\n\\nBe a ‚ÄòGo-To‚Äô person for any data analytical needs ranging from data extraction/manipulations, long term trend analysis, statistical analysis and Machine learning models\\n\\nUse hypothesis driven approach to answer analytical questions, provide recommendations to the leadership teams, \\n\\nShare standard methodologies and documentation across teams, \\n\\nBasic Qualifications:,  Bachelor‚Äôs degree or above in a Computer science, STEM, related engineering or Business-related field with strong emphasis on data analytics 2+ years of experience in Data mining and qualitative analytics Curious mind and willing to tackle complex business problems Understanding of Machine learning & statistical analytical tools, \\n\\nPreferred skills:,  Be Skillful at C/C++/C#, SQL programming, python, R Have a strong interest in online advertising products business models and system architectures Experience in online Ad space is a plus]\", 'Experience with various data sources (on-premises vs. cloud; database vs. files)', 'Must be a self-starter with excellent oral and communication skills.The team‚Äôs goal is to continuously improve the company‚Äôs marketplace and shopping efficiencies., ', 'Familiar with spreadsheet tools such as Excel, Google Sheets', 'Exceptional communication and presentation skills are a requirement', ', MINIMUM QUALIFICATIONS', 'Familiar with data visualization tools such as Tableau, Data Studio', 'Negotiation skills and ability to influence others by educating and sharing information', 'Proficiency in either R or Python', 'Experience with Splunk', \"ibm.com/ibm/responsibility/corporateservicecorps/, Master's Degree in Statistics, Mathematics, Engineering or related STEM fields\", 'Works closely with cross-functional teams: Content Strategy, Legal, Marketing (CRM), Product, and financial planning to deliver ad-hoc analysis', 'For more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., We are looking for a Postdoctoral Researcher to perform research in the area of data analysis and machine learning with a goal to develop new techniques, analyze and steer multi-scale simulations in a large-scale parallel workflow.Web analytics ‚Äì working knowledge of SiteCatalyst or Google Analytics', 'has a strong sense of engineering craftsmanship, takes pride in the code they write', 'Deploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform', 'Mentor summer students and assist in the organization of summer programs', 'Create detailed programming specifications', '1 - 3 years in a Business Analyst role', '- An aptitude communicating complex quantitative analysis in a clear, compelling, and actionable manner, ', 'Solid programming skills for statistical analysis (Python or R), ', 'Create, monitor, and maintain a job scheduling system', '2+ years of experience with H2O software or Keras with TensorFlow', 'excited to disrupt online advertising', '401k which includes dollar-for-dollar company match of up to 6%', 'Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions', 'Cloud Computing (Amazon AWS, Microsoft Azure or Google GCP)', 'Experience utilizing SQL to develop queries or profile data OR programming experience in applications or databases', 'Communicate complex solutions to a variety of stakeholders in easily understandable language', 'Attention to details', 'Experience with a host of tools including: Google Analytics, Adobe Analytics, Google Tag Manager and tag auditing tools such as ObservePoint.Experience with Google Cloud Platform or related cloud services., ', '- A natural curiosity to solve complex problems and a desire to learn new skills, ', 'Able to write code in SQL', 'Google Cloud Platform, At Square, our purpose is to empower ‚Äì within and outside of our walls.The Weather Company (an IBM Business) is seeking a Data Engineer to utilize skills in DevOps and data management/engineering to work with architects, developers and other team members to design, build, and operationalize solutions for strategic enterprise data processing in geospatial data.AWS, Google)', 'At least 5 years of experience in data management and coding such as DB2, SQL, Hadoop, PhD in Statistics, Mathematics, Engineering or related STEM fields', 'Experience with developing statistical and simulation models', \"[Position Description, \\n\\nConsults with internal organizations on global strategic initiatives or multi-business initiatives in two or more functional business areas\\n\\nDevelops and directs one or more work streams of a cross-functional project to achieve desired results\\n\\nDevelops tools that that support decision making and business cases\\n\\nDrives the execution of multiple business plans and projects\\n\\nEnsures business needs are being met\\n\\nIdentifies and influences stakeholders\\n\\nPromotes and supports company policies, procedures, mission, values, and standards of ethics and integrity\\n\\nProvides supervision and development opportunities for associates, \\n\\nMinimum Qualifications, \\n\\nBachelor of Science or Bachelor of Art and 3 years' data analytics experience OR 5 years' data analytics experience OR Master of Science or Master of Art and 1 years' data analytics experience., \\n\\nAdditional Preferred Qualifications, 1 year's experience leading project teams to solve problems., Supports all aspects of data on-boarding, data cleansing, analytics, data interpretation and maintaining the analytic data warehouse., Consults with internal stakeholders on data requirements., Will work with unstructured data sets to identify information that can be used for predictive modeling/analytics, Implements best practices to deliver scalable marketing analytics in partnership with the segment analysts., Performing other duties as assigned or apparent., Qualifications, experience and personal specification, Google Analytics (or similar) guru & comfort with large record data sets\\nStrong quantitative and analytic ability with attention to detail.For more information, visit www.weatherford.com and connect with Weatherford on LinkedIn, Twitter, YouTube and Facebook., \\n\\nWeatherford delivers innovative technologies and services designed to meet the world‚Äôs current and future energy needs in a safe, ethical, and sustainable manner.They will have an appetite for learning new technology with an eye for the value it can create., \\n\\nResponsibilites:, \\n\\nWork closely with in-house subject matter experts to thoroughly understand the business domain and use that knowledge to help define, design and implement machine learning systems\\n\\nHelp define project goals and timelines\\n\\nEvaluate new architectures for feature extraction to optimize and extend machine learning models\\n\\nTake ownership of text analysis, image and form recognition projects\\n\\nCreate systems for evaluating model accuracy and anomaly detection\\n\\nWork with development team to put models into product and scale them properly, \\n\\nRequired Skills/Qualifications:, \\n\\nDevelopment languages including Python, R and Javascript\\n\\nMachine learning frameworks such as Tensorflow and Keras\\n\\nData Science algorithms such as decision trees, linear regression, clustering, word embeddings\\n\\nCloud ML resources like Google Cloud Platform\\n\\n.NET Experience is a plus\\n\\nOCR Experience is a plus\\n\\nExperience implementing successful machine learning systems\\n\\nCreativity and willingness to be open and share ideas]\", 'Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required', 'Proficiency with object-oriented and/or functional languages (e.g.Connect with NRG Energy on Facebook and follow us on Twitter @nrgenergy., ', 'At least 5 years of experience data management and coding such as DB2, SQL, Hadoop', 'Design automated solutions for building, testing, monitoring, and deploying ETL pipelines in a continuous integration environment', \"[At Capital One, we‚Äôre building a leading information-based technology company.Basic understanding of marketing analytics\\nStrong understanding of relational databases required with strong SQL skills\\nExperience with Google Analytics and BigQuery preferred\\nProficiency in at least one programming language (Matlab, Python, R, Julia, etc.)AWS, Azure, Google Cloud etc.10% travel required., \\n\\nTravel: 10% travel required., \\n\\nInternal use only: reference code lhrs4262, \\n\\nSAP'S DIVERSITY COMMITMENT\\n\\n\\nTo harness the power of innovation, SAP invests in the development of its diverse employees., Other Credentials Required: Driver's License, Vehicle Liability Insurance]\", 'Strong problem-solving skills and capability to understand and set direction for complex technology integration', 'Multiple peer-reviewed publications in high impact factor journals, Knowledge, Skills & Abilities:, ', \"As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other big data related technologies.RPC, REST, JSON, XML, SOAP)\", 'Design and rigorously test new features in our app that improve quality of service for our customers', '5+ years of data management and marketing experience, with 2+ years direct experience with data management in a cloud environment either in an eCommerce environment or for a Database Management/Customer Insights firm', '- Experience using SQL to manipulate data, ', \"On-call hours and limited travel may be required, Bachelor's degree in an Information Technology discipline or related field (Computer Science, Software Engineering) and six years of work experience designing, programming, and supporting software programs or applications\", 'Collaborative Problem Solving', ', Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\"[', ', Ph.D. in a related field', 'Analytical and Logical Reasoning/Thinking', 'KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.Technical Experience and Expertise:', 'Experience with Big Data computing environments, including Hadoop', 'Conduct data analysis and predictive analysis to meet client needs', 'Ability to explore academic research and apply and modify it to meet the needs of the client', 'Adobe Omniture', 'a chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition', 'Strong project consultative background; creating project requirements', 'Programming experience in Python or Perl', 'Assist in the organization of weekly group seminars', 'Experience with Microsoft Excel and Access', ', Use emerging tools and technology to develop analytical models and automation in music planning, music research, and other areas of the company', 'Become an expert on the data sources and systems at Twitter.Experience architecting and developing end-to-end enterprise scale Big Data analytical solutions in serverless environments such as Google Cloud Platform', 'Listening, verbal and written communications skills with the ability to translate technical information into understandable terms to a variety of audiences', '[\\n3+ years of experience with developing and deploying scalable machine learning or artificial intelligence algorithms\\nExperience with data mining techniques for large-scale datasets, including both structured and unstructured data\\nExperience with advanced analytics, including unsupervised and supervised learning techniques, such as regression, forecasting, clustering, and outlier detection\\nAbility to obtain a security clearance\\nHS diploma or GED\\n, \\nExperience with using APIs to integrate data from multiple systems\\nExperience with using Python scripting for data extraction and manipulation\\nExperience with using Splunk as a data analysis environment\\nExperience with multiple data visualization tools\\nKnowledge of nation-state, targeted, and financially motivated threats\\nKnowledge of Cybersecurity infrastructure and log sources\\nPossession of excellent oral and written communication skills\\nPossession of excellent collaboration skills\\nSecret clearance\\nBA or BS degree\\n]', 'Acquire and manage data from both primary and secondary sources', 'has a sense of intellectual curiosity and a burning desire to learn', '[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.Experience with Distributed Data platforms (HDFS, Elasticsearch, Splunk, Casandra).Experience with AWS and Google Cloud Platform.Founded by MIT roboticists who had the vision of making practical robots a reality., Understand the capabilities of our current system and enhance it to support the capabilities of this new pipeline\\nWork with other groups within the organization to set up and configure big data clusters and assist with data volumetrics as well as hardware and software needs\\nResearch, design and assist in building tools that can be utilized to analyze the data by internal users and support staff\\nMaintain systems to ensure they are highly available\\n, 3+ years of current Java development experience\\nProven experience with a range of big data architectures, including Hadoop, HBase or other big data frameworks\\nExperience building large scale distributed data processing systems\\nSolid understanding of data structures, algorithms & object-oriented design concepts\\nA passion for big data technologies and a flexible, creative approach to problem solving\\nExcellent communication skills\\n, Experience with languages such as Python/Perl\\nExperience developing software using agile methodologies\\nWorking knowledge of development tools such as debuggers, memory profilers, and performance analysis\\n, Apply Now]', 'enjoy sifting through large amounts of data', 'Knowledge in website analytics tools such as Google Analytics', 'Working with data science workbench solutions (Dataiku, IBM DSX, Domino), ', \"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \\n\\nAs a Solutions Architect with a core focus on Machine Learning (ML), you'll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.You can find us in 27 cities across the U.S., U.K., and Canada., \\n\\nJob Title, \\n\\nSolution Principal ‚Äì Machine Learning, \\n\\nAs a Solution Principal, you‚Äôll design and deliver innovative Machine Learning solutions on Amazon Web Services, Azure and Google Cloud using core cloud data science tools and other big data related technologies.Master‚Äôs preferredProven experience with data mining, cleansing and manipulations, variable transformations, linear and non-linear multi-variable regression analysis, K-mean and hierarchical cluster analysis, discrete and continuous probability distributions, systems of equations and numerical analysisProven exp using the cloud to do large computationsProven exp joining large data sets from various repositoriesProven experience with 1 or more statistical programming languages: R, Python, Matlab, SAS.Experience with queries to extract and transform data from multiple data sources, including Oracle, Teradata, and SQL ServerExperience utilizing Excel, PowerPoint, and other MS Office softwareExperience with 1 or more statistical analysis software: Minitab, Stata, SPSS, APTKnowledgeable about digital, E-commerce, marketing a plus]\\n[With demand sensing, OM Partners is breaking through some boundaries of classical demand forecasting.and multithreading\", '- Academic degree in quantitative field, Advanced degree is a plus, ', 'Experience with collaboration tools such as Bitbucket, GitHub, Teams, or Jira', 'Establish reporting processes and implement regular reporting on all marketing initiatives', 'Optimizely‚Äôs Stats Engine https://blog.optimizely.com/2015/01/20/statistics-for-the-internet-age-the-story-behind-optimizelys-new-stats-engine/', 'A chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition', 'Ensure consistency between data analyses, Google-based tools, and Tableau dashboards', '3-5 years of experience leading Human Subjects Research projects', 'Passion for digital marketing, eagerness to learn in a constantly-changing space, and a natural curiosity', 'Collaborate with Marketing to measure impact of website strategy across all campaign channels and to refine strategy driven by data-based insights', 'Work with a variety of software platforms, including Google AdWords, Google Analytics, Google Tag Manager, Bing Ads, DSPs, PPC and social media platforms', 'Strong background in Machine Learning and AI', 'Be an expert on all things ads-related: how are we monetizing our inventory?Manage multiple tasks/projects and deadlines simultaneously to meet internal and client data needs', 'Bachelor‚Äôs degree in computer science, mathematics, engineering or related discipline', 'Experience with various data environments (on-premises vs. cloud; database vs. data lake; small vs. medium vs. big data), such as Google, AWS, Oracle, or Hadoop', 'Data mining using state-of-the-art methods', 'Translate functional requirements into SQL and execute to pull lists for messaging campaigns', 'Experience with Tableau (or similar data visualization tools such as Spotfire, PowerBI, QlikView, etc.)That‚Äôs why:, Our infrastructure is in Google Cloud Platform,', 'Expanding industry knowledge and relevant skillsets through internal training, ', 'Responsibilities include:', 'Experience with graph algorithms and semantic Web', 'Experience supporting Data Scientists in model validation and algorithm / model optimization, ', 'Experience with Business Intelligence, Analytics and Data Visualization tools, e.g.\"[', 'Presentation skills and ability to present information in various ways to meet audience needs', 'Experience using one or more advanced analytic software: numpy, scipy, pandas, R, SPARK', 'participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', '- Experience using Python programming language, ', 'Experience with identifying analytic insight in data, developing visualizations, and presenting findings to stakeholders', 'Knowledge and experience with electronic health records (EHRs)', 'Experience in and knowledge of big data batch streaming architectures', 'Import data from sources including PostgreSQL, Mixpanel, Google Analytics, Amazon Kinesis, and Zendesk', 'Commitment to IT innovation through initiatives like our Business Innovation Garage where professionals can test new ideas, technology and prototypes', 'Dynamic company culture that encourages engagement, supports Employee Resource Groups, values your input and embraces a relaxed atmosphere', 'Healthcare onsite and standard benefits (medical, dental, vision)', 'Fluency in SQL', 'Experience and/or interest in working with open source eco-system components such as Tensorflow, Scikit learn, Hadoop, Apache Spark, Apache Flume and Apache Kafka.As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners., The Google Cloud Revenue Acceleration team (RevX) focuses on boosting business growth of Google Cloud using quantitative programs.Represents T-Mobile at professional meetings, in professional societies and universities.You will conduct original research and publish results in academic and industry conferences., ', 'Plan and manage engagement objectives and key deliverables using analytics processes to mitigate risks in data, modeling, validation and delivery while working with team members to capture assumptions, risks, and develop approaches to mitigate issues', 'Proactively develop site performance reports and analysis such as segmentation analysis; highlight observations and business context to deliver actionable recommendations to business leads, not just data', 'TS/SCI clearance', '- A strong understanding of the scientific method and its role in developing business insights and decision making process, ', 'Ability to work with the business to understand business goals to create an artificial intelligence solution and an accompanying business case that meets the business objectives and business constraints; With expertise in delivering projects using leading processes including strong knowledge of data discovery, cleaning, model selection, validation and deployment', 'Ability to ask questions and figure out what‚Äôs the right data and data science solution, in a collaborative team environment that follows an agile data science process', 'Consult with clients on how to integrate a new technology stack', 'Backup and Recovery', 'Exposure and experience with Social Listening tools (i.e., Netbase, Brandwatch, Affinio, Crimson Hexagon)', 'iD Tech has been voted a Top Workplace by the Bay Area News Group 8 times!Familiarity with visualization software and techniques (including Jupyter Notebook, Google Cloud Datalab).MIT Sloan Management Review says that in many organizations, there is a consistent disconnect between data scientists and the executive decision makers ‚Äì that‚Äôs why it‚Äôs time for a new role ‚Äì the data translator., ', 'Define data sources and implement a customized real time, reliable system', '[\\n2+ years of experience with supporting or executing data building, data queries, modeling, or programming of complex analytical methods to support military applications\\n2+ years of experience with analytical technologies used in enterprise reporting, including Tableau, Qlik, Looker, OBIEE, or equivalent\\n1+ years of experience in working with data infrastructure approaches, including open data architectures, Cloud infrastructure, and Infrastructure as a Service, Platform as a Service, or Data as a Service\\n1+ years of experience in working with Microsoft Excel to perform data analysis and data cleansing\\nActive Secret clearance\\nBS degree in Science, Technology, IT, Data Science, Engineering, Command and Control Research, or Mathematics or 6+ years of experience with operational research or assessment\\n, \\nExperience with leveraging varying data methods to inform qualitative and quantitative analyses, including SAS, SPSS, STATA, Python, and R\\nKnowledge of basic concepts in computer science and data science, including machine learning and artificial intelligence a plus\\nTS/SCI clearance\\n]', 'Experience with a consumer packaged goods (CPG) company or retailer', 'Identify key questions, problems, and KPIs to improve the experience of our users', 'Ability to partner with business and technical groups in a cross-functional capacity, ', 'Identify opportunities to operate the marketplace more efficiently, working closely with business, product, and engineering leaders', 'Lead in a fast-paced and dynamic environment utilizing virtual and face-to-face interactions; Manage complex workstreams, expectations, budgets, deliverables, and multiple responsibilities using structured approaches for operational excellence and communicating results to executive level audiences', '[\\n5+ years of experience\\nPredictive modeling (eg: neural networks, logistic regression, variable reduction, imputation)\\nStatistical Analysis with R, Python, or other scripting language\\nLinux command line (eg: Bash, AWK, Perl, Sed)\\nFamiliar with RDBMS concepts\\nData visualization (eg: ggplot, Python, Splunk, Tableau, Excel)\\nProven quick self-directed learner\\nGood communication skills\\nTeam Player\\nBA or BS in Math, Computer Science, Engineering, Physics, or a related field\\nExposure to the areas of AI, ML, and Data Science with an ability and desire to grow\\n, \\nMachine learning libraries (eg: Tensor Flow, Keras)\\nHadoop (Hive, Impala, MapReduce)\\nCloud (AWS, Azure)\\nIT Infrastructure Engineering exposure\\nRegular expressions\\nInfrastructure components (e.g.Deep understanding of digital advertising industry and Google‚Äôs ad product suite in particular ad serving and yield management expertise.Create automated systems to track performance metrics\\n\\nIdentify and troubleshoot any issues or discrepancies\\n\\nProject coordination and management - manage multiple high priority tasks/projects simultaneously\\n\\nTrack project performance, specifically to analyze the successful completion of short- and long-term goals, \\n\\nIntegrate data from others sources into the system\\n\\nConsistently maintain and improve the system, \\n\\nData Science / Statistics / Quantitative / Mathematics / Economics background\\n\\nMust have experience with Google Sheets, Excel, Tableau, SQL, Google Forms, Google Slides and/or PowerPoint\\n\\nKnow at least one script language, such as Python or JavaScript\\n\\nFamiliarity with database engines, such as SQL Server, \\n\\nPossess strong communication skills, and specifically an ability to take a complex problem and explain it very simply\\n\\nBe a teamplayer who enjoys cross-functional collaboration with colleagues and teams worldwide\\n\\nBe a technical expert - not only fix issues as they arise, but be a proactive adviser to your manager and the Global Security team\\n\\nBe driven and self-taught - seek solutions, identify gaps, create solutions and solve problems independently\\n\\nPossess high integrity - you will be responsible for handling and safeguarding sensitive data, and encounter potential exposure to incident reports.Experience with, MATLAB or a similar mathematical programming language is desirable., Experience or research work related to satellite orbits is particularly, desirable., MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.Getting the answers you need to solve a problem from Google, finding the right person to ask, or digging deep technically\\nMentoring junior developers.AspenTech‚Äôs customer list (over 1700 companies) includes the world‚Äôs leading companies such as ExxonMobil, Shell, Dow Chemicals and BASF.[', 'Experience in one or more natural language processing topics, including tagging, syntactic parsing, word sense disambiguation, topic modeling, contextual text mining, and application of deep learning to NLP', '[Bachelor‚Äôs degree\\n\\nMinimum of 5 years of relevant Natural Resources industry experience\\n\\nMinimum of 5 years working in advanced analytics and business transformation\\n\\nMinimum of 5 years in strategy or management consulting\\n\\nMeet travel requirements, up to 80%, \\nBachelor‚Äôs degree in quantitative discipline (Engineering, Economics, Statistics, Operations Research, Computer Science)\\n\\nMasters or MBA\\n\\nPhD in Analytics, Statistic or other quantitative disciplines\\n\\nExceptional presentation skills ‚Äì ability to convey technology and business value propositions\\n\\nAbility to understand and apply statistical methods and outputs to create client value in a business context\\n\\nExperience with evolving approaches and technologies such as Big Data, Artificial Intelligence, Machine Learning, Cognitive Systems, and Robotics\\n\\nData management skills\\n\\nData visualization skills\\n\\nValue based constructs, Proven ability to build, manage and foster a team-oriented environment\\n\\nProven ability to work creatively and analytically in a problem-solving environment\\n\\nDesire to work in an information systems environment\\n\\nExcellent communication (written and oral) and interpersonal skills\\n\\nExcellent leadership and management skills, \\nYour entrepreneurial spirit and vision will be rewarded, and your success will fuel opportunities for career advancement.This role is key to activating our innovative solutions and the role requires an individual who can work with other analysts and business users to create solutions which integrate with our marketing technology stack., \\n\\nIn this role, the Marketing Data Engineer will:, \\n\\nIntegrate data from various third-party and first-party data sources, including but not limited to Google Analytics 360, YouTube, LinkedIn, Facebook, Twitter, SFDC and Hubspot\\nCollaborate with our team of in-house RPA engineers to automate API integrations and tedious process around marketing data collectionResponsible for all extract, transform and load (ETL) processes and the creation of applications that can connect to remote APIs.Experience working with cloud platforms such as AWS, and Google Cloud Platform and distributed computing technologies such as Apache Spark.]If you said yes, we‚Äôd love to talk to you about joining our award-winning team., ', 'Working in a variety of reporting systems and databases for the creation of recurring reports and dashboards', \"[Partner with Business Developer team to maximize our marketplace health and performance through data-driven insights\\n\\nPresent as appropriate to individuals throughout the organization and to Criteo clients externally (i.e.Research and develop analysis, forecasting and optimization methods to improve the quality of Google's user facing products; example application areas include ads quality, search quality, end-user behavioral modeling, and live experiments.Minimum 4 years full-time, analytics-relevant work experience (experience in the digital industry is preferred, SQL proficiency is required)\\n\\nKeen intellectual curiosity and ability to structure & solve difficult problems with minimal supervision\\n\\nPassion for translating ‚Äòdata-speak‚Äô into relevant, compelling stories\\n\\nBackground in any of the following preferred: Tableau, Vertica, Hive/Hadoop, R, Python, Pentaho, Kettle\\n\\nExceptional attention to detail coupled with an ability to see the big picture\\n\\nThorough conceptual and practical understanding of relational databases, data architecture/governance, and real-world application of statistical concepts (particularly in a testing context)\\n\\nEffective presentation and public speaking skills with the ability to present and defend complex analysis both internally and externally to both technical and non-technical audiences ‚Äì and a passion for making the\\n\\nMust have the combination of technical skills, passion for learning, and the soft skills to work with all personality types in a dynamic environment]\", '1 - 3 years in Research and Development, Preferred Qualifications:', 'At least 7 years of experience in project management for external consulting engagements', 'Excellent analytical and time-management skills', '[Working at MIT offers opportunities, an environment, a culture ‚Äì and benefits ‚Äì that just aren‚Äôt found together anywhere else.You have a passion for Data products from cloud providers like Amazon Web Services (AWS), Google Cloud or Azure you might want to leverage to make a difference to our Analytics stack., In this role, you will use your knowledge of data processing, technical systems, and project management to enhance our existing data and machine learning platforms for internal and customer facing use cases., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud., Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\\n, Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\\n, Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\\nProficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\\nAbility to digest and explain complex ideas to a diverse group of stakeholders\\nMust be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\\nExperience with digital media measurement and reporting platforms preferred as well as programming languages\\nExperienced in effective dashboard designing with a focus on customizing to client needs\\nAbility to work under pressure and manage multiple priorities\\nStrong communication and presentation skills equally capable of interacting with peers and senior leaders\\nMust be a team player but also have the ability to work independently]', 'Must have at least 7 years experience working mapping and analyzing data within a Data Warehousing or Data Lake environment, with 5 years experience working with clinical Healthcare data.We offer a highly competitive base salary and a comprehensive benefits program, including medical, prescription drug, dental, vision, 401(k) with company match, life insurance, paid time off, tuition assistance and an employee stock purchase plan., ', 'Statistical Analysis', 'Effective data visualization skills with analytical tools such as Tableau, Looker, D3.js or other tools, ', 'Developing data visualizations to help guide decision making', 'Curious and numerical minded', 'Manage testing and debugging of analytics/tagging code', 'Security (SIEM, UEBA, VPNs)', 'Hortonworks or Cloudera certification', '- Experience using data visualization tool, Tableau preferred]\"', 'At least 5 years of experience in advanced analytics tools such as R, SPSS, Python, SAS', 'Work with stakeholders to develop learning plans with recommendations of analytics approaches, including A/B testing', 'A demonstrable understanding of machine learning theory', '5 - 10 years in Data Analytics', '[Passion: The Kinsa team is driven towards a goal that is bigger than themselves, they have a real passion in working toward a solution for a widespread social issue.Come join a friendly, seasoned team and a great company as we change the world., \\n\\nWhat you‚Äôll do, \\n\\nBuild ETL code to populate our Google BigQuery data warehouse with Apache Airflow scheduled batch updates from our Sansar Virtual Reality platform\\n\\nDevelop real-time ETL apps using Google DataFlow (Java or Python) to provide critical insights into the business\\n\\nMaintain, improve, troubleshoot, and evaluate real-time data processing systems such as PubSub, Kafka, and Stackdriver\\n\\nWork closely with our Data Architect, Product Managers, and Analysts to design and model new tables to meet constantly-evolving analytics needs\\n\\nLiaise with our systems engineers, Google support, and our consulting partners to quickly assess the impact of production system changes to existing data warehouse processes\\n\\nOther duties may be assigned, \\n\\nWhat you need, \\n\\nExtensive Real Time Data Engineering experience - we are not looking for a Data Analyst or Scientist.Relevant certifications considered but not required., \\n\\nTechnical Requirements, \\nExperience with distributed computing technologies including Hadoop, HBase, Cassandra, Elasticsearch and Apache Spark\\nDevelopment experience with Java, C++, Scala, Groovy, Python, and/or shell scripting\\nExperience with data warehousing tools and technologies\\nAbility to work within UNIX/Linux operating systems\\nAWS experience a plus\\n, Company Benefits, \\n6 weeks PTO\\n\\nPaid Overtime\\nAnnual Bonuses\\n10% Employer 401k Contribution\\nHealth/Vision/Dental/Disability/Life Insurance\\nAnnual Training and Tuition Budgets\\nTechnology/Fitness/Communications Reimbursement\\nCharity Matching Program\\n, EOE/M/F/Vet/Disabled]', \"[Senior Data Engineer- E-commerce Start-Up, \\n\\nSan Francisco, Bay Area, \\n\\n$1650,000-$185,000 (cap varies by expertise) + equity, \\n\\nWill support Visa transfer, \\n\\nHarnham has partnered with a dominant San Francisco based start-up that has been taking over a trillion dollar U.S. market by storm.[What You‚Äôll Do:, You will work with our team of experts in machine learning and software engineering to build powerful and scalable models and surface the most relevant content on Twitter.You will work in a team environment alongside a group of expert mathematicians, statisticians and data scientists., The perfect candidate‚Ä¶:, is an analytic leader who can mentor and teach to help enhance, build, and grow Hallmark‚Äôs analytic capabilities.You believe that great just isn't good enough, and constantly seek out opportunities to improve Google‚Äôs security services, by leveraging data.Your passion for technology, learning, and solving problems, along with your enthusiasm for working with customers will empower a diverse audience of decision makers to embrace the Google Cloud to build what‚Äôs next for their businesses., \", 'Understanding of data preparation, machine learning, deep learning, natural language processing, and development practices (testing, code design, complexity, and code optimization); Ability to discuss mathematical formulations, alternatives, and impact on modeling approach', 'Primary country and city: United States (US) || || Plano || Consulting&SysInt]\"', 'Maintain repository of R scripts for automated overnight data processing and incorporate new analyses and descriptives as needed', 'Learn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk, Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw', 'Strong work ethic and intellectual curiosity, with laser focus on execution]\"', 'Possession of excellent oral and written communication skills', '[\\n3 years of experience with Big Data, systems, including Hadoop, Hive and Pig\\nExperience with ETL tools including NiFi and StreamSets\\nExperience with Java\\nExperience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services\\nSecret clearance\\nBA or BS degree\\n, \\nExperience with Agile software development\\nPossession of excellent oral and written communication skills\\nBS degree in CS, Computer Information Systems, Information Systems, or a related field\\n]', 'DCM (DoubleClick), ', 'Strong verbal and written communication skills across all levels of the organization', \"Master's degree from an accredited college/university in Computer Science, Engineering, or related fields; PhD from an accredited college/university is preferred\", 'Instead of a degree, eight years of related work experience designing, programming, and supporting software programs or applications may be accepted, In-depth knowledge of computer coding/programming languages and software development concepts in a large IT environment', 'Experience in data visualization tools such as Tableau or Looker', 'Self-driven and demonstrates the ability to drive project across multi-discipline teams, ', 'o Modeling and word representations (RNN / ConvNets, TF-IDF, LDA, Word2Vec), ', ', Deadline', 'Strong communication skills: written, verbal, and presentation', 'Working knowledge of Informatica, Hadoop/AWS, IBM Infosphere products and other Big Data tools.This individual will dig into raw and processed data (backend DBs, Google Analytics, and event/message data), transform information into visualizations using Tableau, R, Excel, etc., and effectively articulate the story behind the data.Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required', 'Excellent English communication skills - verbal and written]\"', 'Ability to build complex extraction, transformation, and loading (ETL) pipelines to clean and fuse data together', 'Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.Experience building re-usable data integration frameworks and patterns', '3 years in a previous position as a data analyst, ideally for a web or mobile-based business', 'Experience with Python and/or Java preferred', '1+ years working with big data sets', ', Works with stakeholders throughout WestRock to identify opportunities for leveraging data to drive business solutions', '2-3 years of experience with Agile and Scrum development', 'We are always looking for team members that have what it takes to be mission critical.Familiarity with Google Cloud Platform (e.g.At TMS, we‚Äôre the agency AND the client!, ', 'A record of excellence in scientific publication', '[At Google, data drives all of our decision-making.[Work with resort marketing teams to ensure Google Tag Management is properly applied on their websites and Ecommerce engines ensuring accurate tracking, Help develop and manage acquisition funnels for all resorts ‚Äì on datarama, Work with Marketing teams to take advantage of guest data in our sequel azure database, Once in SQL, develop queries that provide insights to marketing teams as well as responding, Expertise in Google Tag Manager and utilizing tracking toolsExpertise in SQL and ability to write queriesExpertise in Microsoft Office applicationsGood listening and communication skills]\\n\\n[Clarivate Analytics clients are the trailblazers and risk takers who come up with life-changing ideas.[Bachelor‚Äôs degree in a related field of study3+ years of experience with digital analytics or web analyticsStrong analytic and critical thinking skillsImpeccable attention to detailsProficiency with Google Analytics or OmnitureDemonstrates understanding of digital tracking and tagging QASQL, Python, R, or any coding experience a plusTableau or Microsoft PowerBI experience a plusComfortable and effective working in a dynamic and past-paced environment, with the ability to be flexibleMust have legal right to work in the United States]', 'The ability to quickly \"\"switch gears\"\" while remaining organized across multiple projects', 'Someone who can work quickly and manage multiple tasks to completion', \"[\\n\\nWork with your team to determine product direction and customer needs\\n\\nDevelop and improve the service layers that connect the data backend to web apps\\n\\nShare knowledge, methodologies and best practices amongst the product engineering team and other teams\\n\\nParticipate in a team-wide on-call rotation to keep the systems ticking along\\n\\nMentor Software Engineers and Interns, \\n\\nBachelor's or Master‚Äôs degree in Computer Science, related field and 5+ years of software development experience\\n\\nExceptional experience in programming with Java., \\n\\nBachelor Degree in Data Science, Information Systems, Computer Science, Economics, Mathematics or similar\\n\\n2+ years of experience as a Business/Financial Analyst, BI Engineer or Data Analyst preferably with exposure to large complex data sources\\n\\nProficient in SQL and Microsoft Excel\\n\\nProven analytical and quantitative skills and an ability to use data and metrics to back up assumptions, develop business cases, and complete root cause analyses\\n\\nQuick learner with a strong data-driven and quantitative focus when solving problems\\n\\nKnowledge of fundamental relational database technology and terminology\\n\\nProficient in converting large datasets into actionable business insights\\n\\nExperience using business intelligence reporting and visualization tools such as Tableau, Looker, Cognos, Domo, or others\\n, \\n\\nExperience in payments, billing and subscriptions\\n\\nExperience with analytical software (Python, R) and solid grasp of common statistical methods and applications (A/B testing, probability, regression)\\n\\nExperience working with databases such as AWS Redshift\\n\\nAdvanced understanding of data analysis and visualization techniques\\n\\nFamiliarity with Google Analytics, web analytics, and funnel conversion concepts\\n]\", 'To harness the power of innovation, SAP invests in the development of its diverse employees.If you require an accommodation due to a disability, please contact Ericsson at hr.direct.dallas@ericsson.com or (866) 374-2272 (US) or (877) 338-9966 (Canada) for further assistance., ', 'Working knowledge in Google Tag Manager, ', 'Demonstrate personal accountability for quality of work', ', BENEFITS, ibm.com/employment/us/benefits/', 'Tableau, Excel and PowerPoint experience and strong presentation skills required', \"[Science and Technology on a Mission!, \\n\\nFor more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., We have multiple openings for Postdoctoral Research Staff Members to engage in the research, design, and deployment of machine learning and statistical methods to solve important data and science problems stemming from the Laboratory's mission spaces.Experience managing various tagging and tracking platforms such as Adobe Marketing Cloud (Omniture), Tealium, Google Analytics, etc.Experience with Google and Adobe analytics.All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.Experience in Google Cloud Services strongly preferred.Includes agency management, budget allocation, SME curation, publishing assets into the campaign and the appropriate IBM tracking systems.[\", 'Very strong SQL query language skills is a must have', 'Stats Engine Academic Paper - https://arxiv.org/abs/1512.04922, ', 'We‚Äôre looking for strong, impactful work experience, which typically includes:, ', 'Highmark Health‚Äôs Pharmacy Services Team has identified this exciting new role to play a critical role in bridging the technical expertise of data engineers and data scientists with the operational expertise of our Pharmacy frontline business staff., ', '2-3 years of experience working with Big Data, data mining or machine learning, data visualization to draw actionable insights', 'Strong understanding of classical ML techniques, ', 'Responsibilities:, ', '- Define campaign targeting/selection criteria, design A/B test and learn, multivariate testing, and perform related marketing effectiveness and incrementality assessments to inform future decisions, ', 'Experience with Lean Startup, Design Thinking, and Agile Methodologies preferred, Collaborate to build an end-to-end, extendable customer data solution from defining requirements to data migration and creation of dashboards, ensuring data integrity, accuracy and compliance.At Google, engineers not only revolutionize search, they routinely work on massive scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world.Gracenote, a Nielsen Company is the leading provider of entertainment metadata and media recognition technology that powers discovery features and discover the music, TV shows, movies and sports they love across the world‚Äôs most popular entertainment platforms and devices, from Amazon, Apple, Facebook, Google, Time Warner Cable, Tesla and others.Depending on your experience - hence level of autonomy - it will be required to work from the head office., OM Partners is a software and consulting company focused on Supply Chain Planning.Deliver data and data analysis on an ad-hoc basis using whatever tools are necessary for the task, ', 'Relocation assistance to Northeast Ohio or Colorado Springs available', \"[\\nExperience in building machine learning infrastructure on AWS, Google Cloud, or Azure.Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.[Splunk‚Äôs Guild of Data Science has been tasked with helping Splunk build smarter software and make data-driven decisions.The team partners with Publishers and App Developers of all sizes to promote their ad inventory, working with Google's broad range of partner solutions including AdSense, AdMob and Google Ad Manager, across mobile, display, and video formats, helping our partners and their audiences get the most out of the web.Learn more at sensus.com and follow @SensusGlobal on Facebook, LinkedIn and Twitter., \", 'Strong written and verbal communication skills with internal and external clients]\"', 'Excellent communication skills with the ability to distill complex problems into digestible insights, ', 'Interest at the intersection of computer vision and language', 'Track, prioritize, and manage analytics implementation initiatives across multiple teams; act as primary lead for analytics/tracking implementation efforts', \"Leverage IBM offerings, assets, and capabilities to create and deliver differentiated service offerings to our clients.As a Data Analyst with Geo Operations, you design and implement methodologies, dashboards and presentations, all while partnering with stakeholders across multiple functions and locations., Google's Consumer Hardware is looking for a Data Analyst to join its rapidly growing Reverse Logistics team.Develop visualization based on user needs on Google dashboards or Tableau.Data Analytics packages such as Pandas, Scikit-learn, Numpy or R.\", 'Netbase', '2+ years of experience in working with a wide range of predictive and decision models and tools for developing such models', 'A subject matter expert leading hands-on with technical know-how, determining methods and procedures on new projects, and providing leadership to other engineers', \"[Title: Data Analyst\\nReports to: Research Director\\nClassification: Exempt\\nLocation: New York\\nStart Date: Immediately, \\n\\nSummary:\\n\\nThe Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \\n\\nThe Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets.Our customers include some of the nation‚Äôs largest hospitals including Stanford, UCSF, NewYork-Presbyterian, the University of Texas MD Anderson Cancer Center, and more\\nOur team includes veteran executives and the brightest minds from Google, McKinsey, Stanford, MIT, Duke, Berkeley, UIUC, and more., \\n\\nBachelor‚Äôs degree in related field or 8 to 11 years of experience., \\n\\nABOUT THE DEPARTMENT, \\n\\nABOUT EXPRESS SCRIPTS, \\n\\nAdvance your career with the company that makes it easier for people to choose better health., \\n\\nExpress Scripts is a leading healthcare company serving tens of millions of consumers.You can find us in 27 cities across the U.S., U.K., and Canada., \\n\\nJob Title, \\n\\nData Engineer, \\n\\nAs a Data Engineer, you‚Äôll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core cloud data warehouse tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.Hadoop, Spark, Kafka, Clickhouse, NiFi)\\n\\nExperience with crafting and managing data pipelines\\n\\nDevOps mindset with experience on agile team\\n\\nStrong technical writing and communication skills\\n\\nExcellent problem solving and decision-making skills, \\n\\nExperience with containerization (specifically Docker & Kubernetes)\\n\\nExperience with SQL and Linux\\n\\nSecurity experience\\n\\nSplunk dashboards, reports, and alerting, \\n\\nAt Cisco, each person brings their unique talents to work as a team and make a difference.Experience with front-end analytics tools, Google Analytics a plus.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Google Analytics, etc.)Experience with Anaconda, IBM Blue, Oracle Big Data) to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations.Whether battling large system processes or leveraging our homegrown suite of Google products for Googlers themselves, you help Googlers work faster and more efficiently., As part of the Google Technology Solution (GTS) Data and Business Intelligence team, you will help build out a data platform that will support our users in Google Cloud business and the needs of executives for data and insights.Expert in python\\n\\nExpert working with cloud platforms (AWS, Google Cloud, etc)\\n\\nExperience with Airflow or other workflow management software\\n\\nAbility to define data model and data storage strategies, including knowledge of distributed data systems\\n\\nAbility to manage multiple/competing priorities and make the right tradeoffs and timely delivery of features\\n\\nExperience or familiarity with geography, geometry and GIS systems\\n\\nExperience working with satellite/remote imagery\\n\\nRelevant education (Coding Bootcamp, and/or Bachelors in Computer Science) or equivalent experience, \\n\\nWHAT‚ÄôS YOUR STYLE, \\n\\nA developer who loves the speed of a start-up and won‚Äôt quit until the job is done with quality, whatever it takes\\n\\nA team-player with a good sense of humor and the ability to work on multiple projects under a tight schedule\\n\\nSomeone with strong communication skills, excellent ability to analyze and diagnose, good planning and work management skills, and great attention to detail, WHAT'S IN IT FOR YOU, \\n\\nThe opportunity to join a fast growing startup that is out to disrupt the insurance and real estate markets\\n\\nCompetitive salary\\n\\nGenerous early stage equity\\n\\nThe coolest office space in Jack London\\n\\nBenefits\\n\\nOur culture is awesome!You‚Äôre looking to join a strong, high-performing team., We build new ways for advertisers to buy ads on Twitter, such as paying up front for guaranteed results\\n\\nWe design incrementality studies to measure the lift in brand awareness that our advertising campaigns drive\\n\\nWe dive into individual products (e.g.Geo helps merchants get their businesses on Google, and more than a million developers use the power of Google Maps to enhance their apps and websites.Visit www.guycarpenter.com for more information and follow us on LinkedIn and Twitter @GuyCarpenter, \\n\\nGuy Carpenter & Company, LLC and its separately incorporated operating entities around the world are part of Marsh & McLennan Companies, a publicly held company (ticker symbol: MMC)., \\n\\nMarsh & McLennan Companies offers competitive salaries and comprehensive benefits and programs including: health and welfare, tuition assistance, pension, employee assistance program, domestic partnership benefits, career mobility, employee network groups, volunteer opportunities, and other programs.You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.You will have access to distinctive analytics assets that we use to accelerate delivering value to our clients including more than 550 analytics assets underpinned by a strong information management and BI technology foundation.Work closely with engineers to identify opportunities, design and assess improvements to Google products.Experience connecting and analyzing data from multiple business applications(SAP, SFDC, IBM Cognos)\\n\\nSystems engineer or reliability engineering experience.Desired skills: MATLAB, Python, or C++ programming experience is strongly desired., \\n\\nMIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.Successful candidate shall analyze data in the BI tool, consolidate data, and present findings., \\n\\nResponsibilities include, but are not limited to:, \\nDevelops pre and post-campaign analyses for digital marketing and loyalty campaigns to measure effectiveness\\nAnalyzes overall customer data trends to create and present actionable insights that help drive decision making in support of the Subway Digital marketing initiatives\\nSupports Loyalty Strategy by analyzing loyalty customer trends and program performance overall and within campaigns\\nDesigns and manages the reporting and dashboards using for customer insights and campaign performance\\nSupports the offer management and analysis of offers for the marketing campaigns\\nLiaises with the Analytics, Reporting and Experience Optimization teams\\n, Skills and Abilities Required:, \\n5+ years experience\\nStrong analytics skills and structured problem solving skills\\nStrong financial analysis background\\nStrong understanding of Excel, PowerPoint, and data visualizations\\nExperience in using BI tools to query and analyze data\\nFamiliar with campaign data, digital/web analytics, digital display advertising, and customer analysis\\nCapable of telling the big picture story and making recommendations based on trends founds in the data\\nExcellent communications skills and deep knowledge of marketing trends\\nAble to mentor a junior analyst, once he/she is on-boarded\\nExperience in the QSR space or related industry]\", \"[Piper Companies is currently looking for a Customer Quality Data Analyst in West Chester, PA to work for one of the largest medical device companies globally focused on orthopaedic and neuro products and services., The consultant will be responsible for data ETL, database management and visualization/ analysis of data to support complaint excursion/ signal detection, management reporting (metrics)/ process monitoring, audit requests, and special projects associated with Customer Quality and business data., Responsibilities for the Customer Quality Data Analyst:, Perform data extraction and transformation to deliver operational reporting and predictive outcomes analysis\\nMethodically documents assumptions, methods and results through code commentary and preparation of verification/ validation reports\\nWorks with internal customers to define required data sets/ views, assists in prioritization and planning including appropriate scheduling of tasks, properly contextualizing materials as appropriate (ex., Strong Candidates will also have:, \\nZapier, Slack API, Netsuite ERP/SOAP API, Google API.Highly proficient with Microsoft Excel and Google Apps.You are a strong team player who will interact with a global team, gather business requirements, and bring order to chaos by becoming and expert in the operation‚Äôs nuances, and creating and maintaining state-of-the-art data solutions, on Google dashboards for Tableau.Guide and help other teams in using our ads data, \\n\\nWe are the fastest growing health information site on the planet, and the 2nd largest health site in the US (per comScore)!Extensive experience manipulating and analyzing complex data with SQL, Python and/or R. Knowledge of Google BigQuery and Java/Scala is a plus.Hallmark is a company rooted in connecting people.Experience with at least 2 of the following data ecosystem elements such as Hbase, MongoDB, Cassandra, and/or CouchDB; graph databases such as Neo4j; Hadoop, MapReduce, and/or Spark; AWS, Google Cloud, and/or Azure\\nMinimum of 3 years of fluency in a JVM language such as Java or Scala, or demonstrated mastery of another language\\nExcellent data management and software development practice\\nThe ability and desire to coach and learn from other excellent practitioners\\nExceptional verbal and written communication, interpersonal and problem-solving skills such as required to negotiate scope and resources, manage projects, and synchronize activities with team members, stakeholders, and management, \\nExperience with Platform-as-a-Service software such as Cloud Foundry or Kubernetes; demonstrated experience building cloud native applications\\nKnowledge of data science practices, to better steer our efforts to support them through the infrastructure we create\\nPublic contributions to conference presentations, community forums (e.g.SQL or other querying languages\\n\\nDashboard and visualization software (Tableau, D3, Mixpanel, Flurry, Google Analytics, etc.to ensure data is quickly and reliably available in all contexts\\n\\nPrepare technical documentation to include as-built design, requirements, and Standard Operating Procedures\\n\\nInterface with the broader Forcepoint data science team about analytic opportunities and accomplishments in the field to drive the evolution of the Forcepoint UEBA platform\\n\\nProvide technical briefings to customer leadership and Forcepoint corporate leadership as required\\n\\nCoordinate tasks and activities with various groups within Forcepoint, the government or partners\\n\\n, Required Skills & Experience:\\n\\n, Experience writing modular and reusable code in Python\\n\\nFacility in scripting and troubleshooting application errors in Linux/Unix environments\\n\\nExperience with the ETL: cleaning, transforming, and ingesting large datasets\\n\\nExperience with full Software Development Life Cycle (SLDC) from requirements through to testing and deployment\\n\\nPossess strong analytical, verbal, and technical written communication skills\\n\\nMust be able to coordinate collaboratively across traditional engineering disciplines and effectively engage with customers\\n\\nMust be eligible to work in the US\\n\\n, Desired Skills:\\n\\n, Prior technical experience in finance and/or information security organisations\\n\\nExperience with Apache NiFi and high volume ETL tasks\\n\\nIntegration experience with data stores such as Elasticsearch, PostgreSQL, Splunk, ArcSight, Cloudera, etc.Experience with Google Analytics API and Facebook Business Manager API is a plus., \\n\\nReady to Grow: The BI team is the engine driving Sun Basket's stupendous growth, and you are eager and ready for this job to get bigger over time.[Adept at researching, testing, and analyzing.Review existing analytics to make informed data-driven recommendations for SEO improvements.Collaborate with internal teams to recommend and implement SEO improvements to a wide variety of sites.Keep current with trends and advancements in technology, SEO, UI/UX, Google algorithm updates, etc.Ability to manage several projects simultaneously in a fast-paced environment.Help prioritize projects for maximum impact in as short a time as possible.Assist SEO team with site audits through crawling tools and personal direct assessment to maintain best practices as well as diagnosis potential issues., A strong analytical mind, with demonstrated experience with SEO.A great communicator, boiling complex concepts down into clear, actionable instructions.A true collaborator, working with multiple stakeholders across teams to educate, influence, and execute.Willingness to dive in and research a problem from multiple points-of-view, provide supported conclusions, and lay out a clear go forward game plan.]And that‚Äôs where you come in‚Ä¶, \\n\\nYour background includes:, \\n3+ years of industry data analysis experience, with solid knowledge of statistical methods\\nBachelor‚Äôs Degree, preferably in a STEM discipline\\nExpert SQL skills and experience querying very large data sets\\nProven ability to thrive using multiple mixed, varied, and inconsistent data sources\\nFundamental knowledge of project management methodologies\\nComfort presenting complicated material to diverse audiences\\n, To take things a level up, it would be nice to have:, \\nExperience with Google BigQuery, Tableau, JIRA and/or other project management software\\nExperience working for a social or mobile game developer\\nExperience working in the performance ad space\\nUnderstanding of game design concepts and principles\\nMaster‚Äôs Degree\\n, Joining a team of highly-motivated individuals inquisitive spirits who are always searching for the answers to hard questions.In this role, you will be working across industry sectors such as retail, finance, healthcare and high-tech and you'll get an opportunity to solve some of the most challenging business problems., \\n\\nQualifications:, \\n\\n5+ years of demonstrated data engineering experience\\n\\n3+ years of experience with Big Data Technologies like Hadoop or Hive\\n\\n 2+ years of experience scripting using Perl, Python, Ruby, or other programming languages\\n\\nAdvanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases\\n\\n3+ years‚Äô experience in custom ETL design, implementation and maintenance\\n\\nPreferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure\\n\\nBachelor‚Äôs degree in CS or related discipline preferred]\", 'Self-motivated, proactive, and able to work cooperatively in a team environment, ', 'Who We Are:', 'Experience with at least one statistical analytical programming language, including Python or R', 'Synthesize data from multiple sources, developing assumptions where needed, to drive customer insights and strategy development', 'GCP, Linux, Kubernetes, Dockers, New Relic, Elasticsearch, Kibana', 'Identifying nuances in data to optimize our clients‚Äô business', 'Hands-on experience writing complex SQL queries and working with relational databases such as Oracle DB2 and SQL Server', 'Own our data infrastructure and use Supermetrics and Google Spreadsheets to ensure uptime on all client reporting', 'Experience with the following is a plus: Splunk, Azure Kusto, Azure Machine Learning Studio and TLC, Jupyter]\"', 'Ability to obtain a security clearance', '[M inimum Requirements:\\n]', '3+ years of experience programming in Java and Unix shell scripts', 'Conduct quantitative research and analysis requiring complex data retrieval that results in actionable insights and recommendations, ', \"Assist peer groups in the development of, and reporting on, additional KPIs and metrics illustrating the success of customers' digital campaigns, \", 'Own business forecasts ‚Äì overall and by product', 'Google Analytics or similar user funnel analytics tools', 'Work daily with product managers, engineers, and designers to discover and guide the most impactful product investments, ', '[\\nCB\\n]', 'Experience with the development of Hadoop, MapReduce, or HDFS', 'Present information that summarizes overall application or technology status and trends for business level review', 'Familiar with Google Cloud Platform Service cloud services like: Cloud Sql, BigQuery, DataFlow, DataPrep, AppEngine', \"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; New York, NY, USA, \\n\\nBusinesses that partner with Google come in all shapes, sizes and market caps, and no one Google advertising solution works for all.The goal of the residency is to help residents become productive and successful AI researchers., As part of this program, Residents collaborate with distinguished scientists from various Google AI teams working on machine learning applications and problems.If you're as passionate about your future as we are, join our team., \\n\\nKPMG is currently seeking a Sr Associate, Data Science to join our Ignition practice., \\n\\nResponsibilities:, \\n\\nWork closely with various KPMG's Tax functional teams and clients to incorporate cognitive and NLP models and algorithms into both KPMG and client solutions\\n\\nDefine and develop new Tax solutions leveraging approaches such as Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, image recognition, deep learning, Machine Learning, cognitive science and analytics\\n\\nDesign and implement cognitive computing/AI applications using some combination of the following commercial and open source platforms and libraries such as Microsoft AI, Google AI, AWS AI, IBM Watson, Tensor flow, Keras, Spark, Mahout, Torch, Caffe, ScIkit-learn, and NLTK, \\n\\nQualifications:, \\n\\nMinimum of five years of IT industry experience with at least three years of experience in one of the following domains of interest - Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, Image Recognition, Deep Learning, Machine Learning, Cognitive Science and Data Analytics\\n\\nMS or BS in Computer Science, Applied Statistics, Engineering, Science or other quantitative discipline with specialization and experience in Artificial Intelligence, Machine Learning, Natural Language Processing, Cognitive Science or other related areas\\n\\nExperience working with leading cognitive computing commercial and open source platforms and libraries such as IBM Watson, Google AI, Microsoft AI, AWS AI, or Apache Mahout\\n\\nDemonstrated expertise with analytics and cognitive engagements across design and implementation\\n\\nExcellent verbal and written communication skills with the ability to work with diverse teams in a highly matrixed environment, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.As a cross-functional and global team, it's our job to help keep the lights on and the ads relevant., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.Degree(s) should be in a technical discipline such as Computer Science, Engineering, Statistics, Physics, Math, quantitative social science\\n\\nWork experience as an engineer highly desired\\n\\nExperience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\\n\\nRequired: SQL, Python, R, linux shell scripting\\n\\nDesired: Scala, Java, or Ruby\\n\\nExperience with machine learning and computational statistics packages (sci-kit learn, nltk, statsmodels, networkx, gephi, arules, glmnet, bigrf, caret, igraph, MLLib, GraphX, MADlib, Weka, etc)\\n\\nExperience with visualization tools (seaborn, d3, plotly, bokeh, ggplot2, rCharts, networkD3, Shiny, Tableau, CartoDB, etc)\\n\\nFrequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\\n\\nBonus Points for: experience with web application frameworks (Shiny, Flask, Tkinter, Ruby on Rails, Pyramid, Django, etc)\\n\\nDouble Bonus Points: previous work on medical applications and/or with claims data]\", 'Everyday Responsibilites:, ', 'Experience leading/advising software development teams', 'Experience with ELT/ETL development, patterns and tooling', 'Work with clients to discover data sources, and create data requests; Lead the ETL process to ingest structured data and annotation processes to enrich unstructured data; Leverage a variety of data sources (social media, news, internal/external documents, images, video, voice, emails, financial data and operational data)', '[\\n3 years of experience with Big Data, systems, including Hadoop, Hive, and Pig\\nExperience with ETL tools, including NiFi and StreamSets\\nExperience with Java\\nExperience with using Cloud services, including Amazon Web Services (AWS), Azure, or Google Cloud\\nTop Secret clearance\\nBA or BS degree\\n, \\nExperience with Agile software development\\nPossession of excellent oral and written communication skills\\nBS degree in CS, Computer Information Systems, Information Systems, or a related field\\n]', 'Role Responsibilities, ', 'For research we leverage both Python and R,', 'Proven experience building positive working relationships and working successfully in cross-functional teams, including demonstrated success in managing and influencing without direct authority', 'Supporting marketing initiatives across project and campaign lifecycles, including measurement plans, primary and secondary research, and performance reporting', 'Deep understanding and empathy for users', 'Ability to manage multiple projects and deliver against aggressive deadlines, ', 'Experience with SAS, R, Python, Tableau, SQL, Hadoop, Spark', 'Apache Kafka, Nginx', 'Excellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills', ', Expertise in a query language such as SQL or equivalent, ', 'Dedication to work/life balance which includes flexible work arrangements and tools to support your lifestyle', 'Familiarity with capabilities within AWS, Azure, or Google Cloud Services', '[Partners with our Marketing Engagement, In-Product Discovery, and Machine Learning Teams to drive cross-sell, upsell and retention outcomes\\n\\nCreates and deploys advanced statistical models and analyses from relational data sources to power initiatives and programs\\n\\nPresents technical findings in a summarized form to non-technical audiences; translates complex quantitative data into succinct actionable insights\\n\\nDesigns, implements and measures results for A/B and multivariate tests; drives end to end test process from launch, to readout, to recommendation, to retest\\n\\nMeasures and reports on actual performance vs target; performs analysis to identify root cause drivers of variances\\n\\nDevelops and maintains reports and dashboards to track performance\\n\\nConducts research projects, including surveys, to produce actionable customer insights\\n\\nWorks with members of multiple departments to understand processes, data and reporting requirements, At least 2 years of experience in an analytical role in a business environment.Helping build a storage and caching system that facilitates both a deep archive of data that can explored and fast-moving real-time data that is accessible to thousands of users\\n, \\nStrong experience with scientific Python, particularly NumPy and Pandas\\nBuilt systems on Linux and cloud platforms, preferably Google Cloud Platform (GCP) or Amazon Web Services (AWS)\\nWorked with both relational databases (preferably Postgres/PostGIS) and some sort of Non-SQL database (preferably MongoDB)\\nFamiliarity with automated deployments and continuous integration\\nKnowledge of service-oriented and/or microservice architectures\\nExperience building services that interface via message queues, RPC, or REST interfaces\\nA passion for automated testing\\nExperience with parallel processing systems (joblib, Dask, Ray, Spark, Hadoop)\\n, \\nBachelor‚Äôs degree in Computer Science, Computer Engineering, or similar, or equivalent experience\\n4+ years of relevant experience\\n, \\nExperience with geospatial data, especially gridded data (GRIB, GeoTIFF, NetCDF, BUFR)\\nExperience with other scientific Python libraries or frameworks (SciPy, sklearn, skimage, xarray, Numba, etc.)This role includes heavy technical knowledge in implementing Google Tag Manager, gathering insights from Google Analytics and other analytics platforms as well as knowledge of the marketing life cycle and common marketing channels., General Responsibilities, Responsibilities are applicable based on the position focus/channel, Helps to identify, analyze/execute new and potential product/services, markets, and advertising opportunities.Experience writing production ready code is a plus\\nExperience with GCP or other cloud platforms is a plus\\n, If you are a true data enthusiast who wants to elevate yourself and your company to the next level then please send your Word resume to afagin@daleyaa.com for consideration., #LI-AF1]', 'Support the integration of additional data sources into New Visions data warehouse and data tools', 'Support all cross-functional teams by prioritizing and responding to ad hoc analytics needs, ', 'Knowledge of object-oriented programming, including Java, C++, and various machine learning algorithms, their design, capabilities, and limitations', \"[Los Alamos Technical Associates, Inc. (LATA) is a premier employee-owned engineering services company with over three decades of success.Experience with BI / Big-data solutions (Hadoop, Google Cloud, Amazon Web Services Microsoft Azure)\\n\\nExperience with Microservice development is a plus\\n\\nCapable of guiding and inspiring team members, peers and stakeholders to drive the best possible practices\\n\\nAbility to think out-of-the-box and give pleasant surprises to end users over the data, Competencies, \\n\\nExcellent thought leadership in bioinformatics technology\\n\\nStrong customer and quality-focus is a must.We are building shared components to unify & advance recommendation systems, e.g., embeddings and approximate nearest neighbor solutions., \\n\\nMLX team has a unique mix of ML engineers & scientists who work together to explore & build new prototypes and scale them to augment Twitter‚Äôs ML capability., As a Project and Data Analyst, you'll deliver innovative solutions that help our entire team keep pace with Google‚Äôs rapidly changing landscape.Experience using streaming data processing techniques is a plus\\n\\nBachelor's degree from four-year college or university; four years related experience; or equivalent combination of education and experience\\n\\nExperience with Agile]\", 'Experience working with Big Data', \"The person we're looking for:, \", 'Modeling ‚Äì machine learning technique is a plus (i.e., Na√Øve Bayes, Random Forests, Deep Learning, Ensemble).You have interacted with clickstream data (e.g., command of Google Analytics) and raw data ingested from paid marketing channels (e.g., Adwords, Facebook) and have derived insights from those data sources to positively-influence the business.)Working knowledge of cluster computing environments including Hadoop, Spark and HiveExperience with data visualization tools and techniquesWorking knowledge of multiple analytics and programming languages such as R, Python, SAS, Julia, Java, Scala or similarUnderstanding of relational databases and SQL, Desired Characteristics, Experience with multi-billion record datasets and leading projects that span the disciplines of data science and data engineeringExperience with television ratings and digital measurement tools (Nielsen, Rentrak, comScore, Omniture, etc., Job Summary:', 'Work with clients‚Äô software architects and engineers to provide technical solutions w/ company‚Äôs technologies', 'Growth mindset; the ability to thrive in a dynamic and collaborative environment]\"', 'Preferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure', '5 years of experience in data engineering in a cloud based environment', '[Principal Data Scientist, \\n\\nSouth Bay, \\n\\nHarnham are currently partnering with a well funded Series A start up based in the South Bay in their search for a Principal Data Scientist, \\n\\nWith a high degree of flexibility and ownership, you will be working with a high performing, mission driven team, that is disrupting the way we understand, diagnose and treat numerous illnesses.Programming / Scripting (Python, Java, C/C++, Scala, Bash, Korn Shell)\\n\\nLinux / Windows (Command line)\\n\\nBig Data (Hadoop, Flume, HBase, Hive, Map-Reduce, Oozie, Sqoop, Spark)\\n\\nCloud Platforms (AWS, Azure, Google Cloud Platform)\\n\\nData Concepts (ETL, near-/real-time streaming, data structures, metadata and workflow management)\\n\\nData Integration Tools (Ab Initio, DataStage, Informatica, SSIS, Talend)\\n\\nDatabases (DB2, HANA, Netezza, Oracle, Redshift, Teradata, Vertica)\\n\\nMarkup Languages (JSON, XML, YAML)\\n\\nCode Management Tools (Git/GitHub, SVN, TFS)\\n\\nDevOps Tools (Chef, Docker, Puppet, Bamboo, Jenkins)\\n\\nTesting / Data Quality (TDD, unit, regression, automation)\\n\\nSolving complex data and technology problems\\n\\nLeading technical teams of 2+ consultants\\n\\nAbility to design components of a larger implementation\\n\\nExcellent communication to narrate data driven insights and technical approach\\n]', 'Participate in the design, set up, and evaluation of A/B and multivariate testing', \"[This is your opportunity to join AXIS Capital ‚Äì a trusted global provider of specialty lines insurance and reinsurance.Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \\n\\nPredictive Science is looking for a Senior Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results., The CX Lab conducts scaled research on Google's advertisers., We do research differently here at Google., Knowledge and Experience:\\n\\n, Advanced degree or equivalent work experience in a quantitative discipline such as statistics, computer science, actuarial, applied mathematics, or engineering\\n\\nExpertise in SQL query development\\n\\nBig Data expertise in Hadoop, including: Hue, HDFS, Hive, Python, Spark, GitHub, and data visualization\\n\\n2+ years of Experience with Cloudera Data Science Workbench (CDSW)\\n\\nShare and Document Best Practices for CDSW including project collaboration, production code migrations, and automation\\n\\nKnowledge of, or a desire to learn, IBM SPSS Modeler\\n\\nSome on-call support may be required.Learn how to use and navigate our various databases and write scripts using our data for various analyses\\n\\nLearn about our existing code-base and best practices\\n\\nCollaborate with other data scientists to help build our patient-physician matching products, Integrate into long-term multi-data-scientist ventures and deliver on one or several short-term individual projects\\n\\nPerform analyses that help us better understand patients and/or physicians, while helping you get familiarized with our data\\n\\nSpend time with Staff Physicians and other medical domain experts to learn about the world of healthcare\\n\\nDevelop an understanding of both immediate business objectives as well as longer term company aspirations to develop intuition around prioritization and trade-offs between short-term deliverables and longer term R&D efforts, \\n\\nDevelop creative solutions to diverse problems including engineering challenges, unstructured data messes, ontology development, and machine learning applications\\n\\nLead and develop major projects from end-to-end encompassing planning, design, technical implementation, debugging, roll-out to Product & Engineering, testing, and iteration\\n\\nOperate at level of sophistication in statistics, machine learning, or computer science that is publication-worthy\\n\\nRegularly monitor pull requests, perform code reviews, and produce excellent peer reviews on projects prior to shipping to Product & Engineering\\n\\nEvaluate and experiment with new technologies and tools prior to wider adoption by the team\\n\\nWork closely with analysts, data scientists, product managers, and engineers, \\n\\nMinimum 2 years of industry production experience as a Data Scientist or Engineer\\n\\nExcellent verbal communications, including the ability to clearly and concisely articulate complex concepts to both technical and non-technical collaborators\\n\\nDegree(s) should be in a technical discipline such as Computer Science, Computational Biology, Engineering, Statistics, Physics, Math, quantitative social science\\n\\nExperience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\\n\\nRequired: SQL, Python, R, linux shell scripting\\n\\nDesired: Scala, Java, or Ruby\\n\\nExperience with machine learning and computational statistics packages\\n\\nExperience with visualization tools\\n\\nFrequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\\n\\nBonus Points: previous work on medical applications and/or with claims data]\", 'At least 7 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling', '1-3 years of professional software development experience', 'Strong statistical analysis background]\"', '5 - 7 years utilizing Statistical Software', 'Write or modifies code for complex software programs, components or applications', 'Preferred Qualifications:, 2+ years experience with AWS cloud2+ years of experience in Java, Scala, or Python2+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python2+ years of experience building data pipelinesAt least 1 year of Cloud (AWS, Azure, Google) development experienceExperience with Streaming and/or NoSQL implementation (Mongo, Cassandra, etc.)Be versed in Amazon Web Services, Google Cloud Platform and/or Microsoft Azure cloud solutions, architecture, related technologies and their interdependencies.To achieve this, we‚Äôre working on projects that utilize the latest techniques in Machine Learning (including Deep Learning approaches like Google Brain) and Natural Language Understanding., We‚Äôve already been joined by some of the best minds, and we‚Äôre looking for talented Research Scientists that have applied experience in the fields of Machine Learning, Natural Language Processing and Machine Intelligence to join our team.Hadoop, Spark or Vertica) is required', 'Expert in SQL and Excel required', ', Keeping a pulse on day-to-day performance data, including display media, site, search, email, and/or social campaigns', 'Experience with analytical visualization tools such as Tableau, Looker, D3.js or similar tools', 'Coding experience with one or more of the following languages: Java, C++, Python, Go and/or JavaScript', 'Bachelor‚Äôs Degree in related field and Masters or higher a plus', 'Industry Experience with one or more of the deep learning frameworks (CNTK, MXNet, TensorFlow, Caffe/Caffe2, PyTorch) is a plus', 'Reverse-engineer implemented solutions to understand the client problem and resolve client challenges', '- Experience with database marketing, CRM platforms, reporting and analysis design, measurement reporting based on relevant business metrics, ', '[Note: By applying to this position your application is automatically submitted to the following locations: Seattle, WA, USA; New York, NY, USA; Mountain View, CA, USA; Pittsburgh, PA, USA, \\n\\nResearch in machine intelligence has already impacted user-facing services across Google including Search, Maps and Google Now.Experience with cloud platforms such as Amazon Web Services (AWS) and/or Google Cloud Platform (GCP)\\n\\nExperience with power engineering and power-related data.Work with cross-functional partners across the business\\n\\n, QUALIFICATIONS\\n\\n, Advanced degree in Computer Science, Statistics, Mathematics, Economics, or related field\\n\\n3+ years of work experience in data science and/or predictive analytics functions in business environment (preferably internal or external consulting)\\n\\nProgramming experience in one or more of Python and R, or other open-source programming languages\\n\\nExperience with big data technology (such as Hadoop, Hive, Data Lake), either cloud or on-premise platforms\\n\\nKnowledge of statistics and experience using statistical packages for analyzing datasets\\n\\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\\n\\nAbility to write queries, generate reports, and present findings\\n\\nStrong communication and facilitation skills\\n\\nExcellent planning and organizing skills\\n\\nStrong ability to continuously learn and upgrade technical skills\\n\\n, EOE/Disabled/Veterans]', 'Collaborating with internal and external consulting teams on transformation projects', 'Experience solving problems using one or more of the following techniques: Regression, Support Vector Machines, Decision trees, random forest, Boosting, PCA, KMeans', 'Ability to work cross-functionally with different teams with varying technical levels', 'BA or BS degree', 'ibm.com/ibm/responsibility/corporateservicecorps/, At least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling', '[Our client, One of the biggest Software Companies, is actively looking for a Data Analyst to join their growing team in San Jose, CA!, The Service Management Analyst will be responsible for analyzing macro trends across a Cloud Technology and Digital Media service landscape which includes a rich ecosystem of services supporting customers, businesses, and employees., A background in Incident, Problem, Change, and Release Management will provide the context necessary to analyze the datasets., Preferred Qualifications:, Analytical mindset and critical thinking ability\\nAbility to use data to derive actionable insights (including skills in designing data models, collecting data, data preparation, data augmentation, data mining)\\nFamiliarity with Service Management and ITIL Framework (Incident Management, Problem Management, Change Management, Release Management)\\nAbility to work with relational datasets and excel spreadsheets\\nAbility to build partnerships with cross functional teams in order to achieve objectives and results\\nAbility to work through failed attempts and look at it as a learning experience on the road to success\\nEffectively communicate with leadership and technical personnel by ‚Äútranslating‚Äù and conveying ideas and insights between the two\\n, Experience:, 3-5 years experience working with data models and conducting data analysis and applying insights learned from the data into working processes to achieve desired results\\nSQL, Excel, Python, or Tableau Experience\\n, The Offer:, Up to $65/hr DOE\\nHSA Health Savings plan\\n, Benefits:, Medical insurance\\n401k\\nTransportation benefits\\nPaid Sick Time\\n, Benefits & Perks, A competitive benefits package is offered complete with: health, transportation benefits, accrued sick-time off, and a 401k option.]Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google Cloud Platform ‚Äòbig data‚Äô technologies.Your relationships with customers are crucial in helping Google grow its Google Cloud business and in bringing our product portfolio into companies around the world., Our Analytics and Data Science team is responsible for the data needs of the Google Suite support services, a large global support team for customers around the globe.Responsibilities:', 'Stats Engine White Paper - http://pages.optimizely.com/rs/optimizely/images/stats_engine_technical_paper.pdf, ', 'Hands-on experience building data processing pipelines (e.g, in Storm, Beam)', '5+ years of relevant Data Warehouse work experience', 'ibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally', 'Works on site at Vue offices in Los Angeles, CA', 'Conference Talks, ', '[Job Description, \\n\\n\\nWhat You‚Äôll Get to Do:, \\n\\nJOB DESCRIPTION:\\n\\n, The Business Intelligence Data Analyst is a software data analysis/engineering position for BIG Data Analytics, using SAS/IBM COGNOS Solutions to help business clients.Lucktastic is consistently ranked in the top 3 on Google Play Store‚Äôs lifestyle category (beating brands like Tinder, Zillow, and Starbucks) and are regularly in the Apple Store‚Äôs top 10.\\n\\n, Jump Ramp‚Äôs team of nearly 40 employees works out of an airy 11th-floor loft in Midtown Manhattan‚Äôs Fashion District, and includes action-figure collecting developers, tattooed fixed-bike-riding artists, Classic Rock-singing CSR reps, globe-trotting marketing and sales people, and two founders who keep their shirts untucked and their office door open., \\n\\nFollow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com., Hallmark is an equal opportunity employer.[Hands on experience in implementing Data Lake and AWS Cloud DATA and Enterprise Data Warehouse Solutions, Providing Solutions for Big Data Platform infrastructure for across AWS VPC, Understand GDPR laws, Architect and standardize the way data is ingested, processed and exported, Expertise working with AWS and Other Cloud infrastructure:, Strong Database knowledge in Cloud based Database like RedShift, Snowflake etc, Monitoring (CloudWatch, and ideally commercial solutions like DataDog, Splunk, PagerDuty), Identity Management & Security (e.g.Experience with analytics tools such as Adobe Analytics or Google Analytics.Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]\\n[Twitter users generate many terabytes of data every day; Twitter engineers run hundreds of experiments; Twitter Data Engineers build data pipelines and data processes that calculate metrics and scale increasingly sophisticated models of users and content., ', 'Day-to-day, your role includes:', 'Provide publicly available software for use by the scientific community', 'Experience with Python and/or Java preferred, ', 'Strong project management skills with ability to supervise multiple projects', \"[Your consulting projects will include integrating data in a virtual manner for operational and/or informational purposes - Integration of 100+ data sources for a Customer Service Multichannel IT Infrastructure; implementation of Logical Data Warehouses and Virtual Datamarts to enable modern Business Intelligence solutions, Integration Layers for Hadoop-based Data Lakes, and support for Agile Operational Reporting on a diverse Big Data infrastructure are just a few flavours of your future projects.Prior experience with Google Analytics and web analytics platforms such as Adobe Analytics, Test & Target, Maxymiser preferred.Built software with technologies like ElasticSearch, GraphQL, and Google Cloud Platform.can hit the ground running and bring new analytical approaches not currently practiced by Hallmark., Require Skills & Experience:, \\n\\nBachelor's or Master's degree in Electrical or Mechanical Engineer or Physics\\n\\nStrong experience with Apache Spark/Spark streaming\\n\\nExperience building out pipelines for API's\\n\\nExperience in production level code\\n\\nExperience working in the cloud (AWS or Google)\\n\\nKafka experience a plus, \\n\\nBenefits:, \\n\\n$160,000 - $180,000\\n\\nNew amazing office\\n\\nFull medical, dental, vision]\", 'Job Summary, ', '4+ years experience within business/marketing/data analytics, ', 'ibm.com/ibm/responsibility/corporateservicecorps/, At least 2 years of experience working on predictive analytics and data mining projects', '[At Yapstone, we approach payments with the same startup mentality that we had when we launched our first payment solution in 1999.IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.]\"[Required:, \\n\\nExperience in AWS technologies such as EC2, Cloud formation, EMR Cluster, AWS S3, Splunk, and AWS Analytics.Maintain internal Alloy logic to automate the interpretation of data across channels through the unified Alloy data model, \\n\\nStrong knowledge of Python and SQL, especially in data wrangling and ETL applications\\n\\nFamiliarity with Java is a plus\\n\\nExperience in interpreting and manipulating supply chain-related datasets (Point-of-sale, logistics/EDI, product master)\\n\\nWorking knowledge of Selenium and other web-scraping tools, \\n\\nGoogle Cloud Platform\\n\\nPostgres, Redis\\n\\nPython, modern Java, React]', 'Experience with using statistical software applications, including SAS, R, MATLAB, SPSS, or Stata', ', Manage infrastructure for processing large data sets for use in NV data tools and analyses, ', 'Own business intelligence and reporting of overall company KPIs and performance metrics by product, ', 'very hardworking', 'BS degree in Operations Research, Data Science, Applied Mathematics, CS, Engineering, or a related technical field preferred; MS degree in Operations Research, Data Science, Applied Mathematics, CS, Physics, Statistics, Engineering, or a related technical field a plus', 'Excellent written and oral communication skills; must be capable of effectively articulating technical concepts to executive level and business audiences', '[\\n\\nFor the 28th year, MSK has been named a top hospital for cancer by U.S. News & World Report.[', 'Manage and design reporting dashboards for Executive view', 'Problem solver with a track record of addressing root-cause issues', \", Bachelor's degree in Computer Science or related field, or equivalent experience\", ', Required Application Materials', '[Description, The Position, \\n\\niD Tech is looking for a Temporary Machine Learning Content Developer to produce the educational content and classroom tools to be used by our machine learning summer instructors across the nation with Python and TensorFlow., As an Application Data Engineer, you will develop solutions to high visibility data challenges in one of the fastest growing businesses within Google., Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running.We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status]', 'Participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government', 'Act as a backup to Analytics partners to perform more complex data pulls based on ad-hoc requests as necessary', \"[Are passionate about working on cutting edge, high profile projects and are motivated by delivering solutions on an aggressive schedule\\nAren‚Äôt satisfied with status quo, insatiably curious, and regularly look for creative ways to solve problems and help your team meet commitments\\nLove learning new technologies and sharing them with your team\\nHave a keen interest in using any and all appropriate tools, especially Cloud-based and Open Sourced, to solve the problem at hand\\nHave strong verbal and written communication skills, and enjoy participating in dynamic, face-paced collaborations with customers, vendors, and other engineering teams to solve complex business problems together\\nUse your experience and leadership skills to motive your teammates to deliver high quality results in a fast-paced work environment\\n, Work within a team of like-minded professionals to design, build and deploy critical business and mission data-centric applications in a production environment\\nDesign and implement appropriate data extraction, transform, and load (ETL) processes to properly prepare data, ensuring data quality and accuracy, for consumption by business and mission applications\\nIdentify, retrieve, manipulate, relate and/or exploit multiple structured data sets from various sources\\nDesign and implement data storage, sharing, and dissemination environment, ensuring support for all relevant agency and community policies\\nEngineer suitable data management and governance procedures and provide production support when required\\nDesign and develop automation workflows, perform unit tests and conduct reviews to make sure your work is rigorously designed, elegantly coded, and effectively tuned for platform performance, and assess the overall quality of all delivered components\\n, Master's Degree preferred, or a Bachelor‚Äôs degree and 4 years‚Äô experience, or 10 years of specialized experience\\nMinimum 4 years‚Äô experience working on complex data/database projects as a data analyst, data architect, or database engineer\\nTS Clearance with ability to obtain an SCI and CI poly\\n, Certified Data Management Professional (CDMP), Microsoft Certified Solutions Associate (Business Intelligence) or equivalent certification(s) strongly desired\\nExperience building n-tier web-based applications using SQL and non-SQL back-ends\\nExperience with large-scale data processing tools, such as Spark, NiFi, Hadoop, Kafka, etc.Using analytical rigor and statistical methods, you mine through data to identify opportunities for Google and our clients to operate more efficiently, from enhancing advertising efficacy to network infrastructure optimization to studying user behavior.Experience with Google Analytics is a plus\\n\\nStrong technical aptitude and a willingness to learn and adapt to new and evolving technologies\\n\\nExcellent communication skills\\n\\nTeam Skills: facilitation, presentation & group dynamics, \\n\\nMuch has changed since our start in 1912, but the important things remain the same.in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.Proficiency developing in one or more languages such as C++, Python or Java.Self-starting, requiring minimal supervision with strong problem-solving skills.Excellent communication and teamwork skills., \\n\\nDESIRED QUALIFICATIONS:, Hands-on experience with Cloud environments, such as AWS, Google Cloud, or AzureExperience with Cloudera, Job Function\\n\\n, R&D, ___________________________________________________________________________________, \\n\\nPrivacy Statement, \\n\\n***Keysight is an Equal Opportunity Employer.Experience working with Journey, Voice of the Customer and operational data sources such as Splunk is preferred\\nExperience working with Web and native Mobile app data\\n\\nExperience applying aggregations, segmentation, statistics, clustering, to complex business problems.Accepted file types are Microsoft Word (DOC or DOCX), PDF, HTML, or TXT., In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States.Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, The following is required to be considered for this role:, Bachelor‚Äôs degree in Business or quantitative field (Data Science, Statistics, Analytics, Economics, Mathematics, Computer Science).TrueCar offers a specialized digital marketplace and private targeted incentive solutions to help make that spend more efficient, while at the same time providing exclusive savings to the 6M+ consumers who visit our car buying service sites\\n\\n, ABOUT THE JOB:\\n\\n, Serve as the champion in data visualization techniques, analytics, dashboard design, and best practices for information delivery\\n\\nOwn all aspects of analytics, reporting, design, and optimization insights for our all of our TrueCar OEM affinity partners\\n\\nBuild, maintain and iterate on Tableau data visualizations\\n\\nSupervise creation of all visual reports in Tableau for internal and external clients that summarize findings clearly and effectively\\n\\nCollaborate with data engineering team to design data pipelines for Tableau Server\\n\\nLead data analysis projects from the research phase to production\\n\\nDevelop analytics and reporting capabilities for new OEM and Partner programs using Tableau and PowerPoint as they launch\\n\\nTrack and measure optimization efforts using Google Analytics or Redshift/SQL\\n\\nUnderstand program results from key marketing and product initiatives and articulate the key drivers of program success or needs for improvement\\n\\nLeverage insights created by the OEM Partner & OEM team into actionable recommendations to improve program performance\\n\\nMust be well-spoken and comfortable with presenting to an executive audience\\n\\nAnalyze digital marketing campaigns and provide cost analysis\\n\\n, WHAT YOU NEED:\\n\\n, 3 - 5+ years‚Äô experience working in an analytics role\\n\\nA passion for using data visualization to tell complex data stories\\n\\nAbility to communicate complex ideas to any audience, ranging from teammates to business executives\\n\\n3+ years of profession experience creating Tableau dashboards\\n\\nExperience with publishing and maintaining workbooks on Tableau Server\\n\\n3+ years of experience with database software (RedShift, Hive, SQL, MYSQL, ‚Ä¶)\\n\\nExperience with statistical programming software (Spark, R, Python preferred)\\n\\nProficiency with Tableau Desktop and Server\\n\\nBachelor‚Äôs Degree in Statistics, Data Science, Economics, CS, Engineering or related field\\n\\nStrong analytical background, with experience identifying trends and key takeaways from data\\n\\nAbility to analyze, organize, and integrate large amounts of complex data into clear and concise presentations and status reports\\n\\nOutstanding attention to detail and time-management skills\\n\\nExpert knowledge in Excel and PowerPoint required\\n\\nExperience tracking web metrics using Google Analytics\\n\\n, NICE TO HAVE:\\n\\n, Passion for the automotive and internet industries\\n\\n]\", 'Applied knowledge on simulation and optimization', 'At NRG, we apply advanced analytics and modeling to address challenging business problems.Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, Bachelors or Master‚Äôs degree in Statistics, Physics, Math, Engineering, Economics, Finance, Data Science, Computer Science, Operations Research OR a quantitative field', 'BS degree in CS, Computer Information Systems, Information Systems, or a related field', \"Understands NI's products and how NI engages customers is strongly preferred\", 'Hands-on experience constructing and manipulating JSON and XML documents and working with NoSQL databases such as MangoDB and CouchDB.Have experience in extracting data and building complex data transformation using SQL on MS SQL Server, IBM DB2, Sybase, XML, and other popular data structures.At Raytheon, we work together as one global team creating trusted, innovative solutions to make the world a safer place.You‚Äôll have the opportunity to collaborate with the best AI talents in the company, both inside cloud as well as Google Research, DeepMind and other organizations.Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]', 'Design and analyze rigorous a/b experiments, ', \"[Req.Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \\n\\nPredictive Science is looking for a Data Analyst who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results.Experience with the Google Cloud Platform.Perform statistical analyses and build machine learning solutions to support Google Cloud business needs.Experience with data instrumentation, interpretation and visualization tools (ETL Tools, Splunk, Tableau).Master's degree in Engineering, Mathematics, Computer Science, Supply Chain or related field., \\n\\nCompany Summary, Position Summary]\", 'Experience with NoSQL databases and key-value stores, such as Cassandra, Redis, ', \"The incumbent helps to ensure that the deep insights generated through sophisticated analytics translate into impact at scale in the Pharmacy organization.You won't accept anything less than helping our dealer customers measure the success of their digital campaigns against their business goals with easy to understand dashboards and reports., \", 'Passion for business analytics and working with large amounts of data with demonstrated ability to use data to influence decision making', 'Machine learning is advancing products at Twitter (e.g., Timeline ranking, On-boarding) and Cortex is advancing Machine learning at Twitter.We partner with companies to push the boundaries of what‚Äôs possible‚Äîtogether., ', 'Build multivariate models to arrive at inferences or predict future behavior', 'Develop effective problem statements and drive to resolution, ', 'Three (3) letters of recommendation submitted confidentially by the letter writers to astro@simonsfoundation.org', ', The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.DOD Secret Clearance preferred]\"', 'Splunk, Splunk MLT a plus, ', 'Excellent communication and writing skills', 'Build automated tests to ensure data quality', 'Review documentation and ensure standards are being met', 'Experience in Salesforce Marketing Cloud is a plus', 'Ability to simultaneously understand computer science concepts, data context, and mission objectives while completing projects', 'Experience building tools and automated processes to extract, clean, and distill data in a procedural language of your choice such as Python, Julia or R, ', ', Work with Apache Beam, Airflow, Google Dataflow, BigTable, and BigQuery to build the next generation of the Censys data processing pipeline', '- Conduct ad-hoc analyses that include basic ROI reports and in-depth conversion funnel insights, ', 'Respond to organizational requests for data analysis', 'Experience with Java', ', All applications must be submitted no later than November 15, 2017.', 'Analyze requirements for software programs or application enhancements', 'Preferred experience working with either a Map Reduce or an MPP system', 'Bachelor of Science degree in STEM (Science, Technology, Engineering or Math)', 'Experience working with Distributed Architecture technologies', '[Extensive experience building RESTful APIs, preferably in Java 8/J2EE., Expertise with micro services design and development, including API and cloud based platforms and technologies such as containers a plus., Write code and set coding standards / best practices within the team.It is an exciting time to be in the Greetings business at Hallmark!, WE ARE LOOKING FOR:, Hallmark is in the midst of a data analytics revolution and we need a talented senior-level Data Analytics Lead to join our Customer Analytics team.Learn more at www.hasbro.com, and follow us on Twitter (@Hasbro & @HasbroNews) and Instagram (@Hasbro).]Advanced Degree preferred but not required., 10+ years of professional level experience in a related role', 'Closing date: January 2019., ', 'Work with internal clients and stakeholders to understand, design, and implement analytics solutions tailed to our customers', 'Data engineering experience is highly desirable', 'Demonstrated ability to derive explanatory variables from high-dimensionality collections of data: social, click-stream, SKU-level sales, digital marketing, weather, economic', ', Experience with project management tools and methodologies required.]\"Build algorithms, tools, custom solutions, and new technologies from diverse and large-scale data sets to enhance comScore‚Äôs measurement products, or contribute to new products.Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., ', 'The Company:, ', 'Ability to translate complex requirements for the delineation of distinct customer groups into executable SQL which can return lists of users to send tailored messaging', 'Big picture thinking combined with an exacting attention to detail', 'Assess the performance of tests, updates, and strategic optimizations, Requirements:', 'Concentration in Computer Science, Computer Engineering, or related field strongly preferred', 'Blog Posts, ', 'As a member of this dynamic, exciting team, you will use your expertise in cloud technology to communicate directly with businesses of all types to help them seamlessly adopt Google products and solutions wherever they are on their cloud journey.The team‚Äôs most important roles are to enable fast, rigorous product experimentation and to provide automated tools to generate insights and understanding of our users., ', ', Location', 'Ensure site tagging is implemented properly to provide visibility to impact and value of various initiatives and releases', 'Provide reliable estimates for lead time necessary to develop and execute against functional requirements', 'Operate as the subject matter expert on web analytics, tagging, audience and attribution technologies', 'Solid experience with display ad-serving, 1st party onboarding/targeting, brand study measurement partners, and Site Analytics', 'Strong data visualization skills using Tableau or open-source tools', 'Minimum of 1-2 years implementing solutions in a cloud environment (AWS, Azure or Google)Prior experience leading technical teams of data scientists/engineers at various levels where you were responsible for providing project estimates for your work stream and assigning tasks to other team members', 'Work collaboritavely to establish a stable, repeatable process for working within a cross-functional team to deliver manual user lists and actionable insights', 'Excellent communication skills', 'BS/MS in Engineering, Computer Science, Math, Economics, Statistics, or equivalent experience.Citizenship', '3+ years‚Äô business experience in application of advanced analytics and data mining including predictive algorithms', 'Build and utilize tools and processes that will scale our reporting and analytics capabilities and help shape the data roadmap', 'BS degree', '[\\nDeliver end-to-end analytics projects, including data ingest, data transformation, data science, and data visualization\\nDesign and deploy databases and data pipelines to support analytics projects\\nClearly document datasets, solutions, findings and recommendations to be shared internally & externally\\nLearn and apply tools and technologies proficiently, including:\\nLanguages: SQL (standard and DB-specific), Python, R, Spark/Scala, Bash\\nFrameworks: Hadoop, Spark, AWS\\nTools/Products: Data Science Studio, Alteryx, Jupyter, RStudio, Tableau, PowerBI\\nBuild compelling visualizations and dashboards that address the analytic needs of the end-user/customer\\nPerformance optimization for queries and dashboards\\nDevelop and deliver clear, compelling briefings to internal and external stakeholders on findings, recommendations, and solutions\\nAnalyze client data & systems to determine whether requirements can be met\\nTest and validate data pipelines, transformations, datasets, reports, and dashboards built by team\\nDevelop and communicate solutions architectures and present solutions to both business and technical stakeholders\\nProvide end user support to other data engineers and analysts\\n, \\nExpertise in SQL and Python.Significant scientific background with prior experience in clinical research\\nPhD in relevant domain highly preferred (Data Science, Machine Learning ideally applied to health-related insight generation)\\nAbility to derive robust insights from complex RWD datasets\\nMust have experience in performing data analysis utilizing statistical frameworks (R, SciPy) and ideally experienced already in using environments such as Jupyter Notebooks/Google Datalab\\nSome data engineering experience (ETL, SQL) desirable\\nMust be comfortable working in rapid prototyping environment, using agile approaches to guiding teams and projects\\nSome understanding of drug development process and use of biomedical data for drug development and clinical trials design preferred\\nStrong communication skills; ability to guide small projects, interacting with clients and internal management.We are building a team to develop the technical framework to drive performance and success at Hallmark., IN THIS ROLE YOU WILL:, Automate analytics and data science solutions\\nDevelop robust data pipelines while ensuring data integrity\\nConnect staff to big data from various internal and external sources\\nCreate technical solutions to simplify the processes at Hallmark Greetings\\nHave a proven track record in big data and cloud environments\\n, APPLICATION INSTRUCTIONS:, You must show how you meet the basic qualifications (listed below) in a resume or document you upload, or by completing the work experience and education application fields.Check out the Times Open blog , which is written by engineers and other technical team members, and follow @nytdevs on Twitter to see what we‚Äôre up to.Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\\n\\nExposure to Google Machine Learning is a plus, \\n\\nWe are an Equal Opportunity Employer M/F/Disability/Vet and maintain a drug-free and smoke-free workplace.]You will be a trusted partner in the team tackling the toughest and most impactful analytical problems while making the data accessible to the broader organization., ', 'Ensure quality and timeliness of deliverables that meet expectations while balancing business needs with the appropriate level of analytical rigor', '[Hub Data Analyst\\n\\n\\n\\nThe Fund for Public Health in New York City, (FPHNYC) is a 501(c)3 non-profit organization that is dedicated to\\n\\nthe advancement of the health and well-being of all New Yorkers.[Degree in Analytics, IT, Economics or related field (Advanced Technical or Business Degree a plus)', 'fascinated to learn more analysis techniques', 'Partner with Marketing Managers, Sales, and executives as a strategic thought partner to deliver key insights from web tracking metrics', 'Strong experience wrangling, exploring and cleaning structured and unstructured data', '- Work with manager to identify opportunities to improve campaign analysis and reporting efficiencies, Your Skills, Required Skills and Experience:, ', 'Knowledge of statistical analysis technique', '[Key Responsibilities:\\n\\n, Drive end to end analytical process: from formulation of requirements, data acquisition, identification of analytical methods, creation/validation of models to business-friendly summarization of results\\n\\nInteract with stakeholders to identify critical questions that need to be answered in order for the Analytics team to provide effective KPIs - actionable insights rather than just reports\\n\\nConduct analysis and data modeling to draw insights that drive critical decision making and to uncover social media patterns, fan engagement, behavior and feedback\\n\\nAnalyze data to identify outliers, missing, incomplete, and/or invalid data\\n\\nCreate models, KPIs, and dashboards to operationalize outcomes of analytics\\n\\nCreate, automate, and maintain reports and visualizations (e.g., social media mentions, competitive engagement, talent impact mapping)\\n\\nWork in complex data environment comprising several heterogeneous internal and third party data sources, manipulate large data sets and navigate a variety of servers, data types, and data structures to complete statistical and other analyses\\n\\nDesign and build dashboards and automated reports with embedded visualizations\\n\\n, Qualifications:\\n\\n, Proven track record of identifying and highlighting key insights, signals, and trends deep within data\\n\\nWell-rounded individual with the ability to write code to query and transform both unstructured and structured data\\n\\nOpenness to an environment of active developmental feedback and coaching from peers and managers, with desire to learn and grow rapidly\\n\\nExperience publishing reports using visualization and presentation tools\\n\\nStrong planning and organizational skills\\n\\nShould enjoy generating actionable insights by mining data and be passionate about answering challenging questions and telling stories with data and visualizations\\n\\nSelf-motivated, attentive to detail, and driven to continuously improve analytics skill set\\n\\nBachelor‚Äôs degree in Statistics/Mathematics, Econometrics/Economics, Engineering/Computer Science, Business/Finance, or related quantitative field\\n\\nWorking knowledge of at least two technologies: SQL, SAS, Python, Big Query, Google Analytics, Excel, and Tableau\\n\\nSPSS and/or R\\n\\nKnowledge of social media platforms including but not limited to Facebook, Twitter, Instagram, Snapchat, YouTube\\n\\n, _]', 'Strong communication skills with an ability to interact with a variety of researchers and business partners in different disciplines', 'Familiarity with media data sets (Nielsen, comScore, Adobe Analytics, social platforms, etc.), Bachelor‚Äôs degree in marketing, business, finance or other quantitative field., Over three years of marketing analytics experience., Proficient at Excel, PowerPoint and Word, Tableau., Experience with statistical packages such as SAS and reporting packages., Experience with using web analytics tools such as Google Analytics., Experience with using CRM data from Salesforce., Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.Creative problem solver, ability to handle multiple projects, and strong work ethic needed', 'In-Memory Databases (other than GigaSpaces like Redis, etc.)\"[', ', Cloud-based services (Google Cloud, Amazon Web Services)', 'Developing and enhancing data models to deliver predictive insights', \"Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\", '[Who we are:, \\n\\nOver ten years ago, we launched AppFolio(NASDAQ: APPF) to revolutionize the way small and medium-sized businesses grow and compete.Experience with A/B and multivariate testing\\n\\nAdvanced Google Analytics and Google AdWords certified\\n\\nPositive attitude and entrepreneurial spirit, \\n\\nPreferred:, \\n\\nYou have familiarity with audience, attribution, and optimization solutions such as Google Audience / Adometry, Google Optimize, Adobe Target, Oracle and Adobe Audience Managers.Splunk offers the chance to work with cutting-edge technology in a collaborative, exciting, and fast-paced environment., \\n\\nResponsibilities: I want to and can do that!, \\n\\nPartner with Splunk‚Äôs product managers and internal teams to address complex business data questions and provide insightful analysis and strategic recommendations to both technical and non-technical colleagues.Please submit any online presence you may have (Twitter, Facebook, Fan pages made because of you), and if you are a DIY enthusiast, whether you think you are a good one or not, that means a lot to us, and we would love to hear about it when you send us your information!]#CJ]\"', 'Experience with BI tools - Periscope Data or equivalent tool (Tableau, etc.)\"[We do research differently here at Google.Passion for Rockstar Games and our titles., ', 'Lead workshops, innovation sessions with clients, multi-disciplinary, and cross-functional teams to identify business opportunities and artificial intelligence solutions utilizing processes and best practices to plan, lead, and execute delivery of artificial intelligence engagements across different areas (risk management, financial services, mergers and acquisitions, and public policy)', 'Compose effective cross-team and inter-departmental communications, ', 'Ability to work under pressure with ambiguous or competing priorities', 'Programming experience in JavaScript or Java for use in reading existing code or building prototypes (you do not have to have experience building production applications)', \"[OVERVIEW, \\n\\nAs a member of our R&D organization, your work will directly and rapidly impact our award winning Conversant One-to-One Relationship Engine.We're developing Cloud ML on Google Cloud Platform, in close partnership with a number of teams across the company.Partner with customers to build the best strategy to increase profitability while respecting business rules by leveraging various Google offerings.[\", 'Define and measure metrics that quantify the tradeoffs between different fulfillment models', '2 + years of text analytics experience', 'An understanding of Kafka, NiFi, Spark Streaming and IoT architectures and concepts', 'Knowledge of Hub Spot, CRM integration, Survey Monkey and Google Analytics', 'values data and truth over ego', 'Create predictive models, train and leverage machine learning APIs, build machine learning pipelines, build Chatbots for the enterprise, embed intelligence in a variety of industry or domain-specific use-cases, and more, BENEFITS, ibm.com/employment/us/benefits/', 'Responsibilities Include:, ', 'Responsible for experimentation (A/B testing) methodology and implementation', '5-8 years of experience in web analytics decision support and website optimization', 'Tableau, Looker', '[Responsible for analytic data needs of the business unit.Additional responsibilities include, but are not limited to: participating in the activities and discussions of various Board advisory committees and task forces; serving as the Board‚Äôs representative in relevant stakeholder meetings; and working cooperatively with Arizona Department of Education staff as directed., \\n\\nKNOWLEDGE, SKILLS AND ABILITIES (KSAs):, \\n\\nKnowledge Required:,  Knowledge of data and statistical analysis Knowledge of sound research practices General understanding of the Arizona public education system, \\n\\nSkills Required:,  Skilled in presenting highly effective written, visual and oral presentations on complex data to a wide variety of audiences Skill in Microsoft Office and Google Suite products, including Microsoft Excel and Google Sheets Knowledge and capable ability in one or more of the following: SPSS, SAS, or R Skilled in working on multiple complex projects simultaneously Skilled in working in high pressure environments Skilled in detailed oriented reports Skilled in analyzing and developing complex policy in a variety of areas Skilled in interpreting and applying federal and state codes and regulations, \\n\\nAbilities Required:\\n\\n,  Ability to perform and analyze complex calculations associated with technical properties of educational assessments and accountability measures Ability to develop and articulate potential policy recommendations in the areas of school accountability, assessment and research Ability to work collaboratively with stakeholder groups and other state agencies Ability to perform detailed work with a high degree of accuracy, \\n\\nSELECTIVE PREFERENCE:,  Master degree or doctorate in Education, Educational Administration, Educational Leadership, Research and Development.Experience linking multiple data platforms with data visualization tools (e.g., Tableau)\\n\\nExperience with Public Cloud Platforms (AWS, Azure, Google Cloud Platform)\\n\\nAdvanced knowledge of data management tools including SQL/RDBMS, NoSQL (e.g.[Must Have:, ', 'Background in statistics]\"', 'Create cross-sectional and longitudinal data sets from raw data files', 'Learn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk]\"', 'Nearest Major Market: New Jersey', 'Willingness to get your hands dirty conducting data analysis, building dashboards, and supporting internal and external data requests', 'Hands-on experience with Hadoop, Teradata (or other MPP RDBMS), MapReduce, Hive, Sqoop, Splunk, STORM, SPARK, Kafka and HBASE', 'Experience developing pipelines using Google proprietary backend and frontend tools', 'You are able to:, ', 'Qualifications:', 'Proficient knowledge in MS Excel or Google Sheets including formats, charts, tables, functions', '5 years of data analyst experience', 'Travel, predominantly domestic, approximately 10-15%., ', \"Bachelor's degree required\", 'Architect and implement high performance data pipelines for distributed systems and data analytics for deep learning teams', 'Job Segment: Analytics, Database, Engineer, Electrical, Computer Science, Management, Technology, Engineering]\"', 'Implement best practices to address customer and product analytics and reporting needs via dashboard and custom report templates', 'Deploy machine learning models at scale, writing production code in collaboration with machine learning platform engineers, ', ', Experience with all-source analysis in the U.S. Intelligence Community', 'Excellent communication, facilitation, and interpersonal relations skills required', 'o Pre-processing (tokenization, part-of-speech tagging, parsing, stemming)', 'Twitter', '[Responsibilities and Capabilities:, Coordinate the communication between the data science team and the development teams., Analyze data and study the system to provide meaningful insights on the product performance and the ways to improve it., Build predictive models to improve the advertising campaigns performances., Cross-collaborate with engineers on building statistical models, applying machine learning techniques for targeted solutions and effectively communicating the analysis and findings through interactive visualizations, documents and presentations., Cross-collaborate with the account management and sales teams to conduct dedicated studies for some of our big customers or demonstrate in client meetings, Some of the capabilities should include:, Strong interpersonal, oral and written communication and presentation skills, ability to communicate complex findings in a simple manner., Ability to communicate with Developers or Data-Analysts to describe complex algorithms in a simple manner., Enjoy discovering and solving problems; proactively seeking clarification of requirements and direction; being a self-starter who takes responsibility when required., Ability to explore different directions based on data and be able to quickly change direction based on the analysis., Minimum requirements:, 2+ years of work experience in a Data-Science team., Proven ability and experience in using data science, statistical computing, and modeling to improve business KPIs., Experience with statistical, predictive modeling, machine learning with big-data using tools like R, Hadoop, Spark, Strong mathematical skills., Solid communication skills,  Preferred Qualifications:, MS/ PhD in fields like computer science, mathematics, statistics, machine learning, operations research, data mining, AI., Understanding of public cloud design patterns and considerations in the areas of distributed systems, distributed storage systems, big-data, data mining, cluster computing., Basic understanding of the distributed concepts behind Hadoop and Spark Data-Analysis frameworks., Strong ability to learn new concepts quickly., PostgreSQL, Hadoop, Cassandra, Aerospike, Redis, LevelDB, Golang; Java; JavaScript; Python; C; C#, AWS; Google Cloud; OpenStack, NSQ, Kafka, Flume, GCP Pub/Sub, Consistently trying out new possibilities]', 'believes that good software development includes good testing, good documentation, and good collaboration', 'self-motivator who contribute effectively with limited supervision', 'Familiar with Apache BEAM SDK', 'The Role: Sensus, a Xylem brand seeks to hire a Data Scientist with a desire to join a team delivering Big Data applications in the Cloud.Learn more about Diversity and Inclusion at Dell here.]\"Above all, your work will impact the way the world experiences art., Build large-scale batch and real-time data pipelines with data processing frameworks like Scio, Storm or Spark and the Google Cloud Platform.Python or shell scripting)', 'A passion for leveraging data for business impact, ', 'Knowledge of human factors methods is a plus', 'Proficient computer skills, Microsoft Office Suite (Word, PowerPoint, Outlook, and Excel)', 'TS/SCI clearance with CI polygraph', 'Tableau, Looker, or similar data visualization tools', 'Optimizely‚Äôs Stats Engine https://blog.optimizely.com/2015/01/20/statistics-for-the-internet-age-the-story-behind-optimizelys-new-stats-engine/, ', 'Collaborating with LOB/function strategy, sales, marketing, and product teams to address issues identified, Requirements, ', 'Secret clearance', 'Involvement in the pre-sales process', 'Solution driven - strong analytical skills to identify, analyze and solve problems given ambiguous information', 'Cloud deployment system (AWS, Azure, Google) and/or microservice architectures', 'Study website behavior patterns to analyze and optimize business results and user experience', \"[\\nEstablish and adhere to best practices in reporting and analysis: data integrity, test design, analysis, validation to ensure team is providing exceptional quality work and is continuously gaining everyone's trust.While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \\n\\nFacebook\\n\\nTwitter\\n\\nLinkedIn\\n\\nGoogle\\n\\nMore]\", 'Experience with data warehouses, Big Data and Data Lakes a plus', 'Inherently Curious, Self-starter, Proactive, Comfort with Ambiguity, Passion for Problem-solving, Creative, Collaborative, Team-oriented', 'Our Google-backed client has recently closed 30M in funding, located in the Bay Area specializes in autonomous vehicles.You will also collaborate closely with Engineers, Program Managers and other stakeholders to implement model-based solutions, measure the effectiveness of programs, and drive customer growth and success., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.So, bring your creativity and pioneering spirit to KPMG Lighthouse., ', \"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \\n\\nAs a Solutions Architect with a core focus on Machine Learning (ML), you'll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.You'll be a trusted partner in the team tackling the toughest and most impactful analytical problems., Responsibilities, Quantitative research and data analysis of partnerships, Complex data retrieval using SQL, Actionable insights and recommendations on relationships with existing partners and acquisition of new partners\\n\\n\\nAnalyze and present results of partner campaigns and make improvements, Build effective and scalable data models, Build and maintain production data within a data warehouse, Work with product managers, data and machine learning engineers to discover and guide the most impactful product investments, Design and analyze rigorous A/B experiments, Build dashboards and other analytical tools, Automate insights alerting anomaly detection, Requirements, Data leveraging for impact, preferably in customer facing retail or CPG space, SQL, and Python or R or SAS or Pandas, A/B testing, statistical analysis, Tableau, Looker, D3.js or similar tools, Data modeling, ETL and data pipeline development, Advanced degree in statistics or other quantitative field]\", '1 - 3 years in Consulting', 'Manage and coordinate teams to deploy data analytics projects using innovative solutions and to provide analytics-driven insights', ', Collaborate with internal and external colleagues to infuse New Visions tools, structures and strategies with a data-driven approach, ', 'Refactor, deploy, and validate models; work with clients iteratively to validate performance metrics, and sample output to drive towards a business-first solution utilizing APIs, platforms, containers, multi-threading and distributed processing to achieve throughput goals, ', 'Research statement outlining both past research accomplishments and a vision for scientific research at the Flatiron Institute', 'Keen eye for detail and precision', 'Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.There will be extended periods of sitting and using a computer', 'Assemble large, complex data sets that meet functional / non-functional business requirements', 'Strong theoretical and applied background in machine learning, statistics, data-mining and optimization', 'BA or BS degree required', 'Translate complex technical findings, conclusions and recommendations in compelling written and oral delivery formats, often to non data science personas', 'Deep subject matter expertise with Google Analytics and SQL; experience with Google AdWords, Google Webmaster tools and Google Tag Manager a plus', \"SAP'S DIVERSITY COMMITMENT\", 'Access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk', '[The Google Cloud team helps companies, schools, and government seamlessly make the switch to Google products and supports them along the way.Experience developing in AWS, Google cloud, or Azure (Azure preferred).PhD from an accredited college/university is preferred\\n\\nAbility to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\\n\\nSolid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\\n\\nFluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\\n\\nAbility to travel up to eighty percent of the time; US Citizenship is required, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.Our work helps Google Assistant understand and speak with users, helps self-driving cars move safely, and helps Google Images and Geo understand the content of images among other cases across the company., Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\\n, Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\\n, Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\\nProficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\\nAbility to digest and explain complex ideas to a diverse group of stakeholders\\nMust be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\\nExperience with digital media measurement and reporting platforms preferred as well as programming languages\\nExperienced in effective dashboard designing with a focus on customizing to client needs\\nAbility to work under pressure and manage multiple priorities\\nStrong communication and presentation skills equally capable of interacting with peers and senior leaders\\nMust be a team player but also have the ability to work independently]', 'Experience or interest in controlling physical systems using Machine Learning', '5+ years of experience with ETL tools including NiFi and StreamSets', '2+ years of marketing and/or finance]\"', 'Coaching skills and ability to assist others in learning new technical and professional capabilities', 'Experience with developing experimental and analytic plans for data modeling processes, use of excellent baselines, and determine cause and effect relationships accurately', \"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.The Supply Chain Research group at Coyote Logistics is responsible for designing, selling, and implementing Coyote‚Äôs emerging portfolio of non-transactional supply chain services.Skilled in SQL and Google Analytics.We represent the voice of Google's users and many of our partners globally, sharing insights with the larger Google organization to enable exceptional customer and product experiences.Preferably including DoubleClick, Google Analytics, AdWords and Google Tag-Manager and stream data into environments such as BigQuery\\n\\nResponsible for the management of multiple processes and applications, performance reporting and error checking\\n\\nResponsible for the management of all data created within client applications, the structure of data held and the views of data created\\n\\nResponsible for recommending the correct technologies to be used and in the most cost effective manner\\n\\nResponsible for the design and creation of data led strategies which provide clients with opportunities to leverage their data for greater insight or performance\\n\\nProvide thought leadership with regards to best practice and use of the google cloud platform, BS Degree\\n\\nData Engineering/ BI Development/ Data Warehousing experience.Provide domain expertise around public cloud and enterprise technology, and effectively promote Google Cloud with customers, at conferences, and online.[\", 'Must have an advanced user understanding of Microsoft Excel and PowerPoint', 'Experience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics, ', '4+ years of JVM-based languages/systems', 'Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.Learn more about Diversity and Inclusion at Dell here., ', \"[(NYSE: WRK) partners with our customers to provide differentiated paper and packaging solutions that help them win in the marketplace.Must be willing and able to pass a counterintelligence (CI) polygraph examination\\n, Python\\nLinux\\nElasticsearch, NoSQL, Hadoop ecosystem, or similar big data technology\\n, Interest In:\\n\\nBuilding data services and APIs\\nLeveraging event-driven architecture concepts\\nScaling systems on AWS\\nPair programming\\nExperience with:\\n\\nWorking on a cross functional team\\nGoogle's Protobuf data format\\nAmazon Web Services - EMR, DynamoDB, SQS, SNS\\nDevOps best practices - Jenkins\\nComfortable with:\\n\\nAgile development\\nHands on system engineering tasks\\nModule development\\n, Building data services and APIs\\nLeveraging event-driven architecture concepts\\nScaling systems on AWS\\nPair programming\\n, Working on a cross functional team\\nGoogle's Protobuf data format\\nAmazon Web Services - EMR, DynamoDB, SQS, SNS\\nDevOps best practices - Jenkins\\n, Agile development\\nHands on system engineering tasks\\nModule development\\n]\", '- Collaborate with Global Partners to accommodate analytical needs, ', 'Assist in the organization of computational astrophysics workshops and conferences', \"[\\n\\nGather, document, and communicate requirements effectively to ensure appropriate implementation of solutions and processes\\n\\nDevelop effective problem statements and drive to resolution, \\n\\nPerform as-is and to-be analysis, \\n\\nServes as a data steward, ensuring accurate and timely data capture, \\n\\nPlan and manage projects; anticipate and mitigate risk, document decisions, manage change, \\n\\nCompose effective cross-team and inter-departmental communications, \\n\\nEnsure continuous improvement in quality of data and deliverables, \\n\\nCollaborate with cross-functional teams to enable and promote Enterprise adoption of Master Data Platforms, \\n\\n5 years of data analyst experience\\n\\nBachelor of Science degree in STEM (Science, Technology, Engineering or Math)\\n\\nProject Management experience\\n\\nExperience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\\n\\nExperience manipulating and analyzing large datasets, \\n\\nExperience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\\n\\nExperience manipulating and analyzing large datasets, \\n\\nConcentration in Computer Science, Computer Engineering, or related field strongly preferred\\n\\nUnderstands NI's products and how NI engages customers is strongly preferred\\n\\nSelf-Starter, high level of ownership, proactive nature, problem-solving skills\\n\\nKeen eye for detail and precision\\n\\nStrong technical skills, comfortable working with technical teams (Excel, PIM IBM, Datawarehousing, SQL Queries)\\n\\nSolution driven - strong analytical skills to identify, analyze and solve problems given ambiguous information\\n\\nStrong personal organizational and project planning and management skills\\n\\nTeamwork skills essential; sense of humor required\\n\\nExcellent English communication skills - verbal and written]\", 'Onsite gym and wellness programs with discounts & rewards', 'Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, ', 'Written & Oral Presentation Skills', 'Interpersonal skills and ability to motivate and inspire others to achieve goals and accomplish work', 'Pinterest', 'Experience with designing and implementing machine learning, data mining, statistics, or graph algorithms in an academic or professional work environment', '- Ability to interpret the results of analyses and communicate findings to internal stakeholders and leadership by utilizing data discovery, visualization, and statistical techniques, ', 'Opportunity to expand responsibilities as internal capabilities develop to help define advertising segments, and to provide input on automated tools for trigger messaging', 'Managing and manipulating large data sets', 'Proficient knowledge in SQL and relational databases', 'In-depth knowledge of data structures, data management practices, system interaction patterns and interfaces', \"[Senior Data Engineer, \\n\\nSan Francisco Bay Area, CA, \\n\\n$160,000 - $180,000 + Bonus + Equity + Benefits, \\n\\nFeel that your everyday work is not making a big impact on people's lives?For additional information on BlackRock, please visit www.blackrock.com | Twitter: @blackrock | Blog: www.blackrockblog.com | LinkedIn: www.linkedin.com/company/blackrock., Job Description:, Data Science at BlackRock:, \\n\\nIn February 2018, BlackRock announced the creation of a new central Data Science team in order to accelerate innovation and technology in artificial intelligence, and to have firm-wide impact using data science to solve strategic problems.PREFERRED EXPERIENCE:, PREFERRED EXPERIENCE:, \\n\\nTechnical Expertise ‚Äì Experience with modeling tools & platforms (like MiniTab, R, Python, IBM SPSS, SAS or other), data management/data mining skills, visualization techniques and descriptive statistics to solve complex problems required.degree in communications, journalism, mathematics, business administration or a related field preferred\\nFour to six years managing data analytics\\nAdvanced experience with Excel, Google Analytics/Omniture and native and aggregated social analytics platforms, including Sprout Social and Simply Measured\\nExperience working with CRM systems, including Salesforce, to interpret data\\nExperience working with content management systems, including Drupal\\n]\", 'KPMG is currently seeking a Director to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics., ', '[Design, implement and deploy custom applications using real-time data streams and/or big data platforms\\n\\nCollect, create, and structure data sets from disparate sources to be able to leverage them for machine learning applications\\n\\nBuild data pipelines to ingest, transform, and analyze data in artificial intelligence and analytics systems\\n\\nDesign data architectures that address specific client needs, using combinations of relational databases, No-SQL databases, and unstructured file stores in both cloud and on-premise settings\\n\\nDevelop solutions and iterate rapidly\\n\\nEnsure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts., Minimum 2 years of hands-on technical experience implementing or supporting big data or real-time analytics solutions\\n\\nHigh level of competence in SQL, Python and/or scripting languagesBachelor‚Äôs Degree or Associate‚Äôs Degree with 6 years of work experience or equivalent work experience of 12 years, Ability to travel about 10% of the time, Experience with delivering Big Data Solutions in the cloud with AWS, Azure or Google CloudAbility to configure and support API and OpenSource integrationsExperience administering Hadoop or other Data Science and Analytics platforms using the technologies aboveExperience working with DevOpsDesigning ingestion, low latency, visualization clusters to sustain data loads, Experience developing solutions utilizing any of the following:]', 'Primarily using R, write and maintain scripts to clean and organize raw data sets', 'Demonstrates the ability to transform ambiguous business problem to a technical problem and communicate the technical result to non-technical audience', 'Masters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable', \"[o Gain understanding of business processes in their assigned business unit.Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \\n\\nPredictive Science is looking for a Chief Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them stand-up, manage, or take their data science practice to a whole new level.We can only do that by understanding how people connect with those who mean the most to them., We are seeking innovative individuals who are energized by solving data mysteries; people who see the thought of bringing unknown or unexploited data to the Hallmark environment is a career high., You have 3 years‚Äô experience and working knowledge of Lambda and Kappa architecture in a cloud environment (AWS, Google, Azure)\\n\\n, You have a deep understanding of SDLC, Agile methodologies, metadata, data modeling, and designing databases\\n\\n, Working knowledge on Linux/Unix Operating systems\\n\\n, Strong scripting skills - Python (a huge plus), Bash , Shell etc.Leverage data to guide Analyst Relations leads to maximize amplification of IBM messages.Develop a keen understanding of how to build credible and impactful relationships with key influencers and leading industry analysts.To learn more about Hill's and Colgate, please visit http://www.hillspet.com and http://www.colgatepalmolive.com, or find us on LinkedIn, Facebook, Twitter and YouTube., \\n\\nLocation: Topeka, Kansas, United States\\n\\nRelocation Assistance Offered Within Country\\n\\n# 62547, \\n\\nThe focus of the Data Scientist role is to analyze large amounts of complex raw and processed information to find patterns that will improve our understanding of the relationship between nutrition and health/wellbeing.Alternatively, summarize and critique a machine learning paper you have read that you found interesting., \\n\\n**Although cover letters are optional for most job applications at Google (as noted on the website), it is a mandatory component for this application.Deep experience or knowledge in foundational information management arenas, such as Master Data Management, Data Governance, Modern Data Architecture, and Data Integration\\nExperience in Data Architecture/Modeling, ETL, Data Quality and MDM tools, including IBM Infosphere and Microsoft SQL Server Integration Services, Data Quality Services, and Master Data Services\\nExperience in architecting and implementing emerging technologies/tools, such as AWS, Hadoop, Cloudera, and/or Hortonworks, to address predictive analytics and unstructured data use cases\\nExperience in designing and implementing Next Generation Architecture solutions incorporating Big Data, NoSQL, Cloud-Based Analytics, and Real-Time Analytics\\nExperience in working with large volumes of data from disparate data sources across complex business processes and functions\\nMust have strong leadership and interpersonal skills to resolve problems in a professional manner, lead working groups, negotiate, and create consensus\\nMust be able to astutely operate in and navigate through client organizations\\nMust have strong written/oral communication and presentation skills\\nMust be highly self-motivated, entrepreneurial, humble, and curious\\n, Location, \\nWork remotely from home, your favorite coffee shop, or HatchWorks., The Retail Marketing Analytics team develops and drives the advancement of the marketing data and analytics strategy for Hallmark Retail.In this role, you'll be involved with product marketing strategy from beginning to end., \\n\\nGoogle has been at the forefront of data analytics and AI innovations and BigQuery is one of the most innovative and disruptive product offerings from Google in the data management space.In this role, you‚Äôll be responsible for driving product marketing for Google BigQuery and other data analytics solutions.Splunk, PagerDuty, DataDog or Graphite), \\n\\nData Architecture & Governance, Zillow Group is owned, fueled and grown by innovators who help people make better, smarter decisions around all things home.Comp Science, Math, Engineering) or related experience\\n\\n2+ years of collective experience in data engineering, data analysis, data warehousing, data integration or business intelligence, in a similarly sized organization\\n\\n2+ years of experience architecting, building and administering big data and real-time streaming analytics architectures in both on premises and cloud environments (AWS, Azure, Google) leveraging technologies such as Hadoop, Spark, S3, EMR, Aurora, DynamoDB, Redshift, Neptune, Cosmos DB\\n\\n1+ years of experience architecting, building and administering large-scale distributed applications\\n\\n1+ years of experience with Linux operations and development, including basic commands and shell scripting\\n\\n2+ years of experience with execution of DevOps methodologies and Continuous Integration/Continuous Delivery within a large scale data delivery environment\\n\\nSoftware development experience in least two or more of following languages: Java, Python, Scala, Node.js\\n\\nExpertise in usage of SQL for data profiling, analysis and extraction, Preferred Qualifications:, \\n\\nMaster‚Äôs Degree in a technical field (e.g.Cloud ‚Äì AWS, Azure, Google, Languages/Libraries ‚Äì Python, Java, Scala, Spark, Kafka, Hadoop, HDFS, Parquet., ABOUT EXPRESS SCRIPTS, \\n\\nAdvance your career with the company that makes it easier for people to choose better health., \\n\\nExpress Scripts is a leading healthcare company serving tens of millions of consumers.Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world.]X was formerly known as Google[x]., Partner cross-functionally with software engineers, aerospace engineers, flight operations/business teams to design, develop and deliver data pipelines that drive scalable operational excellence\", 'Advanced analytical, technical troubleshooting, diagnosing and problem-solving skills', 'Experience with Tensorflow, BigQuery, Tableau', 'Deep understanding of relational as well as NoSQL data stores (e.g., Snowflake, Redshift, BigTable, Spark) and approaches', '[It‚Äôs Time For A Change‚Ä¶, \\n\\nYour Future Evolves Here, \\n\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered.Education\\n\\n\\nBachelors or above in Operations Research, Math, Statistics, Computer Science, Physics and Economics\\n]', 'Job Summary:, ', 'Strong interest in adopting new technologies and evangelizing them', 'Work with application engineers to develop internal APIs and data solutions to power Censys product offerings', 'Well-versed in Microsoft Office suite ‚Äì Excel, Word, PPT', 'Teamwork skills essential; sense of humor required', '[Position Purpose:, \\n\\nThe Data Analyst is responsible for the collection, analysis and reporting of client/customer data using complex analysis of datasets in areas of research, development, product enhancement or other targeted business objectives.While we invest in our live games, we are also proud to be one of the first gaming companies innovating on emerging platforms such as Facebook Messenger and Google Play Instant., \\n\\nCome join us, thrive, take risks and dream big to shape the future of fastest growing gaming platform ‚Äì mobile., \\n\\nThe Role, \\n\\nThe Central Technology team at Zynga provides products and services that are foundational for building games across mobile and emerging platforms.Must like to laugh.Exceptional skills with: Word, Excel, PowerPoint, and other analytics tools as well as, Tableau, SQL, Slack, Zoom, Box and Architect., Develop, manage and create content for the Analyst Relations department.The content you generate educates IBM executives, the most influential technical analysts, hybrid analysts, bloggers, marketers, etc., who work with existing or prospective IBM customers, key global media and financial markets.Work closely with and for Vice President, department colleagues and BU‚Äôs to influence strategy while improving analyst/influencer perceptions and relationships.Collaborate with colleagues in Analyst Relations, Marketing, Sales, Product Management, Communications, Finance and BU leadership to ensure that IBM is receiving the best representation with the analyst/influencer community.Develop and broaden Analyst Relations key performance metrics to elevate efforts to key BU leadership and stakeholders.Analyze analyst inputs, such as social media, blogs, reports, and other forms of influence.The role serves as a key Marketing Analytics team member in measuring performance of marketing initiatives and making proactive recommendations that deliver the key performance goals of the agency‚Äôs clientele., Create custom reports and dashboards, audit performance on an on-going basis, and build automated reports where relevant\\n\\nBuild and distribute repeatable reports and performance metrics/insights on client marketing campaigns\\n\\nCollect, maintain, manage, interpret and analyze data received from internal and external data sources\\n\\nProficient with Excel when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\\n\\nExperience with data visualization and analytic dashboard development in Tableau\\n\\nReport requirements collection/analysis, writing SQL, extracting structured data sets, building reports\\n\\nPerform ad hoc analysis and data investigation/ discovery to identify and/or explain business and marketing trends or anomalies\\n\\nAnalyze marketing channel and website performance data for assigned projects and develop recommendations on ways to further optimize for performance\\n\\nWork cross-functionally to help inform the agency and clients on key learnings from data analysis, Able to perform in a highly analytical role delivering actionable marketing campaign insights\\n\\nAbility to deep dive into performance data on a daily basis, drawing conclusions and making optimization recommendations\\n\\nHighly analytical, focused on informing performance optimization based on gathering and examining data from multiple sources\\n\\nExcel guru when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\\n\\nDeep knowledge of web analytics tools (Adobe Analytics, Google Analytics, Optimizely, etc.)(Google Data Studio, Birst, and other tooling)Data analyst with the innate curiosity to uncover interesting/differentiating insights for a projectExcellent communication skillsExcellent attention to detailAbility to manage multiple projects concurrently and prioritize workload to meet deadlinesExperience with/understanding of the requirements for designing enterprise software/mobile applications, Data visualization and storytelling (i.e., Nate Silver, Zach Lowe, Hans Rosling or Kirk Goldsberry)Ability to execute on mixed method projects combining quant and qualThe North Star: Scale our data practice as an independent service to Infor, backed by the power of designExperience running regressions, or using Python to mung, transform and analyze dataSelf-motivated and monitoringEager to contribute, 2-3+ years of related job experience, General office environmentNo special physical demandsSome stress may occur at timesAbility to work across multiple time zones (requires some meetings before/after regular business hours to accommodate), \\n\\nHook & Loop designs and builds products that scale user experience into the enterprise.Familiarity with cloud infrastructure such as Amazon AWS, Google Cloud Platform, Microsoft Azure (AWS preferred)\\n\\nExperience designing and building APIs, especially using Swagger (Open API)\\n\\nBS in Computer Science or equivalent technical domain\\n\\n4+ years experience in software development or IT organizations\\n\\n, Working with wicked smart, super cool people in a campus-like atmosphere\\n\\nWorking on leading edge technologies in cloud micro-services, big data, and IoT\\n\\nCompetitive salary, benefits, and retirement plan\\n\\nEasy commute right off Mass Pike\\n\\nA culture of excellence, respect, opportunity and passion for innovation\\n\\n]', 'Automate insights through alerting and anomaly detection', 'Experience with designing and implementing custom machine learning algorithms', 'Use a measured risk approach in business decisions', 'Azure Machine Learning Studio or comfortable working in cloud hosted environments (AWS, Google Cloud, etc)', 'Experience in using SQL/No SQL databases is an advantage', 'Requirements, ', 'Use and extend open source software to deliver solutions to iHeartMedia business partners Present solutions and ideas to other team members, IT leadership, and business leaders', 'Statistical modelling experience', 'Desired Qualifications', ', Required Qualifications:, ', 'Develop software in Scala, Kafka, Akka, Spark, and other reactive platforms', 'Self-Starter, high level of ownership, proactive nature, problem-solving skills', 'Understanding of A/B testing and other forms of statistical analysis using statistical packages similar to R, SAS, or Pandas, ', ', Doctorate degree in Analytics, Mathematics, Physics, Computer and Information Science, or Engineering', 'A four-year college degree', '5+ years of experience with Big Data, systems, including Hadoop, Hive and Pig', 'Effective data visualization skills (Tableau, Looker, or D3.js), ', 'Work within the company‚Äôs Agile process and systems to prioritize projects into sprints', 'Coordinate with external partners and business stakeholders to develop actionable dashboards which present the end to end funnel metrics, contributing to the development of hypotheses and actions', '[At least 5 years of related experience\\n\\nStrong expertise in software development using Java, Node JS, Python and Bash\\n\\nExperience in the use of R\\n\\nExperience working with front end languages/document formats like JavaScript, HTML/CSS, XML/XSL\\n\\nExperience with relational (SQL) and non-relational databases (Mongo DB, Couch DB and others)\\n\\nStrong IT background including Windows and Linux\\n\\nExperience in building Cloud Applications using APIs and Services\\n\\nExperience in building solutions leveraging artificial intelligence systems and services such as IBM Watson\\n\\nKnowledge in software engineering practices including agile techniques\\n\\nKnowledge in system building/debugging/testing\\n\\nExperience with GitHub Enterprise based source control systems\\n\\nProject management skills, Developer skills in web technologies such as apache wicket, IBM Websphere, Django, Docker but also C coding\\n\\nExperience IT infrastructure architecture]', '[In this role, the candidate will be responsible for performing data engineering duties such as planning, developing, Testing, maintaining and monitoring systems.S/he is experienced with Google Analytics, and works closely with the Marketing team to evaluate careers site data and prepares reports of findings relevant to audience, behavior, and acquisition.)Demonstrate knowledge of networking concepts and devices (Firewalls, Routers, Switches, and Load Balancers)Demonstrate an understanding of network and web related protocols (such as, TCP/IP, UDP, IPSEC, HTTP, HTTPS, routing protocols)Experience developing and improving KPIs, metrics, and trending for vulnerability management functionsUnderstanding of how applications, networking, operating systems, and databases work, Interested candidate must submit a resume/CV through www.nbcunicareers.com to be consideredMust be willing to work at one of the following locations: New York, NY, Desired Characteristics, Intellectual capability and curiosity to learn complex processes.Highly collaborative; personally, and professionally self-aware; able to and interested in interacting with employees at all levels; embody integrity; and represent and inspire the highest ethical standards.Strong sense of urgency and commitment, as well as sound business sense with a strategic, conceptual and operational orientationExperience advising on technical related issuesPassion for and interest in media and entertainment industry highly desiredFlexible, organized, and passionate about advanced cyber securityGreat interpersonal skills and love for a team environment, Sub-Business, Career Level, City, State/Province, Country, About Us, Notices]', \"[\\nBuild scalable and reliable near real time data pipeline on cloud (AWS and GCP) that collects, transforms, loads and curates data from various internal and external data sources\\nBuild a scalable distributed data store that will be central source of truth\\nOwn data quality for the pipelines you build and make them auditable\\nBuild self service tools that helps our data consumers to extract, analyze and visualize data faster\\nEvaluate new technologies and build prototypes for continuous improvements in Data Engineering\\nPartner with Infrastructure and Engineering teams to ensure instrumentation, logging and monitoring is in place\\nImplement Machine learning algorithms\\n, \\nExtensive experience in using big data technologies such as Spark, Kafka, Hadoop, HBase and Hive or their equivalents\\nExperience with AWS and/or GCP\\n5+ years of experience with Java, Scala and Python\\n5+ years of experience with SQL (MySQL, Redshift, etc)\\n3+ years of experience in building and monitoring near real time scalable ETL pipelines\\nExperience with shell scripting\\nExcellent written and verbal communication skills\\nBS or MS in Computer Science or related technical field\\n, \\nExperience with Machine learning algorithms will be a huge plus., \\n\\nExperience training machine learning models in a cloud computing environment such as: Amazon EC2, Google Cloud Platform, Microsoft Azure, etc., 3+ years of hands on experience with building productionized data ingestion and processing pipelines using Java, Spark, Scala, Python\\n\\n2+ years of hands on experience designing and implementing production grade data warehousing solutions on large scale data technologies such as Teradata, Oracle or DB2\\n\\nExperience of large scale Data Migration from on premise to cloud data warehouses\\n\\nExpertise and excellent understanding of Snowflake Internals and integration of Snowflake with other data processing and reporting technologies\\n\\nExcellent presentation and communication skills, both written and verbal\\n\\nAbility to problem solve and architect in an environment with unclear requirements\\n, Bachelor's degree in Computer Science, Engineering, Technical Science or 3+ years of technical architecture and build experience with large scale solutions\\n\\nMinimum 1 year of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders\\n\\nExperience in building data ingestion pipeline using Talend, Informatica\\n\\nExperience in working with AWS, Azure and Google data services\\n\\nExperience with dev-ops tools\\n\\nPrior experience in working with a consulting firm in client facing projects.]Excellent communication skills\", 'Come join us!Able to provide a GitHub or coding portfolio of prior data science, computer programming and statistical work and projects', 'Create visualizations to help users understand and explore data', 'Ability to design and implement data model tables, with experience using Erwin or IBM Data Architect data modeling tools required', 'The Data Scientist role involves working on all the stages of the data science pipeline, from acquiring and understanding the data, modeling various algorithms, performing evaluation of the performance of algorithms but also implementing these solutions in a commercial product either as standalone code or in existing ML frameworks like Spark/MLib.Experience with Google Cloud Platform (Dataflow, Beam, BigQuery, Tensorflow) and other big data technologies a plus.Proficiency with SQL like relational database technology', 'Perform diagnostics and data-driven recommendations to improve overall performance', ', 4 - 10 years of graduate and postgraduate research experience in computer science, machine learning and statistics', 'Nice to Haves, ', 'MA or MS degree in Mathematics, CS, or quantitative fields', 'Experience working in Linux and in a High Performance Computing environment is an advantage', 'Write code that meets standards and delivers desired functionality using agreed upon technology', 'Exceptional database and schema design skills including Star and Snowflake schema design', 'Demonstrated experience working under pressure, both individually and collaboratively in a team environment', ', Requirements:', '[Job Summary, Join Accenture Digital and leave your digital mark on the world, enhancing millions of lives through digital transformation.Use tools such as Google Sheet, Tableau and many internal tools to work efficiently at scal, ', 'Develop algorithms that match owners with providers or solve other customer needs', 'Google Analytics', 'Strong project management capabilities to manage multiple project streams with a focus on prioritization, resourcing and timely business impact', 'Experience deriving insight from structured and unstructured data', 'Strong quantitative, analytical, and problem solving skills, ', 'Additional consideration given to candidates who bring experience with, or understanding of:, ', 'Familiarity with Salesforce', '[\\n\\nDeliver lectures and tutorials on scientific Python, SQL, probability, statistics (Bayesian and frequentist), machine learning, and data engineering.[Build, design and implement high impact data analytics and machine learning solutionsBring new ideas in machine learning software developmentLeverage industry knowledge and stay close to technology developments in the open-source communitiesCollaborate with cross-functional teamsAssist and drive the team by providing oversight., Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms', 'Job Title: Data Engineer, ', 'Passion for, and track record of leveraging data for business impact, preferably in a consumer facing digital environment, ', 'Present papers at scientific conferences', 'Expertise in wrangling large datasets (SQL, Hive, or Spark), ', 'Responsibilities, ', ', 5+ years of commercial experience in data science', 'Experience compiling measurement plans and identifying KPIs and optimization metrics', \"[You will lead and guide technical aspects of small- and medium-sized project delivery through the entire project lifecycle ‚Äì from requirements gathering, analysis, design, development, testing, deployment, audit and post-production support., Secret clearance is required\\n\\nBachelor's degree required, additional years of experience may be substituted for a degree\\n10 years of professional experience is required, including 2 years of supervisory experience\\n\\nMust be technically savvy\\nMust have at least 1 year of experience with data analytics\\nMust have a strong knowledge of statistics and the ability to translate statistical reports into easy-to-read formats\\n\\nAbility to complete tasks under tight deadlines\\n, Experience with Google Analytics strongly desired\\nMarketing experience\\nState Department experience\\n\\n]\", 'At least 7 years of experience in advanced analytics tools such as R, SPSS, Python, SAS', \"[\\n\\nAssist with data collection and optimization of storage approaches\\n\\nProvide support for scalable batch or real-time data processing for discovery and model creation\\n\\nImplement scalable APIs for utilizing analytics results (e.g., utilizing models produced)\\n\\nCollaborate with data scientists and help them evaluate the computation/data requirements for discovery and the deployed solution\\n\\nDesign, build, operationalize, and scale some of the largest data pipelines in the world\\n\\nAdvise on and manage big data infrastructure\\n\\nArchitect and develop data ingestion pipelines\\n\\nDevelop proofs of concept with emerging technologies\\n\\nAssist with data preparation, \\n\\nBachelor's degree in Computer Science or a related technical field\\n\\n3 years of experience as a Software Engineer or closely related position\\n\\n3 years of of experience with the following:\\n\\nDesigning, integrating, and optimizing distributed data-processing pipelines\\n\\nUtilizing database technologies, including: SQL and No-SQL (e.g., Hadoop, Splunk, Spark, Samza, MySQL, Postgres, MongoDB, Sqlite, Neo4j, Apache Giraph), within a cloud environment\\n\\nWriting data processing code in Go, Java, Python, Scala, or other high-performance languages\\n\\nUsing distributed and fault-tolerant computing and map/reduce processing techniques\\n\\nUtilizing Linux/UNIX systems\\n\\nSystems-level debugging\\n\\nBuilding REST APIs for analytics services\\n\\nWorking with or in support of multiple open source communities\\n\\nOptimizing critical components in applications for efficiency using C or C++\\n\\nUtilizing cloud deployment and virtualization and containerization technologies (e.g, Docker, Ansible, Terraform and Vagrant)\\n\\n1 year of experience with the following:\\n\\nMachine learning libraries, such as Google CloudML, DataFlow, DataLab, TensorFlow, SciKit Learn, Mahout, and MLib\\n\\nOptimizing advanced SQL queries\\n\\nWorking in an agile environment with SCRUM and PODS]\", 'GigaSpaces XAP', '- Define and design analytical methodologies that result in weekly, monthly, and quarterly reporting that offers actionable recommendations based on data, ', 'Great interpersonal skills', 'Strong desire to explore various data sources to uncover hidden trends and opportunities for the organization', 'Define key business problems from starter conversations, gather and analyze relevant data, conduct advanced transformations and integrations, identify suitable algorithmic approaches, conduct proper evaluations and stage outputs for operational deployments', '2+ years of experience with applying various machine learning techniques and understanding the key parameters that affect their performance', 'Cloud computing experience, Knowledge and/or experience with the following:', 'Distill complex datasets into actionable KPIs; build and automate reporting to empower data driven decision making across the company', 'Create and maintain optimal data and model dataOps pipeline architecture', 'Develop mechanisms for collecting feedback and modifying analyses and data tools to reflect internal and external data priorities', '[Leverage analytics to enhance existing products and deliver new impactful products.The ideal candidate should be highly analytical and have a strong technical skill-set, with solid experience in a data extraction language (such as SQL) and experience working in the Salesforce environment., \\n\\nResponsibilities:, \\n\\nWork cross-functionally with west region executives, marketing, member experience, real estate, sales ops and finance to analyze data, identify trends, implement optimization\\n\\nLeverage predictive analytics to support demand pipeline forecast, by segment, product and territory/market, to support 80% occupancy rate for new building openings\\n\\nEstablish regional KPIs and benchmarks for growth acquisition and across multiple channels, including paid search/social, display, mobile, email marketing, and OOH campaigns\\n\\nEstablish measurement framework for pilot programs on member experience, via both qualitative studies and quantitative approach, including using analytics to measure the impact of member interactions and satisfaction\\n\\nExecute accurate test design and evaluation ‚Äì including sampling techniques and determining statistical significance\\n\\nOwn the reporting and dashboards of west region, with rigorous quality control and timely delivery\\n\\nImplement standard processes, data infrastructure, operational best practices for west region\\n\\nDevelop recommendations for changes to investment and marketing strategy, optimize the efficacy of marketing spend based on quantitative analyses\\n\\nExecute on data strategy and implement technology to support hyper-segmentation, account-based marketing, and multi-touch attribution\\n\\nLead the training processes on a range of marketing analytics and BI tools, and foster the data-driven culture across teams, Qualifications:, \\n\\nStrong quantitative, analytical, and problem solving skills\\n\\n4+ years experience within business/marketing/data analytics\\n\\nFlexibility and ability to adapt to evolving business objectives\\n\\nExpertise in a query language such as SQL or equivalent\\n\\nExperience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics\\n\\nOrganized with strong problem solving skills, attention to detail, communication skills, and time management abilities\\n\\nAbility to manage multiple projects and deliver against aggressive deadlines\\n\\nMasters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable]', 'Owner mentality and an entrepreneurial drive; proven ability to think big and influence others', 'Help develop effective and scalable data models in our production environment and develop, build, and maintain a user-friendly version our production data in our data warehouse', 'Project Management experience', 'Salary: Entirely depends on skill-level and location (wide range), ', 'Educate and coach both clients and team members on machine learning knowledge, practical mathematical modeling, simulation and optimization in multiple analytics platform', 'Basic knowledge of SQL: its concepts and basic syntax, ', 'Strong experience creating ETLs and pipelines (streaming vs. batch; low vs. high frequency pipelines), using tools such as AirFlow, ApacheNiFi, Kafka', 'Growth mindset; the ability to thrive in a dynamic and collaborative environment, ', 'Update and create scripts in Python, Node.js, and similar languages', 'Experience with Tableau', 'Clean, manipulate, organize and analyze student and school performance data, ', '[Responsible for collaborating with the business analyst to develop business requirements and translating requirements into a technical solution\\n\\nAnalyze and defines tasks, data flows, and dependencies\\n\\nDevelop and maintain advanced reporting, analytics, dashboards and other BI solutions using Tableau and/or Alteryx\\n\\nResponsible for identifying and communicating design and scope issues to the stakeholders\\n\\nConduct design reviews and oversee QA functions for the information delivery applications, including ensuring that system and integration test plans are developed and executed\\n\\nCreate other technical deliverable artifacts needed for project implementation\\n\\nDevelop and delivers knowledge transfer to the client, \\n\\n2+ years of background developing Data Visualization solutions using Tableau, PowerBI and/or Alteryx\\n\\nExcellent client interaction, problem solving & communication skills\\n\\nUnderstanding of data modeling techniques\\n\\nExperience working with relational databases (Oracle, SQL Server, Netezza, Teradata) is required\\n\\nExperience using Tableau, PowerBI and/or Alteryx for the creation of dashboards, standard reports and ad-hoc reports\\n\\nExperience working with multiple disparate data sources in Tableau and/or Alteryx\\n\\nExperience with advanced Tableau, PowerBI and Alteryx topics such as complex calculations, table calculations, parameters, geographic mapping, and performance optimization\\n\\nFamiliar with Data Visualization best practices\\n\\nTravel to the client on a weekly basis is required.[', 'Experience building and managing efforts in both batch and streaming data processing pipelines with technology like Beam, Spark, etc.), Caffe/TensorFlow/Keras/etc, Hadoop, Spark, PigExperience providing direct support to analystsExperience building models and tools to help analysts understand data and answer intelligence questionsExperience using Data Science libraries in Python or R: tidyverse, NumPy, SciPy, PandasFamiliarity with commercial and open source data science software: IBM SPSS Modeler, SAS, KNIME, RapidMiner, StatisticaFamiliarity with software development (Scala, C#, Java, JavaScript, etc.Knowledge of Google BigQuery and Java/Scala is a plus.Learn more about Splunk careers and how you can become a part of our journey!, Splunk is looking for highly motivated college students to join our team.Experience with Java (Python a plus)', 'Excellent critical thinking, communication, and collaboration skills, including the ability to communicate technical findings to non-technical audiences', 'Mentor and coach others to enhance professional and technical skills', 'eCommerce experience]\"', 'Provide access to data through dashboards and other analytical tools to empower your team through self-service', 'An understanding of A/B testing and other forms of statistical analysis using statistical packages similar to R, SAS, or Pandas', 'Experience in developing applications in Spark', '1-3 years of work experience in the social analytics space', 'At least 3 years of experience in visualization such as d3, Javascript, HTML, CSS, Advanced degree in a technical field', 'Gather, document, and communicate requirements effectively to ensure appropriate implementation of solutions and processes', 'Strong personal organizational and project planning and management skills', ', Relational SQL and NoSQL databases, graphical database (e.g.\"[', 'Knowledge of Meta and Master Data Management', '[\\n\\nLead team in designing analytic solutions that meet customer needs\\n\\nEnhance existing analytic solutions to ensure quality, and performance\\n\\nSelect and implement appropriate measurements, and scoring metrics to evaluate performance of existing algorithms\\n\\nSelect and implement industry machine learning algorithms to enhance or compete with existing algorithms\\n\\nIntegrate Data from multiple sources to create a common operating picture\\n\\nPresentations to internal and external customers\\n\\nIdentifying and Implementing data visualization for analysis, presentation, and end-user UI needs\\n\\nDuties will also include feature engineering, classifier optimization, event forecasting, and anomaly detection\\n\\nData processing, cleansing, and validating both existing and incoming data, \\n\\nPython and good working knowledge of numpy, scikit-learn, pandas, scipy, matplotlib\\n\\nExperience in applying machine learning techniques to time series and geospatial data\\n\\nStrong statistical background in areas such as statistical testing, regression, and probability\\n\\nGood interpersonal skills and communication with all levels of management\\n\\nBachelors in Mathematics or related discipline with 6+ years of data science industry experience\\n\\nAble to multitask, prioritize, and manage time efficiently\\n\\nUS Citizenship and an active Public Trust clearance, \\n\\nAlgorithm performance scoring\\n\\nData Visualization of multi-source, multi-dimensional data, and analytic results in both real-time and for presentations\\n\\nMS in Computer Science, Physics, Mathematics, or other related discipline with 5+ years of industry experience of the data science field\\n\\nFamiliarity with database / data file system such as PostgreSQL, Kudu, HDFS\\n\\nStrong Google-Fu\\n\\nExperience with time series event forecasting\\n\\nWide breadth of machine learning algorithm experience and posses understanding of which problems those ML algorithms solve\\n\\nUp-to-date on latest industry trends; able to articulate trends and potential clearly and confidently]', 'Demonstrated expertise in constructing and performing complex database search queries of various databases', 'Networking and/or mobile systems (TCP/IP stack, cellular, Wi-Fi, Android, iOS)', '[As a Data scientist/Machine learning engineer, You will be part of a very fast growing engineering team and one of the first engineers in our machine learning team.Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\\n\\nExposure to Google Machine Learning is a plus]', 'Advanced degree in statistics or other quantitative field', 'Track record of building Data Warehouses that enable accurate and easy analyses', 'Python', '6+ years‚Äô experience in business application of advanced analytics and data mining including predictive algorithms in a professional environment', 'Bachelor‚Äôs degree in math, statistics, or computer science', 'Data Security', 'PostgreSQL and Mixpanel experience is preferred]\"', 'Ability to write complex and performant queries in your dialect of SQL to extract data from our Redshift cluster, ', 'Knowledge of stream-processing systems: i.e.You‚Äôll work on exciting brand and acquisition campaigns, perform site optimizations, monitor and run reporting, contribute to an online testing strategy and more., ', 'Advanced knowledge of reading and writing SQL queries', 'Working knowledge of ad trafficking/ad serving platforms including but not limited to Doubleclick etc., ', 'Uses a variety of techniques to demonstrate product expectations and prevent production problems, Annual gainshare bonus of up to 30% of your salary; Progressive rewards each of us with an annual bonus based on company performance', '3 - 5 years in the Healthcare Industry', \"[\\nAnalyze information from various sources to identify options and communicate recommendations\\n\\nPresent information that summarizes overall application or technology status and trends for business level review\\n\\nReview the work of others to provide design or programming recommendations and guide work to completion\\n\\nMentor and coach others to enhance professional and technical skills\\n\\nAnalyze requirements for software programs or application enhancements\\n\\nCreate detailed programming specifications\\n\\nWrite or modifies code for complex software programs, components or applications\\n\\nSupport and clarify direction in times of change to minimize confusion or disruption to business processes\\n\\nReview documentation and ensure standards are being met\\n\\nOn-call hours and limited travel may be required, \\nBachelor's degree in an Information Technology discipline or related field (Computer Science, Software Engineering) and six years of work experience designing, programming, and supporting software programs or applications\\n\\nInstead of a degree, eight years of related work experience designing, programming, and supporting software programs or applications may be accepted, \\nIn-depth knowledge of computer coding/programming languages and software development concepts in a large IT environment\\n\\nAn understanding of Kafka, NiFi, Spark Streaming and IoT architectures and concepts\\n\\nExperience in developing applications in Spark\\n\\nHortonworks or Cloudera certification\\n\\nFamiliarity with capabilities within AWS, Azure, or Google Cloud Services\\n\\nHands on experience with HBase, Cassandra, or other NoSQL database\\n\\nUnderstanding of version control systems, particularly GIT\\n\\nIn-depth knowledge of data structures, data management practices, system interaction patterns and interfaces\\n\\nIn-depth knowledge of vendor software integration and interaction patterns\\n\\nAdvanced analytical, technical troubleshooting, diagnosing and problem-solving skills\\n\\nNegotiation skills and ability to influence others by educating and sharing information\\n\\nInterpersonal skills and ability to motivate and inspire others to achieve goals and accomplish work\\n\\nCoaching skills and ability to assist others in learning new technical and professional capabilities\\n\\nListening, verbal and written communications skills with the ability to translate technical information into understandable terms to a variety of audiences\\n\\nPresentation skills and ability to present information in various ways to meet audience needs\\n\\nUses a variety of techniques to demonstrate product expectations and prevent production problems, \\nAnnual gainshare bonus of up to 30% of your salary; Progressive rewards each of us with an annual bonus based on company performance\\n\\n401k which includes dollar-for-dollar company match of up to 6%\\n\\nDedication to work/life balance which includes flexible work arrangements and tools to support your lifestyle\\n\\nCommitment to IT innovation through initiatives like our Business Innovation Garage where professionals can test new ideas, technology and prototypes\\n\\nDynamic company culture that encourages engagement, supports Employee Resource Groups, values your input and embraces a relaxed atmosphere\\n\\nOnsite gym and wellness programs with discounts & rewards\\n\\nHealthcare onsite and standard benefits (medical, dental, vision)\\n\\nRelocation assistance to Northeast Ohio or Colorado Springs available\\n\\nLearn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\\n\\nLearn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk, Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\\n\\nLearn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk]\", 'Experience with data analysis tools (such as SQL, PLX and with data processing algorithms such as Flume, MapReduce)', 'Partner with Customer Strategy Manager to understand the messaging requirements for upcoming initiatives', '2-3 years experience', 'Our ETL pipelines and production models are in Python and Scala., How you will impact WestRock:', '[\\n\\nCollaborating with BU Partners & exercising expertise in selecting methods & techniques to design, develop, implement, modify & support software products involving data movement of very large data sets and integration processes in preparation for analysis, data warehousing & operational data stores\\n\\nDevelop ETL process on big data platforms & ensuring the data is available per the SLA\\n\\nDevelop APIs to provide access to in-house and third-party data and enable analysis\\n\\nCollect, process, and interpret large data sets, identify and analyze features of interest such as key performance metrics for channel marketing strategies, what if scenarios, aggregations, filtering, statistical modeling\\n\\nWork on problems of complex scope requiring the synthesis of various inputs, analyzing large quantities of data & related products/services\\n\\nAssist in data model documentation, data dictionary, data flow, and data mapping for analysts\\n\\nCreate new metrics and develop tools for monitoring and reporting\\n\\nParticipate in complete end-to-end data warehousing & analytics work, including design, reviews, development, unit tests, and deployment\\n\\nResearching & POC of the latest tools & technologies required for software & data engineering tasks, \\n\\n4+ years of experience with data warehouse & software engineering background\\n\\nUsing Data integration (ETL) Tools such as Informatica, Pentaho, ODI & SQLSERVER Technologies such as SSIS, SSAS & SSRS or equivalent\\n\\nExperience using scheduling & orchestration tools such as Tidal, Oozie or Control-M\\n\\nRDBMS expertise on Oracle, SQL Server, etc and MPP systems such as Netezza & Vertica\\n\\nSecure handling of sensitive information using Safenet, HSM, SSL, Access Control Lists (ACLs), encryption & key management\\n\\nProficient in SQL, Unix and Perl\\n\\nImplementing big data analytical solutions using Hadoop, Hive and Pig\\n\\nUsing Cloud based technologies such as Amazon s3, Redshift, EMR, DynamoDB, or RDS\\n\\nProgramming & Automation skills in Python, Scala, Java or R using bigdata\\n\\nMaintaining centralized data cataloging/quality using technologies such as Informatica Data Quality (IDQ) or Alation\\n\\nDesign and development of analytical reports and dashboards using Business Objects, QlikView, Tableau or similar visualization technologies is preferred\\n\\nExperience working with SaaS-based subscription metrics including conversion, retention and product usage is preferred]', 'Bayesian vs Frequentist Statistics https://blog.optimizely.com/2015/03/04/bayesian-vs-frequentist-statistics/', 'Collaborate with data users to understand their needs, build tools, and conduct analyses to support them', 'Understanding of version control systems, particularly GIT', 'Data modeling, ETL and data pipeline development experience', 'Experience with managing big datasets', 'Establish best practices and standards for data definitions and quality', 'Experience in the MVPD or vMVPD space, or within TV | Studio | Entertainment Industry preferred', ', Position Type', 'Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)', 'Supervise research conducted by Flatiron research fellows and graduate and undergraduate students from neighboring institutions', 'Experience with Google Analytics or other Web Analytics tool, and A/B testing concepts Demonstrated capacity to clearly define product and business KPIs in support of company goals and strategies', ', PREFERRED QUALIFICATIONS, Business experience working with large-scale consumer analytics datasets', 'Languages: Python', 'Employ a pragmatic approach to evaluate new algorithms and technologies for positive impact within iHeartMedia', 'Experience with Agile software development', 'Experience in the mortgage industry is a plus, Proficient with Excel Tables and Pivot tables', 'Using available data to address business questions or concerns.Prior experience with IBM Guardium tool.SAP HANA, IBM SPSS, DSX.Create pipelines: and know what‚Äôs the right infrastructure, both in terms of storage and in terms of computing at massive scale, that can run scoring or predictions on new data., 5-8 years of related professional experience', \"[\\nPartner with marketing, product and engineering team to understand our customers and ultimately create a better shopping experience\\nDesign dashboards and reports to communicate business trends and opportunities\\nWork closely with data engineering to validate data and ensure we have data points needed for analysis\\nEnable self service analytics through BI enhancements\\n, \\n2+ years of related work experience in analytics\\nStrong SQL skills\\nExperience with at least one analytics & visualization tool such as Looker, Tableau, Mode\\nHighly analytical and quantitative, with strong attention to detail\\nAbility to communicate complex ideas effectively\\nBachelor's degree in Mathematics, Statistics, Economics, Business or quantitative focused study\\nProficiency with website analytics tools like Heap, Mixpanel or Google Analytics a plus\\n, \\nComprehensive health benefits\\nEquity\\n401k plan\\nSubsidized lunches and fully stocked kitchen\\nWellness benefits including in-office massage visits\\nQuarterly product allotment -- a package of the world's best bras every 3 months![Who We Are:, \", 'Extensive knowledge in data management, data mining, data integration', \"[Born and built 100% in the cloud, Zscaler operates a massive, global cloud security architecture, delivering the entire gateway security stack as a service.2+ years of experience in data ingestion and storage systems for big data environment using at least one of the COTS integration tools, like - Snap Logic, webMethods, TIBCO, Talend, Informatica, and/or custom scripting in Python/Java\\n2+ years of MUST have experience in using Apache Beam / Google Dataflow / Apache Spark in creating end-to-end data pipelines\\n2+ years of data engineering experience with big data environments and writing map-reduce jobs using Java/ Scala or Python.We continue to be on a tear while enjoying incredible growth year over year., \\n\\nAs a Senior Business Data Analyst at Splunk, you will help drive projects by enabling data and analytics to improve the company's Enterprise Data processes and the applications it builds and uses.As a key member of the team, you work with engineers to analyze and interpret data, develop metrics to measure results and integrate new methodologies into existing systems., Google is and always will be an engineering company.Associate level3+ year(s) of managing parts of the client engagement, including: leading conversations to understand business context, building relationships with the client, identifying key business issues, structuring analysis, and managing the development and delivery of recommendations3+ year(s) of people management experienceExperience participating in the firm's recruiting activities, \\n\\nSkill Set, \\n\\nRequired, Ability to structure analysis to solve complex business problemsAbility to package findings/recommendations from analysis in a coherent, impactful wayStrong presentation and communications skillsProficiency in analysis and business modeling using ExcelBasic understanding of statistics and A/B testing, \\n\\nNot required but nice to have, Experience working on engagements focused on online businessesExperience working on engagements focused on subscription businessesBasic to mid-level proficiency in data extraction using SQLWeb analytics tools like Google Analytics, OmniturePredictive modeling, regression analysis using R or Python]\", 'Experience in visualization such as d3, Javascript, HTML, CSS]\"', ', As a Data Scientist, you will:', 'Analyze and share the results of product features and find opportunities to improve them, ', 'Experience with AWS, Google Cloud, etc.Most importantly, you‚Äôll work and collaborate with a nimble, autonomous, cross-functional team of makers, breakers, doers, and disruptors who love to solve real problems and meet real customer needs., ', '[\\nIdentifying and assessing sources of crypto data\\nAnalyzing assets and exchanges\\nData collection and automation\\nDaily monitoring of news and publications, websites, Twitter feeds, etc.Proficient in querying, segmenting and modeling data from large datasets located in Google BigQuery and CRM databases.If you have what it takes to bring innovative new products and services to life in collaboration with world-class experts, this is your opportunity to develop with Dell.Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\\nAt least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\\nExperience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\\nExperience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\\nMust be a self-starter and have excellent oral and communication skills\\n, The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.Expertise with the AWS platform is a plus!, \\n\\nResponsibilities, \\n\\nBuild design, develop, test, deploy, maintain and enhance full-stack software solutions\\n\\nProvide technical leadership to the Data Warehouse organization, as well as the Shutterfly teams who use Shutterfly‚Äôs Enterprise Data Warehouse\\n\\nWith your technical expertise own and manage project priorities, deadlines and deliverables\\n\\nAlways with a customer focus, evangelize the benefits of existing solutions and new technologies to drive the use and push the technology of the Data Warehouse forward\\n\\nWork closely with Data Operations to improve CI/CD pipelines, as well as continually improving the operation and performance of the Data Warehouse\\n\\nWork across multiple teams in high visibility roles and own solutions end-to-end, \\n\\nQualifications, \\n\\nExpert knowledge of one of the following languages: Python, Java\\n\\n10+ years of hands on experience in software development, including design, implementation, debugging, support, and building scalable system software and/or Services\\n\\nDeep understanding of distributed, message driven systems\\n\\nStrong at applying data structures, algorithms, and object oriented design, to solve challenging problems\\n\\nExperience working with REST and RPC service patterns and other client/server interaction models\\n\\nExperience working in the AWS Services Ecosystem or relevant Cloud Infrastructures such as Google Cloud or Azure\\n\\nBachelor‚Äôs degree in Computer Science or equivalent]', 'Perform any other duties or tasks as assigned or required', 'Lawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE).Process Management - Excellent at figuring out the processes to get things done, understands efficient work flows', '2+ years of statistical modeling experience', 'Must Haves, ', 'Experience with Navy mission systems', '[The Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \\n\\nThe Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets., Excellent oral and written communication skills required for presenting to and collaborating with groups of diverse backgrounds., \\n\\nAbility to explain complex research concepts to individuals without a research background., \\n\\nExtensive knowledge of Microsoft Office and Google Suite applications (Docs, Sheets, Slides, Excel, and Powerpoint), \\n\\nDesired Qualification:, \\n\\nMBA/MS or higher in a statistical, mathematical or technical field.), \\n\\nE- Strong verbal, presentation, and written skills, \\n\\nE- Strong critical thinking and creative problem solving skills, \\n\\nE- Strong planning and organizational skills, \\n\\nE- Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets, \\n\\nE- Proficiency in MS Office suite (Excel, Access, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail), \\n\\nE- Knowledge of statistical tests and procedures such as ANOVA, Chi-squared, Correlation, Regression, Student t-test, and Time Series, \\n\\nP- Familiarity with Tableau , BI, Spotfire, or other data visualization software and techniques, \\n\\nP- Proficiency with the SAS language and toolset (Enterprise Guide, Forecast Studio, etc.Provide expertise in building for scale, including potentially migrating data warehouse operations to a cloud service such as Google Compute Engine, Snowflake, and/or other platforms\\n\\nAdvise and train members of the team to maximize overall productivity and effectiveness of the team\\n\\nIdentify skills gaps and silos on the team and advocate for resolution\\n\\nParticipate in and contribute to scrum meetings i.e.Minimum of 3 years of experience with cloud architectures, e.g., AWS (preferred), Azure, Google Cloud.As a Technical Program Manager at Google, you lead complex, multi-disciplinary engineering projects using your engineering expertise.Experience in visualizing data to stakeholders in a simple and concise manner through visualization software such as ggplot, D3,Tableau Qlinkview, Periscope, Business Objects, or other similar software.Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc...\\nSelf-starter who can multi-task, prioritize, and manage a multitude of conflicting priorities against competing deadlines without breaking a sweat.We also manage the industry-leading services that help make Google a great place to work - from how we design healthy and collaborative workspaces, create energizing food experiences, provide convenient transportation and fitness options, to delivering inclusive environments where Google and our employees can thrive., Work closely with REWS management and their teams to understand their business problems and processes and how data can be applied to those problems and processes, and create appropriate analyses and tools to address them.We are seeking an entrepreneurial Senior Data Scientist capable of working across functional and business areas with minimal supervision in order to support the application of data science methods and statistical techniques to data for internal use at Raytheon.Dell will not tolerate discrimination or harassment based on any of these characteristics.Agile: Experience participating in Scrum based projects, \\n\\nExperience working with ML & AI technology platforms such as Google.AI, AWS, and or Azure a plus.Our products inspire outdoor exploration, exercise, and meaningful social interaction., \\n\\nOriginally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.[T-Mobile Home and Entertainment is seeking a proactive and driven Marketing Data Analyst with a passion for numbers and solving big data problems with actionable solutions.Develop comprehensive understanding of Google data structures and metrics, advocating for changes where needed for both products development and sales activity.Knowledge of Google BigQuery is a plus.Responsibilities:', 'BA or BS degree in mathematics, statistics, operations research, or other quantitative field', 'Develop training curriculum for clients', 'Papers, ', '2+ years of experience with advanced analytical functions', 'Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements, Solid foundation in SQL, data structures, algorithms, design patterns and strong analytical and problem-solving skillsExperience working with predictive modeling in SAS, Python, R or other2+ years of experience leading workstreams with significant experience leading components of data engagements and team sizes ranging from 3 to 10 resources.A strategic thinker who is proactive in providing valuable insights and strong leadership skillsExcellent communications and interpersonal skills, Experience in data management consulting or industry experience (master data, metadata, data architecture, data governance, data quality, data modeling) with experience including the following tools: Informatica, IBM, Oracle and Cloud MDM, Reltio, PIM, SAP BODS, etc.Experience with other visualization tools is a major plus, such as TableauAbility to work independently; lead small teams focused on specific work streams of larger projects.Strong oral and written communication skills, including presentation skills (MS Visio, MS PowerPoint).Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.Eagerness to mentor junior staffBachelor‚Äôs Degree or 4+ years of equivalent professional experience, As used in this posting, ‚ÄúDeloitte‚Äù means Deloitte Consulting LLP, a subsidiary of Deloitte LLP.We establish new, flexible and iterative approaches that only IBM can offer through our unique combination of skills, experience and capabilities, leveraging the proven roadmaps and frameworks we have developed across our 17 industries.Above all, your work will influence the way people experience music., Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.We leverage the Google Cloud Platform (including Google Dataflow, Bigtable, and BigQuery) for processing data as well as build our own analysis tools.Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.Python or shell scripting)', 'Experience with using relational databases, including MySQL', 'PostgreSQL, MySQL, Aerospike, Druid, Bigtable', 'Experience leading a team and driving results, Demonstrated track record leading high performing and engaged teams', 'Python, C++, Django, React.js', 'Diversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html', '[\\n\\nWork with others to define, and propose for approval, a modern data platform design strategy and matching architecture and technology choices to support it, with the goals of providing a highly scalable, economical, observable, and operable data platform for storing and processing very large amounts of data within tight performance tolerances., Key Responsibilities:\\n\\n, Build and validate large-scale batch and real-time data pipelines with Big Data Technologies such as Talend Real-Time Big Data Platform, Python, Spark, Hadoop, Hive, Pig, Redshift, Snowflake, NoSQL DB on AWS/Google Cloud\\n\\nEvaluate, configure and implement new technologies, methodologies and architecture design patterns to build data processing ETL pipeline\\n\\nDesign and Develop processes for data discovery, modeling, mining and archival\\n\\nCollaborate with data analytics team to ensure the integrity and availability of the data necessary for the business analytics & reporting\\n\\nThink strategically & bring new ideas to build the ETL pipeline architecture and how to scale it with the business as it grows\\n\\nBuild reusable components and framework to speed up the data pipeline development\\n\\nProvide guidance/ directions to the data engineers team and implement best practices as well as standards across all the data pipelines\\n\\n, Education & Technical Experience Requirements:\\n\\n, Bachelor‚Äôs in computer science, science, or similar field of study\\n\\n8+ years of Data Warehousing, OLAP, SQL Queries, ETL/ELT design and development experience\\n\\n3+ years of experience with AWS services including S3, Redshift, EMR, Lambda and RDS\\n\\n3+ years of solid experience in developing and performance tuning the data pipeline with Hadoop, Hive, Spark, Talend Big Data Platform\\n\\n3+ years of experience in programming languages such as Python, Scala, R, Java or C#\\n\\n2+ years of experience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka\\n\\n2+ years of experience in columnar databases such as RedShift, Snowflake as well as NoSQL databases such as MongoDB, DynamoDB\\n\\nSelf-starter and highly motivated to add value to the team and platform using innovations around data and data solutions\\n\\nExperience in dealing with the structured, semi-structured and unstructured datasets\\n\\nExcellent communication skills to collaborate with the data engineering, analytics and science teams\\n\\nExperience in Social Media Datasets such as Twitter, YouTube, Facebook, Instagram is a plus\\n\\nExperience in Google Clickstream, DFP, or Adobe Analytics datasets is a plus\\n\\nExperience in dealing with the Media content subscription-based datasets is a plus\\n\\nExperience in creating restful API‚Äôs is a plus\\n\\nExperience in AI, machine learning and statistics is a plus\\n\\nExperience in Media and Entertainment Industry is a plus\\n\\n, _]', 'Analysis of business problems/needs', 'C#, Java, .Net, Tomcat', 'Experience manipulating and analyzing large datasets, ', 'Crimson Hexagon', \"Whether you're on a consumer product (like Gmail, Search, Maps, Chrome, Android) or a business product (Google Ads, AdSense, Google Marketing Platform, Analytics), you take part in a complete marketing experience as you lead every facet of the product's journey.Familiarity with web analytics (Google Analytics, Site Catalyst), statistical packages (SAS, R), and visualization tools (Qlikview, Tableau).Using your influencing and relationship-building skills, you provide Google-caliber client service, research and market analysis.Building data visualizations, reports and presentations\", 'Proficiency in Python, R, Java, Tableau or similar', ', Good to Have:, ', 'Demonstrate passion about using data assets to optimize systems and products across iHeartMedia', 'Identify key questions, problems, and KPIs using your sharp business acumen and judgment, ', ', Preferred:, Previous experience in an eCommerce or Logistics/Supply Chain management environments', 'Understand the ad ecosystem including how an ad gets monetized', 'Collaborate with Data Analysts, Product Managers, and Engineers to design a high-quality PostgreSQL Data Warehouse schema and solution', 'Design experiments to help with cutting edge technology such as augmented reality or indoor GPS', 'Some experience in math education such as teaching, teaching assistantships, consulting, or conference talks, ', '#LI-post]\"', '2 years of working experience in an analyst/quantitative role', 'Strong data analytics expertise, including experience translating customer KPIs into actionable marketing strategies that drive growth', ', Education', 'Experience working for Facebook, Amazon, LinkedIn or Google required', 'Collaborate with cross-functional teams to enable and promote Enterprise adoption of Master Data Platforms, ', 'Orchestrate large PB sized data storage and compute clusters across bare-metal and cloud', '6+ years‚Äô business experience of mathematical predictive algorithm development utilizing large-scale multivariate datasets', 'Database Design and System Analysis', \"[Where good people build rewarding careers., Think that working in the insurance field can‚Äôt be exciting, rewarding and challenging?Actively partner and develop effective relationships with related groups in eCommerce management, eMarketing, product and tech to facilitate and manage efforts across teams to turn insights into practice on the site., Qualifications\\n\\n4-year Degree in Marketing, Finance, Economics, Mathematics or related areas of study\\n\\n4+ years experience working in data analytics or related areas\\n\\n2+ years experience using web analytics tools such as Adobe Analytics/Omniture, Google Analytics, or similar\\n\\nProficient in web analytics fundamentals and website measurement strategy, \\n\\nKnowledge of data modeling (using SQL, Python, and/or Excel) to support our S&OP team's demand planning process\\n\\nAbility to construct custom queries using web analytics tools\\n\\nGood knowledge eMarketing activities such as SEM/SEO, remarketing/retention, targeted display, affiliates, etc.Job Description includes:\\n, Experience in defining Data standards, Data governance and lineage, and Data migration between data base technologies\\n\\nDefine standards for data tagging into a data lake following industry best practices\\n\\nDefine Metadata standards\\n\\nGuide programs related to data standardization, data stewardship and master data management\\n\\nAbility to work with large amounts of data: facts, figures, and number crunching\\n\\nFamiliarity with establishing Master Data Management and Reference Data repositories\\n\\nFacilitate data meetings\\n\\nBuild data assessment metrics\\n\\nFamiliar with ETL/ELT best practices in the creation of the database\\n\\nWorking knowledge of message queuing, stream processing, and highly scalable big data stores\\n\\nDevelop and drive data governance, quality and analytics initiatives are executed successfully to provide appropriate data, information & analysis to various business functions/departments\\n\\nCommunicate effectively, both orally and written, to varied levels of the organization to include technical personnel, business managers, and senior leadership, Required Experience, Data architecture experience; experience including but not limited to metadata management, reference and master data management, data warehousing and business intelligence management and document and content management\\n\\nBreadth in established and emerging data technologies\\n\\nStrong critical thinking and problem solving skills\\n\\nExperience with relational SQL and NoSQL databases\\n\\nAbility to conceive and portray the big data picture\\n\\nAbility to astutely operate in the organization: well respected and influential, able to emphasize methodology, modeling, and governance, technologically and politically neutral, articulate, persuasive, and a good salesperson, and enthusiastic, Education Requirements, Bachelor‚Äôs Degree (preferred Master‚Äôs) in Computer Science, Information Systems, Data Analysis, Systems Engineering, Applied Mathematics/Statistics, Operation Research, or other physical science/engineering fields, Desired Requirements, Experience with Big Data solutions\\n\\nHands on experience working with AWS products (S3, Redshift, EC2, RDS, Aurora, Glacier), certifications recommended\\n\\nData intelligence (i.e., data mining and profiling) Data governance to establish guidelines and processes for a data management program for the enterprise is a plus\\n\\nData Analytics\\n\\nKnowledge/familiarity with DAMA and the Data Management Body of Knowledge, Security Clearance Level, Must be able to obtain and maintain a US Department of Defense SECRET Security Clearance]\", 'Demonstrated experience showing strong critical thinking and problem solving skills paired with a desire to take initiative', 'Stats Engine White Paper - http://pages.optimizely.com/rs/optimizely/images/stats_engine_technical_paper.pdf', \"[Data Engineer- Solution Design, \\n\\nData Engineers will report into MapR‚Äôs Professional Services Organization.Twitter is an equal opportunity employer.Use of Google Analytics and other analytic and statistical tools to provide in-depth statistical analyses to leverage data when making business decisions\\n\\nCommunicate insights to key internal stakeholders and executive leadership team\\n\\n\\n, Communicate insights to key internal stakeholders and executive leadership team\\n, Education:, \\nBachelor's Degree Required (Concentration in a quantitative field preferred including Business, Engineering, Math, Statistics, Economics, Operations Research)\\\\\\nMaster's Degree Preferred]\", \"[Engage with Actuaries in order to develop innovative BI solutions containing actuarial methodologies to drive business decisions across all of Actuarial and Underwriting.Experience with cloud analytics platforms such as Microsoft Azure/AWS/Google Cloud Platform.Experience in using statistical analysis and data science to drive corporate decision making\\n\\n5+ years of experience preferred\\n\\nBachelor‚Äôs degree in business, data science or other quantitative discipline; Masters degree preferred, Dell offers:, \\n\\nOpportunity to work with a strong brand at one of the world's largest IT solutions providers\\n\\nDynamic, challenging, international work environment\\n\\nA team with a high level of energy, integrity and motivation to win\\n\\nExciting internal career opportunities\\n\\nA commitment to diversity and inclusion\\n\\nCompetitive compensation including bonus plans & a great benefit package\\n\\nAn individual professional development plan, Company Description, \\n\\nWith more than 100,000 team members globally, we promote an environment that is rooted in the entrepreneurial spirit in which the company was founded.If you are a Senior Engineer or Manager, looking for a step up and the chance to really make an impact on businesses across the nation, this could be the role for you., \\n\\nThe Role:, \\n\\nAs Analytics Engineer Manager, your responsibilities will include:, \\n\\nMentor and lead data engineers\\n\\nParticipate in strategic discussions for continued advancement of data infrastructure\\n\\nDesign, build and launch robust data pipelines and platform to ingest data and deployment of ML products/model\\n\\nDesign, build and launch highly scalable analytic tools\\n\\nPartner with other teams and intern stakeholder to gather requirements, \\n\\nYour Skills & Experience:, \\n\\nBachelor's degree or high qualification in Computer Sciences or relevant degree\\n\\nProduction level code in Python is a must\\n\\nStrong commercial experience in Spark and Kafka is essential\\n\\nExperience with Google Cloud Platform or AWS is a must\\n\\nStrong communication skills\\n\\nDemonstrable ability to work with real-time data sets and reducing latency, \\n\\nBenefits:, \\n\\nSalary is $150,000 - $180,000, + bonus + equity]\", 'Work with marketing, finance, operations, support teams to help shape and track business objectives with a data-driven approach', \"Bachelor's degree in Computer Science, Mathematics, related technical field or equivalent practical experience\", 'GigaSpaces InsightEdge', 'Express Scripts is committed to hiring and retaining a diverse workforce.)Link analysis and related topicsAnalytic software development in Python, Perl, R, Java, or other languages]', 'Experience building real-time reporting/dashboarding, knowledge of quantitative and qualitative side of analytics', 'Strong work ethic and intellectual curiosity, with laser focus on execution, ', 'Ability to scale systems and performance tune', 'Change Control Management', 'Possession of excellent analytic skills', 'Some of our public work:, ', '[Develop in-depth knowledge of several Staples business processes and systems environment\\nWork closely with key business partners to understand critical, complex, data-driven business and operations challenges, and then apply analytical methods to solve them ‚Äì resulting in a significant, positive impact on the Staples‚Äô bottom-line.[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, ', 'Oracle DBA', 'Master of DDL, DML, and query SQL', ', QUALIFICATIONS, Bachelor‚Äôs degree required', 'Experience with Cloud Dataflow, BigQuery, Hadoop/Spark, and Tableau', 'Prior experience in logistics and marketplace systems preferred]\"', ', Many of the greatest ideas and discoveries come from a diverse mix of minds, backgrounds and experiences, and we are committed to cultivating an inclusive work environment.Coding experience in Python is added bonus.Tagging/labeling/parsing/indexing unstructured text data.Processing text data indexed for Bibliometric Analysis Tool (BAT)Supervised and unsupervised clustering of text data; experience with Natural Language Processing, Coding experience in R is required; Coding experience in Python is added bonus.Graph Theory / Image Processing / Neural Networks, Experience with Big Data (parallel processing power and options for handling analysis of)Ability to understand retrieval processes in Microsoft SQL or experience working in SQL]', 'Experience in building big data based IT processes, understanding data science workflows and building pipelines', 'BA/BS or above in Computer Science or a related field]\"', 'Knowledge of statistics, linear algebra, multiple variable calculus, Fourier analysis or machine learning', 'Got what it takes?Javascript coding skills: you need to be able to write snippets for custom event tracking for different softwares & tools we use, like Google Analytics or Active Campaign.Ability to manage multiple projects and deliver against aggressive deadlines', \"As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other big data related technologies.), Caffe/TensorFlow/Keras/etc, Hadoop, Spark, Pig, Experience providing direct support to analysts, Experience building models and tools to help analysts understand data and answer intelligence questions, Experience using Data Science libraries in Python or R: tidyverse, NumPy, SciPy, Pandas, Familiarity with commercial and open source data science software: IBM SPSS Modeler, SAS, KNIME, RapidMiner, Statistica, Familiarity with software development (Scala, C#, Java, JavaScript, etc.If you share our passion for data and you‚Äôre keen to play a key role in driving progress, this is your opportunity to develop with Dell., \", ', Bonus:', 'Hands on experience with HBase, Cassandra, or other NoSQL database', 'Experience profiling data within relational data model structures is required', 'Experience with end-to-end solution architecture for data capabilities including:', 'At least 4 years of experience in visualization such as d3, Javascript, HTML, CSS]\"', 'Masters degree in public administration, public policy, education, statistics, economics, psychology, sociology, or related social science field.2-4 years of relevant data science experience; comScore or other media measurement experience can be included.One of:', 'Affinio', 'Experience with E-commerce concepts, things like Conversion rate, Customer Acquisition Costs, Attribution, etc.All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status., ', 'At least 2 years of experience working with one or more data mining tools such as R, Python, SAS and SPSS', 'Solid understanding of Paid Search, SEO, and other digital marketing channels such as Affiliate, Social, and Display', 'Brandwatch', 'Experience with AWS services (Athena, Glue, Redshift, Kinesis) or Google cloud services (BigQuery, BigTable)', 'o Semantic analysis (named entity recognition, sentiment analysis)', 'Working with evolving Google Cloud and Amazon Web Services (AWS) cloud technologies', 'Create systems for assuring data quality and accuracy', 'Strong technical skills, comfortable working with technical teams (Excel, PIM IBM, Datawarehousing, SQL Queries)', 'Must have significant experience creating logical source to target maps for complex data warehouses', '3+ years of full-time, industry experience', 'Bachelor‚Äôs Degree, ', 'Strong analyst background; generated insights and business recommendations', 'A high sense of urgency and ownership, ', '- Work closely with cross-functional team that includes CRM, eComm, marketing, brand teams and IT to improve overall digital investment efficiency through insights and analytics, ', 'Identify the optimal product strategy for different marketplaces', 'Extensive experience with Python and/or R', 'Familiar with DFP, Google Analytics', 'Experience programming in Matlab, R, Python, or other statistical and mathematical language', 'Perform as-is and to-be analysis, ', 'Work related travel as needed (2-3 times per quarter)', 'Approximate Counting and Statistical Significance https://medium.com/engineers-optimizely/approximate-counting-and-statistical-significance-two-great-ideas-that-dont-play-nice-2bd643287644#.6uyxiytlr, ', 'Active Kaggle user', 'Cloud Technology Stacks from providers such as AWS and Google Cloud.iO is an innovation lab within Ochsner Health System, Louisiana‚Äôs largest not-for-profit health system.Publish research in refereed scientific and technical journals', 'Experience in BigQuery', 'Retail and/or beauty experience is a plus, Facebook', '[\\n\\nLead a small team of data scientists to build products and services to delight our partners and customers.[', 'Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw', '[Position Description, \\n\\nA Staff Data Scientist is responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions., Responsibilities:\\n\\n, Maintain ongoing reporting that paints a picture of the ‚Äúpulse‚Äù of our business\\n\\nProactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance\\n\\nAbility to understand the business operations as a whole and translate questions into effective analysis based on the goals behind the specific asks\\n\\nCommunicate findings effectively and translate them into recommended actions appropriate for each area of the business\\n\\nDesign and build automated reporting dashboards on our BI platform\\n\\n, Maintain ongoing reporting that paints a picture of the ‚Äúpulse‚Äù of our business\\n\\n, Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance\\n\\n, Ability to understand the business operations as a whole and translate questions into effective analysis based on the goals behind the specific asks\\n\\n, Communicate findings effectively and translate them into recommended actions appropriate for each area of the business\\n\\n, Design and build automated reporting dashboards on our BI platform\\n\\n, Qualifications:\\n\\n, Excellent verbal and written communication skills\\n\\nComfortable deconstructing complex and open-ended problems which may not yield a clear cut solution\\n\\nAbility to work independently and to carry out assignments to completion based on the original goals with minimal supervision\\n\\n4-year degree in statistics or related field\\n\\n3+ years of experience in a data analyst role at an affiliate marketing, e-commerce company, or online publisher\\n\\n3+ years of experience using SQL is required\\n\\n1+ year of experience designing and building automated reporting dashboards with a data visualization tool such as Tableau or similar\\n\\nProficient with statistical analysis tools such as R or similar\\n\\nGoogle Analytics certification or equivalent experience\\n\\nDemonstrated ability to work collaboratively in a multi-disciplinary team\\n\\nStrong interest in Wirecutter‚Äôs mission\\n\\n, Excellent verbal and written communication skills\\n\\n, Comfortable deconstructing complex and open-ended problems which may not yield a clear cut solution\\n\\n, Ability to work independently and to carry out assignments to completion based on the original goals with minimal supervision\\n\\n, 4-year degree in statistics or related field\\n\\n, 3+ years of experience in a data analyst role at an affiliate marketing, e-commerce company, or online publisher\\n\\n, 3+ years of experience using SQL is required\\n\\n, 1+ year of experience designing and building automated reporting dashboards with a data visualization tool such as Tableau or similar\\n\\n, Proficient with statistical analysis tools such as R or similar\\n\\n, Google Analytics certification or equivalent experience\\n\\n, Demonstrated ability to work collaboratively in a multi-disciplinary team\\n\\n, Strong interest in Wirecutter‚Äôs mission\\n\\n, Culture and benefits at The New York Times Company and Wirecutter:\\n\\n, Though Wirecutter has physical locations in both NYC and LA, the company promotes and encourages a remote workforce, so that our employees can work in flexible and comfortable ways.Extensive knowledge of Microsoft Office and Google Suite applications (Docs, Sheets, Slides, Excel, and Powerpoint), \\n\\nBA/BS degree in statistics or mathematics., \\n\\nStrong quantitative analysis skills using statistical software such as Python or R., \\n\\nWorking knowledge of Structured Query Language.We work on every high-priority ads project at Twitter., You‚Äôre a data scientist with a track record of delivering results.Orchestrate large PB sized data storage and compute clusters across bare-metal and cloud\\nDeploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform.Analytical/problem-solving skills.Strong communication and interpersonal skills to communicate effectively with all levels of staff; both verbally and in writing.Strong skills in analyzing and synthesizing large amounts of data for preparing sound and relevant proposals.Ability to multi-task with demanding time-frames.Ability to use discretion and maintain all confidentiality., Bachelors degree in related area and/or equivalent experience/training]\\n[Fossil Group is seeking a passionate Data Analyst to join our Omni-Channel Marketing team., ', '2+ years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9P_ag3lhYgv6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617904015406,"user_tz":-330,"elapsed":936,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"505ac207-b587-4aaf-a23c-1d74c101fb0c"},"source":["len(description_texts)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["955"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"fnAU4JqIYgwb"},"source":["#Clear the corpus text by removing any punctuation marks etc\n","def clean_text(txt):\n","    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n","    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n","    return txt \n","\n","corpus = [x for x in description_texts]\n","corpus[:100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q0palxNAYgwo"},"source":["tokenizer = Tokenizer()\n","\n","def get_sequence_of_tokens(corpus):\n","    ## tokenization\n","    tokenizer.fit_on_texts(corpus)\n","    total_words = len(tokenizer.word_index) + 1\n","    \n","    ## convert data to sequence of tokens \n","    input_sequences = []\n","    for line in corpus:\n","        token_list = tokenizer.texts_to_sequences([line])[0]\n","        for i in range(1, len(token_list)):\n","            n_gram_sequence = token_list[:i+1]\n","            input_sequences.append(n_gram_sequence)\n","    return input_sequences, total_words\n","\n","inp_sequences, total_words = get_sequence_of_tokens(corpus)\n","# inp_sequences[:10]\n","inp_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S9j6U6iDYgyA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617904042984,"user_tz":-330,"elapsed":1807,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"5764a587-5bc1-40ca-8d5d-7e9e0f1dcfdf"},"source":["def generate_padded_sequences(input_sequences):\n","    max_sequence_len = max([len(x) for x in input_sequences])\n","    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n","    \n","    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n","    label = ku.to_categorical(label, num_classes=total_words)\n","    return predictors, label, max_sequence_len\n","\n","predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)\n","print(max_sequence_len)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["1129\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Tc8SVPbFYgyF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617904063741,"user_tz":-330,"elapsed":1023,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"eb420bf9-a845-45d4-a95a-ac631e774bab"},"source":["from keras.layers import Activation, Embedding, Masking, Dense, SimpleRNN, Dropout\n","from keras.models import Sequential\n","def create_model(max_sequence_len, total_words):\n","    input_len = max_sequence_len - 1\n","    model = Sequential()\n","    \n","    # Add Input Embedding Layer\n","    model.add(Embedding(total_words, 10, input_length=input_len))\n","    \n","    model.add(SimpleRNN(100))\n","    model.add(Dropout(0.1))\n","    \n","    # Add Output Layer\n","    model.add(Dense(total_words, activation='softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer='adam')\n","    \n","    return model\n","\n","rnn_company_model = create_model(max_sequence_len, total_words)\n","rnn_company_model.summary()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 1128, 10)          45870     \n","_________________________________________________________________\n","simple_rnn_1 (SimpleRNN)     (None, 100)               11100     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 100)               0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4587)              463287    \n","=================================================================\n","Total params: 520,257\n","Trainable params: 520,257\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1aB2ZUgfYgyM","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"error","timestamp":1617904369819,"user_tz":-330,"elapsed":290354,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"41764758-9ca0-4803-d996-3a52e319d499"},"source":["rnn_company_model.fit(predictors, label, epochs=25, verbose=5)\n"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Epoch 1/25\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-3f65f038d294>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn_company_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"1fLO6Ww4cNEj"},"source":["from keras.models import load_model\n","model_path = '/content/drive/MyDrive/nlp-job-generator/app/main/resources/models/rnn/rnn_company_model.h5'\n","rnn_model.save(model_path, overwrite=True, include_optimizer=True)  # creates a HDF5 file 'my_model.h5'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OubGZ5ATiITq","executionInfo":{"status":"ok","timestamp":1617896146011,"user_tz":-330,"elapsed":6116,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"9b640cb5-326d-48b7-8564-a8bffffc26fe"},"source":["!pip install pydantic"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pydantic\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/a3/0ffdb6c63f45f10d19b8e8b32670b22ed089cafb29732f6bf8ce518821fb/pydantic-1.8.1-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n","\u001b[K     |████████████████████████████████| 10.1MB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic) (3.7.4.3)\n","Installing collected packages: pydantic\n","Successfully installed pydantic-1.8.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c2WtlC24cj4X"},"source":["from pydantic import BaseModel\n","\n","class requestObject(BaseModel):\n","  seedText: str\n","  nextWords: int"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVP3CCcVYgyR"},"source":["def generateText(seed_text, next_words, model, max_sequence_len):\n","    for _ in range(next_words):\n","        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","        predicted = model.predict_classes(token_list, verbose=0)\n","        \n","        output_word = \"\"\n","        for word,index in tokenizer.word_index.items():\n","            if index == predicted:\n","                output_word = word\n","                break\n","        seed_text += \" \"+output_word\n","    return seed_text.title()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DlGiOD0UYgyZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617896168179,"user_tz":-330,"elapsed":12198,"user":{"displayName":"ANNASAHEB KASHINATH SUNTHE","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjN8Rxd5dfl-55Z7st3_Lh3Ooh6TjVQG3C5s7Iw=s64","userId":"15124525762395221116"}},"outputId":"8b5bcdaa-dd9b-4934-ddbc-b13f32372e2b"},"source":["print (generateText(\"Monitor operations\", 100, rnn_model, max_sequence_len))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Monitor Operations Symbolic Symbolic Symbolic Symbolic Symbolic Symbolic Symbolic Stunning Stunning Standing Improvement Improvement World'S Must Symbolic Symbolic Symbolic Symbolic Symbolic Symbolic Accelerator Symbolic Symbolic Symbolic Symbolic World'S Verbal World'S Symbolic Speaking Symbolic Solid Institute Facilitating Symbolic Strives Allowed Crime Possession Allowed Dtr Supports Symbolic Designers Fortune‚Äôs Institute Exceptional Specialists Strives Monitoring Symbolic 123 Platforms Typically Groups Beyond Symbolic Scorecard Spec World'S Protocols Verbal Different Outcomes Charts Geo Made Linc‚Äôs Changing Paced Omniture Picture Offices Receipt Recommendationsdrives Speaking Suite Monitoring Architect Complex Omniture Appreciation Optoro'S Adobe Degree Exhibits Sponsored Observational Countries Matters Drinks Perceive Whether Hypothesis Symbolic Oracle Id Nyc Normal Emerging\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vo4s2rk1Ygyj"},"source":["#Install colabcode and fastapi\n","!pip install colabcode\n","!pip install fastapi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q_xl1RXVc3C2"},"source":["#import libraries for loading saved model, fast api, colabcode\n","import tensorflow as tf\n","from tensorflow import keras\n","from colabcode import ColabCode\n","from fastapi import FastAPI\n","from keras.models import load_model\n","\n","import logging\n","from fastapi import FastAPI\n","\n","app=FastAPI(title=\"NlpJdGeneratorAPI\", description=\"NLP based RNN model Job Description Generator\")\n","\n","#initializing logging\n","my_logger = logging.getLogger()\n","my_logger.setLevel(logging.DEBUG)\n","logging.basicConfig(level=logging.DEBUG, filename='rnn_logs.log')\n","\n","#Initalize lstml model to load and model file path\n","rnn_company_model = None\n","rnn_company_model_path = '/content/drive/MyDrive/nlp-job-generator/app/main/resources/models/rnn/rnn_company_model.h5'\n","max_sequence_length = 1000\n","\n","@app.on_event(\"startup\")\n","#Returns a compiled model identical to the saved after trained\n","def load_saved_model():\n","  global rnn_company_model\n","  rnn_company_model = tf.keras.models.load_model(rnn_model_path)\n","\n","@app.post(\"/api\")\n","async def getJobDescription(request:requestObject):\n","  try:\n","    print(request)\n","    my_logger.debug(\"request:\", request)\n","\n","    prediction = generateText(request.seedText, request.nextWords, rnn_company_model, max_sequence_length)\n","    my_logger.debug(\"prediction:\", prediction)\n","    print(prediction)\n","\n","    return {\"job_description\" : prediction}\n","  except:\n","    my_logger.error(\"Someting went wrong!\")\n","    return {\"prediction\": \"error\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WD5aQjQUdX3S"},"source":["from colabcode import ColabCode\n","from fastapi import FastAPI\n","cc = ColabCode(port=1200, code=False, authtoken=\"1qhOBp2p5qxw80yQipxR0JHwMbl_5choeHxGXkp6HVXZ66hTh\")\n","cc.run_app(app=app)"],"execution_count":null,"outputs":[]}]}