{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4t3z7Ttej7gw",
    "outputId": "17c42019-60d1-48a7-8462-bbf41388a3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "import io\n",
    "import os\n",
    "\n",
    "from google.colab import files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D6Lwn2Q1kC0B"
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('/content/gdrive/My Drive/jd_role_res_corpus_V1.csv', encoding= 'unicode_escape')\n",
    "headers = [\"Description\"] \n",
    "all_headlines = pd.read_csv(\"/content/gdrive/My Drive/jd_role_res_corpus_V1.csv\", names = headers, sep='\\t',nrows= 100) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wSCJJ8s8kJpA"
   },
   "outputs": [],
   "source": [
    "texts = list(set(all_headlines['Description']))\n",
    "#texts = texts[:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIESQc43kLTZ",
    "outputId": "6b51348c-c5ab-4fd4-ac01-a087acb84bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You can write quality production code;', 'Successful experience working in a fast-paced start-up work environment a plus', 'Clinical database experience preferred', 'Demonstrated experience with report creation tools (e.g., Crystal reports, SQL Server Reporting Services)', 'Experience in ESRI software key', \"Cloud environment development & operations experience (e.g.We work in complementary teams comprising members from Data Science and various groups at Visa.Flexible and adaptable attitude, disciplined to manage multiple responsibilities and adjust to varied environments.).,  Exposure to mathematical programming libraries (e.g., 3+ Years‚Äô relevant working experience.You will use SAS daily and should be familiar with Tableau, SQL and/or R. Take the first step to join our team by applying now., Bachelor's degree required\", 'Good knowledge of Python and/or R', ', Skills, Qualifications, and Competencies, Related work experience', ', Data Services', 'User Training', 'Complies with company policies and procedures', 'Performs other tasks as required', 'Excellent SQL, Excel and general programming / coding skills', 'Team player', ', DESIRED QUALIFICATIONS:', 'Strong written and verbal communication skills', 'Experience in a financial and/or technical analysis business related environment', 'Strong organization & project management skills.Work alongside software developers and software engineers to translate algorithms into commercially viable products and services.General inquiries about application status will not be addressed.]\"Specifically, you will be responsible for the following:, What you\\'ll be doing, Building out a robust T&S data platform from how we define T&S issues to developing reporting mechanisms to share that data with key stakeholdersMonitoring and managing incident rates globally, and working proactively to identify opportunities for improvements in data quality and/or Trust and Safety efforts.Collaborate with cross-functional agile teams, including product, marketing, analytics and data science, to understand, design and develop data models to support business reporting and analysisAssist the Data Services Team Lead in maintaining optimal data pipeline architecture and performanceResearch, design and share your ideas in technical design and architecture discussionsIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etcBe subject matter expert of our data warehouse stack; MySQL, Alooma, Snowflake, dbt and TableauEnsure compliance with international data storage regulations (e.g.Thorough understanding of Multivariable Calculus and Linear Algebra', 'Prior relevant industry experience preferred', 'Process oriented, logical thinker', \"[At Abbott, we're committed to helping people live their best possible life through the power of health.R, SAS) or other methods, \\n\\nAdvanced degrees, \\n\\nExperience with distributed computing (Hive/Hadoop)]\", 'Understanding of projections and datum transformations', 'Experience in Auto / Motorcycle lending a plus', ', The qualified candidate will become part of the Data Science and Artificial Intelligence Department., IT is where business, innovation and technology integrate to build a competitive advantage for P&G.If the following qualities ring true, you would fit right in at Shift Technology:, ', 'Support the cyber incident response team in specified vulnerability discovery and identification tasks during crisis management.Ability to work collaboratively with others in team environment', 'Ability to develop and manage effective relationships', ']\"', 'You combine strong analysis with synthesis abilities and are not afraid to deal with the details;', 'Attention to detail', 'Excellent analytical thinking - you connect the dots between the data and operations and gut check every number you see', 'Optimize existing data and reporting processes', 'Quality Control of imagery prepared by others', 'DESIRED QUALIFICATIONS:', 'Basic understanding of statistical techniques and ability to employ them in solving business problems', 'BA/BS in Economics, Business, Engineering, Operations Research, or other quantitative focus', 'Planimetric collection - Using CAD software to create vectors for mapping purposes', 'Tool Standards', 'Strong interpersonal skills and ability to interact seamlessly with all levels of management', ', Two (2) years of experience in database analysis design involving experience with database and software validation, current querying tools and knowledge of relational database structures and methodologies required', \"[s and assign them to descriptive, dynamically-generated item categories\\n\\nWrite heuristics to figure out when two or more listings are talking about the same item.Experience in creating and automating analytics reports preferably for B2B enterprise technology clients\\n\\nDeep understanding of data dimensioning and metrics, proper use of tracking variables and how they are implemented for deep dive analysis and automated reporting.Participates in model integration and convergence activities.This person will also lead VC, FTS and back off data cleansing for subsequent go-lives.Experience with the latest in modular programming technologies, best practices with micro-services architecture, and the latest in Big Data tech; like Hadoop, Kafka, Scala, Spark, and Cassandra.The resulting software will be added to an existing C++/Python code library., KEY FUNCTIONS, Conduct research and implementation of multi-category object recognition/classification software\\nContribute to an existing C++/Python code library.Work with HRIS to align, integrate, and automate compensation processes in support of the University's compensation strategy.If so, please describe the data and how it was used.S/he works closely with the Bureau‚Äôs systems administrator to maintain the REE Tracking Application (REETA), including maintaining user-defined system tables; add, modifying or inactivating letter/email templates; creating data entry templates for new programs and updating the server with current status/standing for applicants/candidates.[Discover customer and patient insights using advanced analytics techniques such as natural language processing, text analytics, machine learning, and analytic modeling aligned with and guided by the Medical Affairs business priorities and strategies for the Therapeutic area (TA); support the Director in recommending the advanced analytics applied solution for the TA or USMA broadly, Develop advanced analytics solutions based on an understanding of the listening priorities, business challenges, the competitive environment, and challenges/opportunities for the TA or overall USMA, Ensure advanced analytics method application excellence with attention to detail and quality measures in place; Share best practices, demonstrate and further develop business acumen, and ensure customer focus for solutions aligned with key priorities for the TA, Identify and proactively seek out opportunities for improved advanced analytics methods, approaches, and applications by researching industry trends, academic/external methods applied successfully, best practices, and external benchmarks for competitive value; stay on top of new and emerging trends and methods to maximize insights from available data sources (both unstructured and structured), Analyze unstructured data collected from multiple feedback sources including but not limited to Medical voice of customer feedback resulting from customer listening with Medical Engagement, feedback collected via surveys and research, forums, online communities, social media/publicly available information, and call center voice and email feedback as well as any other available sources of customer feedback data and information, Translate unstructured data, in combination with other structured data sources, into actionable insights for the Medical Matrix Team (MMTs) and Medical strategies; Conduct text, sentiment, and root cause analyses to answer critical Medical business questions and produce data-driven stories that reveal key insights into customer and patient experience, needs, and understanding to determine appropriate Medical opportunities., Develop broad methodological and approach expertise; Act as a key text analytics and voice of customer expert for US Medical Affairs staying on top of the latest external methods and approaches, current and emerging industry trends, and advanced methods/best practices to continue to produce deeper customer insights for business decision making; Earn the trust of stakeholder partners through active engagement, demonstrated learning, and business acumen development., Responsible for delivering timely/close to real time strategic, relevant and actionable insights and for leading Voice of the Customer (VOC) analyses leveraging a wide range of analytical and data visualization tools and resources available to uncover and communicate opportunities; Collect, document, synthesize and organize complex information, making it relevant, understandable and actionable for internal stakeholders.Be able to regularly report on these members flowing through the intervention process.Identify and implement short-term solutions in a timely manner, while helping define the long-term solution\", 'Collaborate with infrastructure and application owners on security hot-fixes or patch management validation', 'Travel required (approx.Challenge your coworkers to a Nintendo Wii U or Xbox 360 gaming break.Excel and/or Access Certificate preferred.Interpret data, analyze results to provide insight into business performance and suggest areas and methods of improving operations.The Data Analyst is responsible for the Quality Assurance /Quality Control of post-acquisition LiDAR data in preparation for final product generation, Key Accountabilities, Feature coding - 2D/3D feature coding and or quality control of collected LiDAR data', 'Experience using Microstation/ESRI/Imagery processing software packages', 'Monitor operations, develop and report quality metrics to key stakeholders', 'Knowledge of relational databases, SQL', 'Ensure data integrity across several data sources, reports, and dashboards', ', Preparation and processing of ortho imagery and associated deliverables', 'Proficient with real-time data replication/streaming tools & techniques', 'Post-secondary educational in Geography, GIS, Geomatics or other related discipline, or equivalent work experience', 'Must possess strong analytical thinking and problem-solving skills', 'Extensive knowledge with SQL / Oracle, SAS, KnowledgeStudeo, R, Python', 'Experience in Agile methodology', 'Good presentation skills and ability to present data to Senior Management', 'Working within an agile environment, the Senior Data Engineer will provide input into architectural design decisions, develop code to meet business needs and ensure the applications we build are meeting high standards of quality and supportability.Excellent communication skills; this role requires regular interaction with team leads from each part of the product.Data Steward, Quality Specialist)', 'Define & implement Policies & SOPs', 'Create data pipelines using big data technologies like Hadoop, Spark etc.\"[Seattle City Light, a department of the City of Seattle, is one of the nation\\'s largest municipally owned utilities in terms of the number of customers served.Approximately 10-week summer internship from May/June to August 2019.', ', Skills & Responsibilities:, Expert-level ETL designer/developer', 'Build and maintain data pipelines', 'Skilled use of DBVisualizer, DB2 and/or Oracle', 'Ability to manage multiple projects with competing deadlines a must', 'Data Lineage', 'Assess publicly and privately announced security vulnerabilities to determine the risk based on severity, threat likelihood and impact', 'Strong SQL', 'Collaborate with regional POCs to understand KPI and data requirements', 'Data Dictionary', 'PLS‚ÄìCADD project and .bak file - creation of the final deliverables for clients', 'Demonstrated competency in developing program materials for use by external partners and project staff', 'Experience working with solutions lifecycle development methodology preferred', 'Experience using Microsoft Office Suite', 'Experience using Microstation/PLS-CADD is desirable', 'Familiarity with business processes related to business channel supported preferred', '4+ years of collective experience in data engineering, data analysis, data warehousing, data integration or business intelligence, in a similarly sized organization.The role will be tightly interlinked to ZF‚Äôs divisions / functions and IT, closely partnering with respective technical and business teams and data subject matter experts to deliver a comprehensive model strategy, roadmap, and actual models leveraging data sets synthesized from multiple data sources by the data engineering teams.Demonstrated experience with SAS, SPSS, R, or STATA', ', Using internal GIS software prepare/review and process input GIS data to final products', \"You don't mind meeting with clients to discuss their needs and integrate their feedback in your projects;\", 'Identify and recommend appropriate measures to manage and remediate vulnerabilities and reduce potential impacts on information resources to a level acceptable to the senior management of the company', ', ', 'Understands relationship between people, processes and technology within an organization to create a feasible solution on projects of low to medium complexity', 'Own change management as our business changes and new data sources are added, KPIs change, etc, ', 'High level of computer literacy', 'Demonstrated ability to participate in requirements gathering process, provide user documentation, and write clear, concise comments within programs', 'Minimum of three years of demonstrated successful use of major components of the solution delivery methodology or demonstrated knowledge of business processes related to the business channel supported', 'You have advanced technical skills in Applied Mathematics, preferably in machine learning and/or operations research;', 'You are bilingual in English !]\"You have experience with SQL and Data Warehousing using a relational database.You will need to be an individual who is ready to work through a fast paced startup environment., Required Skills & Experience, B.S.Experience with BI/reporting tools such as Tableau is a plus.Identify and articulate risks and remediation in a relevant and approachable manner with both technical and non-technical audiences', ', Promotes and behaves in a fashion to support GeoDigital‚Äôs Cultural Pillars', 'Demonstrated competency in collaborating on projects and with program staff and conduct statistical analysis that represents the project', 'Knowledge of and experience with testing concepts and skilled in formulating test strategies, managing, and executing system testing initiatives', 'Structured & unstructured data expertise', 'THE FOLLOWING IS DESIRED, BUT NOT REQUIRED TO BE CONSIDERED FOR THIS POSITION:, Experience with Health Level-7 (HL7) standards', 'Excellent written and oral communication skills', 'Ability to thrive under pressure and in challenging environments', 'Preparation and processing of oblique imagery and associated deliverables', 'Proficiency in developing complex SQL queries', 'Best Practices', 'Assists in designing correction plans, mitigations, and full remediation actions', ', St. Jude is an Equal Opportunity Employer, St. Jude Children\\'s Research Hospital does not accept unsolicited assistance from search firms for employment opportunities.\"[', \"Bachelor's degree in health sciences, computer science or related field preferred\", ', Work Environment, Works in a fast paced office environment with multiple priorities and competing demands; potential set-backs in project completion due to internal or external issues, resourcing and re-allocation.Comp Science, Math, Engineering) or related experience', '[\\n\\nApply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand how our users interact with both our consumer and business products, \\n\\nPartner with Product and Engineering teams to solve problems and identify trends and opportunities, \\n\\nInform, influence, support, and execute our product decisions and product launches, \\n\\nThe Data Scientist Analytics role has work across the following four areas:, \\n\\nProduct Operations, \\n\\nForecasting and setting product team goals, Forecasting and setting product team goals, \\n\\nDesigning and evaluating experiments, Designing and evaluating experiments, \\n\\nMonitoring key product metrics, understanding root causes of changes in metrics, Monitoring key product metrics, understanding root causes of changes in metrics, \\n\\nBuilding and analyzing dashboards and reports, Building and analyzing dashboards and reports, \\n\\nBuilding key data sets to empower operational and exploratory analysis, Building key data sets to empower operational and exploratory analysis, \\n\\nEvaluating and defining metrics, Evaluating and defining metrics, \\n\\nExploratory Analysis, \\n\\nProposing what to build in the next roadmap, Proposing what to build in the next roadmap, \\n\\nUnderstanding ecosystems, user behaviors, and long-term trends, Understanding ecosystems, user behaviors, and long-term trends, \\n\\nIdentifying new levers to help move key metrics, Identifying new levers to help move key metrics, \\n\\nBuilding models of user behaviors for analysis or to power production systems, Building models of user behaviors for analysis or to power production systems, \\n\\nProduct Leadership, \\n\\nInfluencing product teams through presentation of data-based recommendations, Influencing product teams through presentation of data-based recommendations, \\n\\nCommunicating state of business, experiment results, etc.Develop reports and conduct quantitative analysis to understand the trend or issues and to identify the opportunity to improve the quality of care and member experience by using survey data along with other administrative data.to unlimited vacation, flexible work hours, competitive pay, and generous equity!Prior experience developing, maintaining, and supporting application, business glossary, business intelligence, data integration, data modeling, and database management resources in Metadata Management.Publications in robotics and computer vision conferences and journals.Experience deploying datascience in investing is a plus., Job Summary :\\n\\n, 3M‚Äôs Corporate Security team is seeking a Security Data Scientist to analyze structured and unstructured data and to enhance monitoring activities and improve efficiencies.Portfolio of interactive notebooks, with experience in single-page web app dev nice-to-have\\n\\nAcademically-rigorous, but commercially-minded, and enjoy seeing your work make money for a company that rewards you in return\\n\\nAdaptable, resourceful, well organized team player with a strong work ethic\\n\\nAgree that verbal and written communication skills are vital\\n\\nEager to grow your skills\\n\\nEducated to degree level or above]', 'Minimum 2 years of experience in a quantitative / reporting / analytical role']\n"
     ]
    }
   ],
   "source": [
    "print (texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YEzBGkgkM7m",
    "outputId": "8392305f-55cb-4058-cf25-4bb3535c0cd9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "VQ4bHq4FkPS1"
   },
   "outputs": [],
   "source": [
    "file_name = 'training.txt'\n",
    "outF = open(file_name, 'w') \n",
    "for line in texts:\n",
    "  outF.write(str(line))\n",
    "  outF.write(\"\\n\")\n",
    "outF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDnFIF5kkR18",
    "outputId": "6d88b90e-3419-4cf7-8845-ba2448822257"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping transformers as it is not installed.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gk1Bq_1V5O2C",
    "outputId": "2cf14c49-22f0-41a7-a828-2197274b6c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\n",
      "remote: Enumerating objects: 314, done.\u001b[K\n",
      "remote: Counting objects: 100% (314/314), done.\u001b[K\n",
      "remote: Compressing objects: 100% (225/225), done.\u001b[K\n",
      "remote: Total 69600 (delta 162), reused 179 (delta 76), pack-reused 69286\u001b[K\n",
      "Receiving objects: 100% (69600/69600), 53.02 MiB | 29.59 MiB/s, done.\n",
      "Resolving deltas: 100% (49254/49254), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers\n",
    "#!cd transformers\n",
    "#!pip install .\n",
    "#!pip install transformers\n",
    "#!pip install git+https://github.com/huggingface/transformers\n",
    "#!pip install -r transformers/examples/language-modeling/requirements.txt\n",
    "#!git clone https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gz4jZpls4Wo4",
    "outputId": "4f108eaf-3b4b-4e46-ddd3-413c43bdc562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/transformers/transformers\n"
     ]
    }
   ],
   "source": [
    "cd transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "exUMhvMC6bDa",
    "outputId": "7f3313c9-a53d-4adc-caa1-9c209309dafa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\n",
      "Your branch is up to date with 'origin/master'.\n",
      "\n",
      "nothing to commit, working tree clean\n"
     ]
    }
   ],
   "source": [
    "!git status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mxeqb6Tb6oCC",
    "outputId": "cb22f22a-2f4e-48be-c1a7-289327ed0ce1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: checking out 'tags/v4.1.1'.\n",
      "\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\n",
      "changes and commit them, and you can discard any commits you make in this\n",
      "state without impacting any branches by performing another checkout.\n",
      "\n",
      "If you want to create a new branch to retain commits you create, you may\n",
      "do so (now or later) by using -b with the checkout command again. Example:\n",
      "\n",
      "  git checkout -b <new-branch-name>\n",
      "\n",
      "HEAD is now at bfa4ccf77 Release: v4.1.1\n"
     ]
    }
   ],
   "source": [
    "!git checkout tags/v4.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wx2GWSC4Y1f",
    "outputId": "7435a8e7-2333-4524-f46b-a6aad8afcfb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/transformers/transformers\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKqxnNXG4fSz",
    "outputId": "77ef0bc8-962f-4152-9582-be236b8b716e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /content/transformers/transformers\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (0.0.44)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (3.0.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2019.12.20)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (0.9.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.1.1) (2.23.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.1.1) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.1.1) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.1.1) (1.24.3)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.1.1-cp37-none-any.whl size=1512966 sha256=7525ec685c51a84edca9a60afec611174717d511f7b7ba5975de5319f30b51ad\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l0mf0c0s/wheels/24/4e/ad/9bac5e50177cae64c9b8ec988ae7d7d1f114f296276d2080f5\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "Successfully installed transformers-4.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "su_G3cPG47eB",
    "outputId": "187e3e44-0ce4-49eb-c164-062003fb1b30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/transformers\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RjTG_mtC4qC1",
    "outputId": "bff491d9-7b8c-41f5-af55-553fba1a59ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/language-modeling/requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/language-modeling/requirements.txt (line 2)) (0.1.95)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/language-modeling/requirements.txt (line 3)) (3.12.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (1.1.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.70.11.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (4.41.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->-r transformers/examples/language-modeling/requirements.txt (line 3)) (54.2.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r transformers/examples/language-modeling/requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2018.9)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.0.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r transformers/examples/language-modeling/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RjiWPUaolTS4",
    "outputId": "afb8ec2d-2c10-42ca-b991-f25b4aefaa84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.0)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.41.1)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.8)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "dYNXngXelVgZ"
   },
   "outputs": [],
   "source": [
    "weights_dir = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "cIqyTEFnlXai"
   },
   "outputs": [],
   "source": [
    "cmd = '''\n",
    "python transformers/examples/language-modeling/run_clm.py \\\n",
    "    --model_name_or_path distilgpt2 \\\n",
    "    --train_file {0} \\\n",
    "    --overwrite_output_dir \\\n",
    "    --do_train \\\n",
    "    --num_train_epochs 3 \\\n",
    "    --per_device_train_batch_size 2 \\\n",
    "    --output_dir {1} \\\n",
    " '''.format(file_name, weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LHf8bfjFyYx_",
    "outputId": "e6b6c516-318e-442d-f9c9-09a58520e4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version        Location                               Installer\n",
      "----------------------------- -------------- -------------------------------------- ---------\n",
      "absl-py                       0.12.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "alabaster                     0.7.12         /usr/local/lib/python3.7/dist-packages pip      \n",
      "albumentations                0.1.12         /usr/local/lib/python3.7/dist-packages pip      \n",
      "altair                        4.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "appdirs                       1.4.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "argon2-cffi                   20.1.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "astor                         0.8.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "astropy                       4.2            /usr/local/lib/python3.7/dist-packages pip      \n",
      "astunparse                    1.6.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "async-generator               1.10           /usr/local/lib/python3.7/dist-packages pip      \n",
      "atari-py                      0.2.6          /usr/local/lib/python3.7/dist-packages pip      \n",
      "atomicwrites                  1.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "attrs                         20.3.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "audioread                     2.1.9          /usr/local/lib/python3.7/dist-packages pip      \n",
      "autograd                      1.3            /usr/local/lib/python3.7/dist-packages pip      \n",
      "Babel                         2.9.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "backcall                      0.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "beautifulsoup4                4.6.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "bleach                        3.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "blis                          0.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "bokeh                         2.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Bottleneck                    1.3.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "branca                        0.4.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "bs4                           0.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "CacheControl                  0.12.6         /usr/local/lib/python3.7/dist-packages pip      \n",
      "cachetools                    4.2.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "catalogue                     1.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "certifi                       2020.12.5      /usr/local/lib/python3.7/dist-packages pip      \n",
      "cffi                          1.14.5         /usr/local/lib/python3.7/dist-packages pip      \n",
      "chainer                       7.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "chardet                       3.0.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "click                         7.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "cloudpickle                   1.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "cmake                         3.12.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "cmdstanpy                     0.9.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "colorcet                      2.0.6          /usr/local/lib/python3.7/dist-packages pip      \n",
      "colorlover                    0.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "community                     1.0.0b1        /usr/local/lib/python3.7/dist-packages pip      \n",
      "contextlib2                   0.5.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "convertdate                   2.3.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "coverage                      3.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "coveralls                     0.5            /usr/local/lib/python3.7/dist-packages pip      \n",
      "crcmod                        1.7            /usr/local/lib/python3.7/dist-packages pip      \n",
      "cufflinks                     0.17.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "cupy-cuda101                  7.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "cvxopt                        1.2.6          /usr/local/lib/python3.7/dist-packages pip      \n",
      "cvxpy                         1.0.31         /usr/local/lib/python3.7/dist-packages pip      \n",
      "cycler                        0.10.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "cymem                         2.0.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Cython                        0.29.22        /usr/local/lib/python3.7/dist-packages pip      \n",
      "daft                          0.0.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "dask                          2.12.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "datascience                   0.10.6         /usr/local/lib/python3.7/dist-packages pip      \n",
      "datasets                      1.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "debugpy                       1.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "decorator                     4.4.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "defusedxml                    0.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "descartes                     1.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "dill                          0.3.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "distributed                   1.25.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "dlib                          19.18.0        /usr/local/lib/python3.7/dist-packages pip      \n",
      "dm-tree                       0.1.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "docopt                        0.6.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "docutils                      0.16           /usr/local/lib/python3.7/dist-packages pip      \n",
      "dopamine-rl                   1.0.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "earthengine-api               0.1.258        /usr/local/lib/python3.7/dist-packages pip      \n",
      "easydict                      1.9            /usr/local/lib/python3.7/dist-packages pip      \n",
      "ecos                          2.0.7.post1    /usr/local/lib/python3.7/dist-packages pip      \n",
      "editdistance                  0.5.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "en-core-web-sm                2.2.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "entrypoints                   0.3            /usr/local/lib/python3.7/dist-packages pip      \n",
      "ephem                         3.7.7.1        /usr/local/lib/python3.7/dist-packages pip      \n",
      "et-xmlfile                    1.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fa2                           0.3.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fancyimpute                   0.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fastai                        2.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fastcore                      1.3.19         /usr/local/lib/python3.7/dist-packages pip      \n",
      "fastdtw                       0.3.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fastprogress                  1.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fastrlock                     0.6            /usr/local/lib/python3.7/dist-packages pip      \n",
      "fbprophet                     0.7.1          /usr/local/lib/python3.7/dist-packages          \n",
      "feather-format                0.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "filelock                      3.0.12         /usr/local/lib/python3.7/dist-packages pip      \n",
      "firebase-admin                4.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fix-yahoo-finance             0.0.22         /usr/local/lib/python3.7/dist-packages pip      \n",
      "Flask                         1.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "flatbuffers                   1.12           /usr/local/lib/python3.7/dist-packages pip      \n",
      "folium                        0.8.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "fsspec                        0.9.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "future                        0.16.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "gast                          0.3.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "GDAL                          2.2.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "gdown                         3.6.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "gensim                        3.6.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "geographiclib                 1.50           /usr/local/lib/python3.7/dist-packages pip      \n",
      "geopy                         1.17.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "gin-config                    0.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "glob2                         0.7            /usr/local/lib/python3.7/dist-packages pip      \n",
      "google                        2.0.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-api-core               1.26.2         /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-api-python-client      1.12.8         /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-auth                   1.28.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-auth-httplib2          0.0.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-auth-oauthlib          0.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-bigquery         1.21.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-bigquery-storage 1.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-core             1.0.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-datastore        1.8.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-firestore        1.7.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-language         1.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-storage          1.18.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-cloud-translate        1.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-colab                  1.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-pasta                  0.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "google-resumable-media        0.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "googleapis-common-protos      1.53.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "googledrivedownloader         0.4            /usr/local/lib/python3.7/dist-packages pip      \n",
      "graphviz                      0.10.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "greenlet                      1.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "grpcio                        1.32.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "gspread                       3.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "gspread-dataframe             3.0.8          /usr/local/lib/python3.7/dist-packages pip      \n",
      "gym                           0.17.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "h5py                          2.10.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "HeapDict                      1.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "hijri-converter               2.1.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "holidays                      0.10.5.2       /usr/local/lib/python3.7/dist-packages pip      \n",
      "holoviews                     1.14.2         /usr/local/lib/python3.7/dist-packages pip      \n",
      "html5lib                      1.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "httpimport                    0.5.18         /usr/local/lib/python3.7/dist-packages pip      \n",
      "httplib2                      0.17.4         /usr/local/lib/python3.7/dist-packages pip      \n",
      "httplib2shim                  0.0.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "huggingface-hub               0.0.8          /usr/local/lib/python3.7/dist-packages pip      \n",
      "humanize                      0.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "hyperopt                      0.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "ideep4py                      2.0.0.post3    /usr/local/lib/python3.7/dist-packages pip      \n",
      "idna                          2.10           /usr/local/lib/python3.7/dist-packages pip      \n",
      "imageio                       2.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "imagesize                     1.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "imbalanced-learn              0.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "imblearn                      0.0            /usr/local/lib/python3.7/dist-packages pip      \n",
      "imgaug                        0.2.9          /usr/local/lib/python3.7/dist-packages pip      \n",
      "importlib-metadata            3.8.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "importlib-resources           5.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "imutils                       0.5.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "inflect                       2.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "iniconfig                     1.1.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "intel-openmp                  2021.2.0       /usr/local/lib/python3.7/dist-packages pip      \n",
      "intervaltree                  2.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "ipykernel                     4.10.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "ipython                       5.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "ipython-genutils              0.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "ipython-sql                   0.3.9          /usr/local/lib/python3.7/dist-packages pip      \n",
      "ipywidgets                    7.6.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "itsdangerous                  1.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jax                           0.2.11         /usr/local/lib/python3.7/dist-packages pip      \n",
      "jaxlib                        0.1.64+cuda110 /usr/local/lib/python3.7/dist-packages pip      \n",
      "jdcal                         1.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jedi                          0.18.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "jieba                         0.42.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "Jinja2                        2.11.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "joblib                        1.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jpeg4py                       0.1.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jsonschema                    2.6.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jupyter                       1.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jupyter-client                5.3.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jupyter-console               5.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jupyter-core                  4.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jupyterlab-pygments           0.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "jupyterlab-widgets            1.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "kaggle                        1.5.12         /usr/local/lib/python3.7/dist-packages pip      \n",
      "kapre                         0.1.3.1        /usr/local/lib/python3.7/dist-packages pip      \n",
      "Keras                         2.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Keras-Preprocessing           1.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "keras-vis                     0.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "kiwisolver                    1.3.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "knnimpute                     0.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "korean-lunar-calendar         0.2.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "librosa                       0.8.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "lightgbm                      2.2.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "llvmlite                      0.34.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "lmdb                          0.99           /usr/local/lib/python3.7/dist-packages pip      \n",
      "LunarCalendar                 0.0.9          /usr/local/lib/python3.7/dist-packages pip      \n",
      "lxml                          4.2.6          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Markdown                      3.3.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "MarkupSafe                    1.1.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "matplotlib                    3.2.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "matplotlib-venn               0.11.6         /usr/local/lib/python3.7/dist-packages pip      \n",
      "missingno                     0.4.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "mistune                       0.8.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "mizani                        0.6.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "mkl                           2019.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "mlxtend                       0.14.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "more-itertools                8.7.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "moviepy                       0.2.3.5        /usr/local/lib/python3.7/dist-packages pip      \n",
      "mpmath                        1.2.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "msgpack                       1.0.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "multiprocess                  0.70.11.1      /usr/local/lib/python3.7/dist-packages pip      \n",
      "multitasking                  0.0.9          /usr/local/lib/python3.7/dist-packages pip      \n",
      "murmurhash                    1.0.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "music21                       5.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "natsort                       5.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "nbclient                      0.5.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "nbconvert                     5.6.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "nbformat                      5.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "nest-asyncio                  1.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "networkx                      2.5            /usr/local/lib/python3.7/dist-packages pip      \n",
      "nibabel                       3.0.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "nltk                          3.2.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "notebook                      5.3.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "np-utils                      0.5.12.1       /usr/local/lib/python3.7/dist-packages pip      \n",
      "numba                         0.51.2         /usr/local/lib/python3.7/dist-packages pip      \n",
      "numexpr                       2.7.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "numpy                         1.19.5         /usr/local/lib/python3.7/dist-packages pip      \n",
      "nvidia-ml-py3                 7.352.0        /usr/local/lib/python3.7/dist-packages pip      \n",
      "oauth2client                  4.1.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "oauthlib                      3.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "okgrade                       0.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "opencv-contrib-python         4.1.2.30       /usr/local/lib/python3.7/dist-packages pip      \n",
      "opencv-python                 4.1.2.30       /usr/local/lib/python3.7/dist-packages pip      \n",
      "openpyxl                      2.5.9          /usr/local/lib/python3.7/dist-packages pip      \n",
      "opt-einsum                    3.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "osqp                          0.6.2.post0    /usr/local/lib/python3.7/dist-packages pip      \n",
      "packaging                     20.9           /usr/local/lib/python3.7/dist-packages pip      \n",
      "palettable                    3.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pandas                        1.1.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pandas-datareader             0.9.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pandas-gbq                    0.13.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "pandas-profiling              1.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pandocfilters                 1.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "panel                         0.11.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "param                         1.10.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "parso                         0.8.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pathlib                       1.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "patsy                         0.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pexpect                       4.8.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pickleshare                   0.7.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Pillow                        7.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pip                           19.3.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "pip-tools                     4.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "plac                          1.1.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "plotly                        4.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "plotnine                      0.6.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pluggy                        0.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pooch                         1.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "portpicker                    1.3.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "prefetch-generator            1.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "preshed                       3.0.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "prettytable                   2.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "progressbar2                  3.38.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "prometheus-client             0.10.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "promise                       2.3            /usr/local/lib/python3.7/dist-packages pip      \n",
      "prompt-toolkit                1.0.18         /usr/local/lib/python3.7/dist-packages pip      \n",
      "protobuf                      3.12.4         /usr/local/lib/python3.7/dist-packages pip      \n",
      "psutil                        5.4.8          /usr/local/lib/python3.7/dist-packages pip      \n",
      "psycopg2                      2.7.6.1        /usr/local/lib/python3.7/dist-packages pip      \n",
      "ptyprocess                    0.7.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "py                            1.10.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyarrow                       3.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyasn1                        0.4.8          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyasn1-modules                0.2.8          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pycocotools                   2.0.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pycparser                     2.20           /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyct                          0.4.8          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pydata-google-auth            1.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pydot                         1.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pydot-ng                      2.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pydotplus                     2.0.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "PyDrive                       1.3.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyemd                         0.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyerfa                        1.7.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyglet                        1.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Pygments                      2.6.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pygobject                     3.26.1         /usr/lib/python3/dist-packages                  \n",
      "pymc3                         3.7            /usr/local/lib/python3.7/dist-packages pip      \n",
      "PyMeeus                       0.5.11         /usr/local/lib/python3.7/dist-packages pip      \n",
      "pymongo                       3.11.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "pymystem3                     0.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "PyOpenGL                      3.1.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyparsing                     2.4.7          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyrsistent                    0.17.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "pysndfile                     1.3.8          /usr/local/lib/python3.7/dist-packages pip      \n",
      "PySocks                       1.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pystan                        2.19.1.1       /usr/local/lib/python3.7/dist-packages pip      \n",
      "pytest                        3.6.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "python-apt                    0.0.0          /usr/local/lib/python3.7/dist-packages          \n",
      "python-chess                  0.23.11        /usr/local/lib/python3.7/dist-packages pip      \n",
      "python-dateutil               2.8.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "python-louvain                0.15           /usr/local/lib/python3.7/dist-packages pip      \n",
      "python-slugify                4.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "python-utils                  2.5.6          /usr/local/lib/python3.7/dist-packages pip      \n",
      "pytz                          2018.9         /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyviz-comms                   2.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "PyWavelets                    1.1.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "PyYAML                        3.13           /usr/local/lib/python3.7/dist-packages pip      \n",
      "pyzmq                         22.0.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "qdldl                         0.1.5.post0    /usr/local/lib/python3.7/dist-packages pip      \n",
      "qtconsole                     5.0.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "QtPy                          1.9.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "regex                         2019.12.20     /usr/local/lib/python3.7/dist-packages pip      \n",
      "requests                      2.23.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "requests-oauthlib             1.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "resampy                       0.2.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "retrying                      1.3.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "rpy2                          3.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "rsa                           4.7.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "sacremoses                    0.0.44         /usr/local/lib/python3.7/dist-packages pip      \n",
      "scikit-image                  0.16.2         /usr/local/lib/python3.7/dist-packages pip      \n",
      "scikit-learn                  0.22.2.post1   /usr/local/lib/python3.7/dist-packages pip      \n",
      "scipy                         1.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "screen-resolution-extra       0.0.0          /usr/lib/python3/dist-packages                  \n",
      "scs                           2.1.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "seaborn                       0.11.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "Send2Trash                    1.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "sentencepiece                 0.1.95         /usr/local/lib/python3.7/dist-packages pip      \n",
      "setuptools                    54.2.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "setuptools-git                1.2            /usr/local/lib/python3.7/dist-packages pip      \n",
      "Shapely                       1.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "simplegeneric                 0.8.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "six                           1.15.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "sklearn                       0.0            /usr/local/lib/python3.7/dist-packages pip      \n",
      "sklearn-pandas                1.8.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "smart-open                    4.2.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "snowballstemmer               2.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "sortedcontainers              2.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "SoundFile                     0.10.3.post1   /usr/local/lib/python3.7/dist-packages pip      \n",
      "spacy                         2.2.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Sphinx                        1.8.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "sphinxcontrib-serializinghtml 1.1.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "sphinxcontrib-websupport      1.2.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "SQLAlchemy                    1.4.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "sqlparse                      0.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "srsly                         1.0.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "statsmodels                   0.10.2         /usr/local/lib/python3.7/dist-packages pip      \n",
      "sympy                         1.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tables                        3.4.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tabulate                      0.8.9          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tblib                         1.7.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorboard                   2.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorboard-plugin-wit        1.8.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorflow                    2.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorflow-datasets           4.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorflow-estimator          2.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorflow-gcs-config         2.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorflow-hub                0.11.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorflow-metadata           0.29.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "tensorflow-probability        0.12.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "termcolor                     1.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "terminado                     0.9.3          /usr/local/lib/python3.7/dist-packages pip      \n",
      "testpath                      0.4.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "text-unidecode                1.3            /usr/local/lib/python3.7/dist-packages pip      \n",
      "textblob                      0.15.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "textgenrnn                    1.4.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Theano                        1.0.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "thinc                         7.4.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tifffile                      2021.3.31      /usr/local/lib/python3.7/dist-packages pip      \n",
      "tokenizers                    0.9.4          /usr/local/lib/python3.7/dist-packages pip      \n",
      "toml                          0.10.2         /usr/local/lib/python3.7/dist-packages pip      \n",
      "toolz                         0.11.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "torch                         1.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "torchsummary                  1.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "torchtext                     0.9.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "torchvision                   0.8.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tornado                       5.1.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tqdm                          4.41.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "traitlets                     5.0.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "transformers                  4.1.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "tweepy                        3.10.0         /usr/local/lib/python3.7/dist-packages pip      \n",
      "typeguard                     2.7.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "typing-extensions             3.7.4.3        /usr/local/lib/python3.7/dist-packages pip      \n",
      "tzlocal                       1.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "uritemplate                   3.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "urllib3                       1.24.3         /usr/local/lib/python3.7/dist-packages pip      \n",
      "vega-datasets                 0.9.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "wasabi                        0.8.2          /usr/local/lib/python3.7/dist-packages pip      \n",
      "wcwidth                       0.2.5          /usr/local/lib/python3.7/dist-packages pip      \n",
      "webencodings                  0.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "Werkzeug                      1.0.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "wheel                         0.36.2         /usr/local/lib/python3.7/dist-packages pip      \n",
      "widgetsnbextension            3.5.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "wordcloud                     1.5.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "wrapt                         1.12.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "xarray                        0.15.1         /usr/local/lib/python3.7/dist-packages pip      \n",
      "xgboost                       0.90           /usr/local/lib/python3.7/dist-packages pip      \n",
      "xkit                          0.0.0          /usr/lib/python3/dist-packages                  \n",
      "xlrd                          1.1.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "xlwt                          1.3.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "xxhash                        2.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "yellowbrick                   0.9.1          /usr/local/lib/python3.7/dist-packages pip      \n",
      "zict                          2.0.0          /usr/local/lib/python3.7/dist-packages pip      \n",
      "zipp                          3.4.1          /usr/local/lib/python3.7/dist-packages pip      \n"
     ]
    }
   ],
   "source": [
    "!pip list -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B4g_6M-AlZui",
    "outputId": "463d53a4-c2c1-4858-d9d1-142c3f128b8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-09 15:42:19.089654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "04/09/2021 15:42:20 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "04/09/2021 15:42:20 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(output_dir='output', overwrite_output_dir=True, do_train=True, do_eval=False, do_predict=False, model_parallel=False, evaluation_strategy=<EvaluationStrategy.NO: 'no'>, prediction_loss_only=False, per_device_train_batch_size=2, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, warmup_steps=0, logging_dir='runs/Apr09_15-42-20_53f3188c5a26', logging_first_step=False, logging_steps=500, save_steps=500, save_total_limit=None, no_cuda=False, seed=42, fp16=False, fp16_opt_level='O1', local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=500, dataloader_num_workers=0, past_index=-1, run_name='output', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, fp16_backend='auto', sharded_ddp=False)\n",
      "04/09/2021 15:42:20 - WARNING - datasets.builder -   Using custom data configuration default-984f3c4123f3085f\n",
      "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/text/default-984f3c4123f3085f/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n",
      "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-984f3c4123f3085f/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n",
      "[INFO|configuration_utils.py:431] 2021-04-09 15:42:21,059 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "[INFO|configuration_utils.py:467] 2021-04-09 15:42:21,059 >> Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:431] 2021-04-09 15:42:21,080 >> loading configuration file https://huggingface.co/distilgpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f985248d2791fcff97732e4ee263617adec1edb5429a2b8421734c6d14e39bee.422318838d1ec4e061efb4ea29671cb2a044e244dc69229682bebd7cacc81631\n",
      "[INFO|configuration_utils.py:467] 2021-04-09 15:42:21,080 >> Model config GPT2Config {\n",
      "  \"_num_labels\": 1,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 6,\n",
      "  \"n_positions\": 1024,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-04-09 15:42:21,155 >> loading file https://huggingface.co/distilgpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/55051ac97dcc32f0a736d21a32a4d42b0d9b90f117ca7c38e65038b04bd5c3f5.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-04-09 15:42:21,155 >> loading file https://huggingface.co/distilgpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/9dfb299b74cdf7601ba7cd3a8073dbdac351caec0ed7ab5849b098b3c8ae3d57.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1802] 2021-04-09 15:42:21,155 >> loading file https://huggingface.co/distilgpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/accb287b5a5396b2597382916b6cc939fdab1366e89475a92338d3971b3d02b7.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "[INFO|modeling_utils.py:1024] 2021-04-09 15:42:21,275 >> loading weights file https://huggingface.co/distilgpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/43a212e83e76bcb07f45be584cf100676bdbbbe9c13f9e5c1c050049143a832f.a83d881ec4d624fd4b5826dd026e315246c48c67504ff91c0500570e291a54ba\n",
      "[INFO|modeling_utils.py:1140] 2021-04-09 15:42:34,207 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "[INFO|modeling_utils.py:1149] 2021-04-09 15:42:34,207 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at distilgpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
      "100% 1/1 [00:00<00:00, 60.66ba/s]\n",
      "100% 1/1 [00:00<00:00, 126.53ba/s]\n",
      "[INFO|trainer.py:388] 2021-04-09 15:42:37,304 >> The following columns in the training set don't have a corresponding argument in `GPT2LMHeadModel.forward` and have been ignored: .\n",
      "[INFO|trainer.py:703] 2021-04-09 15:42:37,306 >> ***** Running training *****\n",
      "[INFO|trainer.py:704] 2021-04-09 15:42:37,306 >>   Num examples = 3\n",
      "[INFO|trainer.py:705] 2021-04-09 15:42:37,306 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:706] 2021-04-09 15:42:37,306 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:707] 2021-04-09 15:42:37,306 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "[INFO|trainer.py:708] 2021-04-09 15:42:37,306 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:709] 2021-04-09 15:42:37,306 >>   Total optimization steps = 6\n",
      "100% 6/6 [00:02<00:00,  3.02it/s][INFO|trainer.py:862] 2021-04-09 15:42:39,332 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'epoch': 3.0}\n",
      "100% 6/6 [00:02<00:00,  2.98it/s]\n",
      "[INFO|trainer.py:1226] 2021-04-09 15:42:39,351 >> Saving model checkpoint to output\n",
      "[INFO|configuration_utils.py:289] 2021-04-09 15:42:39,352 >> Configuration saved in output/config.json\n",
      "[INFO|modeling_utils.py:814] 2021-04-09 15:42:40,502 >> Model weights saved in output/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "7cSRuD2Blc4L"
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "#from transformers import CTRLTokenizer, CTRLLMHeadModel\n",
    "\n",
    "\n",
    "def get_model_tokenizer(weights_dir, device = 'cuda'):\n",
    "    print(\"Loading Model ...\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(weights_dir)\n",
    "    #model = CTRLLMHeadModel.from_pretrained(weights_dir)\n",
    "    model.to('cuda')\n",
    "    print(\"Model Loaded ...\")\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(weights_dir)\n",
    "    #tokenizer = CTRLTokenizer.from_pretrained(weights_dir)\n",
    "    return model, tokenizer\n",
    "\n",
    "\n",
    "def generate_messages(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt_text,\n",
    "    stop_token,\n",
    "    length,\n",
    "    num_return_sequences,\n",
    "    temperature = 0.7,\n",
    "    k=20,\n",
    "    p=0.9,\n",
    "    repetition_penalty = 1.0,\n",
    "    device = 'cuda'\n",
    "):\n",
    "\n",
    "    MAX_LENGTH = int(10000)\n",
    "    def adjust_length_to_model(length, max_sequence_length):\n",
    "        if length < 0 and max_sequence_length > 0:\n",
    "            length = max_sequence_length\n",
    "        elif 0 < max_sequence_length < length:\n",
    "            length = max_sequence_length  # No generation bigger than model size\n",
    "        elif length < 0:\n",
    "            length = MAX_LENGTH  # avoid infinite loop\n",
    "        return length\n",
    "        \n",
    "    length = adjust_length_to_model(length=length, max_sequence_length=model.config.max_position_embeddings)\n",
    "    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    \n",
    "    encoded_prompt = encoded_prompt.to(device)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "            input_ids=encoded_prompt,\n",
    "            max_length=length + len(encoded_prompt[0]),\n",
    "            min_length=length,\n",
    "            temperature=temperature,\n",
    "            top_k=k,\n",
    "            top_p=p,\n",
    "            repetition_penalty=repetition_penalty,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            do_sample=True,\n",
    "        )\n",
    "\n",
    "    if len(output_sequences.shape) > 2:\n",
    "        output_sequences.squeeze_()\n",
    "\n",
    "    generated_sequences = []\n",
    "\n",
    "    for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "        #print(\"=== GENERATED SEQUENCE {} ===\".format(generated_sequence_idx + 1))\n",
    "        generated_sequence = generated_sequence.tolist()\n",
    "\n",
    "        # Decode text\n",
    "        text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "\n",
    "        # Remove all text after the stop token\n",
    "        text = text[: text.find(stop_token) if stop_token else None]\n",
    "\n",
    "        # Add the prompt at the beginning of the sequence. Remove the excess text that was used for pre-processing\n",
    "        total_sequence = (\n",
    "            prompt_text + text[len(tokenizer.decode(encoded_prompt[0], clean_up_tokenization_spaces=True)) :]\n",
    "        )\n",
    "\n",
    "        generated_sequences.append(total_sequence)\n",
    "    return generated_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmNUkWnMleyP",
    "outputId": "c5411895-9b66-41c0-b5b4-e62a427c15c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model ...\n",
      "Model Loaded ...\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = get_model_tokenizer(weights_dir, device = 'cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GOm4kRSdlhoQ"
   },
   "outputs": [],
   "source": [
    "temperature = 1.0\n",
    "k=400\n",
    "p=0.95\n",
    "repetition_penalty = 1.0\n",
    "num_return_sequences = 3\n",
    "length = 100\n",
    "stop_token = '|EndOfText|'\n",
    "prompt_text = \"Machine learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-SXca81Iljng",
    "outputId": "9c0ee2d8-c782-43f9-c618-b45adad671bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.05 s, sys: 186 ms, total: 1.24 s\n",
      "Wall time: 1.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Machine learning features.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " 'Machine learning. How to generate model datasets using pklearn has been published in the best-selling paper of the year 2017, from National Science Foundation School of Medicine at Stanford University. In this report, we use ‐\\\\−5\\\\−5\\\\�{1,4}” of GATS (GATS) data in real-time with full R&D capabilities, to expand our understanding of deep-learning systems across computing.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n',\n",
       " \"Machine learning to use the functions of our most important parts of cognitive science: learning to recognize facts and value them in ways that reflect reality. Knowledge of a cognitive science perspective has a wide range of potential applications. Now that cognitive scientists need to understand each of the appropriate questions in the context of the neuroscience, computer science and history, they'll need to develop new insights into the nature and the importance of the field in every aspect of our thinking.\\n\\n\\n\\n\\nThe World's Deepest Data Project ha\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_messages(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt_text,\n",
    "    stop_token,\n",
    "    length,\n",
    "    num_return_sequences,\n",
    "    temperature = temperature,\n",
    "    k=k,\n",
    "    p=p,\n",
    "    repetition_penalty = repetition_penalty\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrW5F2RnHpbJ",
    "outputId": "3b25d122-82d2-4d7b-fd67-82a69d2f7f99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#model.eval()\n",
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8SA8QbxN32f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aV-BaMMmSya8",
    "outputId": "ebd61a95-09b5-40c1-cde5-f36ee2788f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: fastai in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: torch<1.8,>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied, skipping upgrade: pip in /usr/local/lib/python3.7/dist-packages (from fastai) (19.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pillow>6.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: spacy<3 in /usr/local/lib/python3.7/dist-packages (from fastai) (2.2.4)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai) (3.2.2)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from fastai) (2.23.0)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai) (0.22.2.post1)\n",
      "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from fastai) (20.9)\n",
      "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from fastai) (1.1.5)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai) (3.13)\n",
      "Requirement already satisfied, skipping upgrade: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: fastcore<1.4,>=1.3.8 in /usr/local/lib/python3.7/dist-packages (from fastai) (1.3.19)\n",
      "Requirement already satisfied, skipping upgrade: torchvision<0.9,>=0.8 in /usr/local/lib/python3.7/dist-packages (from fastai) (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from fastai) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch<1.8,>=1.7.0->fastai) (1.19.5)\n",
      "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<1.8,>=1.7.0->fastai) (3.7.4.3)\n",
      "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (3.0.5)\n",
      "Requirement already satisfied, skipping upgrade: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.0)\n",
      "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (7.4.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (54.2.0)\n",
      "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (2.0.5)\n",
      "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (4.41.1)\n",
      "Requirement already satisfied, skipping upgrade: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (0.4.1)\n",
      "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.0.5)\n",
      "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (0.8.2)\n",
      "Requirement already satisfied, skipping upgrade: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3->fastai) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2020.12.5)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (2.10)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai) (1.0.1)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3->fastai) (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fastai) (1.15.0)\n",
      "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3->fastai) (3.4.1)\n"
     ]
    }
   ],
   "source": [
    "pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "Wjh97M_pigTP",
    "outputId": "c5d5a13f-5c83-47ee-8a19-ed5b2d4b8728"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='99' class='' max='99' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [99/99 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "def tokenize(texts):\n",
    "    toks = tokenizer.tokenize(texts)\n",
    "    return tensor(tokenizer.convert_tokens_to_ids(toks))\n",
    "\n",
    "tokenized = [tokenize(t) for t in progress_bar(texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "fvshnNijekMr"
   },
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def __init__(self, tokenizer): self.tokenizer = tokenizer\n",
    "    def encodes(self, x): \n",
    "        toks = self.tokenizer.tokenize(x)\n",
    "        return tensor(self.tokenizer.convert_tokens_to_ids(toks))\n",
    "    def decodes(self, x): return TitledStr(self.tokenizer.decode(x.cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "id": "vXiJQTuuvRSJ",
    "outputId": "534f9778-ef5c-458f-e077-6473872b4afe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Create data pipelines using</td>\n",
       "      <td>data pipelines using big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tools and resources available</td>\n",
       "      <td>and resources available to</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.text.all import *\n",
    "from fastai.metrics import *\n",
    "from fastai.vision import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "df_train,df_valid =  train_test_split(all_headlines,test_size=0.2,train_size=0.8)\n",
    "splits = [list(range_of(df_train)), list(range(len(df_train), len(texts)))]\n",
    "tls_lm = TfmdLists(texts,TransformersTokenizer(tokenizer),dl_type=LMDataLoader)\n",
    "bs = 2\n",
    "sl = 4\n",
    "dls = tls_lm.dataloaders(bs=bs, seq_len=sl)\n",
    "dls.show_batch(max_n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "w2OcdgYs-SKp",
    "outputId": "b005ddf1-093d-4828-c481-deec578dd3a7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Define &amp; implement Policies &amp; SOPs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Description\n",
       "1  Define & implement Policies & SOPs"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "6bx0ETN_oPED"
   },
   "outputs": [],
   "source": [
    "class DropOutput(Callback):\n",
    "    def after_pred(self): self.learn.pred = self.pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "NV3hRHvFodxK"
   },
   "outputs": [],
   "source": [
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), cbs=[DropOutput], metrics=Perplexity()).to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "Hzm90BSjojdY",
    "outputId": "1668e154-2138-4af1-8b2b-2eb23119a76e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(#2) [None,None]"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "-1q6I1xWopVf",
    "outputId": "c2ecacff-d952-4091-feb7-29d28cc4246b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(lr_min=0.025118863582611083, lr_steep=0.2089296132326126)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "1-pXpUH46kwz",
    "outputId": "06e9ecc6-cb2f-4ac2-debf-429b944b166f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.116145</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.529880</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.181194</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.344099</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.745091</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.937003</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "u6DVLJXVozN1",
    "outputId": "f09874e2-5a46-4c26-e98e-803842b3aa11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.707149</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/fastprogress/fastprogress.py:74: UserWarning: Your generator is empty.\n",
      "  warn(\"Your generator is empty.\")\n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spKl58V1znHx",
    "outputId": "e2270fe4-0dd5-403e-a1d6-27d7a94184fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fastai/fastai2.git\n",
      "  Cloning https://github.com/fastai/fastai2.git to /tmp/pip-req-build-nbkmoscg\n",
      "  Running command git clone -q https://github.com/fastai/fastai2.git /tmp/pip-req-build-nbkmoscg\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (19.3.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (20.9)\n",
      "Requirement already satisfied: fastcore>=0.1.34 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.3.19)\n",
      "Requirement already satisfied: torchvision>=0.7 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.8.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.2.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.1.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.23.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (3.13)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.0.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (7.1.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.4.1)\n",
      "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (2.2.4)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fastai2==0.0.30) (1.7.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai2==0.0.30) (2.4.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.7->fastai2==0.0.30) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (2.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai2==0.0.30) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fastai2==0.0.30) (2018.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai2==0.0.30) (2.10)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fastai2==0.0.30) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (3.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (4.41.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.1.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (54.2.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (7.4.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (0.4.1)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy->fastai2==0.0.30) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fastai2==0.0.30) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->fastai2==0.0.30) (1.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2==0.0.30) (3.4.1)\n",
      "Building wheels for collected packages: fastai2\n",
      "  Building wheel for fastai2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fastai2: filename=fastai2-0.0.30-cp37-none-any.whl size=177979 sha256=7883657e69b40147831603eff5ebe65b1cce2a12652365ea53188fa7fd9a443e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tein63ou/wheels/38/fd/31/ec7df01a47c0c9fafe85a1af76b59a86caf47ec649710affa8\n",
      "Successfully built fastai2\n",
      "Installing collected packages: fastai2\n",
      "Successfully installed fastai2-0.0.30\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/fastai/fastai2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFmNc5dbcXvm",
    "outputId": "1dc88315-4d6e-4af6-e0a6-bb1dc8c7fc5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets>=1.1.3 in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/language-modeling/requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/language-modeling/requirements.txt (line 2)) (0.1.95)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from -r transformers/examples/language-modeling/requirements.txt (line 3)) (3.12.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (4.41.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (1.1.5)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.70.11.1)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.23.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.0.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.0.8)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->-r transformers/examples/language-modeling/requirements.txt (line 3)) (54.2.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->-r transformers/examples/language-modeling/requirements.txt (line 3)) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2018.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets>=1.1.3->-r transformers/examples/language-modeling/requirements.txt (line 1)) (3.0.12)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r transformers/examples/language-modeling/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O116b3j_Quc7",
    "outputId": "bbc3ba48-2e54-4701-c56c-4209bf7516c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/fastai/fastcore.git\n",
      "  Cloning https://github.com/fastai/fastcore.git to /tmp/pip-req-build-seh7k47u\n",
      "  Running command git clone -q https://github.com/fastai/fastcore.git /tmp/pip-req-build-seh7k47u\n",
      "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore==1.3.20) (19.3.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore==1.3.20) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore==1.3.20) (2.4.7)\n",
      "Building wheels for collected packages: fastcore\n",
      "  Building wheel for fastcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fastcore: filename=fastcore-1.3.20-cp37-none-any.whl size=52169 sha256=bcf31e712ad8c7408f966c55f1f1bb1e066d9c689b3d186e70b21a7bd3f322b1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8yxqt360/wheels/14/48/6c/a231f357ba914c97927e1a41bf0696634c632908e7f806cef5\n",
      "Successfully built fastcore\n",
      "Installing collected packages: fastcore\n",
      "  Found existing installation: fastcore 1.3.19\n",
      "    Uninstalling fastcore-1.3.19:\n",
      "      Successfully uninstalled fastcore-1.3.19\n",
      "Successfully installed fastcore-1.3.20\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/fastai/fastcore.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8MoUzUSx-57",
    "outputId": "36744b3c-35c8-41a0-cded-e46fe969b231"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "docs = generate_messages(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt_text,\n",
    "    stop_token,\n",
    "    length,\n",
    "    num_return_sequences,\n",
    "    temperature = temperature,\n",
    "    k=k,\n",
    "    p=p,\n",
    "    repetition_penalty = repetition_penalty)\n",
    "\n",
    "print(type(docs))\n",
    "docs2 = texts[:1]\n",
    "print(type(docs2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KZW_d8J97Z-F",
    "outputId": "49baba6f-748c-406c-9657-2f9ca7476a93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity between : Proficiency in developing complex SQL queries and : Machine learning projects to see and share visual learners with others!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "You can learn how to begin your product through our series of best practices on Building Good Behaviour. We take so many risks and we have managed that and are here to help!\n",
      "And for those of you not familiar with our growing in education, this post is for you.\n",
      "Think of the advice that is well-received by our students. In the comments section of our book, learn to draw from ou is: 79.85830237250502\n",
      "The cosine similarity between : Proficiency in developing complex SQL queries and : Machine learning, working with research and well-equipped technology.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " is: 16.188570007365875\n",
      "The cosine similarity between : Proficiency in developing complex SQL queries and : Machine learning using the Knowledge Base model from StackOverflow. We're developing a modular learning framework for building a learning library. We are also developing a similar model with Android to show to other developers how to leverage this model to gain a working understanding of the first programming language.\n",
      "\n",
      "\n",
      "\n",
      "Data are created by the tool, in a text file that’s fully customizable, and are displayed to the developer by an indicator that you are using or starting the application\n",
      "Design your app to help design  is: 81.9891973269127\n"
     ]
    }
   ],
   "source": [
    "def word2vec(word):\n",
    "    from collections import Counter\n",
    "    from math import sqrt\n",
    "\n",
    "    # count the characters in word\n",
    "    cw = Counter(word)\n",
    "    # precomputes a set of the different characters\n",
    "    sw = set(cw)\n",
    "    # precomputes the \"length\" of the word vector\n",
    "    lw = sqrt(sum(c*c for c in cw.values()))\n",
    "\n",
    "    # return a tuple\n",
    "    return cw, sw, lw\n",
    "\n",
    "def cosdis(v1, v2):\n",
    "    # which characters are common to the two words?\n",
    "    common = v1[1].intersection(v2[1])\n",
    "    # by definition of cosine distance we have\n",
    "    return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]\n",
    "\n",
    "\n",
    "threshold = 0.80     # if needed\n",
    "for key in docs:\n",
    "    for word in docs2:\n",
    "        try:\n",
    "            # print(key)\n",
    "            # print(word)\n",
    "            res = cosdis(word2vec(word), word2vec(key))\n",
    "            # print(res)\n",
    "            print(\"The cosine similarity between : {} and : {} is: {}\".format(word, key, res*100))\n",
    "            # if res > threshold:\n",
    "            #     print(\"Found a word with cosine distance > 80 : {} with original word: {}\".format(word, key))\n",
    "        except IndexError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2ZxYLjLE_Nc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NLP_Capstone_GPT2_Transformer (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
