{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/sukanagaraj/opt/anaconda3/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/sukanagaraj/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/sukanagaraj/opt/anaconda3/lib/python3.8/site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/sukanagaraj/opt/anaconda3/lib/python3.8/site-packages (from gensim) (5.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Required library for project \n",
    "#!pip install wordcloud\n",
    "#!pip install spacy\n",
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sukanagaraj/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Required packages \n",
    "\n",
    "import re as re  # For preprocessing\n",
    "import nltk\n",
    "#import spacy  # For preprocessing\n",
    "import numpy as np \n",
    "import pandas as pd # For data handling\n",
    "from time import time  # To time our operations\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict  # For word frequency\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading dataset using Pandas DataFrame.\n",
    "df = pd.read_csv('indeed_job_dataset.csv')\n",
    "\n",
    "type (df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5715, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to data shape, Total number of columns and row.\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'Job_Title',\n",
       " 'Link',\n",
       " 'Queried_Salary',\n",
       " 'Job_Type',\n",
       " 'Skill',\n",
       " 'No_of_Skills',\n",
       " 'Company',\n",
       " 'No_of_Reviews',\n",
       " 'No_of_Stars',\n",
       " 'Date_Since_Posted',\n",
       " 'Description',\n",
       " 'Location',\n",
       " 'Company_Revenue',\n",
       " 'Company_Employees',\n",
       " 'Company_Industry',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'machine learning',\n",
       " 'r',\n",
       " 'hadoop',\n",
       " 'tableau',\n",
       " 'sas',\n",
       " 'spark',\n",
       " 'java',\n",
       " 'Others',\n",
       " 'CA',\n",
       " 'NY',\n",
       " 'VA',\n",
       " 'TX',\n",
       " 'MA',\n",
       " 'IL',\n",
       " 'WA',\n",
       " 'MD',\n",
       " 'DC',\n",
       " 'NC',\n",
       " 'Other_states',\n",
       " 'Consulting and Business Services',\n",
       " 'Internet and Software',\n",
       " 'Banks and Financial Services',\n",
       " 'Health Care',\n",
       " 'Insurance',\n",
       " 'Other_industries']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the summary of DataFrame.\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [<p><b>POSITION SUMMARY</b></p>, <p>\\r\\r\\nThe ...\n",
       "1    [<p><b>What do we need?</b></p>, <ul><li>\\r\\r\\...\n",
       "2    [<ul><li>Validate, analyze, and conduct statis...\n",
       "3    [<p>Full time</p>, <p>Washington, DC metro are...\n",
       "4    [<ul><li>Assist in consultations with business...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job description\n",
    "df['Description'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Queried_Salary</th>\n",
       "      <th>Job_Type</th>\n",
       "      <th>Skill</th>\n",
       "      <th>No_of_Skills</th>\n",
       "      <th>Company</th>\n",
       "      <th>No_of_Reviews</th>\n",
       "      <th>No_of_Stars</th>\n",
       "      <th>Date_Since_Posted</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company_Revenue</th>\n",
       "      <th>Company_Employees</th>\n",
       "      <th>Company_Industry</th>\n",
       "      <th>python</th>\n",
       "      <th>sql</th>\n",
       "      <th>machine learning</th>\n",
       "      <th>r</th>\n",
       "      <th>hadoop</th>\n",
       "      <th>tableau</th>\n",
       "      <th>sas</th>\n",
       "      <th>spark</th>\n",
       "      <th>java</th>\n",
       "      <th>Others</th>\n",
       "      <th>CA</th>\n",
       "      <th>NY</th>\n",
       "      <th>VA</th>\n",
       "      <th>TX</th>\n",
       "      <th>MA</th>\n",
       "      <th>IL</th>\n",
       "      <th>WA</th>\n",
       "      <th>MD</th>\n",
       "      <th>DC</th>\n",
       "      <th>NC</th>\n",
       "      <th>Other_states</th>\n",
       "      <th>Consulting and Business Services</th>\n",
       "      <th>Internet and Software</th>\n",
       "      <th>Banks and Financial Services</th>\n",
       "      <th>Health Care</th>\n",
       "      <th>Insurance</th>\n",
       "      <th>Other_industries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=6a105f495c36a...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['SAP', 'SQL']</td>\n",
       "      <td>2</td>\n",
       "      <td>Express Scripts</td>\n",
       "      <td>3301.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[&lt;p&gt;&lt;b&gt;POSITION SUMMARY&lt;/b&gt;&lt;/p&gt;, &lt;p&gt;\\r\\r\\nThe ...</td>\n",
       "      <td>MO</td>\n",
       "      <td>More than $10B (USD)</td>\n",
       "      <td>10,000+</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=86afd561ea8c6...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Machine Learning', 'R', 'SAS', 'SQL', 'Python']</td>\n",
       "      <td>5</td>\n",
       "      <td>Money Mart Financial Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>[&lt;p&gt;&lt;b&gt;What do we need?&lt;/b&gt;&lt;/p&gt;, &lt;ul&gt;&lt;li&gt;\\r\\r\\...</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e0aad317e6d45...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Data Mining', 'Data Management', 'R', 'SAS',...</td>\n",
       "      <td>9</td>\n",
       "      <td>comScore</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[&lt;ul&gt;&lt;li&gt;Validate, analyze, and conduct statis...</td>\n",
       "      <td>OR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Graduate Studies Program - Data Scientist</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Certified Internal Auditor']</td>\n",
       "      <td>1</td>\n",
       "      <td>Central Intelligence Agency</td>\n",
       "      <td>158.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[&lt;p&gt;Full time&lt;/p&gt;, &lt;p&gt;Washington, DC metro are...</td>\n",
       "      <td>DC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Government</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fec647775a21e...</td>\n",
       "      <td>&lt;80000</td>\n",
       "      <td>data_scientist</td>\n",
       "      <td>['Statistical Software', 'Time Management', 'R...</td>\n",
       "      <td>7</td>\n",
       "      <td>Federal Reserve Bank of Dallas</td>\n",
       "      <td>495.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[&lt;ul&gt;&lt;li&gt;Assist in consultations with business...</td>\n",
       "      <td>TX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>Banks and Financial Services</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  Job_Title  \\\n",
       "0           0                             Data Scientist   \n",
       "1           1                             Data Scientist   \n",
       "2           2                             Data Scientist   \n",
       "3           3  Graduate Studies Program - Data Scientist   \n",
       "4           4                           Data Scientist I   \n",
       "\n",
       "                                                Link Queried_Salary  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=6a105f495c36a...         <80000   \n",
       "1  https://www.indeed.com/rc/clk?jk=86afd561ea8c6...         <80000   \n",
       "2  https://www.indeed.com/rc/clk?jk=e0aad317e6d45...         <80000   \n",
       "3  https://www.indeed.com/rc/clk?jk=1cfdd9e391a63...         <80000   \n",
       "4  https://www.indeed.com/rc/clk?jk=fec647775a21e...         <80000   \n",
       "\n",
       "         Job_Type                                              Skill  \\\n",
       "0  data_scientist                                     ['SAP', 'SQL']   \n",
       "1  data_scientist  ['Machine Learning', 'R', 'SAS', 'SQL', 'Python']   \n",
       "2  data_scientist  ['Data Mining', 'Data Management', 'R', 'SAS',...   \n",
       "3  data_scientist                     ['Certified Internal Auditor']   \n",
       "4  data_scientist  ['Statistical Software', 'Time Management', 'R...   \n",
       "\n",
       "   No_of_Skills                         Company  No_of_Reviews  No_of_Stars  \\\n",
       "0             2                 Express Scripts         3301.0          3.3   \n",
       "1             5   Money Mart Financial Services            NaN          NaN   \n",
       "2             9                        comScore           62.0          3.5   \n",
       "3             1     Central Intelligence Agency          158.0          4.3   \n",
       "4             7  Federal Reserve Bank of Dallas          495.0          4.1   \n",
       "\n",
       "   Date_Since_Posted                                        Description  \\\n",
       "0                1.0  [<p><b>POSITION SUMMARY</b></p>, <p>\\r\\r\\nThe ...   \n",
       "1               15.0  [<p><b>What do we need?</b></p>, <ul><li>\\r\\r\\...   \n",
       "2                1.0  [<ul><li>Validate, analyze, and conduct statis...   \n",
       "3               30.0  [<p>Full time</p>, <p>Washington, DC metro are...   \n",
       "4               30.0  [<ul><li>Assist in consultations with business...   \n",
       "\n",
       "  Location       Company_Revenue Company_Employees  \\\n",
       "0       MO  More than $10B (USD)           10,000+   \n",
       "1       TX                   NaN               NaN   \n",
       "2       OR                   NaN               NaN   \n",
       "3       DC                   NaN               NaN   \n",
       "4       TX                   NaN  Less than 10,000   \n",
       "\n",
       "               Company_Industry  python  sql  machine learning  r  hadoop  \\\n",
       "0                   Health Care       0    1                 0  0       0   \n",
       "1                           NaN       1    1                 1  1       0   \n",
       "2                           NaN       1    1                 0  1       0   \n",
       "3                    Government       0    0                 0  0       0   \n",
       "4  Banks and Financial Services       0    0                 0  1       0   \n",
       "\n",
       "   tableau  sas  spark  java  Others  CA  NY  VA  TX  MA  IL  WA  MD  DC  NC  \\\n",
       "0        0    0      0     0       1   0   0   0   0   0   0   0   0   0   0   \n",
       "1        0    1      0     0       0   0   0   0   1   0   0   0   0   0   0   \n",
       "2        0    1      0     0       1   0   0   0   0   0   0   0   0   0   0   \n",
       "3        0    0      0     0       1   0   0   0   0   0   0   0   0   1   0   \n",
       "4        1    0      0     0       1   0   0   0   1   0   0   0   0   0   0   \n",
       "\n",
       "   Other_states  Consulting and Business Services  Internet and Software  \\\n",
       "0             1                                 0                      0   \n",
       "1             0                                 0                      0   \n",
       "2             1                                 0                      0   \n",
       "3             0                                 0                      0   \n",
       "4             0                                 0                      0   \n",
       "\n",
       "   Banks and Financial Services  Health Care  Insurance  Other_industries  \n",
       "0                             0            1          0                 0  \n",
       "1                             0            0          0                 0  \n",
       "2                             0            0          0                 0  \n",
       "3                             0            0          0                 1  \n",
       "4                             1            0          0                 0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 43)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5715 entries, 0 to 5714\n",
      "Data columns (total 43 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   Unnamed: 0                        5715 non-null   int64  \n",
      " 1   Job_Title                         5715 non-null   object \n",
      " 2   Link                              5715 non-null   object \n",
      " 3   Queried_Salary                    5715 non-null   object \n",
      " 4   Job_Type                          5715 non-null   object \n",
      " 5   Skill                             5483 non-null   object \n",
      " 6   No_of_Skills                      5715 non-null   int64  \n",
      " 7   Company                           5611 non-null   object \n",
      " 8   No_of_Reviews                     4753 non-null   float64\n",
      " 9   No_of_Stars                       4753 non-null   float64\n",
      " 10  Date_Since_Posted                 5611 non-null   float64\n",
      " 11  Description                       5413 non-null   object \n",
      " 12  Location                          5463 non-null   object \n",
      " 13  Company_Revenue                   2017 non-null   object \n",
      " 14  Company_Employees                 3199 non-null   object \n",
      " 15  Company_Industry                  3826 non-null   object \n",
      " 16  python                            5715 non-null   int64  \n",
      " 17  sql                               5715 non-null   int64  \n",
      " 18  machine learning                  5715 non-null   int64  \n",
      " 19  r                                 5715 non-null   int64  \n",
      " 20  hadoop                            5715 non-null   int64  \n",
      " 21  tableau                           5715 non-null   int64  \n",
      " 22  sas                               5715 non-null   int64  \n",
      " 23  spark                             5715 non-null   int64  \n",
      " 24  java                              5715 non-null   int64  \n",
      " 25  Others                            5715 non-null   int64  \n",
      " 26  CA                                5715 non-null   int64  \n",
      " 27  NY                                5715 non-null   int64  \n",
      " 28  VA                                5715 non-null   int64  \n",
      " 29  TX                                5715 non-null   int64  \n",
      " 30  MA                                5715 non-null   int64  \n",
      " 31  IL                                5715 non-null   int64  \n",
      " 32  WA                                5715 non-null   int64  \n",
      " 33  MD                                5715 non-null   int64  \n",
      " 34  DC                                5715 non-null   int64  \n",
      " 35  NC                                5715 non-null   int64  \n",
      " 36  Other_states                      5715 non-null   int64  \n",
      " 37  Consulting and Business Services  5715 non-null   int64  \n",
      " 38  Internet and Software             5715 non-null   int64  \n",
      " 39  Banks and Financial Services      5715 non-null   int64  \n",
      " 40  Health Care                       5715 non-null   int64  \n",
      " 41  Insurance                         5715 non-null   int64  \n",
      " 42  Other_industries                  5715 non-null   int64  \n",
      "dtypes: float64(3), int64(29), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#Get the dateset info\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5355, 43)\n"
     ]
    }
   ],
   "source": [
    "#Removing Duplicates\n",
    "\n",
    "# As of now we are not removing skill. will check if needed will add here. TBD\n",
    "\n",
    "df = df.drop_duplicates(subset=['Job_Title','Job_Type','Description','Location'])\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             0\n",
       "Job_Title                              0\n",
       "Link                                   0\n",
       "Queried_Salary                         0\n",
       "Job_Type                               0\n",
       "Skill                                217\n",
       "No_of_Skills                           0\n",
       "Company                               73\n",
       "No_of_Reviews                        888\n",
       "No_of_Stars                          888\n",
       "Date_Since_Posted                     73\n",
       "Description                          225\n",
       "Location                             216\n",
       "Company_Revenue                     3481\n",
       "Company_Employees                   2359\n",
       "Company_Industry                    1778\n",
       "python                                 0\n",
       "sql                                    0\n",
       "machine learning                       0\n",
       "r                                      0\n",
       "hadoop                                 0\n",
       "tableau                                0\n",
       "sas                                    0\n",
       "spark                                  0\n",
       "java                                   0\n",
       "Others                                 0\n",
       "CA                                     0\n",
       "NY                                     0\n",
       "VA                                     0\n",
       "TX                                     0\n",
       "MA                                     0\n",
       "IL                                     0\n",
       "WA                                     0\n",
       "MD                                     0\n",
       "DC                                     0\n",
       "NC                                     0\n",
       "Other_states                           0\n",
       "Consulting and Business Services       0\n",
       "Internet and Software                  0\n",
       "Banks and Financial Services           0\n",
       "Health Care                            0\n",
       "Insurance                              0\n",
       "Other_industries                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    position summary, the business analyst role is...\n",
       "1    what do we need?, you to have an amazing perso...\n",
       "2    validate, analyze, and conduct statistical ana...\n",
       "3    full time, washington, dc metro area, starting...\n",
       "4    assist in consultations with business partners...\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Before we detect the skills from description , we need to standardize the description features\n",
    "\n",
    "#Converting the Descrition feature into String type\n",
    "df['Description']=df['Description'].apply(str)\n",
    "\n",
    "#Removing tags from description\n",
    "def clean_up_job_description(raw_data) :\n",
    "    \n",
    "    #Convert to lower case\n",
    "    raw_data = raw_data.lower()\n",
    "    \n",
    "    #Remove Special Characters\n",
    "    result = re.sub('(\\\\d|\\\\W)+','',raw_data)\n",
    "    \n",
    "    #Remove Tags\n",
    "    result = result = re.sub('<.*?>','',raw_data)\n",
    "    \n",
    "    # Remove brackets.\n",
    "    result = result.replace('[', '')\n",
    "    result = result.replace(']', '')\n",
    "    result = result.replace(')', '')\n",
    "    result = result.replace('(', '')  \n",
    "    \n",
    "    result = result.replace('\\r','')\n",
    "    \n",
    "    # Remove new line.\n",
    "    result = result.replace('\\n','')\n",
    "    \n",
    "    # Stripping first and last white space. \n",
    "    result = result.strip()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "df['Description'] = df['Description'].apply(lambda raw_data : clean_up_job_description(raw_data))\n",
    "df['Description'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             0\n",
       "Job_Title                              0\n",
       "Link                                   0\n",
       "Queried_Salary                         0\n",
       "Job_Type                               0\n",
       "Skill                                217\n",
       "No_of_Skills                           0\n",
       "Company                               73\n",
       "No_of_Reviews                        888\n",
       "No_of_Stars                          888\n",
       "Date_Since_Posted                     73\n",
       "Description                            0\n",
       "Location                             216\n",
       "Company_Revenue                     3481\n",
       "Company_Employees                   2359\n",
       "Company_Industry                    1778\n",
       "python                                 0\n",
       "sql                                    0\n",
       "machine learning                       0\n",
       "r                                      0\n",
       "hadoop                                 0\n",
       "tableau                                0\n",
       "sas                                    0\n",
       "spark                                  0\n",
       "java                                   0\n",
       "Others                                 0\n",
       "CA                                     0\n",
       "NY                                     0\n",
       "VA                                     0\n",
       "TX                                     0\n",
       "MA                                     0\n",
       "IL                                     0\n",
       "WA                                     0\n",
       "MD                                     0\n",
       "DC                                     0\n",
       "NC                                     0\n",
       "Other_states                           0\n",
       "Consulting and Business Services       0\n",
       "Internet and Software                  0\n",
       "Banks and Financial Services           0\n",
       "Health Care                            0\n",
       "Insurance                              0\n",
       "Other_industries                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of null value.\n",
    "df.isna().sum()\n",
    "# Here we need to drop out the below columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skills and Description are important parameters in the model,hence there shouldnt be any null value for these feartures\n",
    "# Will check in second pahse for re-fill data.\n",
    "# df = pd.DataFrame(df)\n",
    "# df.dropna(inplace = True)\n",
    "# df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                             0\n",
       "Job_Title                              0\n",
       "Link                                   0\n",
       "Queried_Salary                         0\n",
       "Job_Type                               0\n",
       "Skill                                217\n",
       "No_of_Skills                           0\n",
       "Company                               73\n",
       "No_of_Reviews                        888\n",
       "No_of_Stars                          888\n",
       "Date_Since_Posted                     73\n",
       "Description                            0\n",
       "Location                             216\n",
       "Company_Revenue                     3481\n",
       "Company_Employees                   2359\n",
       "Company_Industry                    1778\n",
       "python                                 0\n",
       "sql                                    0\n",
       "machine learning                       0\n",
       "r                                      0\n",
       "hadoop                                 0\n",
       "tableau                                0\n",
       "sas                                    0\n",
       "spark                                  0\n",
       "java                                   0\n",
       "Others                                 0\n",
       "CA                                     0\n",
       "NY                                     0\n",
       "VA                                     0\n",
       "TX                                     0\n",
       "MA                                     0\n",
       "IL                                     0\n",
       "WA                                     0\n",
       "MD                                     0\n",
       "DC                                     0\n",
       "NC                                     0\n",
       "Other_states                           0\n",
       "Consulting and Business Services       0\n",
       "Internet and Software                  0\n",
       "Banks and Financial Services           0\n",
       "Health Care                            0\n",
       "Insurance                              0\n",
       "Other_industries                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5355, 43)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify\n",
      "[nltk_data]     failed: unable to get local issuer certificate\n",
      "[nltk_data]     (_ssl.c:1123)>\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "stop = stopwords.words('english')\n",
    "\n",
    "df['Description'].apply(lambda x: [item for item in x if item not in stop])\n",
    "\n",
    "docs = df['Description']\n",
    "\n",
    "#instantiate CountVectorizer() \n",
    "cv=CountVectorizer(max_df=0.95,max_features=10000,ngram_range=(1,3)) \n",
    " \n",
    "# this steps generates word counts for the words in your docs \n",
    "word_count_vector=cv.fit_transform(docs)\n",
    "# word_count_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>1.051333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>1.066382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>1.067380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>1.068580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1.071985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robinson</th>\n",
       "      <td>7.640063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hallmark</th>\n",
       "      <td>7.794213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fedex</th>\n",
       "      <td>7.794213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predictive science</th>\n",
       "      <td>7.794213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ericsson</th>\n",
       "      <td>7.976535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    idf_weights\n",
       "and                    1.051333\n",
       "in                     1.066382\n",
       "of                     1.067380\n",
       "with                   1.068580\n",
       "to                     1.071985\n",
       "...                         ...\n",
       "robinson               7.640063\n",
       "hallmark               7.794213\n",
       "fedex                  7.794213\n",
       "predictive science     7.794213\n",
       "ericsson               7.976535\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"]) \n",
    " \n",
    "# sort ascending \n",
    "df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(df['Description'].dtypes)\n",
    "sent = [str(row).split() for row in df['Description']]\n",
    "#print (sent)\n",
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88869"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debugging \n",
    "\n",
    "sentences = sent #bigram[sent]\n",
    "word_freq = defaultdict(int)\n",
    "for s in sentences:\n",
    "    for i in s:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'to', 'of', 'the', 'data', 'in', 'with', 'a', 'or', 'for']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'position': 1651,\n",
       "             'summary,': 217,\n",
       "             'the': 45461,\n",
       "             'business': 11558,\n",
       "             'analyst': 1055,\n",
       "             'role': 1485,\n",
       "             'is': 11122,\n",
       "             'primary': 377,\n",
       "             'architect': 148,\n",
       "             'of': 46556,\n",
       "             'reporting': 1890,\n",
       "             'and': 123490,\n",
       "             'dashboard': 122,\n",
       "             'solutions': 3744,\n",
       "             'for': 20666,\n",
       "             'internal': 1928,\n",
       "             'external': 1208,\n",
       "             'clients.': 183,\n",
       "             'utilizing': 433,\n",
       "             'esi': 3,\n",
       "             'corporate': 347,\n",
       "             'standard': 424,\n",
       "             'development': 4022,\n",
       "             'tools': 3620,\n",
       "             'this': 4447,\n",
       "             'responsible': 1164,\n",
       "             'design,': 1231,\n",
       "             'development,': 991,\n",
       "             'implementation,': 160,\n",
       "             'analysis,': 1808,\n",
       "             'interpretation': 131,\n",
       "             'communication': 2421,\n",
       "             'information': 3006,\n",
       "             'based': 1439,\n",
       "             'on': 10527,\n",
       "             'needs': 1105,\n",
       "             'individual': 600,\n",
       "             'ability': 4391,\n",
       "             'to': 61837,\n",
       "             'balance': 199,\n",
       "             'overall': 354,\n",
       "             'aesthetics': 4,\n",
       "             'with': 34017,\n",
       "             'robust': 329,\n",
       "             'intuitive': 66,\n",
       "             'functionality': 91,\n",
       "             'a': 30607,\n",
       "             'critical': 749,\n",
       "             'requirement': 107,\n",
       "             'success': 560,\n",
       "             'in': 36773,\n",
       "             'position.,': 95,\n",
       "             'essential': 488,\n",
       "             'functions,': 145,\n",
       "             'successfully': 258,\n",
       "             'design': 2370,\n",
       "             'implement': 1220,\n",
       "             'client': 1408,\n",
       "             'data': 44804,\n",
       "             'strong': 2467,\n",
       "             'focus': 743,\n",
       "             'product': 3074,\n",
       "             'functionality.aid': 1,\n",
       "             'implementation': 759,\n",
       "             'new': 4623,\n",
       "             'ideas': 547,\n",
       "             'clients.maintain': 2,\n",
       "             'live': 227,\n",
       "             'warehouse': 524,\n",
       "             'objects': 84,\n",
       "             'universes;': 1,\n",
       "             'add': 141,\n",
       "             'fields,': 16,\n",
       "             'modify': 54,\n",
       "             'table': 80,\n",
       "             'joins,': 8,\n",
       "             'structures': 276,\n",
       "             'that': 8006,\n",
       "             'streamline': 55,\n",
       "             'report': 567,\n",
       "             'extraction': 139,\n",
       "             'analysis.develop': 7,\n",
       "             'document': 338,\n",
       "             'best': 1910,\n",
       "             'practices': 894,\n",
       "             'all': 3668,\n",
       "             'points': 107,\n",
       "             'throughout': 374,\n",
       "             'process.coordinate': 1,\n",
       "             'interface': 157,\n",
       "             'account': 191,\n",
       "             'management': 3469,\n",
       "             'teams': 2443,\n",
       "             'gather': 156,\n",
       "             'requirements': 1551,\n",
       "             'provide': 2316,\n",
       "             'insight': 303,\n",
       "             'into': 2766,\n",
       "             'capabilities': 628,\n",
       "             'solutions.research': 3,\n",
       "             'present': 599,\n",
       "             'software': 3035,\n",
       "             'technology': 2415,\n",
       "             'other': 5528,\n",
       "             'developers,': 161,\n",
       "             'as': 12963,\n",
       "             'well': 1792,\n",
       "             'management,': 984,\n",
       "             'allow': 143,\n",
       "             'evaluation': 218,\n",
       "             'potential': 465,\n",
       "             'integration': 864,\n",
       "             'tools.,': 77,\n",
       "             'qualifications,': 658,\n",
       "             'bachelor’s': 917,\n",
       "             'degree': 4020,\n",
       "             'related': 3711,\n",
       "             'field': 1389,\n",
       "             'or': 20743,\n",
       "             '8': 98,\n",
       "             '11': 24,\n",
       "             'years': 6133,\n",
       "             'experience.2-5': 3,\n",
       "             'relevant': 1416,\n",
       "             'experience': 14065,\n",
       "             'master’s': 487,\n",
       "             '0-3': 3,\n",
       "             'experience.recent': 1,\n",
       "             'creating': 795,\n",
       "             'xi': 1,\n",
       "             'reports.designing': 1,\n",
       "             'visualization': 1162,\n",
       "             'applications': 1176,\n",
       "             'using': 4489,\n",
       "             'sap': 216,\n",
       "             'xcelsius': 1,\n",
       "             '2008': 11,\n",
       "             'software.designing,': 1,\n",
       "             'implementing': 798,\n",
       "             'maintaining': 419,\n",
       "             'universe': 15,\n",
       "             'designer.sql,': 1,\n",
       "             'as400,': 1,\n",
       "             'adobe': 173,\n",
       "             'flex,': 1,\n",
       "             'flash': 2,\n",
       "             'preferred.creative': 1,\n",
       "             'problem': 1145,\n",
       "             'solver.fundamental': 1,\n",
       "             'commitment': 236,\n",
       "             'customer': 2267,\n",
       "             'value': 891,\n",
       "             'through': 2449,\n",
       "             'technical': 4105,\n",
       "             'innovation.,': 17,\n",
       "             'experience.,': 191,\n",
       "             'about': 1966,\n",
       "             'department,': 40,\n",
       "             'express': 37,\n",
       "             'scripts,': 56,\n",
       "             'advance': 216,\n",
       "             'your': 3615,\n",
       "             'career': 573,\n",
       "             'company': 1923,\n",
       "             'makes': 154,\n",
       "             'it': 2023,\n",
       "             'easier': 19,\n",
       "             'people': 1219,\n",
       "             'choose': 42,\n",
       "             'better': 589,\n",
       "             'health.,': 13,\n",
       "             'scripts': 152,\n",
       "             'leading': 1159,\n",
       "             'healthcare': 894,\n",
       "             'serving': 206,\n",
       "             'tens': 20,\n",
       "             'millions': 251,\n",
       "             'consumers.': 10,\n",
       "             'we': 6497,\n",
       "             'are': 6789,\n",
       "             'looking': 1222,\n",
       "             'individuals': 654,\n",
       "             'who': 1748,\n",
       "             'passionate,': 28,\n",
       "             'creative': 447,\n",
       "             'committed': 573,\n",
       "             'systems': 2389,\n",
       "             'service': 931,\n",
       "             'promote': 141,\n",
       "             'health': 1542,\n",
       "             'outcomes.': 46,\n",
       "             'join': 1093,\n",
       "             'fortune': 204,\n",
       "             'magazine': 14,\n",
       "             'ranked': 48,\n",
       "             'one': 2039,\n",
       "             '\"most': 2,\n",
       "             'admired': 16,\n",
       "             'companies\"': 2,\n",
       "             'pharmacy': 72,\n",
       "             'category.': 14,\n",
       "             'then,': 10,\n",
       "             'use': 1902,\n",
       "             'intelligence,': 293,\n",
       "             'creativity,': 51,\n",
       "             'integrity': 329,\n",
       "             'hard': 190,\n",
       "             'work': 8336,\n",
       "             'help': 2292,\n",
       "             'us': 1281,\n",
       "             'enhance': 385,\n",
       "             'our': 10070,\n",
       "             'products': 1354,\n",
       "             'services.': 119,\n",
       "             'offer': 460,\n",
       "             'highly': 1159,\n",
       "             'competitive': 768,\n",
       "             'base': 206,\n",
       "             'salary': 268,\n",
       "             'comprehensive': 430,\n",
       "             'benefits': 701,\n",
       "             'program,': 82,\n",
       "             'including': 4590,\n",
       "             'medical,': 229,\n",
       "             'prescription': 24,\n",
       "             'drug,': 3,\n",
       "             'dental,': 208,\n",
       "             'vision,': 256,\n",
       "             '401k': 207,\n",
       "             'match,': 37,\n",
       "             'life': 646,\n",
       "             'insurance,': 203,\n",
       "             'paid': 388,\n",
       "             'time': 1442,\n",
       "             'off,': 45,\n",
       "             'tuition': 117,\n",
       "             'assistance': 252,\n",
       "             'an': 7117,\n",
       "             'employee': 608,\n",
       "             'stock': 99,\n",
       "             'purchase': 75,\n",
       "             'plan.,': 13,\n",
       "             'equal': 1281,\n",
       "             'opportunity': 1927,\n",
       "             'employer/disability/veteran': 1,\n",
       "             'what': 1234,\n",
       "             'do': 919,\n",
       "             'need?,': 3,\n",
       "             'you': 7071,\n",
       "             'have': 3822,\n",
       "             'amazing': 113,\n",
       "             'personality': 32,\n",
       "             'style.that': 2,\n",
       "             'super-organized': 2,\n",
       "             'solver.that': 2,\n",
       "             'take': 640,\n",
       "             'pride': 119,\n",
       "             'everything': 115,\n",
       "             'do,': 74,\n",
       "             'shows.and': 2,\n",
       "             'most': 1017,\n",
       "             'importantly': 6,\n",
       "             'unquestionable': 2,\n",
       "             'integrity.,': 13,\n",
       "             'why': 211,\n",
       "             'us?,': 6,\n",
       "             'invest': 70,\n",
       "             'employees,': 90,\n",
       "             'extensive': 304,\n",
       "             'training,': 166,\n",
       "             'programs': 567,\n",
       "             'set': 394,\n",
       "             'up': 902,\n",
       "             'future': 715,\n",
       "             'success.,': 49,\n",
       "             'if': 1054,\n",
       "             'sound': 154,\n",
       "             'like': 1280,\n",
       "             'fit,': 13,\n",
       "             'you’re': 179,\n",
       "             'ready': 158,\n",
       "             'start': 168,\n",
       "             'exciting': 248,\n",
       "             'organization': 728,\n",
       "             'fosters': 51,\n",
       "             'growth,': 130,\n",
       "             'apply': 1070,\n",
       "             'today!job': 2,\n",
       "             'descriptionthis': 2,\n",
       "             'will': 7677,\n",
       "             'be': 7364,\n",
       "             'for:,': 46,\n",
       "             'develop': 2925,\n",
       "             'marketing,': 384,\n",
       "             'credit': 224,\n",
       "             'risk': 663,\n",
       "             'models,': 727,\n",
       "             'segmentation,': 125,\n",
       "             'analyticsperform': 3,\n",
       "             'required': 1523,\n",
       "             'tests': 217,\n",
       "             'measures': 95,\n",
       "             'developed': 200,\n",
       "             'modelsdeliver': 2,\n",
       "             'model': 1007,\n",
       "             'documentation': 460,\n",
       "             'e.g.,': 772,\n",
       "             'document,': 66,\n",
       "             'specification': 22,\n",
       "             'modeling': 1812,\n",
       "             'projectsunderstand': 4,\n",
       "             'follow': 159,\n",
       "             'procedures,': 175,\n",
       "             'policies,': 118,\n",
       "             'deliver': 1338,\n",
       "             'technical/regulatory': 2,\n",
       "             'internal/external': 93,\n",
       "             'reviewscommunicate': 2,\n",
       "             'verbally': 56,\n",
       "             'writing': 604,\n",
       "             'both': 1661,\n",
       "             'non-technical': 485,\n",
       "             'audiences,': 78,\n",
       "             'education,': 188,\n",
       "             'advanced': 2548,\n",
       "             'masters': 250,\n",
       "             'phd': 655,\n",
       "             'preferred': 941,\n",
       "             'statistics,': 1920,\n",
       "             'applied': 914,\n",
       "             'mathematics,': 1216,\n",
       "             'operations': 1304,\n",
       "             'research,': 738,\n",
       "             'economics,': 578,\n",
       "             'quantitative': 1878,\n",
       "             'finance.': 10,\n",
       "             'mbas': 2,\n",
       "             'should': 579,\n",
       "             'only': 406,\n",
       "             'they': 1141,\n",
       "             'interested': 173,\n",
       "             'specialized': 128,\n",
       "             'discipline,': 94,\n",
       "             'experience,': 1151,\n",
       "             'entry': 45,\n",
       "             'level': 1000,\n",
       "             'position.': 177,\n",
       "             'any': 1630,\n",
       "             'statistical': 3516,\n",
       "             'fields': 174,\n",
       "             'preferred,': 319,\n",
       "             'skills,': 1398,\n",
       "             'very': 344,\n",
       "             'knowledge': 3954,\n",
       "             'statistics': 775,\n",
       "             'methods': 1123,\n",
       "             'machine': 4794,\n",
       "             'learning': 4493,\n",
       "             'techniquesstrong': 20,\n",
       "             'numerical': 60,\n",
       "             'programming': 1877,\n",
       "             'range': 498,\n",
       "             'languages': 989,\n",
       "             'sas,': 554,\n",
       "             'r,': 1547,\n",
       "             'python;': 51,\n",
       "             'working': 4580,\n",
       "             'sqldetail-oriented': 1,\n",
       "             'high': 1402,\n",
       "             'accuracystrong': 7,\n",
       "             'analytical,': 207,\n",
       "             'problem-solving': 381,\n",
       "             'critical-thinking': 6,\n",
       "             'skillsexcellent': 110,\n",
       "             'verbal': 855,\n",
       "             'written': 1465,\n",
       "             'benefits,': 265,\n",
       "             'medical': 653,\n",
       "             '/': 1398,\n",
       "             'dental/': 2,\n",
       "             'vision': 577,\n",
       "             'available': 546,\n",
       "             'after': 97,\n",
       "             '30': 45,\n",
       "             'days': 60,\n",
       "             'employmentcompany': 2,\n",
       "             'insurancepaid': 7,\n",
       "             'holidayspto/': 2,\n",
       "             'reimbursement,': 51,\n",
       "             'kept': 49,\n",
       "             'confidential': 78,\n",
       "             'according': 125,\n",
       "             'eeo': 195,\n",
       "             'guidelines.': 30,\n",
       "             'validate,': 24,\n",
       "             'analyze,': 221,\n",
       "             'conduct': 423,\n",
       "             'analysis': 4317,\n",
       "             'analytical': 2905,\n",
       "             'excel,': 386,\n",
       "             'sql,': 1138,\n",
       "             'sas.analyze': 1,\n",
       "             'define': 573,\n",
       "             'efficient,': 54,\n",
       "             'workable': 3,\n",
       "             'support': 3638,\n",
       "             'processes': 1617,\n",
       "             'functional': 799,\n",
       "             'research': 2312,\n",
       "             'projects.,': 107,\n",
       "             'extract': 298,\n",
       "             'qualitative': 125,\n",
       "             'findings': 586,\n",
       "             'from': 5288,\n",
       "             'large': 2551,\n",
       "             'sets.write': 2,\n",
       "             'reports': 1357,\n",
       "             'include': 843,\n",
       "             'effective': 699,\n",
       "             'graphs,': 74,\n",
       "             'tables,': 121,\n",
       "             'summaries,': 12,\n",
       "             'narratives.develop': 1,\n",
       "             'execute': 525,\n",
       "             'test': 782,\n",
       "             'cases': 182,\n",
       "             'ensure': 1384,\n",
       "             'been': 285,\n",
       "             'met.research': 1,\n",
       "             'resolve': 278,\n",
       "             'client-reported': 2,\n",
       "             'issues.interpret': 1,\n",
       "             'results,': 223,\n",
       "             'findings,': 89,\n",
       "             'recommend': 268,\n",
       "             'alternative': 111,\n",
       "             'decision': 967,\n",
       "             'makers.track': 1,\n",
       "             'daily': 269,\n",
       "             'industry': 1514,\n",
       "             'news': 52,\n",
       "             'disseminate': 61,\n",
       "             'articles': 20,\n",
       "             'team,': 681,\n",
       "             'bachelor': 141,\n",
       "             'sciences,': 148,\n",
       "             'physics,': 383,\n",
       "             'similar': 683,\n",
       "             'required.,': 154,\n",
       "             '2': 559,\n",
       "             'fieldexperience': 75,\n",
       "             'python': 1211,\n",
       "             'languagehighly': 1,\n",
       "             'competent': 20,\n",
       "             'manipulation': 163,\n",
       "             'thinking.intrinsic': 2,\n",
       "             'look': 202,\n",
       "             'at': 4825,\n",
       "             'identify': 1644,\n",
       "             'patterns,': 86,\n",
       "             'problems,': 384,\n",
       "             'opportunities.': 60,\n",
       "             'mining': 720,\n",
       "             'applications.ability': 8,\n",
       "             'distill': 69,\n",
       "             'amounts': 286,\n",
       "             'key': 1982,\n",
       "             'findings.ability': 3,\n",
       "             'clearly': 308,\n",
       "             'articulate': 142,\n",
       "             'presentations': 328,\n",
       "             'clients,': 242,\n",
       "             'sales': 697,\n",
       "             'staff.data': 1,\n",
       "             'more': 2528,\n",
       "             'packages': 274,\n",
       "             'e.g.': 1191,\n",
       "             'spss,': 173,\n",
       "             'stata,': 73,\n",
       "             'r': 721,\n",
       "             'required.experience': 60,\n",
       "             'pivot': 109,\n",
       "             'formulae,': 2,\n",
       "             'vlookups,': 10,\n",
       "             'graphingstrong': 2,\n",
       "             'organizational': 527,\n",
       "             'skills': 3853,\n",
       "             'multi-task': 68,\n",
       "             'prioritize': 313,\n",
       "             'efficiently': 184,\n",
       "             'meet': 908,\n",
       "             'deadlines.strong': 9,\n",
       "             'attention': 488,\n",
       "             'detail': 360,\n",
       "             'skills.self-motivated,': 5,\n",
       "             'takes': 223,\n",
       "             'initiative,': 70,\n",
       "             'loves': 32,\n",
       "             'learn,': 110,\n",
       "             'continuously': 211,\n",
       "             'seeks': 93,\n",
       "             'knowledge.strong': 2,\n",
       "             'perspective.effective': 2,\n",
       "             'troubleshooting': 148,\n",
       "             'investigation': 103,\n",
       "             'root': 231,\n",
       "             'cause': 166,\n",
       "             'problems.proven': 2,\n",
       "             'manage': 1111,\n",
       "             'perform': 910,\n",
       "             'multiple': 2096,\n",
       "             'tasks': 388,\n",
       "             'under': 548,\n",
       "             'conditions': 80,\n",
       "             'fluctuating': 3,\n",
       "             'workloads,': 6,\n",
       "             'competing': 115,\n",
       "             'requirements,': 568,\n",
       "             'changing': 339,\n",
       "             'deadlines': 161,\n",
       "             'while': 819,\n",
       "             'accuracy;': 9,\n",
       "             'independently': 554,\n",
       "             'completing': 95,\n",
       "             'assignments': 119,\n",
       "             'minimal': 201,\n",
       "             'direction.self-starter': 1,\n",
       "             'self-motivated,': 50,\n",
       "             'responsible,': 8,\n",
       "             'dependable.experience': 2,\n",
       "             'television/media': 2,\n",
       "             'plus.,': 140,\n",
       "             'li-jz1,': 1,\n",
       "             'msja': 3,\n",
       "             'full': 515,\n",
       "             'time,': 243,\n",
       "             'washington,': 26,\n",
       "             'dc': 26,\n",
       "             'metro': 12,\n",
       "             'area,': 71,\n",
       "             'starting': 30,\n",
       "             'salary:': 46,\n",
       "             '$56,698': 1,\n",
       "             '-': 1982,\n",
       "             '$76,377': 1,\n",
       "             '$27.17': 1,\n",
       "             '$36.60': 1,\n",
       "             'per': 165,\n",
       "             'hour,': 7,\n",
       "             'citizenship': 288,\n",
       "             'dual': 11,\n",
       "             'national': 1272,\n",
       "             'citizens': 26,\n",
       "             'eligible,': 4,\n",
       "             'description,': 318,\n",
       "             'how': 1158,\n",
       "             'apply,': 45,\n",
       "             'scientist': 1157,\n",
       "             'graduate': 171,\n",
       "             'intern': 27,\n",
       "             'cia,': 11,\n",
       "             'side-by-side': 9,\n",
       "             'scientists': 752,\n",
       "             'organize': 130,\n",
       "             'interpret': 369,\n",
       "             'inform': 246,\n",
       "             'makers,': 16,\n",
       "             'drive': 1841,\n",
       "             'successful': 583,\n",
       "             'operations,': 301,\n",
       "             'shape': 163,\n",
       "             'resource': 301,\n",
       "             'investments.': 13,\n",
       "             \"cia's\": 9,\n",
       "             'global': 1366,\n",
       "             'mission,': 85,\n",
       "             'agency': 176,\n",
       "             'has': 1199,\n",
       "             'access': 744,\n",
       "             'unique': 457,\n",
       "             'data.': 342,\n",
       "             'hardware,': 25,\n",
       "             'software,': 195,\n",
       "             'techniques': 1725,\n",
       "             'computational': 372,\n",
       "             'algorithms': 1404,\n",
       "             'patterns': 373,\n",
       "             'relationships': 587,\n",
       "             'volumes': 142,\n",
       "             'communicate': 1326,\n",
       "             'their': 2781,\n",
       "             'conclusions': 130,\n",
       "             'diverse': 924,\n",
       "             'audience': 168,\n",
       "             'expertise': 1222,\n",
       "             'via': 309,\n",
       "             'hands-on': 571,\n",
       "             'continuous': 564,\n",
       "             'learning,': 1450,\n",
       "             'agency-sponsored': 4,\n",
       "             'academic': 301,\n",
       "             'conferences,': 59,\n",
       "             'professional': 1080,\n",
       "             'activities.,': 31,\n",
       "             'studies': 110,\n",
       "             'program': 714,\n",
       "             'allows': 88,\n",
       "             'assess': 229,\n",
       "             'opportunities': 1320,\n",
       "             'permanent': 41,\n",
       "             'employment': 1501,\n",
       "             'following': 764,\n",
       "             'completion': 128,\n",
       "             'school.,': 1,\n",
       "             'directorate': 13,\n",
       "             'digital': 1390,\n",
       "             'innovation': 613,\n",
       "             'ddi': 15,\n",
       "             'forefront': 81,\n",
       "             'defining': 165,\n",
       "             'within': 2020,\n",
       "             'cia.': 10,\n",
       "             'focuses': 67,\n",
       "             'developing': 1715,\n",
       "             'workforce': 164,\n",
       "             'cutting-edge': 178,\n",
       "             'investing': 58,\n",
       "             'infrastructure,': 136,\n",
       "             'modernizing': 14,\n",
       "             'way': 518,\n",
       "             'does': 318,\n",
       "             'business.': 181,\n",
       "             'officers': 18,\n",
       "             'accelerate': 114,\n",
       "             'innovative': 977,\n",
       "             'cyber': 120,\n",
       "             'scale': 767,\n",
       "             'ultimately': 100,\n",
       "             'safeguard': 12,\n",
       "             'nation.': 18,\n",
       "             'learn': 972,\n",
       "             'click': 229,\n",
       "             'watch': 112,\n",
       "             'video': 118,\n",
       "             'separate': 12,\n",
       "             'page.,': 5,\n",
       "             'addition': 141,\n",
       "             'package,': 51,\n",
       "             'cia': 18,\n",
       "             'offers': 438,\n",
       "             'dynamic': 420,\n",
       "             'environment.': 308,\n",
       "             \"we're\": 248,\n",
       "             'world-altering': 3,\n",
       "             'events': 152,\n",
       "             '–': 1611,\n",
       "             'happen.': 10,\n",
       "             'so': 386,\n",
       "             'here': 203,\n",
       "             \"isn't\": 26,\n",
       "             'just': 386,\n",
       "             'job,': 93,\n",
       "             \"it's\": 55,\n",
       "             'mindset': 112,\n",
       "             'lifestyle.': 4,\n",
       "             'assist': 513,\n",
       "             'consultations': 15,\n",
       "             'partners': 754,\n",
       "             'hr': 138,\n",
       "             'experts': 304,\n",
       "             'maintain': 1152,\n",
       "             'dashboards,': 178,\n",
       "             'models': 2491,\n",
       "             'metrics.research': 1,\n",
       "             'analytics': 5619,\n",
       "             'make': 1577,\n",
       "             'recommendations': 794,\n",
       "             'district.develop': 1,\n",
       "             'queries,': 131,\n",
       "             'validate': 296,\n",
       "             'export': 16,\n",
       "             'various': 1506,\n",
       "             'formats': 112,\n",
       "             'dashboards/metrics,': 1,\n",
       "             'automating': 147,\n",
       "             'delivery': 769,\n",
       "             'where': 877,\n",
       "             'possible.perform': 1,\n",
       "             'produce': 311,\n",
       "             'reports,': 432,\n",
       "             'assessments': 74,\n",
       "             'proposals': 57,\n",
       "             'leaders': 342,\n",
       "             'informed': 103,\n",
       "             'driven': 640,\n",
       "             'decisions.maintain': 1,\n",
       "             'date': 92,\n",
       "             'perspective': 103,\n",
       "             'tools,': 733,\n",
       "             'practices,': 242,\n",
       "             'standards,': 195,\n",
       "             'trends': 659,\n",
       "             'system': 1088,\n",
       "             'standards.,': 30,\n",
       "             'building': 2372,\n",
       "             'delivering': 598,\n",
       "             'customer-centric': 24,\n",
       "             'solutionscollaborates': 1,\n",
       "             'partnerships': 124,\n",
       "             'collaboratively': 246,\n",
       "             'others': 486,\n",
       "             'shared': 161,\n",
       "             'objectivestech': 1,\n",
       "             'savvy': 17,\n",
       "             'utilizes': 66,\n",
       "             'market': 574,\n",
       "             'pricing': 138,\n",
       "             'continually': 110,\n",
       "             'seeking': 580,\n",
       "             'out': 699,\n",
       "             'emerging': 356,\n",
       "             'technologiespersuades': 1,\n",
       "             'uses': 222,\n",
       "             'compelling': 169,\n",
       "             'arguments': 4,\n",
       "             'gain': 190,\n",
       "             'otherscommunicates': 1,\n",
       "             'effectively': 1053,\n",
       "             'develops': 328,\n",
       "             'delivers': 244,\n",
       "             'multi-mode': 5,\n",
       "             'communications': 284,\n",
       "             'convey': 120,\n",
       "             'clear': 449,\n",
       "             'understanding': 2491,\n",
       "             'different': 707,\n",
       "             'audiencesaction': 1,\n",
       "             'oriented': 206,\n",
       "             'taking': 149,\n",
       "             'tough': 34,\n",
       "             'challenges': 365,\n",
       "             'sense': 202,\n",
       "             'urgency,': 15,\n",
       "             'energy,': 61,\n",
       "             'enthusiasmresourcefulness': 1,\n",
       "             'secures': 2,\n",
       "             'deploys': 29,\n",
       "             'resources': 375,\n",
       "             'efficiently,': 30,\n",
       "             'business,': 517,\n",
       "             'studyexperience': 6,\n",
       "             'toolsmicrosoft': 1,\n",
       "             'office': 761,\n",
       "             'suite,': 31,\n",
       "             'specifically': 134,\n",
       "             'ms': 798,\n",
       "             'requiredskilled': 1,\n",
       "             'platforms': 836,\n",
       "             'tableau': 401,\n",
       "             'human': 279,\n",
       "             'capital': 396,\n",
       "             'hcm': 5,\n",
       "             'platformsexcellent': 2,\n",
       "             'multi-tasking,': 4,\n",
       "             'managing': 659,\n",
       "             'providing': 871,\n",
       "             'project': 1983,\n",
       "             'oversightexcellent': 1,\n",
       "             'written,': 124,\n",
       "             'listening': 57,\n",
       "             'staff': 445,\n",
       "             'levelsstrong': 3,\n",
       "             'solving': 924,\n",
       "             'thinking': 366,\n",
       "             'skillsability': 178,\n",
       "             'trust': 102,\n",
       "             'when': 667,\n",
       "             'situations': 81,\n",
       "             'informationability': 7,\n",
       "             'composure': 7,\n",
       "             'pressureability': 4,\n",
       "             'across': 2735,\n",
       "             'variety': 1257,\n",
       "             'units': 130,\n",
       "             'organization.equivalent': 1,\n",
       "             'education': 597,\n",
       "             'and/or': 2651,\n",
       "             'may': 1113,\n",
       "             'substituted': 35,\n",
       "             'above': 215,\n",
       "             'collecting': 68,\n",
       "             'combining': 77,\n",
       "             'sourcesuncovering': 1,\n",
       "             'exploring': 61,\n",
       "             'anomalous': 6,\n",
       "             'metadataapplying': 1,\n",
       "             'scientific': 515,\n",
       "             'process': 1500,\n",
       "             'evaluation,': 76,\n",
       "             'performing': 539,\n",
       "             'inference,': 60,\n",
       "             'miningdeveloping': 1,\n",
       "             'analytic': 1402,\n",
       "             'plans,': 200,\n",
       "             'engineer': 855,\n",
       "             'supporting': 582,\n",
       "             'algorithms,': 391,\n",
       "             'which': 1011,\n",
       "             'plans.designing': 1,\n",
       "             'analysisanalyzing': 1,\n",
       "             'mathematical/statistical': 7,\n",
       "             'methodsevaluating,': 1,\n",
       "             'documenting,': 5,\n",
       "             'communicating': 334,\n",
       "             'processes,': 526,\n",
       "             'analyses,': 232,\n",
       "             'results': 1540,\n",
       "             'customers,': 246,\n",
       "             'peers,': 45,\n",
       "             'leadershipcreating': 1,\n",
       "             'interpretable': 7,\n",
       "             'visualizations,': 115,\n",
       "             'completed': 76,\n",
       "             'computer': 3459,\n",
       "             'science,': 2843,\n",
       "             'passion': 606,\n",
       "             'rigorous': 119,\n",
       "             'datatenacity,': 1,\n",
       "             'integrity,': 175,\n",
       "             'persistence,': 8,\n",
       "             'willingness': 174,\n",
       "             'learnability': 7,\n",
       "             'solve': 1094,\n",
       "             'complex': 3263,\n",
       "             'problemsuse': 3,\n",
       "             'reasoning': 44,\n",
       "             'determinationsworks': 1,\n",
       "             'collaborative': 525,\n",
       "             'environmentstrong': 37,\n",
       "             'audiencesthe': 2,\n",
       "             'desire': 335,\n",
       "             'serve': 357,\n",
       "             'over': 652,\n",
       "             '300': 23,\n",
       "             'million': 140,\n",
       "             'fellow': 45,\n",
       "             'americans': 46,\n",
       "             'difference': 148,\n",
       "             'world': 742,\n",
       "             'events,': 43,\n",
       "             'qualifications': 331,\n",
       "             'listed': 90,\n",
       "             'minimum': 954,\n",
       "             'acceptable': 24,\n",
       "             'considered': 282,\n",
       "             \"candidates'\": 6,\n",
       "             'also': 992,\n",
       "             'provided': 130,\n",
       "             'by': 4926,\n",
       "             'hiring': 313,\n",
       "             'manager/organization': 4,\n",
       "             'regarding': 440,\n",
       "             'nan': 225,\n",
       "             'demand': 180,\n",
       "             'sensing,': 10,\n",
       "             'om': 4,\n",
       "             'breaking': 21,\n",
       "             'some': 668,\n",
       "             'boundaries': 81,\n",
       "             'classical': 23,\n",
       "             'forecasting.': 9,\n",
       "             'state': 857,\n",
       "             'art': 131,\n",
       "             'neural': 371,\n",
       "             'networks': 220,\n",
       "             'step': 49,\n",
       "             'change': 544,\n",
       "             'forecast': 97,\n",
       "             'accuracy,': 91,\n",
       "             'driving': 394,\n",
       "             'immediate': 101,\n",
       "             'creation': 292,\n",
       "             'customers.': 157,\n",
       "             'these': 791,\n",
       "             'functionalities,': 3,\n",
       "             'able': 1263,\n",
       "             'adjust': 54,\n",
       "             'supply': 382,\n",
       "             'plans': 450,\n",
       "             'faster': 51,\n",
       "             'accurate.,': 3,\n",
       "             'revolution': 16,\n",
       "             'chain?': 2,\n",
       "             'passionate': 466,\n",
       "             'finding': 130,\n",
       "             'correlations?': 2,\n",
       "             'then': 234,\n",
       "             'team.,': 215,\n",
       "             'scientist,': 313,\n",
       "             'aim:': 2,\n",
       "             'customers’': 112,\n",
       "             'challenging': 326,\n",
       "             'forecasting': 202,\n",
       "             'needs.,': 93,\n",
       "             'analyze': 1342,\n",
       "             'needs,': 237,\n",
       "             'prototype,': 42,\n",
       "             'optimize': 555,\n",
       "             'solution.you': 4,\n",
       "             'entire': 262,\n",
       "             'schedule.you': 2,\n",
       "             'close': 122,\n",
       "             'collaboration': 482,\n",
       "             'customer’s': 42,\n",
       "             'team': 6008,\n",
       "             'consultant': 83,\n",
       "             'colleagues': 263,\n",
       "             'same': 79,\n",
       "             'project.,': 20,\n",
       "             'next': 433,\n",
       "             'products.': 138,\n",
       "             'high-quality,': 11,\n",
       "             'well-tested': 5,\n",
       "             'documented': 55,\n",
       "             'delivered.,': 2,\n",
       "             'challenge': 161,\n",
       "             'collect': 161,\n",
       "             'formulate': 92,\n",
       "             'translate': 494,\n",
       "             'them': 880,\n",
       "             'can': 1900,\n",
       "             'easily': 127,\n",
       "             'fed': 8,\n",
       "             'design.': 48,\n",
       "             'therefore,': 33,\n",
       "             'manager': 236,\n",
       "             'engineers.,': 18,\n",
       "             'improve': 1476,\n",
       "             'functionalities.,': 2,\n",
       "             'functionalities': 11,\n",
       "             'stakeholders.you': 3,\n",
       "             'developments.,': 4,\n",
       "             'finally,': 10,\n",
       "             'train': 113,\n",
       "             'usage': 158,\n",
       "             'solution.': 22,\n",
       "             'participate': 321,\n",
       "             'pre-sales': 31,\n",
       "             'demonstrate': 256,\n",
       "             'meets': 78,\n",
       "             'prospects': 22,\n",
       "             'goals': 472,\n",
       "             'objectives.,': 35,\n",
       "             'abilities,': 54,\n",
       "             'complemented': 4,\n",
       "             'university': 188,\n",
       "             'degree,': 222,\n",
       "             'indispensable': 2,\n",
       "             'job.,': 48,\n",
       "             'entrepreneurial': 188,\n",
       "             'problems.,': 100,\n",
       "             'correlations': 21,\n",
       "             'big': 2861,\n",
       "             'datasets.you': 5,\n",
       "             'incomplete': 29,\n",
       "             'bridge': 49,\n",
       "             'gap.,': 2,\n",
       "             'solid': 258,\n",
       "             'background': 649,\n",
       "             'least': 1175,\n",
       "             '5': 599,\n",
       "             'year': 575,\n",
       "             'distributions,': 85,\n",
       "             'testing,': 509,\n",
       "             'confidence': 87,\n",
       "             'intervals,': 14,\n",
       "             'series,': 70,\n",
       "             '…': 10,\n",
       "             'practical': 282,\n",
       "             'series': 233,\n",
       "             'exponential': 10,\n",
       "             'smoothing,': 2,\n",
       "             'multivariate': 142,\n",
       "             'regression,': 385,\n",
       "             'arima,': 7,\n",
       "             'real-life': 6,\n",
       "             'problems.you': 7,\n",
       "             'benefit': 215,\n",
       "             'having': 162,\n",
       "             'analyzing': 769,\n",
       "             'multinational': 16,\n",
       "             'organizations.,': 19,\n",
       "             'familiar': 156,\n",
       "             'scripting': 611,\n",
       "             'language,': 116,\n",
       "             'preferably': 394,\n",
       "             'r.': 48,\n",
       "             'basic': 512,\n",
       "             'relational': 772,\n",
       "             'databases': 827,\n",
       "             ...})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_count = int - Ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "#window = int - The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)\n",
    "#size = int - Dimensionality of the feature vectors. - (50, 300)\n",
    "#sample = float - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5)\n",
    "#alpha = float - The initial learning rate - (0.01, 0.05)\n",
    "#min_alpha = float - Learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n",
    "#negative = int - If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n",
    "#workers = int - Use these many worker threads to train the model (=faster training with multicore machines)\n",
    "\n",
    "#gensim.models.Word2Vec(data, min_count = 1, size = 100,window = 5, sg = 1)\n",
    "\n",
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                    # size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.68 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"            \\n                    'University of California San Francisco','Wunderman','MGM Resorts International','Interactive Brokers','Grubhub Amica Insurance Company','UPMC','Hearts and Science','Operation Smile','Sedgwick Claims Management Services','MetLife'\\n                       ,'Code Pilot','Talking Rain Beverage Company','Bright Cellars','MetroStar Systems','Omatic Software Schnucks','Abbott Laboratories','Lawrence Berkeley National Laboratory','Shift Technology','Consumers Energy Penn State University','VillageCare','Intercontinental Exchange','Palo Alto Networks','The Rawlings Group','Devoted Health Caris Life Sciences','ADT Corporation','Thomas Jefferson University and Hospitals','MassMutual Financial Group FourthWall Media','BB&T','AbbVie','National Renewable Energy Laboratory','Sandhills Publishing',\\n                       'Energy Sense Finance New York Media LLC','ESAC Inc','Aunalytics','U.S. Bank','Vistra Energy','Precision for Medicine','Teradata','Greene, Tweed & Co.','PNC TXU Energy','Stryker','Nippon Dynawave Packaging','Smith Hanley Associates','BASF','ADT Security Services Logistics Management Institute','Johns Hopkins','Shippensburg University','CareSource','Universal Consulting Services','DISH Commerce Bank','Beyond Limits','Prime Therapeutics','UCS Consulting','Ball Corporation','Anthem, Inc.','AT&T','West Corporation Parkland Health & Hospital System','Mayo Clinic','SunTrust','Amgen','K12','Broad Institute','Intel','UCHealth','Foxconn','Octic Capital Department of Veterans Affairs','New Mexico State University','USAA','Accenture','WellCare','Banner Health American Axle & Manufacturing, Inc.','Cyient','Swagelok','MEI Technologies','XPO Logistics, Inc.','Citi Universities Space Research Association','Lubrizol','eBay Inc.','KPMG LLP','Childrens Medical Center'\\n                       ,'AvalonBay Communities Cummins Inc.','Cummins Power Systems, LLC.','JB HUNT','Ford Motor Company','Anne Arundel Medical Center','Comrise','Highmark Health Central California Alliance for Health','Booz Allen Hamilton','Lockheed Martin Corporation','Cognizant','Jobspring Partners VincentBenjamin','Travelers','HX5','TFS','CarMax','Talent Plus','Bertelsmann','Forcepoint','Diverse Lynx','RubrYc Therapeutics L3 Technologies','Methodist Le Bonheur Healthcare','Arcadis','Smiths Detection','Orbital Insight','GE Careers The Aerospace Corporation','Odyssey Systems Consulting Group','Simons Foundation','Harvard University','First Horizon Stratacache, A Family of Companies','Axius Technologies','SigOpt','Kaleido Biosciences','Chenega Corporation','Foreground Security Electronic Arts','Miami HEAT','Garmin','Cisco Systems','Day Zero Diagnostics','GM Financial','Nike','EagleView Technologies University of Massachusetts Medical School','Standard Insurance Company','The Hanover Insurance Group Hewlett Packard Enterprise','Prime Solutions Group (PSG)','Weatherford','Next Rev Technologies LLC','Triquetro','ClimaCell','Sprint Synchronoss Technologies, Inc.','Synchronoss','TVG Network Betfair US','Northrop Grumman','Domino's','Cook Medical','Simple CrossFit, Inc.','Comcast','Zurich North America','Gayathri's Sandbox','Pros.','Rifiniti','Arable Labs, Inc.','Zumper','ISE Data Systems Grid Dynamics','Freds','Zillow Group','Nordstrom','HNI Allsteel','Lexmark International, Inc.','Florida Blue','Equifax','Apeel Sciences RELX Group','Andersen Corporation','WestRock','ShipBob Inc','Nielsen','Bosch Group','Xylem','Crossover','NT Concepts','Goodyear Lake Trust Credit Union','Ecolab','Spreetail','TracFone Wireless','eQHealth Solutions','HOMER','Shell','Barri Financial Group','Plaid Vantiv','Trinity Health','AnswerRocket','Northwell Health','Novartis','WeddingWire','US Pharmacopeia','Corning','CGG','Nexidia','Netflix HNI Corporation','Wayfair','PPL Corporation','Seagate Technology','Preferred Resources Inc.','Tek Experts','TriHealth Kaiser Permanente','EMD','P3 North America','Colgate-Palmolive','Staples','The Home Depot','Kantar Careers','Genmab','Walmart eCommerce Formation','Aetna','Aptiv','Schneider National','Press Ganey Associates Inc.','Novetta','Capgemini','HotelTonight','Capax Global LLC', 'AmTrust Financial Services','LendingTree','Ulta Beauty','W.R. Berkley','FinLocker Pearson','Zimmerman Advertising','Leidos','PACCAR','SYSCO','McKinsey & Company','Zachary Piper Solutions','Novelis','devwrx','FleetPride JPMorgan Chase','Klaviyo','Memorial Health System','Crossover Health','Feedzai','Virginia Tech Applied Research Corporation Matrix Medical Network','Niantic, Inc.','Niantic Labs','CenturyLink','Optoro','Bold','Quadrint, Inc.','ActiveCampaign Alaka`ina Foundation Family of Companies','Motorola Solutions','Yamaha','Modern Meadow','Qikspace','CACI','Snap Inc. Knowledge Facilitation Group','Toptal','Subaru of America','Wiley','DTCC','SAP','Verizon','Pluralsight','HCSC Pacific Northwest National Laboratory','IEEE GlobalSpec','AF Group','Accident Fund Holdings, Inc.','Ericsson','Radiant Solutions Micron','Viral Launch, Inc.','Fred Hutchinson Cancer Research Center',\\n                       \\n                       \\n                       'Martins Point Health Care','Carlisle & Company','Qwinix Amne','Colony Brands, Inc.','BAE Systems','Paypal','Carolinas HealthCare System','UPS','Ascena Retail Group, Inc.','Verra Mobility Illumination Works','C.H. Robinson Worldwide, Inc.','MEDSTAR HEALTH RESEARCH INSTITUTE (MHRI)','Albemarle Corporation Lincoln Financial Group','U.S. Venture, Inc.','WWE','Brillio','Karsun Solutions, LLC','Milliman','SanofiUS','Sovrn Holdings','UL LLC Applied Systems Inc.','Delaware North','Lovepop','Trend Micro','Harbor Wholesale Foods','Cardinal Solutions Group Ascensia Diabetes Care','Smartly','MarketDial','Mid-Atlantic Permanente Medical Group','Cardinal Health','Paychex Inc.','Cerebri AI Oath Inc','Numerator','Entergy Corporation','StubHub','Quicken Loans','Centene','Underwriters Laboratories','Prokarma Inc. Tractor Supply Company','Marsh & McLennan Companies','Radian Group Inc.','SumTotal Systems','Facebook','Ultimate Software Ideal Concepts, Inc.','World Fuel','Selective Insurance Group','Monsanto','Vettery','Ascension Healthcare','Dun & Bradstreet The J. M. Smucker Company','Procter & Gamble','City of Seattle','Two Sigma Investments, LLC.','Exact Sciences Corporation Driven Brands','Falls Lake Insurance Companies','Eli Lilly','Pop Healthcare LLC','Skillsoft','Tesla','iHeartMedia, Inc.','3Q Digital Ipsos North America','Exact Sciences','Vanda Pharmaceuticals Inc.','American Chemical Society','SHI International Corp. Medtronic','Precima','UTC','University of Maryland Medical System','DEG','Groupon','elicit','Conagra Brands','Progressive Leasing Thermo Fisher Scientific','Kaplan Test Prep','Kaleidoscope','Tilt Lending','Humana','Hawaiian Airlines','IT Concepts Inc. BAIN & COMPANY','BRS','LogMeIn','Integral Consulting Services, Inc.','DoubleDown Interactive LLC','Essence','SpartanNash First National Bank of Omaha','Visa','ZestFinance','Centura Health','Red Ventures','Barings','Kaplan','Cigna','PRA Health Sciences','ABSc HP','Huawei','BLUEHAWK, LLC','University of Utah','E*TRADE FINANCIAL','Ally Financial','Advantage SCI','Civis Analytics','Maana Equityzen','The Cadmus Group, Inc.','Society for Human Resource Management','Annalect','Northern Trust Corp.','Hitachi Vantara','EXL American Family Insurance','Huntington Bank','Cambia Health','Alion Science and Technology','NORC at the University of Chicago Morning Consult','First National of Nebraska, Inc.','Boll & Branch','Slack','Auto-Owners Insurance','SpaceCurve','Hertz','Welltower TripleLift','Alliant Credit Union','ServiceMaster','PwC','Guidehouse','Visionist, Inc.','Cormac Corporation','SAS Institute','Dexcom Sabre','TopSchoolJobs.org','Oracle','Ingersoll Rand','Axiologic Solutions','Celgene','Tsource','DataLab USA','Drybar','Philips Houston Methodist','Regions Bank','Bristol-Myers Squibb','Mars','BlueLabs Analytics','ConAgra Foods ManTech International Corporation','Engility','Analysis Group','RBC','Medical Science & Computing, Inc. Medical Science & Computing','KAR Auction Services, Inc.','UBS','Fidelity Investments','Agilent','Precocity','MetroHealth RetailMeNot, Inc.','Vivid Seats','Pfizer Inc.','CALNET INC.','Bio-Rad','Northwestern Mutual','Dotdash','Formativ Health','Pfizer Nabler Web Solutions','Varian Medical Systems','Blue Cross Blue Shield of Michigan','KeyBank','Assured Consulting Solutions H2M Group','Kemper Corporation','Enable Midstream','MedStar Health','Experian','Grant Thornton','Experis','Arrayo Brighthouse Financial','AncestryDNA','National Fish Wildlife Foundation','Molekule','Cubic Corporation MedStar National Rehabilitation Network','Tranzact','Aret√© Associates','MasterCard','Harnham','ASET Partners Camp4 Therapeutics Corporation','Lenovo','Jacobs','Redfin','Claritas','KEYW Corporation','Inabia Solutions and Consulting Wells Fargo','Lorven Technologies','OGSystems','Workbridge Associates','Altamira Technologies Corporation','Digital Promise','Bixal Flagship Pioneering','California State University','Intelligent Automation','Solidus Technical Solutions','DNAnexus','JD.com Obsidian Solutions Group','Butterfly Network','Mosaic North America','Early Warning Services','Panasonic','American Express Navstar, Inc.','Lightmatter','Wolters Kluwer','Open Systems Technologies, Inc.','Fifth Third Bank','Rockwell Collins System1 Biosciences','Battelle','eHire, LLC','1st Solution USA','Endurance International Group','Spotify','ViaSat','Foot Locker Ace Technologies','Salesforce','Merck','Norfolk Southern Corp','Eventbrite','Beyondsoft Consulting','Applause','Arthur Lawrence','Square Trimble Inc.','Genedata','Directly','Tradesy','InVision Studio','Time Warner','Siemens','HealthGrades','Edison Energy','Recorded Future SpotX','KBRWyle','KMM Technologies','Transamerica','Snowflake Computing','TripAdvisor','Pitney Bowes','HumanTouch, LLC','Vevo','b.well Legends','MachineZone','Numerdox','citius tech','HyperspaceVentures','Creative Alignments','Williams-Sonoma, Inc.','NetMotion Software Sartorius Corporation','NewYork-Presbyterian Hospital','Trimble','Fora Financial LLC','GlaxoSmithKline','ConnectYourCare Clarivate Analytics','Q2ebanking','Bigfoot Biomedical','State Farm','Brightidea','Catasys','Verb Surgical','MapR','Tessella','Uber PARC, a Xerox company','Wolverine Trading','Dana-Farber Cancer Institute','myCOI','XL Catlin','Country Financial','Centro Impetus Technologies','HouseCall Pro','Huobi','QxBranch','GlassDoor','BMW North America','NBA Properties','Parkview Health','Bose Taboola','Edelman','Watts Water Technologies','ThinkIQ','Upstart','Conversant Media','Calico','CIITS','Nokia','MacAulay-Brown, Inc. (MacB) Ticketmaster','Dropbox','PepsiCo','Mitchell International, Inc.','Etsy','Gartner, Inc.','Pray','Weber Shandwick','Disney','Phreesia Integral Ad Science','Veritone','Opendoor','Aera Technology','Owens Corning','Protective Life Corporation','Arconic','GoDaddy Coupa Software','FedEx','Bind Benefits','Voya Financial','Alere','Xandr','DigitasLBi','Stanley Black & Decker','Lab126','Fair','Houzz Asurion','ACI Worldwide','Predictive Science','NEURA','Unisys','Kogentix','MOBE, LLC','AllianceData','Epsilon','TrueCar, Inc. The TJX Companies, Inc.','Maxim Integrated','SoFi','Church Pension Group','Jewelers Mutual Insurance Company','Esurance Harley-Davidson','BlackLine','Slalom Consulting','Chatmeter','Roche','Wish','Par Government Systems Corporation','OpenTable','Honeywell Atos','Precision Health AI','Domo, Inc.','Coso IT','RS Energy Group','ZF','Realogy','3M','St. Jude Children's Research Hospital EPAM Systems','S&P Global','Rover','Jet.com','Syntelli Solutions, Inc','Improbable','Clarabridge','Honda Research Institute USA Applied Materials Inc.','Manulife','Public Company Accounting Oversight Board','McGraw Hill Financial','NetApp','Mitre Corporation Sage Intacct','Cyberspace Solutions','Blue Nile','Aspen Technology','Amches, Inc.','BoxyCharm','Lowe's','DuPont','Invisibly The Climate Corporation','Upwork','Hackensack Meridian Health','United States Steel','Onyx Government Services, LLC Change Healthcare','Pivotal Commware','CallMiner, Inc','MSA Safety','Proofpoint','OneKreate','Vituity','Hilton','Convey Marketers on Demand Inc.','Akili Interactive','L&T Technology Services Ltd.','Satsyil Corporation','Convey, Inc. HERE Technologies','Signifyd','Esri','Sabio Mobile','Candid Co.','First Tech Federal Credit Union','Faire','Sentieo Planned Systems International','Remedy BPCI Partners, LLC.','Hagerty','Convoy','Strava','Remedy Partners','Vertex Vertex Pharmaceuticals','Engie','Thrive Market','Morgan Stanley','Plymouth Rock Assurance Corporation','IQVIA','Eagle Ray Inc Volanno','Kinetica DB','Prudential','First American Corporation','Picarro','Immuta','Liberty Mutual','Qualtrics','Illumina BMO Financial Group','Kinsa Inc.','Sartorius North America','Intuit','ExtraHop Networks, Inc.','Cityblock Health HR, Legal, & Administration','Ellie Mae','WellSky','Johnson & Johnson Family of Companies','Quartet','Abiomed','Affirm','Alqimi Twentieth Century Fox','Maven Wave Partners','Conduent','Cognitive Scale','SHINE Systems & Technologies','Crowe','AXIS Insurance Criteo','Big Fish Games','Genentech','MSA Safety Inc.','Xactly Corporation','Coherent, Inc.','bluebird bio','FabFitFun Varen Technologies','Coherent Germany','FM Global','All-In Analytics','HHB Systems','BCG Digital Ventures Benson Hill Biosystems, Inc','MultiScale','zulily','High Alpha','Quora','ICR','Blackbaud','Castlight Health','KAYAK Bank of America Merchant Services','Elite SEM','EY','Heartland Dental, LLC','Verisk Analytics','Pragmatics','Vanguard','Bartech Group Berico Technologies','Peraton','Clara','Invesco','Zscaler','American Institutes for Research','Funding Circle US','First Orion Social Solutions','Apogee Integration, LLC','Productive Data Solutions, Inc.','Everlane','Regis Corporation','PetSmart Service Management Group, Inc.','General Dynamics Mission Systems','Clockwork Solutions','Dynetics','Amplitude New York Life Insurance Company','Altair Engineering','Ross-Carlisle Group','Eaton Vance','NVIDIA','Technology Partners BNP Paribas','FICO','Toyota Research Institute','Scaleapi','Liquidnet','2K Games','Ginger.io','Zynga','Symantec','Yelp','Globant Rockstar New York','Restoration Media','Bluecore Inc.','Nutanix','Kelvin','iHerb','Prospect 33','Spokeo','Academia.edu','John Deere Daugherty Business Solutions','YourMechanic','First Republic Bank','AppZen','Ubisoft','Optimizely','LeapYear','Reorg Research Altice USA','Autodesk','LimeBike','Quantcast','DeepCurrent Technologies, Inc.','C3','Neuberger Berman','Liberty Lending','Crowdstrike ServiceTitan','Porsche','VROOM','Sealed Air','Edison Software, Inc.','Rockstar San Diego','Nauto','Gap Inc.','Applied Memetics LLC Lark Health','Blue Owl','Ryder','Quantiply Corporation','Internet Brands','Mist Systems','Helpshift','Viome','ThirdLove','Crystal Dynamics Peak6','Grand Rounds','Yapstone','Aruba Networks','Credit Sesame','Valassis Digital','Uhana, Inc.','EMIDS','Xilinx','Veeva The Carian Group','AIG','Barrick Gold Corporation','Photon','Sony Interactive Entertainment PlayStation','Omnicell','Waymo','Coursera Scalable Digital','Suplari','Tonal','Pocket Gems','Coinbase','Emailage','Zazzle','Otsuka','PG&E','Thunder Token','Scoot Networks','PlaceIQ Franklin Templeton Investments','WW International (formerly Weight Watchers)','Porch','Lumos Labs, Inc.','Polis, Inc. MetroPlus Health Plan','Lieberman Research Worldwide','Safeway Corp.','Lyric','Wealthfront','Dollar Shave Club','Farfetch','Qualys Sirius XM Radio','Perficient','Acuity, Inc.','Atlassian','Infoblox','Research Innovations Inc','General Mills','Lattice Engines Nift Networks','Nerdwallet','Peloton','Goldman Sachs','Tesorio','JUUL Labs','Zot Inc.','BlackRock','Proteus Digital Health','Payette Group Guidewire Software, Inc.','Betterment LLC','GroupM','Maxus','Western Digital','Nanigans','Covance','OneGlobe','Galvanize','Coverent University of California San Francisco Medical Center','JM GROUP','Boeing','The Boston Consulting Group','Sitecore Fluid Intelligence','LabCorp','VMware','Capital Group Companies','Visual Awareness Technologies and Consulting, Inc. Powertek Corporation','Cell Signaling Technology, Inc','Ascent Services Group Redfish Technology - High Tech Executive Recruiters','Turnitin, LLC','Darwin Recruitment','Kaizen','Axelon Services Corporation Chime','Clarity Insights','IQ Workforce','BAE Systems Applied Intelligence','Solving It','stanleyreid','Quest Diagnostics Stride Search','CRGT Inc.','Avanade','NBCUniversal','Dice','3coast','Lionbridge Technologies','Signify','Blue Origin','Medallia, Inc. Stella.ai','TIBCO Software','Discovery Communications, LLC','7Park Data','Narvar','Keep Truckin','David Weekley Homes Moody's Corporation','Linc Global, Inc.','Figure','Alibaba','FoxNext Games','DRW Trading Group','DRW','ServiceNow','Motif Investing CircleUp','Samsung Semiconductor, Inc.','Zingbox','Workday','Synechron','Taino Consulting Group','Parallel HR','Intelligent Waves Llc HeartFlow','HD Vest','JLL','NetBrain Technologies, Inc.','Publicis Spine','Gradient.io','aThingz','ShareThis, Inc','Roku','Datadog DataRobot','Octane Lending','PTP','Juvo','Blume Global','securonix','FireEye','Plume','Cogitativo','QuantumBlack','Unity Technologies','ACS Socure','Averity','TWINN INTELLIGENCE GROUP','Prognos','The Hagan-Ricci Group, Inc.','Trace3','Daley and Associates','Health Catalyst AltaSource Group','CRB Workforce LLC','Invictus International Consulting, LLC','Integrated Management Resources, LLC','Pilot AI Analytic Recruiting','Advanced Micro Devices, Inc.','Great Bay Staffing Group','Lyft','Optimove','Commonwealth of Massachusetts UC DAVIS HEALTH SYSTEM','Columbia University','Bryant & Stratton College','Bloomberg','Servient Inc','HopJump Colliers International','Freedom Forever','Shoes For Crews, Inc.','AVID CENTER STAFF','Tampa Family Health Centers','FIS Wellmore, Inc.','Arkansas Blue Cross and Blue Shield','Youth Policy Institute','McGraw-Hill Education','XLA Lubbock Heart & Surgical Hospital','ZEISS Group','Zeiss','Lockton, Inc.','Boyd Caton Group (bcg)','GOCOOL BHP Engineering & Construction','Levy','New Visions Central Office','City of Minneapolis','Blade','Avkare Inc','The Carle Foundation Arkatechture','Raymond James','BBYO -','Stanford University','Cota','New Visions for Public Schools','Canton-Potsdam Hospital JetBlue Airways Corporation','NYSTEC','National Grid','Resolvit, LLC','Goodwill Industries International, Inc. (GII) Glassview Media','STOBER Drives, Inc.','General Dynamics Information Technology','Advance Auto Parts','23andMe','Healthtronics','DHL Progrexion Holdings Inc','Lytx','Southern California Edison','Fortive','doTERRA International','Abilene Christian University London Stock Exchange Group','Goby','Georgia Military College','CDW','Rational Consulting','Boss Fight Entertainment Butterball, LLC','Clarity USA','Mixbook','Memorial Sloan Kettering','King County Housing Authority','ZIN TECHNOLOGIES INC.','Masco The Wonderful Company LLC','eSpark','Health One Alliance, LLC','Teacher Retirement System of Texas','Emory University Major League Soccer','Brown & Brown Insurance','Fidelity National Financial','City of Tucson','SCAN Health Plan Alegeus Technologies','Ciox Health','CMI Media and Compas, Inc.','Graphic Products','Cresco Labs','AltaMed','Regional One Health Alltran','Logic Rule','Lutron Electronics','jump ramp','First National Bank of America','Outreach Process Partners','ECS Federal LLC Sentry Insurance','WebMD','Johns Hopkins University','AECOM','Office of the Nassau County Comptroller','IPRO','Zeta Global The Dow Chemical Company','GeoDigital','Sigma Space','Keck Medical Center of USC','Fruition Partners','IXIS Alliance Health Professionals','Resource Systems Group, Inc.','CompuCom','Moda Health','Germania Insurance','stearns bank Technicolor','Spy Pond Partners','Pinkerton','Ukpeagvik I√±upiat Corporation/Bowhead Family of Companies','NextGen Healthcare UNITED NEGRO COLLEGE FUND','Fitch Group','Patagonia, Inc','USfalcon','Texas Health and Human Services Commission','The Motley Fool Federal Management Systems, Inc.','Care New England Health System','U.S. Anesthesia Partners','Progressive Alameda Health Consortium/Community Health Center Network','Courtney Raymond Consultants','Facing History and Ourselves, Inc thrivecausemetics.com','BI Worldwide','Advanced ICU Care','AnaVation, LLC','Ingram Content Group','Twitch','Renown Health','DXC Central Health','Western National Insurance Group','AmeriCorps','Gaylord Specialty Healthcare','Housing Works Comprehensive Healthcare','Stormont-Vail Healthcare','Bassett Healthcare','Fiserv','Holleran Consulting','Nestle USA','Payfone University of Pennsylvania','Concerted Care Group','KingsIsle Entertainment','Community Reach Center','The Boston Globe Volvo Group','UNITE HERE HEALTH','2DA Analytics','ForeFlight','Care.org','Tory Burch','GEHA','Buxton','Hylink Group','alliantgroup Culinary Health Center','The Vancouver Clinic','University of Virginia Health System','Cancer Treatment Centers of America Inframark','Jamul Casino','ipsy','Medifast, Inc','American Merchandising Specialists','Success Academy Charter Schools Compass Group USA','Webster Bank','John Clements','ANB Bank','L'OREAL USA','Association of Universities for Research in Astronomy Sullivan, Cotter and Associates, Inc.','Primus Builders Inc.','Medical Transportation Management (MTM) National Financial Partners','Fragomen','Fresenius Medical Care','Evolent Health','Renewable Energy Systems Ltd. Hawaii Medical Service Association','Child Care Resource Center ‚Äì Chatsworth, CA','Aultman Health Foundation D&K Engineering','Axos Bank','Churchill Mortgage Corp','Dexperts','NSD','Primerica','EmblemHealth Health Care District of Palm Beach County','Baystate Health','AccessCNY, INC','Emerson Hospital The International Fund for Animal Welfare','Acquisition Life Cycle Management','Aultman Hospital','AUTHENTIX INC Flair IT Solutions','Boston Children's Hospital','Wood','Targetbase','Edward-Elmhurst Health','Allegheny Health Network','EMA, Inc. MJHS','Aclara','Boyne Resorts','US Software & Consulting','Encompass Community Services','Everything But The House (EBTH) Arc Aspicio','Alnylam','Team Red Dog','Orange County Transportation Authority','Rauxa','Direct Resources Group','Johnson Matthey Vivo','Healdsburg District Hospital','Dime Community Bank','CIBC','Dassault Falcon Jet','Emmis Communications','Logic20/20 CORKCICLE.','Virginia Jobs','Logitech','BBYO','Healthline Media','CSRA','University of Texas at Arlington','Crestron Electronics Crestron','University of Colorado','C5T Corporation','TISTA Science and Technology Corporation','Clearwater Paper','Option Care University of Texas at San Antonio','Knorr-Bremse North America','Bird Rides Inc.','Maryville University','Listrak State of New Mexico','Management Science Associates Inc.','Managed Care Advisors','Flight Centre','RWJBarnabas Health Beaumont Health','Envisagegroup','Ensign Services','Sweetser','The Parking Spot','Zodiac Aerospace','AIDS Foundation of Chicago Baptist Health South Florida','Fabick Cat','Community Behavioral Health','Academy for Urban School Leadership Arrowpoint Corporation','Chicago Public Schools','AUSL Chicago','Gila River Health Care','SECU','Charles Schwab','MultiPlan Inc. Chapman Cubine Adams & Hussey','Management Concepts','NaviHealth','thoughtmatrix','ClassLink Inc','AHMC Healthcare Inc','RE/MAX, LLC Capital Impact Partners','Clayton Homes','United Fire Group','MIT Lincoln Laboratory','BookBub','AssuredPartners','PowerSchool The Situs Companies','Mary Washington Healthcare','Brightree','ITAGroup','Virginia Mason Medical Center Appalachian Regional Healthcare','MaineHealth','Horizon Health Services','Nationwide Children's Hospital','Hitech Assets, LLC. NetVision Resources (NVR)','Kroger','Penobscot Community Health Care','Unilever','NRG Energy','State of Arizona Laureate International Universities','QuEST Global Engineering','ITT Corporation','Citizens Energy Group LiniumTalentAcquistion','Nolij Consulting','ACN','Blue Cross Blue Shield of Arizona Advantage','Wildlife Conservation Society Carter Bank and Trust','Astor Services For Children & Families','2U','Systems Staffing Group','Zumba Fitness, LLC','BOK Financial CHEP','Harvard Pilgrim Health Care','Credit Acceptance','Sun Life Financial','8-Koi','The New School','Curriculum Associates','Dyson Commonwealth Of Virginia','Universal Health Services','Premera Blue Cross','Baltimore Medical System, Inc. University of California Berkeley','Fossil Group','Fund for Public Health in New York City','Indiana University','Siena College Precision Value & Health','Piedmont Healthcare','Children's Hospital & Research Center Oakland','GrayMatter','Parametric Gray Matter Systems','Partners HealthCare','Anchorage Consultants LLC','Advantage Solutions','Cydecor, Inc. Toole Design Group LLC','FARO Technologies','Blue Shield of California','Kongregate','TracyLocke','Florida Hospital Adventist Health System','Geotab','Shutterfly','Rosecrance Health Network','Morneau Shepell','Farm Bureau Insurance of Michigan Pace University','Einstein Healthcare Network','SUBWAY','EnerNOC','Cricut','The Money Source','Santander Consumer USA Nordic Naturals, Inc.','ProMedica','Akima, LLC','Freddie Mac','Northeastern University','Beaver Dam Community Hospitals, Inc. Discover Financial Services','Cloudburst Consulting Group Inc','Crozer Keystone Health System','Capgemini Government Solutions CompuGain','Envision Healthcare','Molina Healthcare','Epic Care','Calero Software','CCC Information Services Inc.','CBRE Freedom Financial Network','Self Regional Healthcare','BlueLinx Corporation','KGPCo','LTD Commodities UT Southwestern Medical Center','Frogdata','The Logistics Company','Imerys','T. Parker Host','Gallagher','maconit','VCU Health System Mount Sinai Health System','Benchmark Education Company','Oxford Global Resources','Astronics','Accountants One, Inc','Ameritas Multnomah County, OR','Mercy Health','Nextiva','Parker Hannifin Corporation','Northwest Permanente, P.C. Matheny School and Hospital','Na Ali'i LLC','The National Association of Manufacturers','Vista Technology Services Liberty University','Anheuser-Busch','AbleVets LLC','Swiss Re','Cymer','Boston Medical Center','Baylor Scott & White Health','Bitcoin Under Armour','Creative Arts Agency (CAA)','Voloridge Investment Management','Dot818','Quinstreet','Cisco Meraki Guardian Industries','Inland Empire Health Plan','Plastiq','Cricket Health','InnovaSystems International','OneAmerica','Techshed Core10','Leadsmarket.com LLC','Fiat Chrysler Automobiles','Aramark','Cognosante, LLC','OppLOans','Fidelis Care','Fullscreen Media Pond5','Ring Inc.','Columbia Sportswear','Manage','Santa Clara Family Health Plan','LawTrades','New York Blood Center','Lucky Day Buchanan & Edwards','Vox Financial Partners','Doximity','Candid Partners','Dentsu Aegis Networks','MKTG','ZeniMax Media Inc. University of Washington','Fullscreen','Polaris Industries','Cogo Labs','The New York Times','RiskSpan','Poll Everywhere NCI Information Systems, Inc.','FPM Technologies','enVista','Cable & Wireless Communications Inc','Dewpoint Northwest Farm Credit Services','IMTAS','Textio','Apptentive','Ascend Performance Materials','Apkudo Prospect Medical Holdings, Inc.','Prospect Medical Systems','Greater Delaware Valley','Silicon Valley Bank','IDT Corporation Celmatix','University of Michigan','FourKites','CONTINUUM','Hilcorp Energy Company','Innove LLC','ResMed','Ellis Medicine Relevant Healthcare Technologies','Hasbro Inc.','UCLA Health','Corcentric','Mentor Graphics','Ingram Micro','Curve IT Consulting GCC Technologies, LLC','AppFolio','Langan Engineering and Environmental Services, Inc.','Legg Mason','Sentara Healthcare Reputation.com','Institute for Health Metrics and Evaluation - Faculty','CliniWorks','Great Wolf Lodge','Stream','IDEO iSpot.tv, Inc.','CHOC Children's Hospital','SocialWithin','Community Medical Centers Inc','Harry's','Verscend Technologies Zelis Healthcare','LevelUp','Delta Dental of Minnesota','Community Medical Centers','Kohler Co.','Galaxy Systems','Asembia LLC Common Securitization Solutions','Tate & Lyle','Ascensus','Getty Images','ddms','Emory Healthcare','Louis Dreyfus Central Maine Medical Center','InfoArmor Inc','Prime Healthcare','Castleton Commodities International University of California UCOP','Collective Health','Fanatics Inc.','T1D Exchange','sweetgreen','Brooks Sports, Inc','Virtru','JFrog Bank of the West','Hiscox Ltd','State Street','Meijer','Kabam','Superior Vision','Archer Daniels Midland Company South Dakota State University Foundation','Starbucks','Arthrex','Spireon','PitchBook Data, Inc.','Commonwealth Care Alliance Donnelley Financial Solutions','CORTEK','VSCO','William E. Wecker Associates, Inc.','Rent-A-Center','New York University Russian School of Mathematics','Din√© Development Corporation','A. H. Belo Corporation','Vera Whole Health','Assurant Strategic Resources, Inc.','Beachbody','Clarkston Consulting','Riot Games','College Raptor','REI','Boxy Charm','Acumen Solutions Pinnacle Engines, Inc.','Glu Mobile','CenCal Health','Ely-Bloomenson Community Hospital','National Instruments','BorderX Lab Inc Central Texas Food Bank','MileOne Automotive','Clemson University','GenapSys, Inc.','Paradyme Management','Coffee & Bagel Brands Aledade, Inc.','Blue Chip Talent','Blue Apron','HelloWorld','Straumann','Libra Services','TSheets','LUXOTTICA','Mindshare','GoodRx','JT4 Berkadia Commercial Mortgage','IHS','IHS Markit','State of Washington','Cambria','Level Ex, Inc.','MUFG','Fremont Bank DSD Partners Inc','Genworth','C&A Industries, Inc','Crown Castle','Union Bank & Trust','CSSI, Inc.','RK','Advance Financial Halfaker and Associates','EBSCO Industries Inc','Arbella Insurance Group','Catholic Health Initiatives','ASML','T. Rowe Price','SAIC Washington State Hospital Association (WSHA)','Vertical Careers, Inc.','L.A. Care Health Plan','George Mason University Willis Towers Watson','Providence Health & Services','AmeriHealth Caritas','New York State Office of the Attorney General RentPath, LLC','Los Alamos Technical Associates','PANGEATWO','Seasoned','Christiana Care Health Systems','Niagara Bottling Allegro MicroSystems, LLC','Virtus Partners','Wargaming.net','Johns Manville','Life Chiropractic College West Federal Reserve Bank of New York','Meridian Health Plan','DCS Corp','Digital Management, LLC','OneSource Virtual Genuine Parts Company','Wyndham Hotels & Resorts','Vitals','Green Dot Corporation','UJA Federation of New York','Inovalon Alliance Data - Retail','FirstCare Health Plans','SunPower Corporation','Solomon Associates','ANTHEM MARKETING Children's Hospital of Wisconsin','Capital One','Mountain America Credit Union','DJO','Radiance Technologies Inc.','HBM Holdings Smith & Nephew','VirtueGroup','The American College of Radiology','Purple Communications, Inc.','CapTech Consulting','SRC, Inc. First San Francisco Partners','AnalogFolk','NinthDecimal','KeepSafe','Periscope technologies inc','Health Team Advantage Bowery Farming','Alteryx, Inc.','Hudson's Bay','Traxion Group, Inc','Foundation Medicine, Inc.','Coty Inc.','QIC Limited Nextphase Systems','Hearsay Social','EPMA','Certara','Women's World Banking','Microfinance Gateway','Impact Makers, Inc.','Balyasny TACG, LLC','AppNexus','Health Dialog','Burlington Stores','ARC Solutions USA','LeafLink','Productive Edge','Credit Suisse General Dentistry 4 Kids','Nuvve','Harvard Business Publishing','Grail Insights','Heartland Business Systems','RocksBox Crohn's & Colitis Foundation of America','goPuff','Layer3 TV','Real Capital Analytics (RCA)','Scholastic','IntroPro','MWW Group ExcelaCom','One Call','Seattle Children‚Äôs','Estee Lauder','[24]7','PeerStreet','WeWork','Virbac Animal Health Mississippi Lime Company','County of San Mateo','Softrams','BLUECUBE Information Technology','CooperVision','IPG Mediabrands','ALC Accolite Software India','Accolite, Inc.','General Motors','BNY Mellon','PJM Interconnection, LLC','WP Engine','Priceline.com Oklahoma Cancer Specialists and Research Institute','Blytheco, LLC','Johns Hopkins Health System','momofuku','RB','Alarm.com ServiceLink','Becton Dickinson','Abacus Data Systems','City National Bank','LendingClub','MGAC','Kennametal','Allergan','MVM','Magento Mission Staffing','HelloFresh','CTG','Health First','MM.Lafleur','Chicago Trading Company (CTC)','National Funding','Looker','Clearpoint uJoynus','CAPCO','Fender','ClearView Healthcare Partners','SWIFT','Bill.com','Motion Recruitment Partners','Publicis.Sapient','PureCars Arch Capital Group Ltd.','Engage Partners','Western Union','Community Health Network','Broadridge','Robert Walters','Merkle Inc. L Brands','Sephora','King.com','HAVI Logistics','Globoforce Limited','Wycliffe Bible Translators','Vistage Worldwide','Wipro LTD Franciscan Health','Coffee Meets Bagel','Zenith','Finra','Ramsey Solutions','Medidata Solutions','J.D. Power','JustAnswer','Carbon Black Performics','JBCconnect','Goodwin Recruiting','DoorDash','MSCI Inc.','Jetblack','EyeView','New York Yankees','EducationDynamics Boston Bruins','State of North Carolina','The University of Kansas Health System','American Specialty Health','Hydromax USA Hill-Rom','Solomon Page','cableyou','Hy-Vee, Inc.','ATN International','Measured Progress, Inc.','Availity, LLC. Arrow Electronics, Inc.','Colorado Community Managed Care Network','Koddi','ELLKAY LLC','A Could Guru','Janus Research Group Quest Analytics','Bealls Inc','Technamo LLC','Eastman Chemical Company','Evonik','Virginia Tech','Renew Financial','Aroghia Group PRA Group','Advanced Technology Group Inc','UpClear','Acustream','Beacon Health System','Grundfos','Grundfos Pumps Corporation','Snag WEX Inc.','East Daley Capital Advisors','Denodo Technologies','AXA General Insurance','Bangor Savings Bank','AQR','AXA','Sierra Lobo Housing Authority','Munich Re','Las Vegas Sands Corp.','BGC Partners','Denodo','Jackson Dawson','Henry Schein','ECRI Institute American Modern Insurance Group, Inc.','Octo Consulting Group','Serco , Inc.','ACT, Inc.','TeleTracking Technologies Farmers Insurance Group','Auth0','Liv Communities','Blue Cross Blue Shield of Arizona','Prosearch Strategies Casey's General Stores','Prodege, LLC','Hook & Loop Creative','ktMINE','Audley Travel','AKRAYA INC.','Viant','SharpSpring','ACCION Pairwise','Accion in Arizona, Colorado, Nevada, New Mexico and Texas','Clear Capital','Catalyst Repository Systems Billings Clinic','Doosan Bobcat','Intrexon Corporation.','Tredence','GlobalLogic, Inc.','Intalere Inc','Rackspace','Nevro Corporation Tompkins International','Asics Digital','The Walsh Group','Object Computing Inc.','Lirio','Paycom','Atlantic Health System VVC Holding Corp','Curbside','Susquehanna International Group','Plante & Moran','State Auto Insurance Companies','Overstock.com Farmers Fridge','Southern Poverty Law Center','Privia Health','Pizza Hut','United States Associati','InsideSales.com, Inc. REsurety','Jebbit','Civitas Learning','Auto Club Group','Hamilton Lane','Navigator Management Partners','Choice Hotels','SailPoint AmeriSourceBergen','Theoris Services','Carbonite','Jellyfish UK','Jellyfish','Tabula Rasa Healthcare, Inc','Morningstar','Armor WebbMason Analytics','BCD Travel','Zilker Partners','Simon-Kucher & Partners','Syngenta','Aegon','Cross River Bank Dev Technology Group, Inc.','W.W. Grainger','Calix','Healthfirst','Mondelƒìz International','Vivint Smart Home','IDEXX','New Knowledge Location3','Windstream Communications','Windstream','Trident Technologies LLC','United Network for Organ Sharing','Penske Macquarie Group Limited','Idexx Laboratories','Schoolzilla','CoreCompete','Netsmart Technologies','Rally Health','Lifetouch Hospital for Special Surgery','TMP Worldwide','The Denzel Group','MicroStrategy','Vets First Choice','PATHORAS CORPORATION','Nice Sumeru Solutions','Cimpress','Brivo Systems','Caesars Entertainment','IMO - Intelligent Medical Objects, Inc. LifeWatch Services, Inc.','BioTelemetry, Inc.','Fannie Mae','The Standard','RhythmOne','Whole Foods Market','Kraken Cleveland Cavaliers','Zeus','LeanTaas','Hulu','BitTorrent Inc.','7-Eleven','Tavant Technologies','Orzota','Reflektive Anadarko Petroleum Corporation','Zeus Living','Blizzard Entertainment','HelloSign','Pandora Media, Inc.','The Black Tux','8X8 INC. Exabeam','N3TWORK','VividCortex','Samsung','US Information Technologies','Gallup','Linden Lab','Brad's Deals Perfect World Entertainment','AirPR','GoodData Corporation','UiPath','Castle Global','Duke Energy','Principal Financial Group','Trianz Warby Parker','Syneos Health Commercial Solutions','Evaya Data Systems','Sun Basket','Drillinginfo','TGS Management Company','Novus Caserta','hiretual.com','ChowNow','Thales','Peloton Technology','St. Joseph Health','SoftVision - North America & UK Keysight Technologies','Mazda North American Operations','Infront Sports & Media Group','Amdocs','14 West Amplify Education, Inc.','Animoto','Change.org','Agent IQ','Zipcar','Citadel Securities','PlacePass','J. Crew Group, Inc. Augmedix Inc.','Myers Media Group, LLC.','SmartThings','Object Partners','Aaptiv','Hinge Health','Swift Navigation Public Consulting Group','Plus3 IT Systems','Pythian','MLB.com','ScienceSoft USA Corporation','NeuStar, Inc.','SSi','ThoughtWorks Criterion Systems','USANA Health Services','USANA Health Sciences','Tendril','Takeda Pharmaceuticals','Softvision University of Maryland, Baltimore','Ten-X','National Home Rentals','Federal Reserve Bank of St. Louis','Sevatec, Inc. athenahealth','Integrity Applications Incorporated','Lucid Motors','TE Connectivity','NISSAN','GoPro','HatchWorks Technologies Merlin Labs','Tableau','Giant Oak','Yodlee','Probity Inc.','Eaton','Zotec Partners','PlayQ','KEYPR','GumGum','drawbridge','Scoop Technologies HotSchedules','iRobot Corporation','National Football League','VideoAmp','Alloy','EquiLend','Viacom','TPC Energy Fund','Shippo INSIGHT ENGINES','Copper','lululemon athletica','Faraday Future, Inc.','William Blair & Company','Applied Thought','Custoria','ZocDoc The Zebra','Symphony Talent','Mercari','Credit Karma','Levi Strauss & Co.','EasyPost','Carrot Inc.','zesty.ai','WeedMaps The Clorox Company','Omada Health','Enlighted','Adaptive Management','Cyberonics','Smule','Boeing Intelligence & Analytics Celtra Inc.','AG Grace Inc','Obsidian Security','thredUP Inc','Guardant Health','Audi Canada','FuelX','Chegg','Hitachi','StreetLight Data Edwards Lifesciences','DATA WORKS','Mojio','Axis Group','A+E Networks','Navy Federal Credit Union','Concur','M&T Bank','East West Bank Vistaprint','Veteran's Enterprise Technology Solutions, Inc.','Dialpad, Inc.','System1','realtor.com','AppDynamics','Conductor Stessa','BigCommerce','Avvo','The Meet Group','Glooko','Coda Search','Intelliswift Software Inc']\\n  \""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''company_keyword_seed = ['google', 'locations','adobe','florida','san francisco','washington'\n",
    "'Government'',Education and Schools',\n",
    "'Energy and Utilities',\n",
    "'Aerospace and Defense',\n",
    "'Transport and Freight',\n",
    "'Organization',\n",
    "'Telecommunications',\n",
    "'Retail',\n",
    "'Computers and Electronics',\n",
    "'Consumer Goods and Services',\n",
    "'Restaurants, Travel and Leisure',\n",
    "'Media, News and Publishing',\n",
    "'Pharmaceuticals',\n",
    "'Industrial Manufacturing',\n",
    "'Auto',\n",
    "'Real Estate',\n",
    "'Human Resources and Staffing' ]\n",
    "'''\n",
    "\n",
    "company_keyword_seed =['Express Scripts','Money Mart Financial Services','comScore','Central Intelligence Agency',\n",
    "                       'Federal Reserve Bank of Dallas National Security Agency','NYC Careers','OM Partners','University of Idaho','usajobs.gov','The University of Pittsburgh Rice University',\n",
    "                       'Elev8 Hire Solutions','Catalina Marketing','Florida Polytechnic University','Achievement Network (ANet) Deloitte',\n",
    "                       'ExxonMobil','MIT','Ochsner Health System','Raytheon','ERM Group','Google','Lawrence Livermore National Laboratory','Adobe Intuitive Surgical','University of Minnesota','Splunk','Southern Methodist University','Microsoft Duke University and Duke University Health System','Coyote Logistics','Twitter','iD Tech','Canvas Technology The Church of Jesus Christ of Latter-day Saints','Riverside Research','OpenAI','IBM','Asendia Management SAS','T-Mobile','Walmart UES','NextEra Energy, Inc.','Argonne National Laboratory','Elder Research Inc','Dell',\n",
    "                       'Hallmark','Allstate L. L. Bean']\n",
    "                       \n",
    "                       \n",
    "'''            \n",
    "                    'University of California San Francisco','Wunderman','MGM Resorts International','Interactive Brokers','Grubhub Amica Insurance Company','UPMC','Hearts and Science','Operation Smile','Sedgwick Claims Management Services','MetLife'\n",
    "                       ,'Code Pilot','Talking Rain Beverage Company','Bright Cellars','MetroStar Systems','Omatic Software Schnucks','Abbott Laboratories','Lawrence Berkeley National Laboratory','Shift Technology','Consumers Energy Penn State University','VillageCare','Intercontinental Exchange','Palo Alto Networks','The Rawlings Group','Devoted Health Caris Life Sciences','ADT Corporation','Thomas Jefferson University and Hospitals','MassMutual Financial Group FourthWall Media','BB&T','AbbVie','National Renewable Energy Laboratory','Sandhills Publishing',\n",
    "                       'Energy Sense Finance New York Media LLC','ESAC Inc','Aunalytics','U.S. Bank','Vistra Energy','Precision for Medicine','Teradata','Greene, Tweed & Co.','PNC TXU Energy','Stryker','Nippon Dynawave Packaging','Smith Hanley Associates','BASF','ADT Security Services Logistics Management Institute','Johns Hopkins','Shippensburg University','CareSource','Universal Consulting Services','DISH Commerce Bank','Beyond Limits','Prime Therapeutics','UCS Consulting','Ball Corporation','Anthem, Inc.','AT&T','West Corporation Parkland Health & Hospital System','Mayo Clinic','SunTrust','Amgen','K12','Broad Institute','Intel','UCHealth','Foxconn','Octic Capital Department of Veterans Affairs','New Mexico State University','USAA','Accenture','WellCare','Banner Health American Axle & Manufacturing, Inc.','Cyient','Swagelok','MEI Technologies','XPO Logistics, Inc.','Citi Universities Space Research Association','Lubrizol','eBay Inc.','KPMG LLP','Childrens Medical Center'\n",
    "                       ,'AvalonBay Communities Cummins Inc.','Cummins Power Systems, LLC.','JB HUNT','Ford Motor Company','Anne Arundel Medical Center','Comrise','Highmark Health Central California Alliance for Health','Booz Allen Hamilton','Lockheed Martin Corporation','Cognizant','Jobspring Partners VincentBenjamin','Travelers','HX5','TFS','CarMax','Talent Plus','Bertelsmann','Forcepoint','Diverse Lynx','RubrYc Therapeutics L3 Technologies','Methodist Le Bonheur Healthcare','Arcadis','Smiths Detection','Orbital Insight','GE Careers The Aerospace Corporation','Odyssey Systems Consulting Group','Simons Foundation','Harvard University','First Horizon Stratacache, A Family of Companies','Axius Technologies','SigOpt','Kaleido Biosciences','Chenega Corporation','Foreground Security Electronic Arts','Miami HEAT','Garmin','Cisco Systems','Day Zero Diagnostics','GM Financial','Nike','EagleView Technologies University of Massachusetts Medical School','Standard Insurance Company','The Hanover Insurance Group Hewlett Packard Enterprise','Prime Solutions Group (PSG)','Weatherford','Next Rev Technologies LLC','Triquetro','ClimaCell','Sprint Synchronoss Technologies, Inc.','Synchronoss','TVG Network Betfair US','Northrop Grumman','Domino's','Cook Medical','Simple CrossFit, Inc.','Comcast','Zurich North America','Gayathri's Sandbox','Pros.','Rifiniti','Arable Labs, Inc.','Zumper','ISE Data Systems Grid Dynamics','Freds','Zillow Group','Nordstrom','HNI Allsteel','Lexmark International, Inc.','Florida Blue','Equifax','Apeel Sciences RELX Group','Andersen Corporation','WestRock','ShipBob Inc','Nielsen','Bosch Group','Xylem','Crossover','NT Concepts','Goodyear Lake Trust Credit Union','Ecolab','Spreetail','TracFone Wireless','eQHealth Solutions','HOMER','Shell','Barri Financial Group','Plaid Vantiv','Trinity Health','AnswerRocket','Northwell Health','Novartis','WeddingWire','US Pharmacopeia','Corning','CGG','Nexidia','Netflix HNI Corporation','Wayfair','PPL Corporation','Seagate Technology','Preferred Resources Inc.','Tek Experts','TriHealth Kaiser Permanente','EMD','P3 North America','Colgate-Palmolive','Staples','The Home Depot','Kantar Careers','Genmab','Walmart eCommerce Formation','Aetna','Aptiv','Schneider National','Press Ganey Associates Inc.','Novetta','Capgemini','HotelTonight','Capax Global LLC', 'AmTrust Financial Services','LendingTree','Ulta Beauty','W.R. Berkley','FinLocker Pearson','Zimmerman Advertising','Leidos','PACCAR','SYSCO','McKinsey & Company','Zachary Piper Solutions','Novelis','devwrx','FleetPride JPMorgan Chase','Klaviyo','Memorial Health System','Crossover Health','Feedzai','Virginia Tech Applied Research Corporation Matrix Medical Network','Niantic, Inc.','Niantic Labs','CenturyLink','Optoro','Bold','Quadrint, Inc.','ActiveCampaign Alaka`ina Foundation Family of Companies','Motorola Solutions','Yamaha','Modern Meadow','Qikspace','CACI','Snap Inc. Knowledge Facilitation Group','Toptal','Subaru of America','Wiley','DTCC','SAP','Verizon','Pluralsight','HCSC Pacific Northwest National Laboratory','IEEE GlobalSpec','AF Group','Accident Fund Holdings, Inc.','Ericsson','Radiant Solutions Micron','Viral Launch, Inc.','Fred Hutchinson Cancer Research Center',\n",
    "                       \n",
    "                       \n",
    "                       'Martins Point Health Care','Carlisle & Company','Qwinix Amne','Colony Brands, Inc.','BAE Systems','Paypal','Carolinas HealthCare System','UPS','Ascena Retail Group, Inc.','Verra Mobility Illumination Works','C.H. Robinson Worldwide, Inc.','MEDSTAR HEALTH RESEARCH INSTITUTE (MHRI)','Albemarle Corporation Lincoln Financial Group','U.S. Venture, Inc.','WWE','Brillio','Karsun Solutions, LLC','Milliman','SanofiUS','Sovrn Holdings','UL LLC Applied Systems Inc.','Delaware North','Lovepop','Trend Micro','Harbor Wholesale Foods','Cardinal Solutions Group Ascensia Diabetes Care','Smartly','MarketDial','Mid-Atlantic Permanente Medical Group','Cardinal Health','Paychex Inc.','Cerebri AI Oath Inc','Numerator','Entergy Corporation','StubHub','Quicken Loans','Centene','Underwriters Laboratories','Prokarma Inc. Tractor Supply Company','Marsh & McLennan Companies','Radian Group Inc.','SumTotal Systems','Facebook','Ultimate Software Ideal Concepts, Inc.','World Fuel','Selective Insurance Group','Monsanto','Vettery','Ascension Healthcare','Dun & Bradstreet The J. M. Smucker Company','Procter & Gamble','City of Seattle','Two Sigma Investments, LLC.','Exact Sciences Corporation Driven Brands','Falls Lake Insurance Companies','Eli Lilly','Pop Healthcare LLC','Skillsoft','Tesla','iHeartMedia, Inc.','3Q Digital Ipsos North America','Exact Sciences','Vanda Pharmaceuticals Inc.','American Chemical Society','SHI International Corp. Medtronic','Precima','UTC','University of Maryland Medical System','DEG','Groupon','elicit','Conagra Brands','Progressive Leasing Thermo Fisher Scientific','Kaplan Test Prep','Kaleidoscope','Tilt Lending','Humana','Hawaiian Airlines','IT Concepts Inc. BAIN & COMPANY','BRS','LogMeIn','Integral Consulting Services, Inc.','DoubleDown Interactive LLC','Essence','SpartanNash First National Bank of Omaha','Visa','ZestFinance','Centura Health','Red Ventures','Barings','Kaplan','Cigna','PRA Health Sciences','ABSc HP','Huawei','BLUEHAWK, LLC','University of Utah','E*TRADE FINANCIAL','Ally Financial','Advantage SCI','Civis Analytics','Maana Equityzen','The Cadmus Group, Inc.','Society for Human Resource Management','Annalect','Northern Trust Corp.','Hitachi Vantara','EXL American Family Insurance','Huntington Bank','Cambia Health','Alion Science and Technology','NORC at the University of Chicago Morning Consult','First National of Nebraska, Inc.','Boll & Branch','Slack','Auto-Owners Insurance','SpaceCurve','Hertz','Welltower TripleLift','Alliant Credit Union','ServiceMaster','PwC','Guidehouse','Visionist, Inc.','Cormac Corporation','SAS Institute','Dexcom Sabre','TopSchoolJobs.org','Oracle','Ingersoll Rand','Axiologic Solutions','Celgene','Tsource','DataLab USA','Drybar','Philips Houston Methodist','Regions Bank','Bristol-Myers Squibb','Mars','BlueLabs Analytics','ConAgra Foods ManTech International Corporation','Engility','Analysis Group','RBC','Medical Science & Computing, Inc. Medical Science & Computing','KAR Auction Services, Inc.','UBS','Fidelity Investments','Agilent','Precocity','MetroHealth RetailMeNot, Inc.','Vivid Seats','Pfizer Inc.','CALNET INC.','Bio-Rad','Northwestern Mutual','Dotdash','Formativ Health','Pfizer Nabler Web Solutions','Varian Medical Systems','Blue Cross Blue Shield of Michigan','KeyBank','Assured Consulting Solutions H2M Group','Kemper Corporation','Enable Midstream','MedStar Health','Experian','Grant Thornton','Experis','Arrayo Brighthouse Financial','AncestryDNA','National Fish Wildlife Foundation','Molekule','Cubic Corporation MedStar National Rehabilitation Network','Tranzact','Aret√© Associates','MasterCard','Harnham','ASET Partners Camp4 Therapeutics Corporation','Lenovo','Jacobs','Redfin','Claritas','KEYW Corporation','Inabia Solutions and Consulting Wells Fargo','Lorven Technologies','OGSystems','Workbridge Associates','Altamira Technologies Corporation','Digital Promise','Bixal Flagship Pioneering','California State University','Intelligent Automation','Solidus Technical Solutions','DNAnexus','JD.com Obsidian Solutions Group','Butterfly Network','Mosaic North America','Early Warning Services','Panasonic','American Express Navstar, Inc.','Lightmatter','Wolters Kluwer','Open Systems Technologies, Inc.','Fifth Third Bank','Rockwell Collins System1 Biosciences','Battelle','eHire, LLC','1st Solution USA','Endurance International Group','Spotify','ViaSat','Foot Locker Ace Technologies','Salesforce','Merck','Norfolk Southern Corp','Eventbrite','Beyondsoft Consulting','Applause','Arthur Lawrence','Square Trimble Inc.','Genedata','Directly','Tradesy','InVision Studio','Time Warner','Siemens','HealthGrades','Edison Energy','Recorded Future SpotX','KBRWyle','KMM Technologies','Transamerica','Snowflake Computing','TripAdvisor','Pitney Bowes','HumanTouch, LLC','Vevo','b.well Legends','MachineZone','Numerdox','citius tech','HyperspaceVentures','Creative Alignments','Williams-Sonoma, Inc.','NetMotion Software Sartorius Corporation','NewYork-Presbyterian Hospital','Trimble','Fora Financial LLC','GlaxoSmithKline','ConnectYourCare Clarivate Analytics','Q2ebanking','Bigfoot Biomedical','State Farm','Brightidea','Catasys','Verb Surgical','MapR','Tessella','Uber PARC, a Xerox company','Wolverine Trading','Dana-Farber Cancer Institute','myCOI','XL Catlin','Country Financial','Centro Impetus Technologies','HouseCall Pro','Huobi','QxBranch','GlassDoor','BMW North America','NBA Properties','Parkview Health','Bose Taboola','Edelman','Watts Water Technologies','ThinkIQ','Upstart','Conversant Media','Calico','CIITS','Nokia','MacAulay-Brown, Inc. (MacB) Ticketmaster','Dropbox','PepsiCo','Mitchell International, Inc.','Etsy','Gartner, Inc.','Pray','Weber Shandwick','Disney','Phreesia Integral Ad Science','Veritone','Opendoor','Aera Technology','Owens Corning','Protective Life Corporation','Arconic','GoDaddy Coupa Software','FedEx','Bind Benefits','Voya Financial','Alere','Xandr','DigitasLBi','Stanley Black & Decker','Lab126','Fair','Houzz Asurion','ACI Worldwide','Predictive Science','NEURA','Unisys','Kogentix','MOBE, LLC','AllianceData','Epsilon','TrueCar, Inc. The TJX Companies, Inc.','Maxim Integrated','SoFi','Church Pension Group','Jewelers Mutual Insurance Company','Esurance Harley-Davidson','BlackLine','Slalom Consulting','Chatmeter','Roche','Wish','Par Government Systems Corporation','OpenTable','Honeywell Atos','Precision Health AI','Domo, Inc.','Coso IT','RS Energy Group','ZF','Realogy','3M','St. Jude Children's Research Hospital EPAM Systems','S&P Global','Rover','Jet.com','Syntelli Solutions, Inc','Improbable','Clarabridge','Honda Research Institute USA Applied Materials Inc.','Manulife','Public Company Accounting Oversight Board','McGraw Hill Financial','NetApp','Mitre Corporation Sage Intacct','Cyberspace Solutions','Blue Nile','Aspen Technology','Amches, Inc.','BoxyCharm','Lowe's','DuPont','Invisibly The Climate Corporation','Upwork','Hackensack Meridian Health','United States Steel','Onyx Government Services, LLC Change Healthcare','Pivotal Commware','CallMiner, Inc','MSA Safety','Proofpoint','OneKreate','Vituity','Hilton','Convey Marketers on Demand Inc.','Akili Interactive','L&T Technology Services Ltd.','Satsyil Corporation','Convey, Inc. HERE Technologies','Signifyd','Esri','Sabio Mobile','Candid Co.','First Tech Federal Credit Union','Faire','Sentieo Planned Systems International','Remedy BPCI Partners, LLC.','Hagerty','Convoy','Strava','Remedy Partners','Vertex Vertex Pharmaceuticals','Engie','Thrive Market','Morgan Stanley','Plymouth Rock Assurance Corporation','IQVIA','Eagle Ray Inc Volanno','Kinetica DB','Prudential','First American Corporation','Picarro','Immuta','Liberty Mutual','Qualtrics','Illumina BMO Financial Group','Kinsa Inc.','Sartorius North America','Intuit','ExtraHop Networks, Inc.','Cityblock Health HR, Legal, & Administration','Ellie Mae','WellSky','Johnson & Johnson Family of Companies','Quartet','Abiomed','Affirm','Alqimi Twentieth Century Fox','Maven Wave Partners','Conduent','Cognitive Scale','SHINE Systems & Technologies','Crowe','AXIS Insurance Criteo','Big Fish Games','Genentech','MSA Safety Inc.','Xactly Corporation','Coherent, Inc.','bluebird bio','FabFitFun Varen Technologies','Coherent Germany','FM Global','All-In Analytics','HHB Systems','BCG Digital Ventures Benson Hill Biosystems, Inc','MultiScale','zulily','High Alpha','Quora','ICR','Blackbaud','Castlight Health','KAYAK Bank of America Merchant Services','Elite SEM','EY','Heartland Dental, LLC','Verisk Analytics','Pragmatics','Vanguard','Bartech Group Berico Technologies','Peraton','Clara','Invesco','Zscaler','American Institutes for Research','Funding Circle US','First Orion Social Solutions','Apogee Integration, LLC','Productive Data Solutions, Inc.','Everlane','Regis Corporation','PetSmart Service Management Group, Inc.','General Dynamics Mission Systems','Clockwork Solutions','Dynetics','Amplitude New York Life Insurance Company','Altair Engineering','Ross-Carlisle Group','Eaton Vance','NVIDIA','Technology Partners BNP Paribas','FICO','Toyota Research Institute','Scaleapi','Liquidnet','2K Games','Ginger.io','Zynga','Symantec','Yelp','Globant Rockstar New York','Restoration Media','Bluecore Inc.','Nutanix','Kelvin','iHerb','Prospect 33','Spokeo','Academia.edu','John Deere Daugherty Business Solutions','YourMechanic','First Republic Bank','AppZen','Ubisoft','Optimizely','LeapYear','Reorg Research Altice USA','Autodesk','LimeBike','Quantcast','DeepCurrent Technologies, Inc.','C3','Neuberger Berman','Liberty Lending','Crowdstrike ServiceTitan','Porsche','VROOM','Sealed Air','Edison Software, Inc.','Rockstar San Diego','Nauto','Gap Inc.','Applied Memetics LLC Lark Health','Blue Owl','Ryder','Quantiply Corporation','Internet Brands','Mist Systems','Helpshift','Viome','ThirdLove','Crystal Dynamics Peak6','Grand Rounds','Yapstone','Aruba Networks','Credit Sesame','Valassis Digital','Uhana, Inc.','EMIDS','Xilinx','Veeva The Carian Group','AIG','Barrick Gold Corporation','Photon','Sony Interactive Entertainment PlayStation','Omnicell','Waymo','Coursera Scalable Digital','Suplari','Tonal','Pocket Gems','Coinbase','Emailage','Zazzle','Otsuka','PG&E','Thunder Token','Scoot Networks','PlaceIQ Franklin Templeton Investments','WW International (formerly Weight Watchers)','Porch','Lumos Labs, Inc.','Polis, Inc. MetroPlus Health Plan','Lieberman Research Worldwide','Safeway Corp.','Lyric','Wealthfront','Dollar Shave Club','Farfetch','Qualys Sirius XM Radio','Perficient','Acuity, Inc.','Atlassian','Infoblox','Research Innovations Inc','General Mills','Lattice Engines Nift Networks','Nerdwallet','Peloton','Goldman Sachs','Tesorio','JUUL Labs','Zot Inc.','BlackRock','Proteus Digital Health','Payette Group Guidewire Software, Inc.','Betterment LLC','GroupM','Maxus','Western Digital','Nanigans','Covance','OneGlobe','Galvanize','Coverent University of California San Francisco Medical Center','JM GROUP','Boeing','The Boston Consulting Group','Sitecore Fluid Intelligence','LabCorp','VMware','Capital Group Companies','Visual Awareness Technologies and Consulting, Inc. Powertek Corporation','Cell Signaling Technology, Inc','Ascent Services Group Redfish Technology - High Tech Executive Recruiters','Turnitin, LLC','Darwin Recruitment','Kaizen','Axelon Services Corporation Chime','Clarity Insights','IQ Workforce','BAE Systems Applied Intelligence','Solving It','stanleyreid','Quest Diagnostics Stride Search','CRGT Inc.','Avanade','NBCUniversal','Dice','3coast','Lionbridge Technologies','Signify','Blue Origin','Medallia, Inc. Stella.ai','TIBCO Software','Discovery Communications, LLC','7Park Data','Narvar','Keep Truckin','David Weekley Homes Moody's Corporation','Linc Global, Inc.','Figure','Alibaba','FoxNext Games','DRW Trading Group','DRW','ServiceNow','Motif Investing CircleUp','Samsung Semiconductor, Inc.','Zingbox','Workday','Synechron','Taino Consulting Group','Parallel HR','Intelligent Waves Llc HeartFlow','HD Vest','JLL','NetBrain Technologies, Inc.','Publicis Spine','Gradient.io','aThingz','ShareThis, Inc','Roku','Datadog DataRobot','Octane Lending','PTP','Juvo','Blume Global','securonix','FireEye','Plume','Cogitativo','QuantumBlack','Unity Technologies','ACS Socure','Averity','TWINN INTELLIGENCE GROUP','Prognos','The Hagan-Ricci Group, Inc.','Trace3','Daley and Associates','Health Catalyst AltaSource Group','CRB Workforce LLC','Invictus International Consulting, LLC','Integrated Management Resources, LLC','Pilot AI Analytic Recruiting','Advanced Micro Devices, Inc.','Great Bay Staffing Group','Lyft','Optimove','Commonwealth of Massachusetts UC DAVIS HEALTH SYSTEM','Columbia University','Bryant & Stratton College','Bloomberg','Servient Inc','HopJump Colliers International','Freedom Forever','Shoes For Crews, Inc.','AVID CENTER STAFF','Tampa Family Health Centers','FIS Wellmore, Inc.','Arkansas Blue Cross and Blue Shield','Youth Policy Institute','McGraw-Hill Education','XLA Lubbock Heart & Surgical Hospital','ZEISS Group','Zeiss','Lockton, Inc.','Boyd Caton Group (bcg)','GOCOOL BHP Engineering & Construction','Levy','New Visions Central Office','City of Minneapolis','Blade','Avkare Inc','The Carle Foundation Arkatechture','Raymond James','BBYO -','Stanford University','Cota','New Visions for Public Schools','Canton-Potsdam Hospital JetBlue Airways Corporation','NYSTEC','National Grid','Resolvit, LLC','Goodwill Industries International, Inc. (GII) Glassview Media','STOBER Drives, Inc.','General Dynamics Information Technology','Advance Auto Parts','23andMe','Healthtronics','DHL Progrexion Holdings Inc','Lytx','Southern California Edison','Fortive','doTERRA International','Abilene Christian University London Stock Exchange Group','Goby','Georgia Military College','CDW','Rational Consulting','Boss Fight Entertainment Butterball, LLC','Clarity USA','Mixbook','Memorial Sloan Kettering','King County Housing Authority','ZIN TECHNOLOGIES INC.','Masco The Wonderful Company LLC','eSpark','Health One Alliance, LLC','Teacher Retirement System of Texas','Emory University Major League Soccer','Brown & Brown Insurance','Fidelity National Financial','City of Tucson','SCAN Health Plan Alegeus Technologies','Ciox Health','CMI Media and Compas, Inc.','Graphic Products','Cresco Labs','AltaMed','Regional One Health Alltran','Logic Rule','Lutron Electronics','jump ramp','First National Bank of America','Outreach Process Partners','ECS Federal LLC Sentry Insurance','WebMD','Johns Hopkins University','AECOM','Office of the Nassau County Comptroller','IPRO','Zeta Global The Dow Chemical Company','GeoDigital','Sigma Space','Keck Medical Center of USC','Fruition Partners','IXIS Alliance Health Professionals','Resource Systems Group, Inc.','CompuCom','Moda Health','Germania Insurance','stearns bank Technicolor','Spy Pond Partners','Pinkerton','Ukpeagvik I√±upiat Corporation/Bowhead Family of Companies','NextGen Healthcare UNITED NEGRO COLLEGE FUND','Fitch Group','Patagonia, Inc','USfalcon','Texas Health and Human Services Commission','The Motley Fool Federal Management Systems, Inc.','Care New England Health System','U.S. Anesthesia Partners','Progressive Alameda Health Consortium/Community Health Center Network','Courtney Raymond Consultants','Facing History and Ourselves, Inc thrivecausemetics.com','BI Worldwide','Advanced ICU Care','AnaVation, LLC','Ingram Content Group','Twitch','Renown Health','DXC Central Health','Western National Insurance Group','AmeriCorps','Gaylord Specialty Healthcare','Housing Works Comprehensive Healthcare','Stormont-Vail Healthcare','Bassett Healthcare','Fiserv','Holleran Consulting','Nestle USA','Payfone University of Pennsylvania','Concerted Care Group','KingsIsle Entertainment','Community Reach Center','The Boston Globe Volvo Group','UNITE HERE HEALTH','2DA Analytics','ForeFlight','Care.org','Tory Burch','GEHA','Buxton','Hylink Group','alliantgroup Culinary Health Center','The Vancouver Clinic','University of Virginia Health System','Cancer Treatment Centers of America Inframark','Jamul Casino','ipsy','Medifast, Inc','American Merchandising Specialists','Success Academy Charter Schools Compass Group USA','Webster Bank','John Clements','ANB Bank','L'OREAL USA','Association of Universities for Research in Astronomy Sullivan, Cotter and Associates, Inc.','Primus Builders Inc.','Medical Transportation Management (MTM) National Financial Partners','Fragomen','Fresenius Medical Care','Evolent Health','Renewable Energy Systems Ltd. Hawaii Medical Service Association','Child Care Resource Center ‚Äì Chatsworth, CA','Aultman Health Foundation D&K Engineering','Axos Bank','Churchill Mortgage Corp','Dexperts','NSD','Primerica','EmblemHealth Health Care District of Palm Beach County','Baystate Health','AccessCNY, INC','Emerson Hospital The International Fund for Animal Welfare','Acquisition Life Cycle Management','Aultman Hospital','AUTHENTIX INC Flair IT Solutions','Boston Children's Hospital','Wood','Targetbase','Edward-Elmhurst Health','Allegheny Health Network','EMA, Inc. MJHS','Aclara','Boyne Resorts','US Software & Consulting','Encompass Community Services','Everything But The House (EBTH) Arc Aspicio','Alnylam','Team Red Dog','Orange County Transportation Authority','Rauxa','Direct Resources Group','Johnson Matthey Vivo','Healdsburg District Hospital','Dime Community Bank','CIBC','Dassault Falcon Jet','Emmis Communications','Logic20/20 CORKCICLE.','Virginia Jobs','Logitech','BBYO','Healthline Media','CSRA','University of Texas at Arlington','Crestron Electronics Crestron','University of Colorado','C5T Corporation','TISTA Science and Technology Corporation','Clearwater Paper','Option Care University of Texas at San Antonio','Knorr-Bremse North America','Bird Rides Inc.','Maryville University','Listrak State of New Mexico','Management Science Associates Inc.','Managed Care Advisors','Flight Centre','RWJBarnabas Health Beaumont Health','Envisagegroup','Ensign Services','Sweetser','The Parking Spot','Zodiac Aerospace','AIDS Foundation of Chicago Baptist Health South Florida','Fabick Cat','Community Behavioral Health','Academy for Urban School Leadership Arrowpoint Corporation','Chicago Public Schools','AUSL Chicago','Gila River Health Care','SECU','Charles Schwab','MultiPlan Inc. Chapman Cubine Adams & Hussey','Management Concepts','NaviHealth','thoughtmatrix','ClassLink Inc','AHMC Healthcare Inc','RE/MAX, LLC Capital Impact Partners','Clayton Homes','United Fire Group','MIT Lincoln Laboratory','BookBub','AssuredPartners','PowerSchool The Situs Companies','Mary Washington Healthcare','Brightree','ITAGroup','Virginia Mason Medical Center Appalachian Regional Healthcare','MaineHealth','Horizon Health Services','Nationwide Children's Hospital','Hitech Assets, LLC. NetVision Resources (NVR)','Kroger','Penobscot Community Health Care','Unilever','NRG Energy','State of Arizona Laureate International Universities','QuEST Global Engineering','ITT Corporation','Citizens Energy Group LiniumTalentAcquistion','Nolij Consulting','ACN','Blue Cross Blue Shield of Arizona Advantage','Wildlife Conservation Society Carter Bank and Trust','Astor Services For Children & Families','2U','Systems Staffing Group','Zumba Fitness, LLC','BOK Financial CHEP','Harvard Pilgrim Health Care','Credit Acceptance','Sun Life Financial','8-Koi','The New School','Curriculum Associates','Dyson Commonwealth Of Virginia','Universal Health Services','Premera Blue Cross','Baltimore Medical System, Inc. University of California Berkeley','Fossil Group','Fund for Public Health in New York City','Indiana University','Siena College Precision Value & Health','Piedmont Healthcare','Children's Hospital & Research Center Oakland','GrayMatter','Parametric Gray Matter Systems','Partners HealthCare','Anchorage Consultants LLC','Advantage Solutions','Cydecor, Inc. Toole Design Group LLC','FARO Technologies','Blue Shield of California','Kongregate','TracyLocke','Florida Hospital Adventist Health System','Geotab','Shutterfly','Rosecrance Health Network','Morneau Shepell','Farm Bureau Insurance of Michigan Pace University','Einstein Healthcare Network','SUBWAY','EnerNOC','Cricut','The Money Source','Santander Consumer USA Nordic Naturals, Inc.','ProMedica','Akima, LLC','Freddie Mac','Northeastern University','Beaver Dam Community Hospitals, Inc. Discover Financial Services','Cloudburst Consulting Group Inc','Crozer Keystone Health System','Capgemini Government Solutions CompuGain','Envision Healthcare','Molina Healthcare','Epic Care','Calero Software','CCC Information Services Inc.','CBRE Freedom Financial Network','Self Regional Healthcare','BlueLinx Corporation','KGPCo','LTD Commodities UT Southwestern Medical Center','Frogdata','The Logistics Company','Imerys','T. Parker Host','Gallagher','maconit','VCU Health System Mount Sinai Health System','Benchmark Education Company','Oxford Global Resources','Astronics','Accountants One, Inc','Ameritas Multnomah County, OR','Mercy Health','Nextiva','Parker Hannifin Corporation','Northwest Permanente, P.C. Matheny School and Hospital','Na Ali'i LLC','The National Association of Manufacturers','Vista Technology Services Liberty University','Anheuser-Busch','AbleVets LLC','Swiss Re','Cymer','Boston Medical Center','Baylor Scott & White Health','Bitcoin Under Armour','Creative Arts Agency (CAA)','Voloridge Investment Management','Dot818','Quinstreet','Cisco Meraki Guardian Industries','Inland Empire Health Plan','Plastiq','Cricket Health','InnovaSystems International','OneAmerica','Techshed Core10','Leadsmarket.com LLC','Fiat Chrysler Automobiles','Aramark','Cognosante, LLC','OppLOans','Fidelis Care','Fullscreen Media Pond5','Ring Inc.','Columbia Sportswear','Manage','Santa Clara Family Health Plan','LawTrades','New York Blood Center','Lucky Day Buchanan & Edwards','Vox Financial Partners','Doximity','Candid Partners','Dentsu Aegis Networks','MKTG','ZeniMax Media Inc. University of Washington','Fullscreen','Polaris Industries','Cogo Labs','The New York Times','RiskSpan','Poll Everywhere NCI Information Systems, Inc.','FPM Technologies','enVista','Cable & Wireless Communications Inc','Dewpoint Northwest Farm Credit Services','IMTAS','Textio','Apptentive','Ascend Performance Materials','Apkudo Prospect Medical Holdings, Inc.','Prospect Medical Systems','Greater Delaware Valley','Silicon Valley Bank','IDT Corporation Celmatix','University of Michigan','FourKites','CONTINUUM','Hilcorp Energy Company','Innove LLC','ResMed','Ellis Medicine Relevant Healthcare Technologies','Hasbro Inc.','UCLA Health','Corcentric','Mentor Graphics','Ingram Micro','Curve IT Consulting GCC Technologies, LLC','AppFolio','Langan Engineering and Environmental Services, Inc.','Legg Mason','Sentara Healthcare Reputation.com','Institute for Health Metrics and Evaluation - Faculty','CliniWorks','Great Wolf Lodge','Stream','IDEO iSpot.tv, Inc.','CHOC Children's Hospital','SocialWithin','Community Medical Centers Inc','Harry's','Verscend Technologies Zelis Healthcare','LevelUp','Delta Dental of Minnesota','Community Medical Centers','Kohler Co.','Galaxy Systems','Asembia LLC Common Securitization Solutions','Tate & Lyle','Ascensus','Getty Images','ddms','Emory Healthcare','Louis Dreyfus Central Maine Medical Center','InfoArmor Inc','Prime Healthcare','Castleton Commodities International University of California UCOP','Collective Health','Fanatics Inc.','T1D Exchange','sweetgreen','Brooks Sports, Inc','Virtru','JFrog Bank of the West','Hiscox Ltd','State Street','Meijer','Kabam','Superior Vision','Archer Daniels Midland Company South Dakota State University Foundation','Starbucks','Arthrex','Spireon','PitchBook Data, Inc.','Commonwealth Care Alliance Donnelley Financial Solutions','CORTEK','VSCO','William E. Wecker Associates, Inc.','Rent-A-Center','New York University Russian School of Mathematics','Din√© Development Corporation','A. H. Belo Corporation','Vera Whole Health','Assurant Strategic Resources, Inc.','Beachbody','Clarkston Consulting','Riot Games','College Raptor','REI','Boxy Charm','Acumen Solutions Pinnacle Engines, Inc.','Glu Mobile','CenCal Health','Ely-Bloomenson Community Hospital','National Instruments','BorderX Lab Inc Central Texas Food Bank','MileOne Automotive','Clemson University','GenapSys, Inc.','Paradyme Management','Coffee & Bagel Brands Aledade, Inc.','Blue Chip Talent','Blue Apron','HelloWorld','Straumann','Libra Services','TSheets','LUXOTTICA','Mindshare','GoodRx','JT4 Berkadia Commercial Mortgage','IHS','IHS Markit','State of Washington','Cambria','Level Ex, Inc.','MUFG','Fremont Bank DSD Partners Inc','Genworth','C&A Industries, Inc','Crown Castle','Union Bank & Trust','CSSI, Inc.','RK','Advance Financial Halfaker and Associates','EBSCO Industries Inc','Arbella Insurance Group','Catholic Health Initiatives','ASML','T. Rowe Price','SAIC Washington State Hospital Association (WSHA)','Vertical Careers, Inc.','L.A. Care Health Plan','George Mason University Willis Towers Watson','Providence Health & Services','AmeriHealth Caritas','New York State Office of the Attorney General RentPath, LLC','Los Alamos Technical Associates','PANGEATWO','Seasoned','Christiana Care Health Systems','Niagara Bottling Allegro MicroSystems, LLC','Virtus Partners','Wargaming.net','Johns Manville','Life Chiropractic College West Federal Reserve Bank of New York','Meridian Health Plan','DCS Corp','Digital Management, LLC','OneSource Virtual Genuine Parts Company','Wyndham Hotels & Resorts','Vitals','Green Dot Corporation','UJA Federation of New York','Inovalon Alliance Data - Retail','FirstCare Health Plans','SunPower Corporation','Solomon Associates','ANTHEM MARKETING Children's Hospital of Wisconsin','Capital One','Mountain America Credit Union','DJO','Radiance Technologies Inc.','HBM Holdings Smith & Nephew','VirtueGroup','The American College of Radiology','Purple Communications, Inc.','CapTech Consulting','SRC, Inc. First San Francisco Partners','AnalogFolk','NinthDecimal','KeepSafe','Periscope technologies inc','Health Team Advantage Bowery Farming','Alteryx, Inc.','Hudson's Bay','Traxion Group, Inc','Foundation Medicine, Inc.','Coty Inc.','QIC Limited Nextphase Systems','Hearsay Social','EPMA','Certara','Women's World Banking','Microfinance Gateway','Impact Makers, Inc.','Balyasny TACG, LLC','AppNexus','Health Dialog','Burlington Stores','ARC Solutions USA','LeafLink','Productive Edge','Credit Suisse General Dentistry 4 Kids','Nuvve','Harvard Business Publishing','Grail Insights','Heartland Business Systems','RocksBox Crohn's & Colitis Foundation of America','goPuff','Layer3 TV','Real Capital Analytics (RCA)','Scholastic','IntroPro','MWW Group ExcelaCom','One Call','Seattle Children‚Äôs','Estee Lauder','[24]7','PeerStreet','WeWork','Virbac Animal Health Mississippi Lime Company','County of San Mateo','Softrams','BLUECUBE Information Technology','CooperVision','IPG Mediabrands','ALC Accolite Software India','Accolite, Inc.','General Motors','BNY Mellon','PJM Interconnection, LLC','WP Engine','Priceline.com Oklahoma Cancer Specialists and Research Institute','Blytheco, LLC','Johns Hopkins Health System','momofuku','RB','Alarm.com ServiceLink','Becton Dickinson','Abacus Data Systems','City National Bank','LendingClub','MGAC','Kennametal','Allergan','MVM','Magento Mission Staffing','HelloFresh','CTG','Health First','MM.Lafleur','Chicago Trading Company (CTC)','National Funding','Looker','Clearpoint uJoynus','CAPCO','Fender','ClearView Healthcare Partners','SWIFT','Bill.com','Motion Recruitment Partners','Publicis.Sapient','PureCars Arch Capital Group Ltd.','Engage Partners','Western Union','Community Health Network','Broadridge','Robert Walters','Merkle Inc. L Brands','Sephora','King.com','HAVI Logistics','Globoforce Limited','Wycliffe Bible Translators','Vistage Worldwide','Wipro LTD Franciscan Health','Coffee Meets Bagel','Zenith','Finra','Ramsey Solutions','Medidata Solutions','J.D. Power','JustAnswer','Carbon Black Performics','JBCconnect','Goodwin Recruiting','DoorDash','MSCI Inc.','Jetblack','EyeView','New York Yankees','EducationDynamics Boston Bruins','State of North Carolina','The University of Kansas Health System','American Specialty Health','Hydromax USA Hill-Rom','Solomon Page','cableyou','Hy-Vee, Inc.','ATN International','Measured Progress, Inc.','Availity, LLC. Arrow Electronics, Inc.','Colorado Community Managed Care Network','Koddi','ELLKAY LLC','A Could Guru','Janus Research Group Quest Analytics','Bealls Inc','Technamo LLC','Eastman Chemical Company','Evonik','Virginia Tech','Renew Financial','Aroghia Group PRA Group','Advanced Technology Group Inc','UpClear','Acustream','Beacon Health System','Grundfos','Grundfos Pumps Corporation','Snag WEX Inc.','East Daley Capital Advisors','Denodo Technologies','AXA General Insurance','Bangor Savings Bank','AQR','AXA','Sierra Lobo Housing Authority','Munich Re','Las Vegas Sands Corp.','BGC Partners','Denodo','Jackson Dawson','Henry Schein','ECRI Institute American Modern Insurance Group, Inc.','Octo Consulting Group','Serco , Inc.','ACT, Inc.','TeleTracking Technologies Farmers Insurance Group','Auth0','Liv Communities','Blue Cross Blue Shield of Arizona','Prosearch Strategies Casey's General Stores','Prodege, LLC','Hook & Loop Creative','ktMINE','Audley Travel','AKRAYA INC.','Viant','SharpSpring','ACCION Pairwise','Accion in Arizona, Colorado, Nevada, New Mexico and Texas','Clear Capital','Catalyst Repository Systems Billings Clinic','Doosan Bobcat','Intrexon Corporation.','Tredence','GlobalLogic, Inc.','Intalere Inc','Rackspace','Nevro Corporation Tompkins International','Asics Digital','The Walsh Group','Object Computing Inc.','Lirio','Paycom','Atlantic Health System VVC Holding Corp','Curbside','Susquehanna International Group','Plante & Moran','State Auto Insurance Companies','Overstock.com Farmers Fridge','Southern Poverty Law Center','Privia Health','Pizza Hut','United States Associati','InsideSales.com, Inc. REsurety','Jebbit','Civitas Learning','Auto Club Group','Hamilton Lane','Navigator Management Partners','Choice Hotels','SailPoint AmeriSourceBergen','Theoris Services','Carbonite','Jellyfish UK','Jellyfish','Tabula Rasa Healthcare, Inc','Morningstar','Armor WebbMason Analytics','BCD Travel','Zilker Partners','Simon-Kucher & Partners','Syngenta','Aegon','Cross River Bank Dev Technology Group, Inc.','W.W. Grainger','Calix','Healthfirst','Mondelƒìz International','Vivint Smart Home','IDEXX','New Knowledge Location3','Windstream Communications','Windstream','Trident Technologies LLC','United Network for Organ Sharing','Penske Macquarie Group Limited','Idexx Laboratories','Schoolzilla','CoreCompete','Netsmart Technologies','Rally Health','Lifetouch Hospital for Special Surgery','TMP Worldwide','The Denzel Group','MicroStrategy','Vets First Choice','PATHORAS CORPORATION','Nice Sumeru Solutions','Cimpress','Brivo Systems','Caesars Entertainment','IMO - Intelligent Medical Objects, Inc. LifeWatch Services, Inc.','BioTelemetry, Inc.','Fannie Mae','The Standard','RhythmOne','Whole Foods Market','Kraken Cleveland Cavaliers','Zeus','LeanTaas','Hulu','BitTorrent Inc.','7-Eleven','Tavant Technologies','Orzota','Reflektive Anadarko Petroleum Corporation','Zeus Living','Blizzard Entertainment','HelloSign','Pandora Media, Inc.','The Black Tux','8X8 INC. Exabeam','N3TWORK','VividCortex','Samsung','US Information Technologies','Gallup','Linden Lab','Brad's Deals Perfect World Entertainment','AirPR','GoodData Corporation','UiPath','Castle Global','Duke Energy','Principal Financial Group','Trianz Warby Parker','Syneos Health Commercial Solutions','Evaya Data Systems','Sun Basket','Drillinginfo','TGS Management Company','Novus Caserta','hiretual.com','ChowNow','Thales','Peloton Technology','St. Joseph Health','SoftVision - North America & UK Keysight Technologies','Mazda North American Operations','Infront Sports & Media Group','Amdocs','14 West Amplify Education, Inc.','Animoto','Change.org','Agent IQ','Zipcar','Citadel Securities','PlacePass','J. Crew Group, Inc. Augmedix Inc.','Myers Media Group, LLC.','SmartThings','Object Partners','Aaptiv','Hinge Health','Swift Navigation Public Consulting Group','Plus3 IT Systems','Pythian','MLB.com','ScienceSoft USA Corporation','NeuStar, Inc.','SSi','ThoughtWorks Criterion Systems','USANA Health Services','USANA Health Sciences','Tendril','Takeda Pharmaceuticals','Softvision University of Maryland, Baltimore','Ten-X','National Home Rentals','Federal Reserve Bank of St. Louis','Sevatec, Inc. athenahealth','Integrity Applications Incorporated','Lucid Motors','TE Connectivity','NISSAN','GoPro','HatchWorks Technologies Merlin Labs','Tableau','Giant Oak','Yodlee','Probity Inc.','Eaton','Zotec Partners','PlayQ','KEYPR','GumGum','drawbridge','Scoop Technologies HotSchedules','iRobot Corporation','National Football League','VideoAmp','Alloy','EquiLend','Viacom','TPC Energy Fund','Shippo INSIGHT ENGINES','Copper','lululemon athletica','Faraday Future, Inc.','William Blair & Company','Applied Thought','Custoria','ZocDoc The Zebra','Symphony Talent','Mercari','Credit Karma','Levi Strauss & Co.','EasyPost','Carrot Inc.','zesty.ai','WeedMaps The Clorox Company','Omada Health','Enlighted','Adaptive Management','Cyberonics','Smule','Boeing Intelligence & Analytics Celtra Inc.','AG Grace Inc','Obsidian Security','thredUP Inc','Guardant Health','Audi Canada','FuelX','Chegg','Hitachi','StreetLight Data Edwards Lifesciences','DATA WORKS','Mojio','Axis Group','A+E Networks','Navy Federal Credit Union','Concur','M&T Bank','East West Bank Vistaprint','Veteran's Enterprise Technology Solutions, Inc.','Dialpad, Inc.','System1','realtor.com','AppDynamics','Conductor Stessa','BigCommerce','Avvo','The Meet Group','Glooko','Coda Search','Intelliswift Software Inc']\n",
    "  ''' \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1123)>\n"
     ]
    }
   ],
   "source": [
    "#jd_sentences = open(\"./jd_sentences.txt\").read()\n",
    "job_description = open(\"./cleaned_jd.txt\").read()\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITION SUMMARY, \\n\\nThe Business Analyst role is the primary architect of reporting and dashboard solutions for internal and external clients.',\n",
       " 'Utilizing ESI corporate standard development tools this position is responsible for the design, development, implementation, analysis, interpretation and communication of business information based on the needs of individual clients.',\n",
       " 'The ability to balance overall aesthetics with robust and intuitive functionality is a critical requirement for success in this position., \\n\\nESSENTIAL FUNCTIONS, \\n\\nSuccessfully design and implement external client data reporting and dashboard solutions with a strong focus on product aesthetics and functionality.',\n",
       " 'Aid in the design, development, and implementation of new product ideas for external and internal clients.',\n",
       " 'Maintain Live and Data Warehouse Business Objects Universes; add new fields, modify table joins, implement data structures that streamline report extraction and data analysis.',\n",
       " 'Develop and document best practices for all points throughout the design and implementation process.',\n",
       " 'Coordinate and interface with Account Management and Implementation teams to gather product design requirements and provide insight into capabilities and solutions.',\n",
       " 'Research and present new software and technology solutions to other internal developers, as well as management, to allow for the evaluation and potential integration of new development tools., QUALIFICATIONS, \\n\\nBachelor‚Äôs degree in related field or 8 to 11 years of experience.',\n",
       " '2-5 years relevant experience with Bachelor‚Äôs Degree or Master‚Äôs degree and 0-3 years of relevant experience.',\n",
       " 'Recent experience creating Business Objects XI reports.',\n",
       " 'Designing data visualization applications using SAP Xcelsius 2008 software.',\n",
       " 'Designing, implementing and maintaining data universe structures using Business Objects Universe Designer.',\n",
       " 'SQL, AS400, Adobe Flex, Flash experience preferred.',\n",
       " 'Creative problem solver.',\n",
       " 'Fundamental commitment to creating customer value through technical innovation.',\n",
       " ', \\n\\nBachelor‚Äôs degree in related field or 8 to 11 years of experience., \\n\\nABOUT THE DEPARTMENT, \\n\\nABOUT EXPRESS SCRIPTS, \\n\\nAdvance your career with the company that makes it easier for people to choose better health., \\n\\nExpress Scripts is a leading healthcare company serving tens of millions of consumers.',\n",
       " 'We are looking for individuals who are passionate, creative and committed to creating systems and service solutions that promote better health outcomes.',\n",
       " 'Join the company that Fortune magazine ranked as one of the \"\"Most Admired Companies\"\" in the pharmacy category.',\n",
       " 'Then, use your intelligence, creativity, integrity and hard work to help us enhance our products and services.',\n",
       " 'We offer a highly competitive base salary and a comprehensive benefits program, including medical, prescription drug, dental, vision, 401(k) with company match, life insurance, paid time off, tuition assistance and an employee stock purchase plan., \\n\\nExpress Scripts is an equal opportunity employer/disability/veteran]\"\\n\"[What do we need?, \\n\\nYou to have an amazing personality and communication style.',\n",
       " 'That you are super-organized and are a problem solver.',\n",
       " 'That you take pride in everything that you do, and it shows.',\n",
       " 'And most importantly that you have unquestionable integrity., \\n\\n\\nWhy work for us?, \\n\\nWe invest in our employees, and offer extensive training, and development programs to set you up for future success., \\n\\nIf we sound like a fit, and you‚Äôre ready to start an exciting career with an organization that fosters employee growth, apply today!',\n",
       " 'Job Description\\n\\nThis position will be responsible for:, \\n\\nDevelop marketing, credit risk models, segmentation, and risk analytics\\n\\nPerform all required tests and measures of developed models\\n\\nDeliver comprehensive model documentation (e.g., Model Development Document, Technical Specification Document) of modeling projects\\n\\nUnderstand and follow modeling procedures, credit policies, and deliver technical/regulatory documentation for internal/external reviews\\n\\nCommunicate technical information verbally and in writing to both technical and non-technical audiences, Education, \\n\\nAdvanced Degree (Masters or PhD preferred) in Statistics, Applied Mathematics, Operations Research, Statistics, Economics, Quantitative Finance.',\n",
       " 'MBAs should apply only if they are interested in career in specialized quantitative risk management discipline, \\n\\n\\nExperience\\n\\n, Entry level position.',\n",
       " 'Any experience in statistical modeling fields is preferred, \\n\\n\\nSkills, \\n\\nVery strong knowledge of statistics methods and machine learning techniques\\n\\nStrong numerical programming ability using a range of languages (SAS, R, Python); working experience with SQL\\n\\nDetail-oriented with high degree of accuracy\\n\\nStrong analytical, problem-solving and critical-thinking skills\\n\\nExcellent verbal and written communication skills, Benefits, \\n\\nMedical / Dental/ Vision benefits available after 30 days of employment\\n\\nCompany paid life insurance\\n\\nPaid holidays\\n\\nPTO/ 401K / Tuition Reimbursement, \\n\\nAll your information will be kept confidential according to EEO guidelines.]\"',\n",
       " '[Validate, analyze, and conduct statistical analysis on data using analytical software (Excel, SQL, and SAS).Analyze and define efficient, workable solutions that support client business processes and functional requirements for research projects., Extract qualitative findings from large data sets.Write reports that include effective graphs, tables, summaries, and narratives.Develop and execute test cases to ensure data requirements have been met.Research and resolve client-reported issues.Interpret results, present findings, and recommend alternative solutions to research management and business decision makers.Track daily industry news and disseminate relevant articles to management and team, Bachelor Degree in Statistics, Decision Sciences, Economics, Physics, Mathematics, or similar field required., 2 years of experience in the analytical fieldExperience with SQL, Python or other programming languageHighly competent in data manipulation and critical thinking.Intrinsic ability to look at data and identify patterns, problems, or analysis opportunities.',\n",
       " 'Knowledge of data mining and software applications.Ability to distill large amounts of information into key findings.Ability to clearly articulate research in written and verbal presentations with software developers, clients, management, and sales staff.Data management experience with one or more data analysis packages (e.g.',\n",
       " 'SPSS, SAS, STATA, R) required.Experience with Excel, including pivot tables, formulae, VLOOKUPs, and graphingStrong organizational skills including the ability to multi-task and prioritize efficiently to meet deadlines.Strong attention to detail and problem-solving skills.Self-motivated, takes initiative, loves to learn, and continuously seeks new knowledge.Strong documentation skills from both a business and technology perspective.Effective troubleshooting and investigation skills to identify root cause of problems.Proven ability to manage and perform multiple tasks under conditions of fluctuating workloads, competing requirements, and changing deadlines while maintaining accuracy; working independently and completing assignments with minimal direction.Self-starter who is self-motivated, efficient, responsible, and dependable.Experience in the television/media research industry is a plus., LI-JZ1, MSJA]\\n\"[Full time, Washington, DC metro area, Starting salary: $56,698 - $76,377 ($27.17 - $36.60 per hour)\\n\\n, US citizenship required (dual national US citizens are eligible), Description, Qualifications, How to Apply, As a Data Scientist Graduate Intern for the CIA, you will work side-by-side with other Data Scientists to organize and interpret data to inform US decision makers, drive successful operations, and shape technology and resource investments.',\n",
       " \"Through CIA's global mission, the Agency has access to unique and highly specialized data.\",\n",
       " 'You will work with advanced hardware, software, and techniques to develop computational algorithms and statistical methods to identify patterns and relationships in large volumes of data.',\n",
       " 'Data Scientists clearly communicate their conclusions to a diverse audience and develop technical expertise via hands-on experience and continuous learning, including Agency-sponsored training, academic conferences, and other professional development activities., \\n\\nThe Graduate Studies Program allows you and the Agency to assess opportunities for permanent employment following your completion of Graduate school., The Directorate of Digital Innovation (DDI) is at the forefront of defining the future of digital expertise within the CIA.',\n",
       " 'DDI focuses on developing the workforce with cutting-edge skills, investing in IT infrastructure, and modernizing the way the Agency does business.',\n",
       " \"DDI officers help accelerate the integration of innovative methods and tools to enhance the CIA's cyber and digital capabilities on a global scale and ultimately help safeguard our nation.\",\n",
       " 'Learn more about the Directorate of Digital Innovation., Click to watch the video on a separate page., In addition to a comprehensive benefits package, the CIA offers exciting career opportunities and a dynamic environment.',\n",
       " \"We're on the forefront of world-altering events ‚Äì as they happen.\",\n",
       " 'So working here isn\\'t just a job, it\\'s a mindset and a lifestyle.]\"',\n",
       " '[Assist in consultations with business partners and internal/external HR functional experts to develop and maintain HR dashboards, models and metrics.Research national best practices for HR data analytics to make recommendations for our district.Develop queries, validate and export data in various formats for HR dashboards/metrics, automating the delivery where possible.Perform quantitative and qualitative data analysis to produce reports, assessments and proposals that will help organizational leaders make informed and data driven business decisions.Maintain an up to date perspective of tools, practices, industry standards, national trends and System standards., Customer Focus - Building strong customer relationships and delivering customer-centric solutionsCollaborates - Building partnerships and working collaboratively with others to meet shared objectivesTech Savvy - Utilizes market pricing and analytical tools available while continually seeking out emerging technologiesPersuades - Uses compelling arguments to gain the support and commitment of othersCommunicates Effectively - Develops and delivers multi-mode communications that convey a clear understanding of the unique needs of different audiencesAction Oriented - Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasmResourcefulness - Secures and deploys resources effectively and efficiently, Bachelor‚Äôs degree in business, economics, mathematics, statistics or other related field of studyExperience using statistical software and data visualization toolsMicrosoft Office suite, specifically MS Excel, experience requiredSkilled using technology tools and digital platforms including R, Tableau and Human Capital Management (HCM) platformsExcellent time management skills including multi-tasking, managing deadlines and providing project oversightExcellent written, verbal and listening skills to effectively communicate with staff at all organizational levelsStrong problem solving and critical thinking skillsAbility to maintain trust and integrity when working with confidential situations and informationAbility to maintain composure under pressureAbility to work collaboratively across a variety of business units within the organization.Equivalent education and/or experience may be substituted for any of the above requirements]\\n\"[Collecting and combining data from multiple sourcesUncovering and exploring anomalous data (including metadata)Applying the scientific process to data evaluation, performing statistical inference, and data miningDeveloping analytic plans, engineer supporting algorithms, and design and implement solutions which execute analytic plans.Designing and developing tools and techniques for analysisAnalyzing data using mathematical/statistical methodsEvaluating, documenting, and communicating research processes, analyses, and results to customers, peers, and leadershipCreating interpretable visualizations\\n\\n, Completed a degree program in the fields of mathematics, statistics, computer science, computational sciences, or a passion for rigorous analysis of dataTenacity, integrity, persistence, and willingness to learnAbility to solve complex problemsUse critical thinking and reasoning to make analytic determinationsWorks effectively in a collaborative environmentStrong communications skills to both technical and non-technical audiencesThe desire to serve over 300 million fellow Americans and make a difference in world events\\n\\n, The qualifications listed are the minimum acceptable to be considered for the position.',\n",
       " \"Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position., The qualifications listed are the minimum acceptable to be considered for the position.\",\n",
       " \"Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position., The qualifications listed are the minimum acceptable to be considered for the position.\",\n",
       " \"Salary offers are based on candidates' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position., The qualifications listed are the minimum acceptable to be considered for the position.\",\n",
       " 'Salary offers are based on candidates\\' education level and years of experience relevant to the position and also take into account information provided by the hiring manager/organization regarding the work level for the position.]\"',\n",
       " '\"[With demand sensing, OM Partners is breaking through some boundaries of classical demand forecasting.',\n",
       " 'The use of state of the art techniques like machine learning and neural networks allow for a step change in forecast accuracy, driving immediate value creation for our customers.',\n",
       " 'By using these innovative functionalities, they are able to adjust their supply plans faster and more accurate.',\n",
       " ', Are you ready to join the demand driven revolution in supply chain?',\n",
       " 'Are you passionate about finding patterns and correlations?',\n",
       " 'Then apply for the position of Data Scientist and join our product development team., As a Data Scientist, you have only one aim: to provide innovative solutions for the customers‚Äô challenging analytics and forecasting needs., You analyze their needs, design a prototype, develop the model and optimize your solution.',\n",
       " 'You support the customer throughout the entire implementation schedule.',\n",
       " 'You work in close collaboration with the customer‚Äôs project team and you consultant colleagues working on the same project.',\n",
       " ', Next to the project work you will be responsible for the design of solutions and the development of the products.',\n",
       " 'You ensure that high-quality, well-tested and documented solutions are delivered.',\n",
       " ', Your challenge is to collect and formulate the business requirements and translate them into functional requirements that can easily be fed into a technical design.',\n",
       " 'Therefore, you work in close collaboration with the product manager and software engineers.',\n",
       " ', You continuously improve the solutions and develop new functionalities.',\n",
       " ', You validate these solutions and functionalities with the different stakeholders.',\n",
       " 'You implement and test the developments.',\n",
       " ', Finally, you document the tools, and train and support your colleagues in the usage of the Solution.',\n",
       " 'You participate in pre-sales to demonstrate functionality that meets the prospects goals and objectives.',\n",
       " ', Strong analytical skills and problem solving abilities, complemented with a university degree, are indispensable in this job.',\n",
       " ', You have an entrepreneurial mindset in looking for innovative solutions for our customers‚Äô analytics and forecasting problems.',\n",
       " ', You are passionate about finding patterns and looking for correlations in big datasets.',\n",
       " 'You take incomplete data as a challenge and use qualitative techniques to bridge the gap.',\n",
       " ', A solid background (at least 5 year) in applied statistics (distributions, statistical testing, confidence intervals, machine learning, time series, ‚Ä¶) is required.',\n",
       " ', You have practical experience with time series analysis and forecasting (exponential smoothing, multivariate regression, ARIMA, ‚Ä¶) to solve real-life business problems.',\n",
       " 'You benefit from having experience in analyzing and implementing forecasting processes, as well as having working experience as an analyst or consultant for large multinational organizations.',\n",
       " ', You are familiar with a statistical scripting language, preferably R. Basic knowledge of relational databases and SQL are a plus.',\n",
       " ', You can present findings clearly to a non-technical audience, using different visualization techniques., You have an excellent command of at least two languages (Dutch, French, English or German).',\n",
       " ', You are able to work autonomous and project based.',\n",
       " ', You can connect with the different stakeholders.',\n",
       " 'You are fun to work with and a great team player!',\n",
       " ', The forecasting team is located in our head office in Wommelgem.',\n",
       " 'Depending on your experience - hence level of autonomy - it will be required to work from the head office., OM Partners is a software and consulting company focused on Supply Chain Planning.',\n",
       " 'As a company we have but one mission: to optimize our customer‚Äôs supply chain.',\n",
       " 'We pride ourselves on developing innovative Advanced Planning Systems (APS) that meet and exceed expectations.',\n",
       " 'Our customer base includes leading companies in different industries, such as ArcelorMittal, BASF, Dow, Johnson & Johnson, Michelin, Shaw, Procter & Gamble and Smurfit Kappa., Are you the right person for the challenge?]\"',\n",
       " '[Masters degree in Bioinformatics or three years‚Äô experience and advanced degree in Computer Science, Statistics, Biology, or related discipline.Experience with computer languages commonly used in scientific programming (ex.',\n",
       " 'C/C++, python, R, or similar languages).Experience working in a UNIX/LINUX, command line environment specifically for bioinformatics data analystDemonstrated ability in analyzing high throughput sequencing data.Must have a flexible and professional attitude towards working hours especially with regards to deadlines., Ph.D. in computational biology, bioinformatics, systems biology, biostatistics or related discipline.Three or more years of hands-on research experience with the analysis of high-throughput biological data analysis.Possesses a sound knowledge of statistics and quantitative modeling, as well as solid computer programming skills.Excellent ability to communicate verbally and in writing.Ability to take direction and work efficiently and effectively within a team environment.Ability to attend to detail and organize workload to complete complex tasks in a timely manner.Working well with people from various organizational disciplines and with people who have varying degrees of technical experience.]',\n",
       " '\"[Duties\\n\\nSummary\\n\\n\\nJOB DESCRIPTION: Data Scientists develop and apply methods to identify, collect, process, and analyze large volumes of data to build and enhance products, processes, and systems.',\n",
       " 'They conduct data mining and retrieval, and apply statistical and mathematical analyses to identify trends, solve analytical problems, optimize performance, and gather intelligence.',\n",
       " \"They visualize information using a range of tools (e.g.,\\n\\nResponsibilities\\n\\n\\nADDITIONAL INFORMATION: The Data & Visualization Career Service (DVCS) serves all of the National Geospatial-Intelligence Agency's (NGA's) data, visualization, and design professionals who in turn contribute to NGA's missions supporting global events, disaster relief, and military operations.\",\n",
       " 'DVCS professionals deliver innovative and dynamic products and services that provide conveyance and context to NGA analysis.',\n",
       " 'The DVCS is seeking qualified applicants (both entry-level and experts), for potential future NGA requirements, in the fields below.',\n",
       " 'Please keep in mind that this will be used as a general repository, and that we will continue to post specific opportunity announcements when necessary.',\n",
       " 'When applying, we ask that you reference any/all work roles you feel qualified for, and understand that you may be looked at for additional work roles if deemed appropriate.',\n",
       " 'Additionally, we ask that you please reference any materials given to you during your discussion with NGA representatives (if applicable).',\n",
       " 'Travel Required\\n\\nOccasional travel - Occasional Travel Required\\n\\nSupervisory status\\n\\nNo\\n\\nPromotion Potential\\n\\n3\\n\\nJob family (Series)\\n\\n1530 Statistics\\n\\nRequirements\\n\\n\\nRequirements\\n\\nConditions of Employment\\n\\nUS Citizenship is required.',\n",
       " 'Designated or Random Drug Testing required.',\n",
       " 'Security Investigation\\n\\n\\nSPECIAL INFO:\\n\\n\\n\\nAs a condition of employment at NGA, persons being considered for employment must meet NGA fitness for employment standards.',\n",
       " 'U.S.',\n",
       " 'Citizenship Required\\n\\nSecurity Clearance (Top Secret/Sensitive Compartmented Information)\\n\\nPolygraph Test Required\\n\\nPosition Subject to Drug Testing\\n\\nTwo Year Probationary Period\\n\\nDirect Deposit Required\\n\\nSPECIAL REQUIREMENTS:\\n\\n\\n\\nYou must be able to obtain and retain a Top Secret security clearance with access to Sensitive Compartmented Information.',\n",
       " 'In addition, you are subject to a Counterintelligence Polygraph examination in order to maintain access to Top Secret information.',\n",
       " 'All employees are subject to a periodic examination on a random basis in order to determine continued eligibility.',\n",
       " 'Refusal to take the examination may result in denial of access to Top Secret information, SAP, and/or unescorted access to SCIFs.',\n",
       " 'Employees with SCI access and who are under NGA cognizance are required to submit a Security Financial Disclosure Report, SF-714, on an annual basis in order to determine continued eligibility.',\n",
       " 'Failure to comply may negatively impact continued access to Top Secret information, Information Systems, SAP, and/or unescorted access to SCIFs.',\n",
       " 'NGA utilizes all processes and procedures of the Defense Civilian Intelligence Personnel System (DCIPS).',\n",
       " 'Non-executive NGA employees are assigned to five distinct pay bands based on the type and scope of work performed.',\n",
       " \"The employee's base salary is established within their assigned pay band based on their unique qualifications.\",\n",
       " 'A performance pay process is conducted each year to determine a potential base pay salary increase and/or bonus.',\n",
       " \"An employee's annual performance evaluation is a key factor in the performance pay process.\",\n",
       " 'Employees on term or temporary appointments are not eligible to apply for internal assignment opportunity notices.',\n",
       " 'This position is a DCIPS position in the Excepted Service under 10 U.S.C.',\n",
       " '1601.',\n",
       " \"DoD Components with DCIPS positions apply Veterans' Preference to preference eligible candidates as defined by Section 2108 of Title 5 USC, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 2005, DCIPS Employment and Placement.\",\n",
       " \"If you are an external applicant claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you must self-identify your eligibility in our ERecruit application.\",\n",
       " 'Qualifications\\n\\nMANDATORY QUALIFICATION CRITERIA: For this particular job, applicants must meet all competencies reflected under the Mandatory Qualification Criteria to include education (if required).',\n",
       " \"Online resumes must demonstrate qualification by providing specific examples and associated results, in response to the announcement's mandatory criteria specified in this vacancy announcement: 1.\",\n",
       " 'Demonstrated ability to deconstruct customer challenges and identify appropriate problem-solving techniques to address complex business operations.',\n",
       " '2.',\n",
       " 'Ability to script or code in languages such as Python, Javascript, R, C++ or other similar languages.',\n",
       " '3.',\n",
       " 'Strong communication and interpersonal skills, including the ability to develop and present briefings to meet the needs of various audiences.',\n",
       " 'DESIRABLE QUALIFICATION CRITERIA: In addition to the mandatory qualifications, experience in the following is desired: It is recommended to have at least 2 years of relevant experience, to include academia, to be considered at the Pay Band 3 level.',\n",
       " \"A Bachelor's degree in specific area of education or as a rule; every 30 semester (45 quarter) hours of college work is equivalent to one year of experience.\",\n",
       " 'Candidates should show that their combination of education and experience totals 4 years.',\n",
       " 'Education\\n\\n\\nAdditional information\\n\\n\\nHow You Will Be Evaluated\\n\\nYou will be evaluated for this job based on how well you meet the qualifications above.',\n",
       " 'Applicants are not required to submit a cover letter.',\n",
       " 'The entire cover letter cannot exceed the specified limits provided in the Cover Letter field (3,000 characters).',\n",
       " 'Pages exceeding this limit will not be considered.',\n",
       " 'THE COVER LETTER IS RECOMMENDED BUT IS NOT REQUIRED FOR EMPLOYMENT CONSIDERATION WITH THE NATIONAL GEOSPATIAL-INTELLIGENCE AGENCY.',\n",
       " 'APPLICANT EVALUATION PROCESS: Applicants will be evaluated for this job opportunity in three stages:\\n\\n\\n\\n\\n1) All applicants will be evaluated using the Mandatory Qualification Criteria,\\n\\n\\n\\n2) Qualified applicants will then be evaluated by an expert or panel of experts using a combination of qualification criteria to determine the best-qualified candidates,\\n\\n\\n\\n3) Best-qualified applicants may then be further evaluated through an interview process.',\n",
       " 'Applicants are encouraged to carefully review the Assignment Description, Additional Information Provided By the Selecting Official, and the Qualification Requirements; and then construct their resumes to highlight their most relevant and significant experience and education for this job opportunity.',\n",
       " 'This description should include examples that detail the level and complexity of the performed work.',\n",
       " 'Applicants are encouraged to provide any education information referenced in the announcement.',\n",
       " 'If education is listed as a mandatory requirement, only degrees obtained from an institution accredited by an accrediting organization recognized by the Secretary, US Department of Education will be accepted.',\n",
       " 'As a condition of employment at NGA, persons being considered for employment must meet NGA fitness for employment standards.',\n",
       " 'In accordance with section 9902(h) of title 5, United States Code, annuitants reemployed in the Department of Defense shall receive full annuity and salary upon appointment.',\n",
       " 'They shall not be eligible for retirement contributions, participation in the Thrift Savings Plan, or a supplemental or redetermined annuity for the reemployment period.',\n",
       " 'Discontinued service retirement annuitants (i.e., retired under section 8336(d)(1) or 8414(b)(1)(A) of title 5, United States Code) appointed to the Department of Defense may elect to be subject to retirement provisions of the new appointment as appropriate.',\n",
       " '(See DoD Instruction 1400.25, Volume 300, at http://www.dtic.mil/whs/directives.)',\n",
       " 'All candidates will be considered without regard to race, color, religion, sex, national origin, age, marital status, disability, or sexual orientation.',\n",
       " 'NGA provides reasonable accommodations to applicants with disabilities.',\n",
       " 'Applications will only be accepted online.',\n",
       " 'If you need a reasonable accommodation for any part of the application and hiring process, please notify us at recruitment@nga.mil.',\n",
       " 'The decision on granting reasonable accommodation will be on a case-by-case basis.',\n",
       " 'Background checks and security clearance\\n\\nSecurity clearance\\n\\nTop Secret/SCI\\n\\nDrug test required\\n\\nYes\\n\\nRequired Documents\\n\\n\\nRequired Documents\\n\\nNone\\n\\nIf you are relying on your education to meet qualification requirements:\\n\\nEducation must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications.',\n",
       " 'Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education .',\n",
       " 'Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.',\n",
       " 'Benefits\\n\\n\\nBenefits\\n\\n\\nReview our benefits, JOB DESCRIPTION: Data Scientists develop and apply methods to identify, collect, process, and analyze large volumes of data to build and enhance products, processes, and systems.',\n",
       " 'They conduct data mining and retrieval, and apply statistical and mathematical analyses to identify trends, solve analytical problems, optimize performance, and gather intelligence.',\n",
       " \"They visualize information using a range of tools (e.g.,\\n, ADDITIONAL INFORMATION: The Data & Visualization Career Service (DVCS) serves all of the National Geospatial-Intelligence Agency's (NGA's) data, visualization, and design professionals who in turn contribute to NGA's missions supporting global events, disaster relief, and military operations.\",\n",
       " 'DVCS professionals deliver innovative and dynamic products and services that provide conveyance and context to NGA analysis.',\n",
       " 'The DVCS is seeking qualified applicants (both entry-level and experts), for potential future NGA requirements, in the fields below.',\n",
       " 'Please keep in mind that this will be used as a general repository, and that we will continue to post specific opportunity announcements when necessary.',\n",
       " 'When applying, we ask that you reference any/all work roles you feel qualified for, and understand that you may be looked at for additional work roles if deemed appropriate.',\n",
       " 'Additionally, we ask that you please reference any materials given to you during your discussion with NGA representatives (if applicable).',\n",
       " ', Occasional travel - Occasional Travel Required\\n\\n, No\\n\\n, 3\\n\\n, 1530 Statistics\\n\\n, Requirements\\n\\n, US Citizenship is required.',\n",
       " 'Designated or Random Drug Testing required.',\n",
       " 'Security Investigation\\n\\n, U.S.',\n",
       " 'Citizenship Required\\n\\nSecurity Clearance (Top Secret/Sensitive Compartmented Information)\\n\\nPolygraph Test Required\\n\\nPosition Subject to Drug Testing\\n\\nTwo Year Probationary Period\\n\\nDirect Deposit Required\\n\\n, SPECIAL REQUIREMENTS:\\n\\n\\n\\nYou must be able to obtain and retain a Top Secret security clearance with access to Sensitive Compartmented Information.',\n",
       " 'In addition, you are subject to a Counterintelligence Polygraph examination in order to maintain access to Top Secret information.',\n",
       " 'All employees are subject to a periodic examination on a random basis in order to determine continued eligibility.',\n",
       " 'Refusal to take the examination may result in denial of access to Top Secret information, SAP, and/or unescorted access to SCIFs.',\n",
       " 'Employees with SCI access and who are under NGA cognizance are required to submit a Security Financial Disclosure Report, SF-714, on an annual basis in order to determine continued eligibility.',\n",
       " 'Failure to comply may negatively impact continued access to Top Secret information, Information Systems, SAP, and/or unescorted access to SCIFs.',\n",
       " ', \\n\\nNGA utilizes all processes and procedures of the Defense Civilian Intelligence Personnel System (DCIPS).',\n",
       " 'Non-executive NGA employees are assigned to five distinct pay bands based on the type and scope of work performed.',\n",
       " \"The employee's base salary is established within their assigned pay band based on their unique qualifications.\",\n",
       " 'A performance pay process is conducted each year to determine a potential base pay salary increase and/or bonus.',\n",
       " \"An employee's annual performance evaluation is a key factor in the performance pay process.\",\n",
       " 'Employees on term or temporary appointments are not eligible to apply for internal assignment opportunity notices.',\n",
       " 'This position is a DCIPS position in the Excepted Service under 10 U.S.C.',\n",
       " '1601.',\n",
       " \"DoD Components with DCIPS positions apply Veterans' Preference to preference eligible candidates as defined by Section 2108 of Title 5 USC, in accordance with the procedures provided in DoD Instruction 1400.25, Volume 2005, DCIPS Employment and Placement.\",\n",
       " \"If you are an external applicant claiming veterans' preference, as defined by Section 2108 of Title 5 U.S.C., you must self-identify your eligibility in our ERecruit application.\",\n",
       " ', MANDATORY QUALIFICATION CRITERIA: For this particular job, applicants must meet all competencies reflected under the Mandatory Qualification Criteria to include education (if required).',\n",
       " \"Online resumes must demonstrate qualification by providing specific examples and associated results, in response to the announcement's mandatory criteria specified in this vacancy announcement: 1.\",\n",
       " 'Demonstrated ability to deconstruct customer challenges and identify appropriate problem-solving techniques to address complex business operations.',\n",
       " '2.',\n",
       " 'Ability to script or code in languages such as Python, Javascript, R, C++ or other similar languages.',\n",
       " '3.',\n",
       " 'Strong communication and interpersonal skills, including the ability to develop and present briefings to meet the needs of various audiences.',\n",
       " ', DESIRABLE QUALIFICATION CRITERIA: In addition to the mandatory qualifications, experience in the following is desired: It is recommended to have at least 2 years of relevant experience, to include academia, to be considered at the Pay Band 3 level.',\n",
       " \"A Bachelor's degree in specific area of education or as a rule; every 30 semester (45 quarter) hours of college work is equivalent to one year of experience.\",\n",
       " 'Candidates should show that their combination of education and experience totals 4 years.',\n",
       " ', You will be evaluated for this job based on how well you meet the qualifications above.',\n",
       " ', Applicants are not required to submit a cover letter.',\n",
       " 'The entire cover letter cannot exceed the specified limits provided in the Cover Letter field (3,000 characters).',\n",
       " 'Pages exceeding this limit will not be considered.',\n",
       " 'THE COVER LETTER IS RECOMMENDED BUT IS NOT REQUIRED FOR EMPLOYMENT CONSIDERATION WITH THE NATIONAL GEOSPATIAL-INTELLIGENCE AGENCY.',\n",
       " ', APPLICANT EVALUATION PROCESS: Applicants will be evaluated for this job opportunity in three stages:\\n\\n\\n\\n\\n1) All applicants will be evaluated using the Mandatory Qualification Criteria,\\n\\n\\n\\n2) Qualified applicants will then be evaluated by an expert or panel of experts using a combination of qualification criteria to determine the best-qualified candidates,\\n\\n\\n\\n3) Best-qualified applicants may then be further evaluated through an interview process.',\n",
       " 'Applicants are encouraged to carefully review the Assignment Description, Additional Information Provided By the Selecting Official, and the Qualification Requirements; and then construct their resumes to highlight their most relevant and significant experience and education for this job opportunity.',\n",
       " 'This description should include examples that detail the level and complexity of the performed work.',\n",
       " 'Applicants are encouraged to provide any education information referenced in the announcement.',\n",
       " 'If education is listed as a mandatory requirement, only degrees obtained from an institution accredited by an accrediting organization recognized by the Secretary, US Department of Education will be accepted.',\n",
       " 'As a condition of employment at NGA, persons being considered for employment must meet NGA fitness for employment standards.',\n",
       " 'In accordance with section 9902(h) of title 5, United States Code, annuitants reemployed in the Department of Defense shall receive full annuity and salary upon appointment.',\n",
       " 'They shall not be eligible for retirement contributions, participation in the Thrift Savings Plan, or a supplemental or redetermined annuity for the reemployment period.',\n",
       " 'Discontinued service retirement annuitants (i.e., retired under section 8336(d)(1) or 8414(b)(1)(A) of title 5, United States Code) appointed to the Department of Defense may elect to be subject to retirement provisions of the new appointment as appropriate.',\n",
       " '(See DoD Instruction 1400.25, Volume 300, at http://www.dtic.mil/whs/directives.)',\n",
       " 'All candidates will be considered without regard to race, color, religion, sex, national origin, age, marital status, disability, or sexual orientation.',\n",
       " 'NGA provides reasonable accommodations to applicants with disabilities.',\n",
       " 'Applications will only be accepted online.',\n",
       " 'If you need a reasonable accommodation for any part of the application and hiring process, please notify us at recruitment@nga.mil.',\n",
       " 'The decision on granting reasonable accommodation will be on a case-by-case basis.',\n",
       " ', Top Secret/SCI\\n\\n, Yes\\n\\n, Required Documents\\n\\n, None\\n\\n, Education must be accredited by an accrediting institution recognized by the U.S. Department of Education in order for it to be credited towards qualifications.',\n",
       " 'Therefore, provide only the attendance and/or degrees from schools accredited by accrediting institutions recognized by the U.S. Department of Education .',\n",
       " ', Failure to provide all of the required information as stated in this vacancy announcement may result in an ineligible rating or may affect the overall rating.',\n",
       " ', Benefits\\n\\n, Review our benefits]\"\\n\"[The Department of Epidemiology at the University of Pittsburgh‚Äôs Graduate School of Public Health is seeking a qualified Data Scientist., \\n\\nThe Data Scientist will work to improve existing data management systems, provide reporting support, and conduct analyses.',\n",
       " 'Duties of the incumbent include developing and implementing programs to process and manipulate large datasets, writing queries for extracting data, preparing reports with both tabular and graphical presentations, and developing statistical and mathematical models.',\n",
       " 'The candidate will be responsible for analysis, design, testing, documentation, and evidence of efficacy.',\n",
       " 'The candidate must have experience working within a team environment, yet independently be able to work on multiple projects simultaneously, and work well under pressure to meet deadlines.',\n",
       " 'The incumbent must be proficient in report generation, query writing, databases, and data visualization.',\n",
       " 'In addition, the candidate must have experience designing, conducting, and interpreting statistical analyses using common statistical software tools (e.g., SAS, R, SPSS, Python) and techniques (e.g., regression modeling, survival analysis, machine learning, data mining, clustering)., Master‚Äôs degree in Biostatistics, Statistics, Data Science, Mathematics, Information Science, Data Sciences, or related field with at least 5 years of experience in data analysis, database management, or information technology; or a Doctoral degree in Biostatistics, Statistics, Epidemiology, Data Science, Mathematics, Information Science, Data Sciences, or related field; or some combination of related experience and graduate education required., The following PA Act 153 clearances and background checks may be required prior to commencement of employment and as a condition of continued employment: PA State Police Criminal Record Check, FBI Criminal Record Check, PA Child Abuse History Clearance., Education benefits and a retirement plan with employer match, Group medical insurance, life insurance, and optional vision and dental insurance, Free transit service within Allegheny County for employees of the Oakland campus (Port Authority Transit), Time off benefits including vacation, sick and personal time]\"\\n\"[The Department of Epidemiology at the University of Pittsburgh‚Äôs Graduate School of Public Health is seeking a qualified Data Scientist., \\n\\nThe Data Scientist will work to improve existing data management systems, provide reporting support, and conduct analyses.',\n",
       " 'Duties of the incumbent include developing and implementing programs to process and manipulate large datasets, writing queries for extracting data, preparing reports with both tabular and graphical presentations, and developing statistical and mathematical models.',\n",
       " 'The candidate will be responsible for analysis, design, testing, documentation, and evidence of efficacy.',\n",
       " 'The candidate must have experience working within a team environment, yet independently be able to work on multiple projects simultaneously, and work well under pressure to meet deadlines.',\n",
       " 'The incumbent must be proficient in report generation, query writing, databases, and data visualization.',\n",
       " 'In addition, the candidate must have experience designing, conducting, and interpreting statistical analyses using common statistical software tools (e.g., SAS, R, SPSS, Python) and techniques (e.g., regression modeling, survival analysis, machine learning, data mining, clustering)., Master‚Äôs degree in Biostatistics, Statistics, Data Science, Mathematics, Information Science, Data Sciences, or related field with at least 5 years of experience in data analysis, database management, or information technology; or a Doctoral degree in Biostatistics, Statistics, Epidemiology, Data Science, Mathematics, Information Science, Data Sciences, or related field; or some combination of related experience and graduate education required., The following PA Act 153 clearances and background checks may be required prior to commencement of employment and as a condition of continued employment: PA State Police Criminal Record Check, FBI Criminal Record Check, PA Child Abuse History Clearance., Education benefits and a retirement plan with employer match, Group medical insurance, life insurance, and optional vision and dental insurance, Free transit service within Allegheny County for employees of the Oakland campus (Port Authority Transit), Time off benefits including vacation, sick and personal time]\"\\n\"[Salary Commensurate with Experience and Qualifications, Monday through Friday, 8 a.m. to 5 p.m.; some late evenings may be required including some weekends., Texas Policy Lab (TPL) is seeking a data scientist.',\n",
       " 'The successful candidate will work with other members of TPL and faculty at Rice University to contribute to analytical projects involving large administrative and survey-generated datasets.',\n",
       " 'S/he will apply frontier data analytic techniques (predictive modeling, machine learning etc.)',\n",
       " 'to address policymaker needs.',\n",
       " 'S/he will import, manipulate, and merge large datasets.',\n",
       " 'S/he will devise and implement strategies to automate the process of importing, exporting and linking datasets arriving from various government agencies., \\n\\nTPL provides Texas state and local government agencies with science driven results to help inform how policy is developed and implemented in Texas.',\n",
       " 'In close collaboration with those agencies, we produce scientific, independent, timely evaluations of current social and economic programs and new program initiatives.',\n",
       " 'These long-term partnerships will improve Texas state and local government capacity to utilize data, scientific evidence and technology in policy-making and resource allocation.',\n",
       " 'The Texas Policy Lab draws on the expertise of Rice University faculty and its own professional research staff., In a relevant field (computer science, mathematics, statistics, economics, finance etc.',\n",
       " ')., Experience may not be substituted for the education requirement., Master‚Äôs degree in a relevant field., Experience in application of predictive modeling or machine learning.Experience in manipulating administrative data collected from multiple sources.Demonstrable interest in public policy.Ability to communicate complex techniques and methods with other researchers.Interest in a substantive public policy area, such as criminal justice, child protective services, health, education or others., Good listening, verbal and written communication, analytical, and research skills.Excellent scientific and numerical skills with meticulous attention to details and accuracy.Ability to work in a team environment, to participate actively, to collaborate and to motivate others in the lab.Good critical thinking, technical, data collection and interviewing skills.Good statistical and graphical analysis skills.Ability to maintain quality, safety and / or infection control standards.Ability to plan and schedule effectively., Expertise, as demonstrated by advanced coursework or other relevant experience, in predictive modeling, machine learning and statistics.Demonstrable expertise in determining the appropriate analytic approaches and computing techniques given the data availability and research question.Strong programming skills in statistical and/or computational programs.',\n",
       " 'Knowledge of frontier data science techniques and experience in their applications.Experience in importing, linking, reshaping and managing large administrative datasets., Will work closely and report to the research scientist(s).Frequent contact with the TPL research team and staff members.Will have regular contact with various Rice University personnel and other stakeholders, including local and state entities from which TPL will acquire data., Must be able to work at a computer terminal for extended periods of time.Must be able to move about campus and go to various TPL sites., Monday-Friday, standard 40 hour work weekSome late evenings and/or weekends required to meet TPL deadlines]\"\\n\"[Mid Data Scientist, Our client in the Midtown area is looking for a Jr. Data Scientist with a passion for Machine Learning, knows the how\\'s & why\\'s of algorithms, and is excited about the fraud industry.',\n",
       " \"You'll be a pivotal piece in the Atlanta/US team in development and application of adaptive real-time analytical modeling algorithms.\",\n",
       " 'So if that gets you excited, apply!, Role Expectations:, End-to-end processing and modeling of large customer data sets.',\n",
       " 'Working with customers to understand the opportunities and constraints of their existing data in the context of machine learning and predictive modeling.',\n",
       " 'Develop statistical models and algorithms for integration with company‚Äôs product.',\n",
       " 'Apply analytical theory to real-world problems on large and dynamic datasets.',\n",
       " 'Produce materials to feedback analytic results to customers (reports, presentations, visualizations).',\n",
       " 'Providing input into future data science strategy and product development.',\n",
       " 'Working with development teams to support and enhance the analytical infrastructure.',\n",
       " 'Work with the QA team to advise on effective analytical testing.',\n",
       " 'Evaluate and improve the analytical results on live systems.',\n",
       " 'Develop an understanding of the industry data structures and processes.',\n",
       " ', Team working with:, Currently 6 other Data Scientist local to Atlanta, the rest of the team (10+) in Cambridge\\n130 people in the entire company\\n, Top skills required:, Degree-level qualification with good mathematical background and knowledge of statistics.',\n",
       " 'Professional experience using Random Forests, machine learning algorithms, development skills with C or Python\\nFirst-hand experience of putting Data Storage into production\\nExperience in implementing statistical models and analytical algorithms in software.',\n",
       " 'Practical experience of the handling and mining of large, diverse, data sets.',\n",
       " 'Must have a USA work visa or Passport.',\n",
       " ', Nice to have:, Ph.D. or other postgraduate qualification would be an extreme advantage\\nAn indication of how relevant technologies have been used (not just a list).',\n",
       " 'Attention to grammatical detail, layout and presentation.',\n",
       " ', Benefits:, Regular bonus scheme\\n20 days annual leave\\nHealthcare package\\nFree Friday lunches\\nRegular social outings\\nFridge and cupboards packed full of edible treats\\nAnnual summer social and Christmas dinner\\nMarket Salary Expectation: $70-85k]\"\\n\"[WHY CATALINA\\n\\n, Catalina‚Äôs personalized digital media connects shoppers to the brands we know they want.',\n",
       " 'We do this by delivering only the most relevant ads and offers from their home to the aisle.',\n",
       " 'And only Catalina knows the evolving purchase history and individual needs of more than three-quarters of (280 million) American shoppers.',\n",
       " 'With the world‚Äôs largest shopper purchase history database driving all personalized media across our networks, Catalina drives lift and loyalty for the world‚Äôs leading CPG brands and retailers.',\n",
       " 'We target consumers with the right behavior-based message when it‚Äôs most impactful via the channel that‚Äôs most likely to reach them ‚Äî digital or in the store.',\n",
       " ', OUR TEAM\\n\\n, The Advanced Analytics and Data Science team at Catalina operates near the tip of spear, creating new, world-class science-based capabilities for external and internal clients, shepherding these initiatives from initial concept, prototyping / proof-of-concept, design, build, testing, training, and handoff.',\n",
       " 'We use advanced machine learning, data science, operations research, statistics, and related analytics methodologies, operating on big data and delivered on a scalable computing platform using modern technologies.',\n",
       " 'We illustrate value and drive to bring these capabilities to initial Production and ensure that these initiatives are successful when we hand off.',\n",
       " ', This position will report directly to the VP of Advanced Analytics and Data Science.',\n",
       " ', WHAT YOU WILL BE DOING\\n\\n, The Incumbent will\\n\\n, Works on moderate to complex projects that require a singular area of expertise\\n\\nLeads project planning sessions with users, business analysts, and team members to gather and analyze user requirements.',\n",
       " 'Develops recommendations\\n\\nFormulates mathematical models in an appropriate programming language or application\\n\\nAnalyzes raw input data from computer or other media\\n\\nValidates and tests of models to ensure adequacy, or determines need for reformulation\\n\\nUtilizes and stays current on applicable programming languages and software technologies\\n\\nTracks progress and reports out to stakeholders\\n\\nKnows what quality means, strives for quality, designs for quality, tests and refines until a very high quality is achieved, and continuously improves\\n\\nDelivers prototypes / proofs of concept\\n\\nRecommends plans to bring to Production\\n\\nThis is a skilled position with minimal supervision required (supervision by manager a couple of times per week)\\n\\n, WHAT YOU BRING TO THE TEAM\\n\\n, Ph.D. in machine learning, computer science, engineering, mathematics, statistics, operations research, or related discipline; OR\\n\\nMasters degree in (same disciplines mentioned above) AND 2+ years experience after graduate school in computation, data science, machine learning or related; OR\\n\\nBachelor degree AND 4+ years experience\\n\\n, Computing skills: programming (e.g., C++), cloud distributed computing, python / R, machine learning framework(s) (e.g., sk-learn, tensorflow), linux, bitbucket, Target Process/JIRA or other issue-tracking\\n\\nGood communications, verbally, and also have ability to construct cogent design documents, emails and PowerPoints\\n\\nAtlanta-based.',\n",
       " '(Will entertain candidates willing to relocate to Atlanta.)',\n",
       " 'Ability to travel up to 25%\\n\\n, ADDITIONAL PREFERRED SKILLS\\n\\n, Sunny disposition, team player\\n\\nAcademic networking\\n\\n , CATALINA CORE VALUES\\n\\n , Be a trusted partner : Act with integrity and positive intent\\n\\n , Focus on the customer: Keep the needs of both internal and external customers as well as\\n\\n , consumers front and center\\n\\n , Act like an owner: Think holistically about how your role helps fulfill our Mission\\n\\n , Be innovative: Share and scale the best ideas regardless of origin\\n\\n , Strive for simplicity: Add meaning and eliminate complexity\\n\\n , Value personal and professional growth: Contribute to an environment that enables\\n\\n , individual, team and organizational success\\n\\n, The intent of this job description is to describe the major duties and responsibilities performed by incumbents of this job.',\n",
       " 'Incumbents may be required to perform other job-related tasks other than those specifically presented in this description.',\n",
       " ', All duties and responsibilities are essential job functions and requirements and are subject to possible modification to reasonably accommodate individuals with disabilities.',\n",
       " ', \\nWe are proud to be an EEO employer M/F/D/V.',\n",
       " 'We maintain a drug-free workplace.',\n",
       " ', Note to Recruiters and Placement Agencies : We do not accept unsolicited resumes from outside recruiters /placement agencies.']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_sentences = sent_tokenize(job_description)\n",
    "jd_sentences[0:255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry --- Express Scripts\n",
      "substring --- , \n",
      "\n",
      "Bachelor‚Äôs degree in related field or 8 to 11 years of experience., \n",
      "\n",
      "ABOUT THE DEPARTMENT, \n",
      "\n",
      "ABOUT EXPRESS SCRIPTS, \n",
      "\n",
      "Advance your career with the company that makes it easier for people to choose better health., \n",
      "\n",
      "Express Scripts is a leading healthcare company serving tens of millions of consumers.\n",
      "entry --- Express Scripts\n",
      "substring --- We offer a highly competitive base salary and a comprehensive benefits program, including medical, prescription drug, dental, vision, 401(k) with company match, life insurance, paid time off, tuition assistance and an employee stock purchase plan., \n",
      "\n",
      "Express Scripts is an equal opportunity employer/disability/veteran]\"\n",
      "\"[What do we need?, \n",
      "\n",
      "You to have an amazing personality and communication style.\n",
      "entry --- Express Scripts\n",
      "substring --- , ABOUT EXPRESS SCRIPTS, \n",
      "\n",
      "Advance your career with the company that makes it easier for people to choose better health., \n",
      "\n",
      "Express Scripts is a leading healthcare company serving tens of millions of consumers.\n",
      "entry --- Express Scripts\n",
      "substring --- We offer a highly competitive base salary and a comprehensive benefits program, including medical, prescription drug, dental, vision, 401(k) with company match, life insurance, paid time off, tuition assistance and an employee stock purchase plan., \n",
      "\n",
      "Express Scripts is committed to hiring and retaining a diverse workforce.\n",
      "entry --- Express Scripts\n",
      "substring --- Express Scripts is a VEVRAA Federal Contractor.]\"\n",
      "entry --- comScore\n",
      "substring --- Preferred: Knowledge of popular ad serving technologies and supporting analytical and research tools (Doubleclick, Atlas, comScore, Compete, etc.)\n",
      "entry --- comScore\n",
      "substring --- We are one of the top-20 largest content publishers on the Internet according to comScore, a leading Internet measurement company, and reach more than 30% of the U.S. population every month.\n",
      "entry --- comScore\n",
      "substring --- Author technical and academic publications showcasing capabilities of comScore‚Äôs data assets to solve real world problems.\n",
      "entry --- comScore\n",
      "substring --- , For eligible employees]\"\n",
      "\"[\n",
      "\n",
      "Independently identify appropriate data science techniques and methodologies that will be used to support comScore‚Äôs cross-platform measurement products, and answer technical and business questions.\n",
      "entry --- comScore\n",
      "substring --- Build algorithms, tools, custom solutions, and new technologies from diverse and large-scale data sets to enhance comScore‚Äôs measurement products, or contribute to new products.\n",
      "entry --- comScore\n",
      "substring --- Maintain existing algorithms, tools, solutions, and methodologies contributing to comScore‚Äôs existing measurement products.\n",
      "entry --- comScore\n",
      "substring --- Work closely with other functional teams, including Software Engineering, Product Management, Data Operations, Client Accounts Managers, and Sales Teams to develop and maintain the methodologies contributing to comScore‚Äôs cross-platform measurement services.\n",
      "entry --- comScore\n",
      "substring --- 2-4 years of relevant data science experience; comScore or other media measurement experience can be included.\n",
      "entry --- comScore\n",
      "substring --- )Working knowledge of cluster computing environments including Hadoop, Spark and HiveExperience with data visualization tools and techniquesWorking knowledge of multiple analytics and programming languages such as R, Python, SAS, Julia, Java, Scala or similarUnderstanding of relational databases and SQL, Desired Characteristics, Experience with multi-billion record datasets and leading projects that span the disciplines of data science and data engineeringExperience with television ratings and digital measurement tools (Nielsen, Rentrak, comScore, Omniture, etc.\n",
      "entry --- comScore\n",
      "substring --- Guide and help other teams in using our ads data, \n",
      "\n",
      "We are the fastest growing health information site on the planet, and the 2nd largest health site in the US (per comScore)!\n",
      "entry --- comScore\n",
      "substring --- We come from a background of companies like, YP, TiVo, CNET, AOL, comScore, BrightRoll, Walmart, Coca Cola and many we just picked up out of college.\n",
      "entry --- comScore\n",
      "substring --- *\n",
      "]\"\n",
      "[Establish overall approach to data strategy with given clients, including the ability to see growth potential within existing accountsOversee the design and management of research projectsUse foresight to build and provide value to clientDevelop and maintain all client relationshipsEnsure that all clients have a long-term Measurement Roadmap in place, leveraging best-in-class internal and external toolsEnsure appropriate staffing levels against staff planEffectively articulate the applications of media research tools and resourcesProvide staff with all the necessary tools and training to improve upon existing expertiseEnsure client service teams have fully optimized their media plans and developed rich and well thought out campaign strategiesWrite POVs on industry topicsSupport new business pitches, Data Visualization: Tableau, Omniscope, PowerBIWeb Analytics: Omniture, Google Analytics, WebtrendsAd Servers: DoubleClick, MediaMind, PointRoll, AtlasSyndicated Measurement: comScore, Nielsen, CompeteAd Effectiveness Research: comScore, Millward Brown Digital, Dimestore, Vizu, Research NowMicrosoft Office: Excel, Word, PowerPointFamiliarity with SAS, SPSS, R, Python a plus, Bachelors or advanced degree in Statistics, Economics, Business, Math, or Sciences is preferredMinimum of eight years‚Äô experience preferredExperience managing a mid-to-large size teamStrong analytic and problem solving skillsExcellent written, oral, and presentation communication abilitiesAbility to foster collaborative relationships with other cross-functional teamsAbility to manage and prioritize competing projects and deliverables]\n",
      "\"[\n",
      "Experience with using Tableau to aggregate and analyze data collected from various sources\n",
      "Experience with the Microsoft program suite\n",
      "Ability to synthesize and communicate organizational performance clearly based on information from disparate sources through oral and written formats\n",
      "Ability to communicate information to senior executives for decision making purposes\n",
      "TS/SCI clearance with a polygraph\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with performance management and identifying and defining performance measures to support an organization's mission and goals\n",
      "Knowledge of overall IC agency processes and policies\n",
      "Ability to execute projects and tasks with minimal guidance and supervision\n",
      "Possession of excellent oral and written communication skills\n",
      "Possession of excellent data gathering, analytical, and problem solving skills\n",
      "]\"\n",
      "\n",
      "\"[\n",
      "\n",
      "Partner with e-commerce leadership and cross-functional analytics teams to increase the sophistication of our e-commerce analytics and reporting capabilities and tools\n",
      "\n",
      "Use Google Analytics to measure and understand consumer behavior on site, ranging from pathing and funnel analysis to product interaction; perform deep dive analyses to identify pain points within the online experience and partner with product team to share results and devise technology solutions and enhancements to improve\n",
      "\n",
      "Establish executive dashboards to provide visibility into business performance and track progress on KPIs vs. goals; perform deep dives and build more sophisticated data models as needed to drive business prioritization and decision-making\n",
      "\n",
      "Prepare executive presentations, including e-commerce reporting, comprehensive business analyses, storylines to tie key strategic updates and action plans to financials & forecasts, and recommendations to senior management and the Board\n",
      "\n",
      "Serve as a thought leader and partner for e-commerce merchandising and product teams\n",
      "\n",
      "Manage and grow team of e-commerce data analysts, \n",
      "\n",
      "Develop a test and learn methodology to optimize our product pricing to drive optimal product category mix, maximize sell-through and profitability, and deliver the best possible value to our customers\n",
      "\n",
      "Partner with Product, Engineering, and internal analytics teams to devise plan for site personalization and implement a test-and-learn approach; seek and manage external consultants and related technology partners as needed to deliver on our business goals\n",
      "\n",
      "Evaluate current processes & tools; identify opportunities to drive efficiencies and deliver stronger outcomes for the business and manage related cross-functional implementation plans\n",
      "\n",
      "Improve and help mature process optimization between e-commerce and internal client-facing teams, including Sales and Customer Success; develop synergies between departments surrounding our e-commerce offering, ensuring efficiencies in the processes related to selling and managing accounts\n",
      "\n",
      "Serve as an e-commerce SME for clients, facilitating ongoing client business reviews, reporting, and related e-commerce analytics\n",
      "\n",
      "Manage and build team to support business optimization and client-facing initiatives, 10+ years of experience in analytical roles with 5+ years in a business analytics, strategy and/or optimization-focused role in a technology environment preferred\n",
      "\n",
      "Entrepreneurial leader ‚Äì ability to develop and lead strategy while getting down in the weeds with the team to drive fast and effective execution with limited resources\n",
      "\n",
      "Proven track record of taking ownership and driving results in an unstructured environment\n",
      "\n",
      "Collaborator who thrives on teamwork and has a demonstrated ability to accomplish goals by working cross-functionally; an evangelist who can get stakeholders on board with a plan and leverage cross-functional resources to get things done\n",
      "\n",
      "Player/Coach mentality and strong management skills; Experience recruiting and managing a high-performing team\n",
      "\n",
      "Desire to make an impact on business decisions with data; possess a balance of strong quantitative and analytical skills with a passion in business and leadership\n",
      "\n",
      "Appreciate the power of a data-driven environment and serve as a data evangelist to help grow and build a highly analytical culture around our e-commerce business and evolving needs\n",
      "\n",
      "Resourceful and creative problem solver ‚Äì proven ability to tackle complex challenges with limited resources\n",
      "\n",
      "Expert with Excel and SQL\n",
      "\n",
      "BA/BS with strong academic record, preferably in Economics, Mathematics, Statistics, or other quantitative discipline preferred\n",
      "\n",
      "MBA from a top tier school or similar degree desired]\"\n",
      "\"[Job Description\n",
      "\n",
      ", Major Job Responsibilities:\n",
      "\n",
      ", Works with internal business stakeholders and senior company management to define information needs, develop business cases and business intelligence reporting priorities\n",
      "\n",
      "Develops and implements business intelligence solutions and plans, assesses cost and ensures the plan supports both strategic and near term needs\n",
      "\n",
      "Proactively identifies future technology trends, challenges and impacts on the company's strategic agenda\n",
      "\n",
      "Creates and communicates clear and compelling vision and strategy and communicates vision to staff and business stakeholders\n",
      "\n",
      "Evaluates and recommends new products, maintain knowledge of emerging technologies\n",
      "\n",
      "Develops annual budgets, capital plans and system development plans and monitors performance against plans\n",
      "\n",
      "Responsible for supervising external consultants as needed\n",
      "\n",
      "Identifies, builds, and maintains enterprise analytics and reporting assets, deliverables and technology solutions\n",
      "\n",
      "Interfaces with all business units and executive leadership to ensure access to business metrics in an easy to consume and highly visual fashion\n",
      "\n",
      "Builds web based dashboards to report on key performance indicators\n",
      "\n",
      "Builds web based self-service modules to allow staff to generate enterprise reports in an ad hoc fashion\n",
      "\n",
      "Regularly ensures that enterprise reports are accurate, rich in actionable content, and useful\n",
      "\n",
      "Ensures that uniform enterprise-wide design standards, style and conventions are maintained\n",
      "\n",
      "Maintains awareness of and participates in data quality assurance, governance, curation, meta-tagging and definition efforts\n",
      "\n",
      "Training, mentoring and knowledge transfer with team members\n",
      "\n",
      ", Works with internal business stakeholders and senior company management to define information needs, develop business cases and business intelligence reporting priorities\n",
      "\n",
      ", Develops and implements business intelligence solutions and plans, assesses cost and ensures the plan supports both strategic and near term needs\n",
      "\n",
      ", Proactively identifies future technology trends, challenges and impacts on the company's strategic agenda\n",
      "\n",
      ", Creates and communicates clear and compelling vision and strategy and communicates vision to staff and business stakeholders\n",
      "\n",
      ", Evaluates and recommends new products, maintain knowledge of emerging technologies\n",
      "\n",
      ", Develops annual budgets, capital plans and system development plans and monitors performance against plans\n",
      "\n",
      ", Responsible for supervising external consultants as needed\n",
      "\n",
      ", Identifies, builds, and maintains enterprise analytics and reporting assets, deliverables and technology solutions\n",
      "\n",
      ", Interfaces with all business units and executive leadership to ensure access to business metrics in an easy to consume and highly visual fashion\n",
      "\n",
      ", Builds web based dashboards to report on key performance indicators\n",
      "\n",
      ", Builds web based self-service modules to allow staff to generate enterprise reports in an ad hoc fashion\n",
      "\n",
      ", Regularly ensures that enterprise reports are accurate, rich in actionable content, and useful\n",
      "\n",
      ", Ensures that uniform enterprise-wide design standards, style and conventions are maintained\n",
      "\n",
      ", Maintains awareness of and participates in data quality assurance, governance, curation, meta-tagging and definition efforts\n",
      "\n",
      ", Training, mentoring and knowledge transfer with team members\n",
      "\n",
      ", Supervisory Responsibilities:\n",
      "\n",
      ", Direct management responsibilities in accordance with the ministry‚Äôs policies and applicable laws, including interviewing, hiring, training, planning, assigning and directing work, appraising performance, rewarding and disciplining staff, addressing complaints, and resolving problems\n",
      "\n",
      ", Member Responsibilities: The following responsibilities apply to any employee who is also a member of the religious organization:\n",
      "\n",
      ", Partnership Development: Build and retain a team of prayer and financial partners that will sustain them during their entire Wycliffe ministry according to the Wycliffe Partnership Development policy\n",
      "\n",
      "Organizational Representative: Present the global ministry of Wycliffe and encourage interested individuals and churches to participate in this work\n",
      "\n",
      "Maintain an exemplary standard of ethics and conduct that reflects biblical principles\n",
      "\n",
      ", Partnership Development: Build and retain a team of prayer and financial partners that will sustain them during their entire Wycliffe ministry according to the Wycliffe Partnership Development policy\n",
      "\n",
      ", Organizational Representative: Present the global ministry of Wycliffe and encourage interested individuals and churches to participate in this work\n",
      "\n",
      ", Maintain an exemplary standard of ethics and conduct that reflects biblical principles\n",
      "\n",
      ", Minimum Skill Sets (KSAs):\n",
      "\n",
      " , Servant‚Äôs-heart attitude towards leadership and team relationships\n",
      "\n",
      "Excellent strategic vision and a global, enterprise mindset\n",
      "\n",
      "Exceptional communication, leadership, and people management skills\n",
      "\n",
      "Good judgment with strong problem-solving and decision-making skills\n",
      "\n",
      "Exceptional project management skills, including the ability to effectively utilize resources and manage multiple sub activities in a cross-functional environment\n",
      "\n",
      "Exceptional technical acumen with current and relevant knowledge of BI practices and technologies\n",
      "\n",
      "Good understanding of corporate policies, practices, and organizations\n",
      "\n",
      "Ability to forge strong partnerships with vendors, business partners and internal customers\n",
      "\n",
      "Ability to meet deadlines and produce quality results under pressure\n",
      "\n",
      "High energy self-starter\n",
      "\n",
      "Ability to interact with all levels of management, c-suite executives\n",
      "\n",
      "Excellent interpersonal skills that fosters a positive and collaborative work environment\n",
      "\n",
      "Proficient in business intelligence tools, developing and delivering scorecards, dashboards, trend data in partnership with the BI and Enterprise Architects\n",
      "\n",
      "Strong analytical and problem-solving skills\n",
      "\n",
      "Familiarity with database design concepts including OLAP, OLTP, ESB, system integration and Big-Data\n",
      "\n",
      "Familiarity with n-tier architecture, performance tuning, and application security\n",
      "\n",
      "Spiritual Bona Fide Occupational Qualification (BFOQ): Demonstrates desire and ability to support corporate Biblical and religious goals and participate in regular work related spiritual activities without mental reservation\n",
      ", Servant‚Äôs-heart attitude towards leadership and team relationships\n",
      "\n",
      ", Excellent strategic vision and a global, enterprise mindset\n",
      "\n",
      ", Exceptional communication, leadership, and people management skills\n",
      "\n",
      ", Good judgment with strong problem-solving and decision-making skills\n",
      "\n",
      ", Exceptional project management skills, including the ability to effectively utilize resources and manage multiple sub activities in a cross-functional environment\n",
      "\n",
      ", Exceptional technical acumen with current and relevant knowledge of BI practices and technologies\n",
      "\n",
      ", Good understanding of corporate policies, practices, and organizations\n",
      "\n",
      ", Ability to forge strong partnerships with vendors, business partners and internal customers\n",
      "\n",
      ", Ability to meet deadlines and produce quality results under pressure\n",
      "\n",
      ", High energy self-starter\n",
      "\n",
      ", Ability to interact with all levels of management, c-suite executives\n",
      "\n",
      ", Excellent interpersonal skills that fosters a positive and collaborative work environment\n",
      "\n",
      ", Proficient in business intelligence tools, developing and delivering scorecards, dashboards, trend data in partnership with the BI and Enterprise Architects\n",
      "\n",
      ", Strong analytical and problem-solving skills\n",
      "\n",
      ", Familiarity with database design concepts including OLAP, OLTP, ESB, system integration and Big-Data\n",
      "\n",
      ", Familiarity with n-tier architecture, performance tuning, and application security\n",
      "\n",
      ", Spiritual Bona Fide Occupational Qualification (BFOQ): Demonstrates desire and ability to support corporate Biblical and religious goals and participate in regular work related spiritual activities without mental reservation\n",
      ", Education & Experience:\n",
      "\n",
      ", Undergraduate degree, or equivalent experience in business analysis, new business development, business intelligence, data analytics and reporting\n",
      "\n",
      "Three years experience in information technology, information systems, data management, and/or business management\n",
      "\n",
      "Background in designing and implementing leading Business Intelligence packages such as MSBI, MicroStrategy, Sisense, Pentaho, Tableau, etc.\n",
      "entry --- comScore\n",
      "substring --- You want to be a part of creating a culture within a small team\n",
      "\n",
      "You strive for simplicity even for complex problems, We are the fastest growing health information site on the planet, and the 2nd largest health site in the US (per comScore)!\n",
      "entry --- comScore\n",
      "substring --- We are one of the top-20 largest content publishers on the Internet according to comScore, a leading Internet measurement company, and reach more than 30% of the U.S. population every month.\n",
      "entry --- comScore\n",
      "substring --- Deep understanding of relational database technologies and database development techniques, Experience working in a version-controlled (Git) development environment is strongly preferred\n",
      "\n",
      "Familiarity with media data sets (Nielsen, comScore, Adobe Analytics, social platforms, etc.)\n",
      "entry --- Central Intelligence Agency\n",
      "substring --- If you have ever worked for the Central Intelligence Agency (CIA), you are not eligible for employment at the Peace Corps in any capacity, and you should not apply for employment.\n",
      "entry --- Central Intelligence Agency\n",
      "substring --- If you have ever worked for the Central Intelligence Agency (CIA), you are not eligible for employment at the Peace Corps in any capacity, and you should not apply for employment.\n",
      "entry --- OM Partners\n",
      "substring --- \"[With demand sensing, OM Partners is breaking through some boundaries of classical demand forecasting.\n",
      "entry --- OM Partners\n",
      "substring --- Depending on your experience - hence level of autonomy - it will be required to work from the head office., OM Partners is a software and consulting company focused on Supply Chain Planning.\n",
      "entry --- OM Partners\n",
      "substring --- Master‚Äôs preferredProven experience with data mining, cleansing and manipulations, variable transformations, linear and non-linear multi-variable regression analysis, K-mean and hierarchical cluster analysis, discrete and continuous probability distributions, systems of equations and numerical analysisProven exp using the cloud to do large computationsProven exp joining large data sets from various repositoriesProven experience with 1 or more statistical programming languages: R, Python, Matlab, SAS.Experience with queries to extract and transform data from multiple data sources, including Oracle, Teradata, and SQL ServerExperience utilizing Excel, PowerPoint, and other MS Office softwareExperience with 1 or more statistical analysis software: Minitab, Stata, SPSS, APTKnowledgeable about digital, E-commerce, marketing a plus]\n",
      "\"[With demand sensing, OM Partners is breaking through some boundaries of classical demand forecasting.\n",
      "entry --- OM Partners\n",
      "substring --- , OM Partners is a software and consulting company focused on Supply Chain Planning.\n",
      "entry --- ExxonMobil\n",
      "substring --- \"[ExxonMobil Research and Engineering Company is seeking ambitious and motivated candidates with Engineering, Applied Math, Computer Science or related experience and with an interest in applying data analytics to solve the world‚Äôs toughest energy problems to join our Modeling & Optimization team at the Clinton, NJ campus., Job Role Responsibilities\n",
      "\n",
      ", Knowledge and experience with distributed data processing environments, non-convex optimization, and numerical methods\n",
      "Curious and analytical mindset\n",
      "Demonstrated strong leadership skills\n",
      "Excellent verbal and written communication skills\n",
      "Desire and ability to grow into new process technology areas and learn new skills\n",
      ", Expected Level of Proficiency\n",
      "\n",
      ", M.S./Ph.D.\n",
      "entry --- ExxonMobil\n",
      "substring --- degree in Computer Science, Electrical/Chemical/Mechanical Engineering, Applied Mathematics, Statistics or other related scientific discipline\n",
      "Strong theoretical and applied background in machine learning, statistics, data-mining and optimization\n",
      "Strong communication skills with an ability to interact with a variety of researchers and business partners in different disciplines\n",
      "Demonstrate personal accountability for quality of work\n",
      "Use a measured risk approach in business decisions\n",
      ", ExxonMobil is an Equal Opportunity Employer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry --- ExxonMobil\n",
      "substring --- Experience in Python, Scala, Java, C, C++ or R is required\n",
      "Knowledge of statistics, linear algebra, multiple variable calculus, Fourier analysis or machine learning\n",
      "Experience using one or more of the following software packages: scikit-learn, numpy, pandas, jupyter, matplotlib, scipy, nltk, spacy, keras, tensorflow\n",
      "Experience solving problems using one or more of the following techniques: Regression, Support Vector Machines, Decision trees, random forest, Boosting, PCA, KMeans\n",
      "Experience in using SQL/No SQL databases is an advantage\n",
      "Experience working in Linux and in a High Performance Computing environment is an advantage\n",
      ", Alternate Location: United States : Baytown, Texas || United States : Clinton, New Jersey || United States : Hugoton, Kansas, ExxonMobil is an Equal Opportunity Employer.\n",
      "entry --- ExxonMobil\n",
      "substring --- spatial pattern extraction and analysis in 2D and 3D)., Responsibilities:, Apply statistical analysis, pattern recognition, and machine learning ‚Äì along with domain knowledge and subject-specific models ‚Äì to solve science, engineering, and commercial problems.Contribute to all stages of data analytics or decision modeling projects, including problem formulation, solution development, and product deployment:Translate business-relevant scientific, engineering, and commercial problems into questions that may be address using data analytics.Design experiments and/or run simulations to generate new data in support of analytic studies.Retrieve and combine data from databases, data historians, and/or data lakes; there is a strong emphasis on programming, particularly using scripting languages.Perform exploratory data analysis for quality control and improved understanding.Rigorously and reproducibly build, analyze, and compare statistical and/or machine learning models.Contextualize the results and synthesize them with existing knowledge and/or domain-specific models.Deploy data-analytic products to end-users and/or document data-analytic results in technical reports., Requirements:, PhD in one of the following disciplines: Statistics, Computer Science, or Science or Engineering with significant experience in data analyticsExperience in Python, MATLAB, or R is requiredExcellent communication skills and experience working in a collaborative environment is requiredKnowledge of numerical methods for linear algebra and optimization is an advantageExperience in technical software development is an advantageExperience working in Linux and in a High Performance Computing environment is an advantagePrevious work experience in the oil and gas industry is an advantage, Alternate Location: United States: Houston, Texas || United States: Clinton, New Jersey || United States: Baytown, Texas, ExxonMobil is an Equal Opportunity Employer.\n",
      "entry --- ExxonMobil\n",
      "substring --- AspenTech‚Äôs customer list (over 1700 companies) includes the world‚Äôs leading companies such as ExxonMobil, Shell, Dow Chemicals and BASF.\n",
      "entry --- ExxonMobil\n",
      "substring --- , Alternate Location:, Employment Opportunities, XTO Energy/ExxonMobil is an Equal Opportunity Employer.\n",
      "entry --- MIT\n",
      "substring --- All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status., \n",
      "Nearest Major Market: New Jersey\n",
      "\n",
      "\n",
      "Job Segment: Analytics, Database, Engineer, Electrical, Computer Science, Management, Technology, Engineering]\"\n",
      "\"[Working at MIT offers opportunities, an environment, a culture ‚Äì and benefits ‚Äì that just aren‚Äôt found together anywhere else.\n",
      "entry --- MIT\n",
      "substring --- You'll find us at over 150 locations across the USA; our most distinguished campuses include Stanford, UCLA, Princeton, and MIT.\n",
      "entry --- MIT\n",
      "substring --- MIT Sloan Management Review says that in many organizations, there is a consistent disconnect between data scientists and the executive decision makers ‚Äì that‚Äôs why it‚Äôs time for a new role ‚Äì the data translator., \n",
      "\n",
      "Highmark Health‚Äôs Pharmacy Services Team has identified this exciting new role to play a critical role in bridging the technical expertise of data engineers and data scientists with the operational expertise of our Pharmacy frontline business staff., \n",
      "\n",
      "The incumbent helps to ensure that the deep insights generated through sophisticated analytics translate into impact at scale in the Pharmacy organization.\n",
      "entry --- MIT\n",
      "substring --- Publish research in refereed scientific and technical journals\n",
      "\n",
      "Provide publicly available software for use by the scientific community\n",
      "\n",
      "Support the public use of available software\n",
      "\n",
      "Assist in the organization of computational astrophysics workshops and conferences\n",
      "\n",
      "Assist in the organization of weekly group seminars\n",
      "\n",
      "Present papers at scientific conferences\n",
      "\n",
      "Supervise research conducted by Flatiron research fellows and graduate and undergraduate students from neighboring institutions\n",
      "\n",
      "Mentor summer students and assist in the organization of summer programs\n",
      "\n",
      "Perform any other duties or tasks as assigned or required\n",
      "\n",
      ", MINIMUM QUALIFICATIONS\n",
      "\n",
      ", Education\n",
      "\n",
      ", Ph.D. in a related field\n",
      "\n",
      ", Experience\n",
      "\n",
      ", 4 - 10 years of graduate and postgraduate research experience in computer science, machine learning and statistics\n",
      "\n",
      "A record of excellence in scientific publication\n",
      "\n",
      ", Required Application Materials\n",
      "\n",
      ", CV\n",
      "\n",
      "Research statement outlining both past research accomplishments and a vision for scientific research at the Flatiron Institute\n",
      "\n",
      "Three (3) letters of recommendation submitted confidentially by the letter writers to astro@simonsfoundation.org\n",
      "\n",
      ", Deadline\n",
      "\n",
      ", All applications must be submitted no later than November 15, 2017.\n",
      "\n",
      ", THE SIMONS FOUNDATION'S DIVERSITY COMMITMENT\n",
      "\n",
      ", Many of the greatest ideas and discoveries come from a diverse mix of minds, backgrounds and experiences, and we are committed to cultivating an inclusive work environment.\n",
      "entry --- MIT\n",
      "substring --- 10% travel required., \n",
      "\n",
      "Travel: 10% travel required., \n",
      "\n",
      "Internal use only: reference code lhrs4262, \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- If you‚Äôre searching for a company that‚Äôs dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment ‚Äì apply now., \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- If you‚Äôre searching for a company that‚Äôs dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment ‚Äì apply now., \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- This position will be responsible for building predictive analytics models using various machine learning techniques., \n",
      "\n",
      "Learning & Development Opportunities, \n",
      "\n",
      "The employee will have the opportunities to lead a customer co-innovation project as a data scientist; to be able to directly interface with customer and understand the requirements, and to be able to apply leading-edge techniques to solve challenging high-value IoT business requirements., \n",
      "\n",
      "Work Experience, \n",
      "\n",
      "Ideally, the Candidate should have professional experiences in the following:, Data mining and machine learning techniquesStatistics, applied mathematics or operations research backgroundR, Python, SQL and other programming languages, \n",
      "\n",
      "Education & Qualifications / Skills & Competencies, \n",
      "\n",
      "Master or above degree in a related field is desirable, \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- \"[Working at MIT offers opportunities, an environment, a culture ‚Äì and benefits ‚Äì that just aren‚Äôt found together anywhere else.\n",
      "entry --- MIT\n",
      "substring --- \"[\n",
      "Experience with applying advanced analytic techniques, including natural language processing and machine learning\n",
      "Experience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\n",
      "Experience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\n",
      "Secret clearance\n",
      "BA or BS degree\n",
      ", \n",
      "TS/SCI clearance preferred\n",
      "BA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\n",
      "]\"\n",
      "\"[\n",
      "Experience with applying advanced analytic techniques, including natural language processing and machine learning\n",
      "Experience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\n",
      "Experience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\n",
      "Secret clearance\n",
      "BA or BS degree\n",
      ", \n",
      "TS/SCI clearance preferred\n",
      "BA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\n",
      "]\"\n",
      "\"[\n",
      "Experience with applying advanced analytic techniques, including natural language processing and machine learning\n",
      "Experience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\n",
      "Experience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\n",
      "Ability to obtain a security clearance\n",
      "BA or BS degree\n",
      ", \n",
      "TS/SCI clearance preferred\n",
      "BA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\n",
      "]\"\n",
      "\"[\n",
      "Experience with applying advanced analytic techniques, including natural language processing and machine learning\n",
      "Experience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\n",
      "Experience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\n",
      "Ability to obtain a security clearance\n",
      "BA or BS degree\n",
      ", \n",
      "TS/SCI clearance preferred\n",
      "BA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\n",
      "]\"\n",
      "\"[\n",
      "Experience with applying advanced analytic techniques, including natural language processing and machine learning\n",
      "Experience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\n",
      "Experience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\n",
      "Ability to obtain a security clearance\n",
      "BA or BS degree\n",
      ", \n",
      "TS/SCI clearance preferred\n",
      "BA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\n",
      "]\"\n",
      "[Apply a variety of analytical techniques to solve customer challenges to include data mining, statistical models, predictive analytics, optimization, risk analysis, and data visualizationPerform original research, development, test and evaluation, and demonstration of advanced analytic capabilitiesBuild and test prototypes in MITRE, government labs, and commercial cloud environmentsPerform independent reviews of contractor proposed architectures, designs and productsApply state of the art techniques, using multiple programming languages and development environments and open source code to drive advances in mission capabilities, Bachelor‚Äôs degree in data science or a related field (e.g.\n",
      "entry --- MIT\n",
      "substring --- If you‚Äôre searching for a company that‚Äôs dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment ‚Äì apply now., \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- If you‚Äôre searching for a company that‚Äôs dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment ‚Äì apply now., \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- You will conduct original research and publish results in academic and industry conferences., \n",
      "\n",
      "Requirements, \n",
      "\n",
      "PhD in Statistics or a closely related field, or 5+ years of equivalent industry experience in A/B testing and digital experimentation\n",
      "\n",
      "Strong research interest and experience with design of experiments, randomized control trials, and inference, particularly aspects of high throughput testing such as multiple hypothesis testing, sequential testing, robustness, data mining of experiments\n",
      "\n",
      "Experience with Python and/or Java preferred\n",
      "\n",
      "Some experience in math education such as teaching, teaching assistantships, consulting, or conference talks, \n",
      "\n",
      "PhD in Statistics or a closely related field, or 5+ years of equivalent industry experience in A/B testing and digital experimentation, \n",
      "\n",
      "Strong research interest and experience with design of experiments, randomized control trials, and inference, particularly aspects of high throughput testing such as multiple hypothesis testing, sequential testing, robustness, data mining of experiments, \n",
      "\n",
      "Experience with Python and/or Java preferred, \n",
      "\n",
      "Some experience in math education such as teaching, teaching assistantships, consulting, or conference talks, \n",
      "\n",
      "Some of our public work:, \n",
      "\n",
      "Papers, \n",
      "\n",
      "Stats Engine White Paper - http://pages.optimizely.com/rs/optimizely/images/stats_engine_technical_paper.pdf\n",
      "\n",
      "Stats Engine Academic Paper - https://arxiv.org/abs/1512.04922, \n",
      "\n",
      "Stats Engine White Paper - http://pages.optimizely.com/rs/optimizely/images/stats_engine_technical_paper.pdf, \n",
      "\n",
      "Stats Engine Academic Paper - https://arxiv.org/abs/1512.04922, \n",
      "\n",
      "Blog Posts, \n",
      "\n",
      "Bayesian vs Frequentist Statistics https://blog.optimizely.com/2015/03/04/bayesian-vs-frequentist-statistics/\n",
      "\n",
      "Optimizely‚Äôs Stats Engine https://blog.optimizely.com/2015/01/20/statistics-for-the-internet-age-the-story-behind-optimizelys-new-stats-engine/\n",
      "\n",
      "Approximate Counting and Statistical Significance https://medium.com/engineers-optimizely/approximate-counting-and-statistical-significance-two-great-ideas-that-dont-play-nice-2bd643287644#.6uyxiytlr, \n",
      "\n",
      "Bayesian vs Frequentist Statistics https://blog.optimizely.com/2015/03/04/bayesian-vs-frequentist-statistics/, \n",
      "\n",
      "Optimizely‚Äôs Stats Engine https://blog.optimizely.com/2015/01/20/statistics-for-the-internet-age-the-story-behind-optimizelys-new-stats-engine/, \n",
      "\n",
      "Approximate Counting and Statistical Significance https://medium.com/engineers-optimizely/approximate-counting-and-statistical-significance-two-great-ideas-that-dont-play-nice-2bd643287644#.6uyxiytlr, \n",
      "\n",
      "Conference Talks, \n",
      "\n",
      "CODE @ MIT 2016: A/B Testing in a Changing World\n",
      "\n",
      "INFORMS 2015: Can I Take a Peek?\n",
      "entry --- MIT\n",
      "substring --- Continuous Monitoring of A/B Tests\n",
      "\n",
      "CODE @ MIT 2014: Can I Take a Peek?\n",
      "entry --- MIT\n",
      "substring --- Continuous Monitoring of A/B Tests, \n",
      "\n",
      "CODE @ MIT 2016: A/B Testing in a Changing World, \n",
      "\n",
      "INFORMS 2015: Can I Take a Peek?\n",
      "entry --- MIT\n",
      "substring --- Continuous Monitoring of A/B Tests, \n",
      "\n",
      "CODE @ MIT 2014: Can I Take a Peek?\n",
      "entry --- MIT\n",
      "substring --- We are one of the World's Most 50 Innovative Companies according to MIT, and one of Forbes Most Promising Companies.\n",
      "entry --- MIT\n",
      "substring --- If you‚Äôre searching for a company that‚Äôs dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment ‚Äì apply now., \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- ), XSA or XS engine\n",
      "\n",
      "SAP UI5\n",
      "\n",
      "Development in Cloud, Cloud Foundry including understanding of containers, microservices, \n",
      "\n",
      "#SAPIBSCareers, \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT, \n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- Led by scientific experts from MIT, Harvard, Mayo Clinic and UCSD, and successful drug developers, informaticians, and company builders, Engine is working on multiple programs and therapeutic areas and growing rapidly across US and Asia., The Bioinformatics & Data Scientist will analyze multi-dimensional biological and genomics data, enhance algorithms and develop novel methods for the utilization in Engine‚Äôs analytics platform that combines advanced system biology analytics with genomics data science and machine learning for accelerated drug discovery and biomarker identification.\n",
      "entry --- MIT\n",
      "substring --- Founded by Murali Aravamudan and Venky Soundararajan, Ph.D., nference is led by a multidisciplinary team of serial entrepreneurs from the tech and biotech worlds and Ph.D‚Äôs in Biology/Genomics from Massachusetts Institute of Technology (MIT) and Harvard Medical School.\n",
      "entry --- MIT\n",
      "substring --- Experience with, MATLAB or a similar mathematical programming language is desirable., Experience or research work related to satellite orbits is particularly, desirable., MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.\n",
      "entry --- MIT\n",
      "substring --- \"[Epic Care is seeking a Medical Systems Data Analyst to join our team to develop or apply mathematical or strategical theory and methods to collect, organize, interpret and summarize numerical data to provide useable information as directed by the Chief Administrative Officer., JOB DUITES INCLUDE BUT ARE NOT LIMITED TO:, In collaboration with others, develop and maintain databases and data systems necessary for projects and department functions.\n",
      "entry --- MIT\n",
      "substring --- , and\n",
      "\n",
      ", Only technical issues will be monitored through the below inbox:\n",
      "\n",
      ", recruiting.support@ imerys.com\n",
      "\n",
      "\n",
      "\n",
      "PLEASE DO NOT SUBMIT RESUMES OR APPLICATIONS TO THIS EMAIL, AS THEY WILL NOT BE REVIEWED.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Experience with computer scripting and programming\n",
      "\n",
      "Experience with human-subjects research and understanding of HIPAA\n",
      "\n",
      "Experience with ticketing systems\n",
      "\n",
      "Experience with statistical-analysis approaches\n",
      "\n",
      "Experience with statistical software in R/Python\n",
      "\n",
      ", THE SIMONS FOUNDATION'S DIVERSITY COMMITMENT\n",
      "\n",
      "\n",
      "\n",
      "Many of the greatest ideas and discoveries come from a diverse mix of minds, backgrounds and experiences, and we are committed to cultivating an inclusive work environment.\n",
      "entry --- MIT\n",
      "substring --- Strong organizational skills and the ability to operate independently are required.US Person, Spreadsheet tools, e.g., MS ExcelDatabase systems (SQL and NO SQL based)Communication and visualizationDescriptive statistics and exploratory data analysisLanguages: R, Python, HTML, Javascript, SQL, C/C++Knowledge of business planning / financial management, applied analytics, and manufacturing operations, preferably in an Aerospace application.Strong continuous improvement background, such as Lean Six Sigma training preferredDemonstrated ability to learn new programs and approach new problems in an efficient methodical manner]\n",
      "\n",
      "\"[Use quantitative methodology and data insights to influence the direction of our product development and business decisions\n",
      "\n",
      "Partner with our product teams to define goals and identify key metrics for existing features and new releases\n",
      "\n",
      "Use data to discover and evaluate new product opportunities\n",
      "\n",
      "Mine our underlying data for trends in user behavior\n",
      "\n",
      "Identify gaps in our existing data infrastructure and develop corresponding solutions\n",
      "\n",
      "Develop data sets to empower operational and exploratory analyses\n",
      "\n",
      "Collaborate cross-functionally with Product, Data Science, Engineering, Marketing, and Customer Success to design, execute and iterate on product experiments\n",
      "\n",
      "Work with business intelligence tools such as Heap, Tableau, or Google Analytics to classify user populations and identify product usage trends\n",
      "\n",
      "Dive deep into raw data sets to identify user behaviors\n",
      "\n",
      "Build connectors between our existing data sets, business intelligence tools, and other systems to provide an integrated view of user behavior\n",
      "\n",
      "Dive deep into a raw data set to identify behavioral inflection points, and propose experiments to influence our users to a desired outcome\n",
      "\n",
      "Work cross functionally to construct, monitor, and measure a usability experiment\n",
      "\n",
      "Build a culture where we ask data-driven business questions, and update our company and product strategies based on the answers, Proven experience with using quantitative analysis to influence business and product decisions\n",
      "\n",
      "The ability to clearly and effectively communicate the business impact & results of complex analyses\n",
      "\n",
      "Minimum of 3 years experience writing production datasets OR building internal/production data tools for ETL, experimentation, or exploration in Python\n",
      "\n",
      "Bachelor's degree in Computer Science, Engineering or related field, or equivalent training, fellowship, or work experience\n",
      "\n",
      "A solid grasp of common statistical applications and methods (experimentation, probabilities, regression)\n",
      "\n",
      "Experience in software engineering a plusExperience in predictive modeling in big data environment is a plus\n",
      "\n",
      "\n",
      "OUR COMMITMENT TO DIVERSITY AND INCLUSION: At Hearsay we believe that diverse teams are the best teams.\n",
      "entry --- MIT\n",
      "substring --- Desired skills: MATLAB, Python, or C++ programming experience is strongly desired., \n",
      "\n",
      "MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.\n",
      "entry --- MIT\n",
      "substring --- IQVIA, Symphony, MMITDeep knowledge in and experience with at least two of GSK U.S. Pharma relevant commercial areas, Primary Care (particularly Respiratory), Specialty (Immunology, Oncology), VaccinesSustained functional leadership of teams, and success in achieving high-performing team levelsRecent experience in managing onshore/ offshore analytics workbench and data management vendorsOutstanding communication and presentation skills as evidenced through impactful senior management presentations, conference presentations, and/ or publications\n",
      ", Understanding of the business impact of diversity & inclusionProven and advanced collaboration skills, and cultural sensitivityStrong business acumenDemonstrated ability to influence senior commercial leadership and confidently defend informed recommendationsAbility to work effectively across a matrix environment and influence without formal authorityAbility to lead through change and inspire agility/flexibility amongst teamExperience fostering personal development of direct reports\n",
      ", Why GSK?\n",
      "entry --- MIT\n",
      "substring --- Mathematics, Statistics, Finance, Economics)\n",
      "\n",
      "Exemplary stakeholder management & ability to effectively communicate complex analyses to internal and external stakeholders at all levels\n",
      "\n",
      "Program management experience with focus on process and detail\n",
      "\n",
      "Substantial experience with analytical tools and techniques, data management and stewardship\n",
      "\n",
      "Contagious intellectual curiosity\n",
      "\n",
      "\n",
      "Job Segment: Analytics, Data Analyst, SAP, ERP, Product Development, Management, Data, Technology, Research, Customer Insights, Data Warehouse, Machine Learning, \n",
      "\n",
      "Job Segment: Analytics, Data Analyst, SAP, ERP, Product Development, Management, Data, Technology, Research, Customer Insights, Data Warehouse, Machine Learning, \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- MIT\n",
      "substring --- You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.\n",
      "entry --- MIT\n",
      "substring --- You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.\n",
      "entry --- MIT\n",
      "substring --- You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.\n",
      "entry --- MIT\n",
      "substring --- You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.\n",
      "entry --- MIT\n",
      "substring --- and business transformationMeet travel requirements, up to 50%, SET YOURSELF APART: Preferred Skills: , Exceptional presentation skills ‚Äì ability to convey technology and business value propositionsStrong Data Management Technology backgroundValue based constructs5 years of experience interacting with clients of all levels to review expected outputs, applicability to business challenges, and model measurementWell connected with cutting-edge analytics techniques and be confident about how to apply them to generate insights and recommendations3 years of experience guiding the data formulation process and exploratory data analysis5 years of experience guiding and managing a team of practitioners to execute analytics solutions, both onshore and offshoreProven ability to manage multiple simultaneous work streams and shift / adjust resources to achieve optimal resultsEvidence of thought leadership in defining innovative analytics within multiple complex applications spanning marketing, risk, and cost reductionExcellent communication skills to drive thought-provoking dialogs with senior clients, Professional Skill Requirements, Proven ability to build, manage and foster a team-oriented environmentProven ability to work creatively and analytically in a problem-solving environmentDesire to work in an information systems environmentExcellent communication (written and oral) and interpersonal skillsExcellent leadership and management skills, OUR COMMITMENT TO YOU, Your entrepreneurial spirit and vision will be rewarded, and your success will fuel opportunities for career advancement.You will make a difference for some pretty impressive clients.\n",
      "entry --- MIT\n",
      "substring --- You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.You will have access to distinctive analytics assets that we use to accelerate delivering value to our clients including more than 550 analytics assets underpinned by a strong information management and BI technology foundation.\n",
      "entry --- MIT\n",
      "substring --- You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Experience with Java, SQL and NoSQL databases, data analytics (such as pattern recognition & change detection) is highly desired., Position will require candidate to acquire and maintain a Secret clearance., MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.\n",
      "entry --- MIT\n",
      "substring --- Our customers include some of the nation‚Äôs largest hospitals including Stanford, UCSF, NewYork-Presbyterian, the University of Texas MD Anderson Cancer Center, and more\n",
      "Our team includes veteran executives and the brightest minds from Google, McKinsey, Stanford, MIT, Duke, Berkeley, UIUC, and more.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Experience with Java, SQL and NoSQL databases, data analytics (such as pattern recognition & change detection) is highly desired., \n",
      "\n",
      "Requisition ID: 25608, For Benefits Information, click http://hrweb.mit.edu/benefits, MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.\n",
      "entry --- MIT\n",
      "substring --- Founded by MIT roboticists who had the vision of making practical robots a reality.\n",
      "entry --- MIT\n",
      "substring --- Example: JOHN SMITH\n",
      "\n",
      "NOTE: Use correct grammar for Names with multiple cases.\n",
      "entry --- MIT\n",
      "substring --- Excellent written and verbal communication and interpersonal skills, able to effectively collaborate with technical and business partners\n",
      "\n",
      "Strong self-drive to teach, learn from, empower, and facilitate your team\n",
      "\n",
      "Sense of humor (everyone says this, but we really mean it)\n",
      "\n",
      "\n",
      "OUR COMMITMENT TO DIVERSITY AND INCLUSION: At Hearsay we believe that diverse teams are the best teams.\n",
      "entry --- MIT\n",
      "substring --- preferred\n",
      "\n",
      "Comfortable working in a GNU Linux/Unix environment\n",
      "\n",
      "Effective communication skills, focusing on presentation of technical information to non-technical team members\n",
      "\n",
      "Adept in cross-team collaboration, with the ability to work autonomously, as well as with colleagues at all levels in the organization\n",
      "\n",
      "Previous travel industry experience is a plus, \n",
      "\n",
      "SAP'S DIVERSITY COMMITMENT\n",
      "\n",
      "\n",
      "To harness the power of innovation, SAP invests in the development of its diverse employees.\n",
      "entry --- Ochsner Health System\n",
      "substring --- Come make a difference at Ochsner Health System and discover your future today!\n",
      "entry --- Ochsner Health System\n",
      "substring --- iO is an innovation lab within Ochsner Health System, Louisiana‚Äôs largest not-for-profit health system.\n",
      "entry --- Ochsner Health System\n",
      "substring --- , Ochsner Health System endeavors to make our site accessible to all users.\n",
      "entry --- Ochsner Health System\n",
      "substring --- Come make a difference at Ochsner Health System and discover your future today!\n",
      "entry --- Ochsner Health System\n",
      "substring --- iO is an innovation lab within Ochsner Health System, Louisiana‚Äôs largest not-for-profit health system.\n",
      "entry --- Ochsner Health System\n",
      "substring --- , Ochsner Health System endeavors to make our site accessible to all users.\n",
      "entry --- Raytheon\n",
      "substring --- , Affirmative Action Policy Statement]\"\n",
      "[Raytheon is an Equal Opportunity/Affirmative Action employer.\n",
      "entry --- Raytheon\n",
      "substring --- [Raytheon is an Equal Opportunity/Affirmative Action employer.\n",
      "entry --- Raytheon\n",
      "substring --- [Raytheon is an Equal Opportunity/Affirmative Action employer.\n",
      "entry --- Raytheon\n",
      "substring --- [Raytheon is an Equal Opportunity/Affirmative Action employer.\n",
      "entry --- Raytheon\n",
      "substring --- We are seeking an entrepreneurial Senior Data Scientist capable of working across functional and business areas with minimal supervision in order to support the application of data science methods and statistical techniques to data for internal use at Raytheon.\n",
      "entry --- Raytheon\n",
      "substring --- At Raytheon, we work together as one global team creating trusted, innovative solutions to make the world a safer place.\n",
      "entry --- Raytheon\n",
      "substring --- We‚Äôre inspired by a noble mission that‚Äôs shared by Raytheon employees around the globe and an inclusive culture that empowers employees and celebrates their contributions.\n",
      "entry --- Raytheon\n",
      "substring --- AWS, Azure, GCP, \n",
      "\n",
      "\n",
      "Required Education:\n",
      "\n",
      ", Bachelor's or higher degree in Computer Science, Engineering, Mathematics, Statistics, Econometrics or equivalent discipline and 6 years of relevant experience, \n",
      "\n",
      "\n",
      "Desired Education:\n",
      "\n",
      ", Industry or University Data Analytics / Data Science Certifications, Raytheon is an Equal Opportunity/Affirmative Action employer.\n",
      "entry --- Google\n",
      "substring --- The Google AI Residency Program will have 3 start dates over the course of 5 months, from June to October 2019.\n",
      "entry --- Google\n",
      "substring --- Exact dates are yet to be determined., \n",
      "\n",
      "About the Program:\n",
      "\n",
      "The Google AI Residency Program is a 12-month role designed to advance your career in machine learning research.\n",
      "entry --- Google\n",
      "substring --- The goal of the residency is to help residents become productive and successful AI researchers., As part of this program, Residents collaborate with distinguished scientists from various Google AI teams working on machine learning applications and problems.\n",
      "entry --- Google\n",
      "substring --- If a candidate requires work authorization for a location, Google will explore the available options on a case-by-case basis., Your application should show evidence of proficiency in programming and in prerequisite courses (e.g., machine learning, user-centered interfaces or applications, data science, mathematical analysis).\n",
      "entry --- Google\n",
      "substring --- Alternatively, summarize and critique a machine learning paper you have read that you found interesting., \n",
      "\n",
      "**Although cover letters are optional for most job applications at Google (as noted on the website), it is a mandatory component for this application.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- The Google AI Residency Program will have 3 start dates over the course of 5 months, from June to October 2019.\n",
      "entry --- Google\n",
      "substring --- Exact dates are yet to be determined., \n",
      "\n",
      "About the Program:\n",
      "\n",
      "The Google AI Residency Program is a 12-month role designed to advance your career in machine learning research.\n",
      "entry --- Google\n",
      "substring --- The goal of the residency is to help residents become productive and successful AI researchers., As part of this program, Residents collaborate with distinguished scientists from various Google AI teams working on machine learning applications and problems.\n",
      "entry --- Google\n",
      "substring --- If a candidate requires work authorization for a location, Google will explore the available options on a case-by-case basis., Your application should show evidence of proficiency in programming and in prerequisite courses (e.g., machine learning, user-centered interfaces or applications, data science, mathematical analysis).\n",
      "entry --- Google\n",
      "substring --- Alternatively, summarize and critique a machine learning paper you have read that you found interesting., \n",
      "\n",
      "**Although cover letters are optional for most job applications at Google (as noted on the website), it is a mandatory component for this application.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- The Google AI Residency Program will have 3 start dates over the course of 5 months, from June to October 2019.\n",
      "entry --- Google\n",
      "substring --- Exact dates are yet to be determined., \n",
      "\n",
      "About the Program:\n",
      "\n",
      "The Google AI Residency Program is a 12-month role designed to advance your career in machine learning research.\n",
      "entry --- Google\n",
      "substring --- The goal of the residency is to help residents become productive and successful AI researchers., As part of this program, Residents collaborate with distinguished scientists from various Google AI teams working on machine learning applications and problems.\n",
      "entry --- Google\n",
      "substring --- If a candidate requires work authorization for a location, Google will explore the available options on a case-by-case basis., Your application should show evidence of proficiency in programming and in prerequisite courses (e.g., machine learning, user-centered interfaces or applications, data science, mathematical analysis).\n",
      "entry --- Google\n",
      "substring --- Alternatively, summarize and critique a machine learning paper you have read that you found interesting., \n",
      "\n",
      "**Although cover letters are optional for most job applications at Google (as noted on the website), it is a mandatory component for this application.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- The Google AI Residency Program will have 3 start dates over the course of 5 months, from June to October 2019.\n",
      "entry --- Google\n",
      "substring --- Exact dates are yet to be determined., \n",
      "\n",
      "About the Program:\n",
      "\n",
      "The Google AI Residency Program is a 12-month role designed to advance your career in machine learning research.\n",
      "entry --- Google\n",
      "substring --- The goal of the residency is to help residents become productive and successful AI researchers., As part of this program, Residents collaborate with distinguished scientists from various Google AI teams working on machine learning applications and problems.\n",
      "entry --- Google\n",
      "substring --- If a candidate requires work authorization for a location, Google will explore the available options on a case-by-case basis., Your application should show evidence of proficiency in programming and in prerequisite courses (e.g., machine learning, user-centered interfaces or applications, data science, mathematical analysis).\n",
      "entry --- Google\n",
      "substring --- Alternatively, summarize and critique a machine learning paper you have read that you found interesting., \n",
      "\n",
      "**Although cover letters are optional for most job applications at Google (as noted on the website), it is a mandatory component for this application.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- Working knowledge of Google docs, calendars, and sheets.\n",
      "entry --- Google\n",
      "substring --- The Data Scientist will be responsible for leveraging BJ‚Äôs wealth of data using advanced statistical methods., \n",
      "\n",
      "Major Tasks, Responsibilities, and Key Accountabilities, \n",
      "\n",
      "Extract actionable insights from complex datasets using data mining, statistics, and database techniques to measure/understand/improve member acquisition/engagement KPIs\n",
      "\n",
      "Apply Data Science methods along with project management skills to assist in developing new approaches to member acquisition, engagement and promotion\n",
      "\n",
      "Work cross functionally with stakeholders to ensure data-driven answers are provided and recommended\n",
      "\n",
      "Build reports, dashboards, and other analytical tools to help communicate the state of business\n",
      "\n",
      "Works with and streamlines established data warehouses, production data, and available tools to build strategic datasets in support of key initiatives\n",
      "\n",
      "Establishes and systematically performs processes to assess and validate data accuracy, \n",
      "\n",
      "Qualifications, \n",
      "\n",
      "Working knowledge on machine learning and statistical methods (Supervised/unsupervised learning, Linear/logistic Regression, Random Forests, Lift Modeling, Linear/nonlinear Programming, Clustering, ARIMA, Neural Networks, Variable selection/feature engineering, hypothesis testing)\n",
      "\n",
      "Experience developing and productionizing machine learning models and application of statistical methods in Python(pandas/numpy/sklearn/scipy)\n",
      "\n",
      "Experience with data ETL in at least one of the following scripting language: Python/R/SAS/SQL\n",
      "\n",
      "Experience with Cloud computing environment preferred (AWS/Azure/Google Cloud)\n",
      "\n",
      "Strong analytics background with the ability to apply analytical skills to business problems\n",
      "\n",
      "Minimum 2 years of experience managing data science/analytics projects\n",
      "\n",
      "Bachelor‚Äôs or Master‚Äôs degree in Computer Science, Mathematics, Statistics, Engineering or a related field, \n",
      "\n",
      "Environmental Job Conditions, \n",
      "\n",
      "Most tasks are performed while seated indoors at a personal computer.\n",
      "entry --- Google\n",
      "substring --- Will accept Bachelor‚Äôs Degree in Mathematics/Statistics plus equivalent experience.Minimum Years of Experience: 3 to 5 years., Google Suite and Microsoft Office, with advanced Microsoft Excel.Working knowledge of SQL.\n",
      "entry --- Google\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Google\n",
      "substring --- Additional responsibilities as needed by manager or supervisor., \n",
      "\n",
      "3 years of experience in an agency or in-house analytics role, ideally in marketing\n",
      "\n",
      "Masters Degree in relevant field\n",
      "\n",
      "Strong understanding of marketing and customer segmentation tactics\n",
      "\n",
      "Experience in one or more marketing channels (email, direct mail, FB), with understanding of how to measure & optimize\n",
      "\n",
      "Intermediate to advanced-level experience in Google Analytics or similar web analytics platform\n",
      "\n",
      "Intermediate to advanced-level experience in coding in Python and Javascript in order to assist in creating new data products that result out of work in predictive models, surveys, & A/B tests\n",
      "\n",
      "Intermediate to advanced-level experience in Excel and 3rd party measurement platform\n",
      "\n",
      "Intermediate to advanced-level experience in SQL and Tableau/other BI tools\n",
      "\n",
      "Experience setting up and distilling insights from experimental lift testing (Creative, A/B, segment)\n",
      "\n",
      "Familiarity with correlation analysis, t-testing, and regression-based forecasting preferred]\"\n",
      "\"[ESAC, Inc., a global provider of data management, informatics research and healthcare IT solutions to government, academic and research institutions is looking for a Software Engineer/ Senior Software Engineer who can contribute to our high-profile projects in the healthcare and bioinformatics domain.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals; ability to work with the business to understand available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Provide assistance, and resolve problems, using solid problem-solving skills, verbal/written communication\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Understanding of development practices such as testing, code design, complexity, and code optimization\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals; ability to work with the business to understand available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Provide assistance, and resolve problems, using solid problem-solving skills, verbal/written communication\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Understanding of development practices such as testing, code design, complexity, and code optimization\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals; ability to work with the business to understand available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Provide assistance, and resolve problems, using solid problem-solving skills, verbal/written communication\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Understanding of development practices such as testing, code design, complexity, and code optimization\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals; ability to work with the business to understand available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Provide assistance, and resolve problems, using solid problem-solving skills, verbal/written communication\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Understanding of development practices such as testing, code design, complexity, and code optimization\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- So, bring your creativity and pioneering spirit to KPMG Lighthouse., \n",
      "\n",
      "KPMG is currently seeking a Director to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Lead workshops, innovation sessions with clients, multi-disciplinary, and cross-functional teams to identify business opportunities and artificial intelligence solutions utilizing processes and best practices to plan, lead, and execute delivery of artificial intelligence engagements across different areas (risk management, financial services, mergers and acquisitions, and public policy)\n",
      "\n",
      "Lead in a fast-paced and dynamic environment utilizing virtual and face-to-face interactions; Manage complex workstreams, expectations, budgets, deliverables, and multiple responsibilities using structured approaches for operational excellence and communicating results to executive level audiences\n",
      "\n",
      "Work with clients to discover data sources, and create data requests; Lead the ETL process to ingest structured data and annotation processes to enrich unstructured data; Leverage a variety of data sources (social media, news, internal/external documents, images, video, voice, emails, financial data and operational data)\n",
      "\n",
      "Leverage a variety of tools and approaches to solve complex business objectives, from Statistical Natural Language Processing, Information Retrieval/Extraction, Machine Learning/ Deep Learning, Image Processing, Rules Engines, Knowledge Graphs and Semantic Search\n",
      "\n",
      "Plan and manage engagement objectives and key deliverables using analytics processes to mitigate risks in data, modeling, validation and delivery while working with team members to capture assumptions, risks, and develop approaches to mitigate issues\n",
      "\n",
      "Refactor, deploy, and validate models; work with clients iteratively to validate performance metrics, and sample output to drive towards a business-first solution utilizing APIs, platforms, containers, multi-threading and distributed processing to achieve throughput goals, \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "Minimum of ten years of experience leading teams of at least ten data scientists, engineers, and other data & analytics professionals, including business development, requirements gathering, people development, and quality management using analytics and software development processes for natural language processing, machine learning on unstructured data, and/or information retrieval; Multidisciplinary backgrounds\n",
      "\n",
      "Master's degree from an accredited college/university in Computer Science, Engineering, or related fields; PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to work with the business to understand business goals to create an artificial intelligence solution and an accompanying business case that meets the business objectives and business constraints; With expertise in delivering projects using leading processes including strong knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing, and development practices (testing, code design, complexity, and code optimization); Ability to discuss mathematical formulations, alternatives, and impact on modeling approach\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly; Work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- So, bring your creativity and pioneering spirit to KPMG Lighthouse., \n",
      "\n",
      "KPMG is currently seeking a Director to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Lead workshops, innovation sessions with clients, multi-disciplinary, and cross-functional teams to identify business opportunities and artificial intelligence solutions utilizing processes and best practices to plan, lead, and execute delivery of artificial intelligence engagements across different areas (risk management, financial services, mergers and acquisitions, and public policy)\n",
      "\n",
      "Lead in a fast-paced and dynamic environment utilizing virtual and face-to-face interactions; Manage complex workstreams, expectations, budgets, deliverables, and multiple responsibilities using structured approaches for operational excellence and communicating results to executive level audiences\n",
      "\n",
      "Work with clients to discover data sources, and create data requests; Lead the ETL process to ingest structured data and annotation processes to enrich unstructured data; Leverage a variety of data sources (social media, news, internal/external documents, images, video, voice, emails, financial data and operational data)\n",
      "\n",
      "Leverage a variety of tools and approaches to solve complex business objectives, from Statistical Natural Language Processing, Information Retrieval/Extraction, Machine Learning/ Deep Learning, Image Processing, Rules Engines, Knowledge Graphs and Semantic Search\n",
      "\n",
      "Plan and manage engagement objectives and key deliverables using analytics processes to mitigate risks in data, modeling, validation and delivery while working with team members to capture assumptions, risks, and develop approaches to mitigate issues\n",
      "\n",
      "Refactor, deploy, and validate models; work with clients iteratively to validate performance metrics, and sample output to drive towards a business-first solution utilizing APIs, platforms, containers, multi-threading and distributed processing to achieve throughput goals, \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "Minimum of ten years of experience leading teams of at least ten data scientists, engineers, and other data & analytics professionals, including business development, requirements gathering, people development, and quality management using analytics and software development processes for natural language processing, machine learning on unstructured data, and/or information retrieval; Multidisciplinary backgrounds\n",
      "\n",
      "Master's degree from an accredited college/university in Computer Science, Engineering, or related fields; PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to work with the business to understand business goals to create an artificial intelligence solution and an accompanying business case that meets the business objectives and business constraints; With expertise in delivering projects using leading processes including strong knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing, and development practices (testing, code design, complexity, and code optimization); Ability to discuss mathematical formulations, alternatives, and impact on modeling approach\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly; Work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; US Citizenship is required, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- Expertise in delivering analytics projects using leading processes including expert knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Knowledge of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms such as Google Cloud, Azure, and AWS; Ability to pick up new languages and technologies quickly; Ability to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- So, bring your creativity and pioneering spirit to KPMG Lighthouse., \n",
      "\n",
      "KPMG is currently seeking a Director to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Lead workshops, innovation sessions with clients, multi-disciplinary, and cross-functional teams to identify business opportunities and artificial intelligence solutions utilizing processes and best practices to plan, lead, and execute delivery of artificial intelligence engagements across different areas (risk management, financial services, mergers and acquisitions, and public policy)\n",
      "\n",
      "Lead in a fast-paced and dynamic environment utilizing virtual and face-to-face interactions; Manage complex workstreams, expectations, budgets, deliverables, and multiple responsibilities using structured approaches for operational excellence and communicating results to executive level audiences\n",
      "\n",
      "Work with clients to discover data sources, and create data requests; Lead the ETL process to ingest structured data and annotation processes to enrich unstructured data; Leverage a variety of data sources (social media, news, internal/external documents, images, video, voice, emails, financial data and operational data)\n",
      "\n",
      "Leverage a variety of tools and approaches to solve complex business objectives, from Statistical Natural Language Processing, Information Retrieval/Extraction, Machine Learning/ Deep Learning, Image Processing, Rules Engines, Knowledge Graphs and Semantic Search\n",
      "\n",
      "Plan and manage engagement objectives and key deliverables using analytics processes to mitigate risks in data, modeling, validation and delivery while working with team members to capture assumptions, risks, and develop approaches to mitigate issues\n",
      "\n",
      "Refactor, deploy, and validate models; work with clients iteratively to validate performance metrics, and sample output to drive towards a business-first solution utilizing APIs, platforms, containers, multi-threading and distributed processing to achieve throughput goals, \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "Minimum of ten years of experience leading teams of at least ten data scientists, engineers, and other data & analytics professionals, including business development, requirements gathering, people development, and quality management using analytics and software development processes for natural language processing, machine learning on unstructured data, and/or information retrieval; Multidisciplinary backgrounds\n",
      "\n",
      "Master's degree from an accredited college/university in Computer Science, Engineering, or related fields; PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to work with the business to understand business goals to create an artificial intelligence solution and an accompanying business case that meets the business objectives and business constraints; With expertise in delivering projects using leading processes including strong knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing, and development practices (testing, code design, complexity, and code optimization); Ability to discuss mathematical formulations, alternatives, and impact on modeling approach\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly; Work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- Expertise in delivering analytics projects using leading processes including expert knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Knowledge of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms such as Google Cloud, Azure, and AWS; Ability to pick up new languages and technologies quickly; Ability to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- So, bring your creativity and pioneering spirit to KPMG Lighthouse., \n",
      "\n",
      "KPMG is currently seeking a Director to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Lead workshops, innovation sessions with clients, multi-disciplinary, and cross-functional teams to identify business opportunities and artificial intelligence solutions utilizing processes and best practices to plan, lead, and execute delivery of artificial intelligence engagements across different areas (risk management, financial services, mergers and acquisitions, and public policy)\n",
      "\n",
      "Lead in a fast-paced and dynamic environment utilizing virtual and face-to-face interactions; Manage complex workstreams, expectations, budgets, deliverables, and multiple responsibilities using structured approaches for operational excellence and communicating results to executive level audiences\n",
      "\n",
      "Work with clients to discover data sources, and create data requests; Lead the ETL process to ingest structured data and annotation processes to enrich unstructured data; Leverage a variety of data sources (social media, news, internal/external documents, images, video, voice, emails, financial data and operational data)\n",
      "\n",
      "Leverage a variety of tools and approaches to solve complex business objectives, from Statistical Natural Language Processing, Information Retrieval/Extraction, Machine Learning/ Deep Learning, Image Processing, Rules Engines, Knowledge Graphs and Semantic Search\n",
      "\n",
      "Plan and manage engagement objectives and key deliverables using analytics processes to mitigate risks in data, modeling, validation and delivery while working with team members to capture assumptions, risks, and develop approaches to mitigate issues\n",
      "\n",
      "Refactor, deploy, and validate models; work with clients iteratively to validate performance metrics, and sample output to drive towards a business-first solution utilizing APIs, platforms, containers, multi-threading and distributed processing to achieve throughput goals, \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "Minimum of ten years of experience leading teams of at least ten data scientists, engineers, and other data & analytics professionals, including business development, requirements gathering, people development, and quality management using analytics and software development processes for natural language processing, machine learning on unstructured data, and/or information retrieval; Multidisciplinary backgrounds\n",
      "\n",
      "Master's degree from an accredited college/university in Computer Science, Engineering, or related fields; PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to work with the business to understand business goals to create an artificial intelligence solution and an accompanying business case that meets the business objectives and business constraints; With expertise in delivering projects using leading processes including strong knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing, and development practices (testing, code design, complexity, and code optimization); Ability to discuss mathematical formulations, alternatives, and impact on modeling approach\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly; Work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- experience with these, or similar tools‚Äù portion of the post:\n",
      "\n",
      "Amazon ‚Äì Sagemaker, AMI‚Äôs, ML Solutions Lab\n",
      "\n",
      "Google ‚Äì BigQuery, Dataproc, Spanner., \n",
      "\n",
      "Amazon ‚Äì Sagemaker, AMI‚Äôs, ML Solutions Lab\n",
      "\n",
      "Google ‚Äì BigQuery, Dataproc, Spanner., \n",
      "\n",
      "Please complete our online application process to be considered for this role., \n",
      "\n",
      "Penguin Random House is the leading adult and children‚Äôs publishing house in North America, the United Kingdom and many other regions around the world.\n",
      "entry --- Google\n",
      "substring --- Expertise in delivering analytics projects using leading processes including expert knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Knowledge of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms such as Google Cloud, Azure, and AWS; Ability to pick up new languages and technologies quickly; Ability to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- Expertise in delivering analytics projects using leading processes including expert knowledge of data discovery, cleaning, model selection, validation and deployment\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Knowledge of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms such as Google Cloud, Azure, and AWS; Ability to pick up new languages and technologies quickly; Ability to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions\n",
      "\n",
      "Generate reports and analysis on key product metrics\n",
      "\n",
      "Develop custom data models and algorithms to apply to data sets\n",
      "\n",
      "Help identify and assess metrics and KPIs that can be tracked to measure impacts and business outcomes\n",
      "\n",
      "Actively involved in the development of our analytics tools for A/B testing, segmentation, funnel analysis, and other analytics needs, Excellent problem solving and communication skills\n",
      "\n",
      "Strong statistics and mathematical fundamentals\n",
      "\n",
      "Familiar with reporting and analytics platforms and tools such as Looker, Google Analytics, and Excel\n",
      "\n",
      "Familiar with our cloud computing platform, AWS, B.S.\n",
      "entry --- Google\n",
      "substring --- Creative problem solver, ability to handle multiple projects, and strong work ethic needed\n",
      ", Preferred:, Previous experience in an eCommerce or Logistics/Supply Chain management environments\n",
      "Azure Machine Learning Studio or comfortable working in cloud hosted environments (AWS, Google Cloud, etc)\n",
      "Active Kaggle user\n",
      "Strong statistical analysis background]\"\n",
      "\"[Data Scientist - 23258, \n",
      "\n",
      "Data Science - USA Tampa, Florida, \n",
      "\n",
      "The Nielsen Company is the largest global measurement company in the world with unique measurement technologies, assets, and data that make it one of the most interesting and challenging places for a measurement or data scientist to work.\n",
      "entry --- Google\n",
      "substring --- Extensive knowledge of Microsoft Office and Google Suite applications (Docs, Sheets, Slides, Excel, and Powerpoint), \n",
      "\n",
      "BA/BS degree in statistics or mathematics., \n",
      "\n",
      "Strong quantitative analysis skills using statistical software such as Python or R., \n",
      "\n",
      "Working knowledge of Structured Query Language.\n",
      "entry --- Google\n",
      "substring --- , Excellent oral and written communication skills required for presenting to and collaborating with groups of diverse backgrounds., \n",
      "\n",
      "Ability to explain complex research concepts to individuals without a research background., \n",
      "\n",
      "Extensive knowledge of Microsoft Office and Google Suite applications (Docs, Sheets, Slides, Excel, and Powerpoint), \n",
      "\n",
      "Desired Qualification:, \n",
      "\n",
      "MBA/MS or higher in a statistical, mathematical or technical field.\n",
      "entry --- Google\n",
      "substring --- You will formulate machine learning approaches and automate predictions while paying attention to the customer journey., Who You Are: You have a strong aptitude of performing large-scale data analysis, managing real world \"noisy\" data within an eCommerce platform; experience with Google Cloud Platform, Google Analytics, and Google Big Query, At least 4 years of experience with Data Analysis, Predictive Analytics, or Machine Learning, At least 2 year or experience with at least one programming language, such as Java or Python, etc., At least 2 year of experience with at least one statistics/data analysis package, such as Python or R, At least 2 year of experience working within a Retail or eCommerce company]\n",
      "\"[Under general direction and minimal supervision perform data extraction and query data for ad hoc analyses and reports.\n",
      "entry --- Google\n",
      "substring --- Experience in cloud computing platforms such as Google Cloud Platform\n",
      "\n",
      "Experience with deep learning framework (ex: Tensorflow, Torch, etc)\n",
      "\n",
      "Proven command of R or Python or Java\n",
      "\n",
      "Excellent interpersonal, verbal, and written communication skills - must be able to communicate complex ideas in both technical and user-friendly language.\n",
      "entry --- Google\n",
      "substring --- Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- Our products inspire outdoor exploration, exercise, and meaningful social interaction., \n",
      "\n",
      "Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- Our products inspire outdoor exploration, exercise, and meaningful social interaction., \n",
      "\n",
      "Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- If you require an accommodation due to a disability, please contact Ericsson at hr.direct.dallas@ericsson.com or (866) 374-2272 (US) or (877) 338-9966 (Canada) for further assistance., \n",
      "\n",
      "Primary country and city: United States (US) || || Plano || Consulting&SysInt]\"\n",
      "\"[\n",
      "\n",
      "Lead team in designing analytic solutions that meet customer needs\n",
      "\n",
      "Enhance existing analytic solutions to ensure quality, and performance\n",
      "\n",
      "Select and implement appropriate measurements, and scoring metrics to evaluate performance of existing algorithms\n",
      "\n",
      "Select and implement industry machine learning algorithms to enhance or compete with existing algorithms\n",
      "\n",
      "Integrate Data from multiple sources to create a common operating picture\n",
      "\n",
      "Presentations to internal and external customers\n",
      "\n",
      "Identifying and Implementing data visualization for analysis, presentation, and end-user UI needs\n",
      "\n",
      "Duties will also include feature engineering, classifier optimization, event forecasting, and anomaly detection\n",
      "\n",
      "Data processing, cleansing, and validating both existing and incoming data, \n",
      "\n",
      "Python and good working knowledge of numpy, scikit-learn, pandas, scipy, matplotlib\n",
      "\n",
      "Experience in applying machine learning techniques to time series and geospatial data\n",
      "\n",
      "Strong statistical background in areas such as statistical testing, regression, and probability\n",
      "\n",
      "Good interpersonal skills and communication with all levels of management\n",
      "\n",
      "Bachelors in Mathematics or related discipline with 6+ years of data science industry experience\n",
      "\n",
      "Able to multitask, prioritize, and manage time efficiently\n",
      "\n",
      "US Citizenship and an active Public Trust clearance, \n",
      "\n",
      "Algorithm performance scoring\n",
      "\n",
      "Data Visualization of multi-source, multi-dimensional data, and analytic results in both real-time and for presentations\n",
      "\n",
      "MS in Computer Science, Physics, Mathematics, or other related discipline with 5+ years of industry experience of the data science field\n",
      "\n",
      "Familiarity with database / data file system such as PostgreSQL, Kudu, HDFS\n",
      "\n",
      "Strong Google-Fu\n",
      "\n",
      "Experience with time series event forecasting\n",
      "\n",
      "Wide breadth of machine learning algorithm experience and posses understanding of which problems those ML algorithms solve\n",
      "\n",
      "Up-to-date on latest industry trends; able to articulate trends and potential clearly and confidently]\"\n",
      "\"[Req.\n",
      "entry --- Google\n",
      "substring --- Experience using streaming data processing techniques is a plus\n",
      "\n",
      "Bachelor's degree from four-year college or university; four years related experience; or equivalent combination of education and experience\n",
      "\n",
      "Experience with Agile]\"\n",
      "\"[At Google, data drives all of our decision-making.\n",
      "entry --- Google\n",
      "substring --- Data Scientists work all across the organization to help shape Google's business and technical strategies by processing, analyzing and interpreting huge data sets.\n",
      "entry --- Google\n",
      "substring --- Using analytical rigor and statistical methods, you mine through data to identify opportunities for Google and our clients to operate more efficiently, from enhancing advertising efficacy to network infrastructure optimization to studying user behavior.\n",
      "entry --- Google\n",
      "substring --- You work with Engineers, Product Managers, Sales Associates and Marketing teams to adjust Google's practices according to your findings.\n",
      "entry --- Google\n",
      "substring --- As a key member of the team, you work with engineers to analyze and interpret data, develop metrics to measure results and integrate new methodologies into existing systems., Google is and always will be an engineering company.\n",
      "entry --- Google\n",
      "substring --- At Google, engineers not only revolutionize search, they routinely work on massive scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world.\n",
      "entry --- Google\n",
      "substring --- From Google Ads to Chrome, Android to YouTube, Social to Local, Google engineers are changing the world one technological achievement after another., Work with large, complex data sets.\n",
      "entry --- Google\n",
      "substring --- Develop comprehensive understanding of Google data structures and metrics, advocating for changes where needed for both products development and sales activity.\n",
      "entry --- Google\n",
      "substring --- Work closely with engineers to identify opportunities, design and assess improvements to Google products.\n",
      "entry --- Google\n",
      "substring --- Research and develop analysis, forecasting and optimization methods to improve the quality of Google's user facing products; example application areas include ads quality, search quality, end-user behavioral modeling and live experiments.\n",
      "entry --- Google\n",
      "substring --- Work with cross-functional partners across the business\n",
      "\n",
      ", QUALIFICATIONS\n",
      "\n",
      ", Advanced degree in Computer Science, Statistics, Mathematics, Economics, or related field\n",
      "\n",
      "3+ years of work experience in data science and/or predictive analytics functions in business environment (preferably internal or external consulting)\n",
      "\n",
      "Programming experience in one or more of Python and R, or other open-source programming languages\n",
      "\n",
      "Experience with big data technology (such as Hadoop, Hive, Data Lake), either cloud or on-premise platforms\n",
      "\n",
      "Knowledge of statistics and experience using statistical packages for analyzing datasets\n",
      "\n",
      "Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\n",
      "\n",
      "Ability to write queries, generate reports, and present findings\n",
      "\n",
      "Strong communication and facilitation skills\n",
      "\n",
      "Excellent planning and organizing skills\n",
      "\n",
      "Strong ability to continuously learn and upgrade technical skills\n",
      "\n",
      ", EOE/Disabled/Veterans]\"\n",
      "\"[Key Responsibilities:\n",
      "\n",
      ", Drive end to end analytical process: from formulation of requirements, data acquisition, identification of analytical methods, creation/validation of models to business-friendly summarization of results\n",
      "\n",
      "Interact with stakeholders to identify critical questions that need to be answered in order for the Analytics team to provide effective KPIs - actionable insights rather than just reports\n",
      "\n",
      "Conduct analysis and data modeling to draw insights that drive critical decision making and to uncover social media patterns, fan engagement, behavior and feedback\n",
      "\n",
      "Analyze data to identify outliers, missing, incomplete, and/or invalid data\n",
      "\n",
      "Create models, KPIs, and dashboards to operationalize outcomes of analytics\n",
      "\n",
      "Create, automate, and maintain reports and visualizations (e.g., social media mentions, competitive engagement, talent impact mapping)\n",
      "\n",
      "Work in complex data environment comprising several heterogeneous internal and third party data sources, manipulate large data sets and navigate a variety of servers, data types, and data structures to complete statistical and other analyses\n",
      "\n",
      "Design and build dashboards and automated reports with embedded visualizations\n",
      "\n",
      ", Qualifications:\n",
      "\n",
      ", Proven track record of identifying and highlighting key insights, signals, and trends deep within data\n",
      "\n",
      "Well-rounded individual with the ability to write code to query and transform both unstructured and structured data\n",
      "\n",
      "Openness to an environment of active developmental feedback and coaching from peers and managers, with desire to learn and grow rapidly\n",
      "\n",
      "Experience publishing reports using visualization and presentation tools\n",
      "\n",
      "Strong planning and organizational skills\n",
      "\n",
      "Should enjoy generating actionable insights by mining data and be passionate about answering challenging questions and telling stories with data and visualizations\n",
      "\n",
      "Self-motivated, attentive to detail, and driven to continuously improve analytics skill set\n",
      "\n",
      "Bachelor‚Äôs degree in Statistics/Mathematics, Econometrics/Economics, Engineering/Computer Science, Business/Finance, or related quantitative field\n",
      "\n",
      "Working knowledge of at least two technologies: SQL, SAS, Python, Big Query, Google Analytics, Excel, and Tableau\n",
      "\n",
      "SPSS and/or R\n",
      "\n",
      "Knowledge of social media platforms including but not limited to Facebook, Twitter, Instagram, Snapchat, YouTube\n",
      "\n",
      ", _]\"\n",
      "\"[Position Description, Work closely with merchants to define objectives and design appropriate analytics solutionsApply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand consumersDevelop analytical models to drive analytics insightsLead small and participate in large data analytics project teamsParticipate in the continuous improvement of data science and analyticsPresent data insights and recommendations to key stakeholdersProvide and support the implementation of business solutionsModel compliance with company policies and support company mission, values, and standards of ethics and integrity, \n",
      "\n",
      "Minimum Qualifications, \n",
      "\n",
      "Bachelor of Science and 5 years data science experience OR Master of Science and 3 years data science experience., \n",
      "\n",
      "Additional Preferred Qualifications, 5 years‚Äô experience in predictive modeling and large data analysis5 years‚Äô experience with statistical programming languages (for example, R, SAS)5 years‚Äô experience with SQL and relational databases (for example, DB2, Oracle, SQL Server)Expert in any scripting language (Python, PHP, Perl, etc.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "Master‚Äôs Degree in GIS, Computer Science, Statistics or related\n",
      ", \n",
      "2+ years of experience and strong understanding of GIS technology (knowledge of ESRI ArcGIS technology stack and Arc Objects)\n",
      ", \n",
      "Python: 2+ years experience with Python or other scripting languages (Python strongly preferred)\n",
      "SQL: 2+ years experience and a demonstrated proficiency in data extraction, analysis and scripting tools, preferably PostgreSQL, Google BigQuery\n",
      ", \n",
      "Statistics: firm understanding of statistical inference and some experience using stats in business settings\n",
      "Research: Experience with empirical research; ability to understand technical papers; general curiosity\n",
      "Machine Learning: Understanding of different ML techniques and fundamentals of model building / execution\n",
      ", \n",
      "Client Management: Ability to problem solve and empathize with key stakeholders\n",
      "Ownership: Ability to own a problem with little oversight\n",
      "Organization: Ability to manage multiple workstreams and priorities with various stakeholders\n",
      "Excellent interpersonal, written, and oral communication skills\n",
      "Self-starter, energetic and motivated contributor\n",
      ", \n",
      "Experience with PyGIS, PyQGIS, and/or QGIS\n",
      "Experience with GitHub for collaboration and version control\n",
      "Experience with data visualization tools (e.g., Tableau, Power BI, D3.js , Highcharts)\n",
      "Shell, Linux, Bash\n",
      ", \n",
      "Competitive pay and stock option grants\n",
      "Fully-covered healthcare (no premiums, co-insurance, etc.\n",
      "entry --- Google\n",
      "substring --- Gracenote, a Nielsen Company is the leading provider of entertainment metadata and media recognition technology that powers discovery features and discover the music, TV shows, movies and sports they love across the world‚Äôs most popular entertainment platforms and devices, from Amazon, Apple, Facebook, Google, Time Warner Cable, Tesla and others.\n",
      "entry --- Google\n",
      "substring --- , Job Summary:\n",
      "\n",
      ", As a Data Scientist, you will:\n",
      "\n",
      ", Use emerging tools and technology to develop analytical models and automation in music planning, music research, and other areas of the company\n",
      "\n",
      "Communicate complex solutions to a variety of stakeholders in easily understandable language\n",
      "\n",
      "Be a contributing member of a scrum team that voluntarily accepts work\n",
      "\n",
      "Write code that meets standards and delivers desired functionality using agreed upon technology\n",
      "\n",
      "Demonstrate passion about using data assets to optimize systems and products across iHeartMedia\n",
      "\n",
      "Use and extend open source software to deliver solutions to iHeartMedia business partners Present solutions and ideas to other team members, IT leadership, and business leaders\n",
      "\n",
      "Employ a pragmatic approach to evaluate new algorithms and technologies for positive impact within iHeartMedia\n",
      "\n",
      ", Requirements:\n",
      "\n",
      ", 5+ years of commercial experience in data science\n",
      "\n",
      "A demonstrable understanding of machine learning theory\n",
      "\n",
      "Extensive experience with Python and/or R\n",
      "\n",
      "Demonstrated experience with SQL\n",
      "\n",
      "Exceptional communication and presentation skills are a requirement\n",
      "\n",
      "Programming experience in JavaScript or Java for use in reading existing code or building prototypes (you do not have to have experience building production applications)\n",
      "\n",
      "MS in Applied Mathematics, Statistics, or Computer Science - PhD desired\n",
      "\n",
      ", Bonus:\n",
      "\n",
      ", Data Engineering/Data Wrangling\n",
      "\n",
      "Experience with Tensorflow, BigQuery, Tableau\n",
      "\n",
      "Experience with Google Cloud Platform or Amazon Web Services\n",
      "\n",
      ", Location\n",
      "\n",
      ", Position Type\n",
      "\n",
      ", The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.\n",
      "entry --- Google\n",
      "substring --- Google drive suite services (Google Docs, Google Sheets, etc.).\n",
      "entry --- Google\n",
      "substring --- , \n",
      "Data mining, data reduction*\n",
      "Classification (Decision Tree, clustering, bagging, boosting, logit regression)\n",
      "Prediction (Neural Network) & validation (cross validation)\n",
      ", \n",
      "Utilization of statistical programming tools (R,SAS, SciPy), coding languages (Python, Java, C++), and Google tools (BigQuery*, TensorFlow)\n",
      "Comfortable with data retrieval and processing with SQL and NoSQL\n",
      "Solid understanding of relational and non-relational database technology, cloud based data lake, ETL, data pipeline\n",
      "Understanding of code version management system\n",
      ", \n",
      "Some management experience, enjoys mentoring, managing direct reports\n",
      "Highly collaborative individual with great communication skill\n",
      "Develop communication styles focusing on technical details for non-technical audiences\n",
      ", \n",
      "Degree / equivalent experiences in applied quantitative field (Statistics, Mathematics, Econometrics, Engineering or CS).\n",
      "entry --- Google\n",
      "substring --- AWS, Azure, Google Cloud) environment., A cover letter is required to apply to this position.\n",
      "entry --- Google\n",
      "substring --- Experience with Amazon S3 and EC2 or Google cloud technologies as well as with raw data management and archiving.\n",
      "entry --- Google\n",
      "substring --- Building data visualizations, reports and presentations\n",
      "Working with evolving Hadoop and Spark technologies\n",
      "Working with evolving Google Cloud and Amazon Web Services (AWS) cloud technologies\n",
      "Delivering solutions to customers including vision workshop, Proof of Concepts / Proof of Value and production implementation.\n",
      "entry --- Google\n",
      "substring --- X was formerly known as Google[x]., Contribute expertise in physical sciences and machine learning to cross-disciplinary projects.\n",
      "entry --- Google\n",
      "substring --- Intellectual curiosity and ability to handle high levels of ambiguity\n",
      "\n",
      "Ability to communicate complex statistical concepts and output to non-experts in both a written and verbal manner\n",
      "\n",
      "Technical experience in SPSs, Big Query, Google Analytics, Excel and/or Tableau a plus\n",
      "\n",
      "Business insight\n",
      "\n",
      "Ability to work under pressure and within tight deadlines]\"\n",
      "\"[A career in National Special Functions, within Internal Firm Services, will provide you with the opportunity to support service, sector, and market leaders deliver the unique PwC client experience to our clients.\n",
      "entry --- Google\n",
      "substring --- Experience working with cloud databases and/or distributed computing platforms, and their query interfaces, such as SQL, Hive, Spark, Google Cloud BigQuery or Dataproc.\n",
      "entry --- Google\n",
      "substring --- Familiarity with visualization software and techniques (including Jupyter Notebook, Google Cloud Datalab).\n",
      "entry --- Google\n",
      "substring --- More than a billion people rely on Google Maps services to explore the world and navigate their daily lives.\n",
      "entry --- Google\n",
      "substring --- Geo helps merchants get their businesses on Google, and more than a million developers use the power of Google Maps to enhance their apps and websites.\n",
      "entry --- Google\n",
      "substring --- Develop comprehensive understanding of Google data structures and metrics, advocating for changes where needed for both products development and sales activity.\n",
      "entry --- Google\n",
      "substring --- Research and develop analysis, forecasting and optimization methods to improve the quality of Google's user facing products; example application areas include ads quality, search quality, end-user behavioral modeling, and live experiments.\n",
      "entry --- Google\n",
      "substring --- Interact cross-functionally with a wide variety of leaders and teams, and work closely with Engineers and Product Managers to identify opportunities for design and to assess improvements for Google products.\n",
      "entry --- Google\n",
      "substring --- \"[Degree in Analytics, IT, Economics or related field (Advanced Technical or Business Degree a plus)\n",
      "\n",
      "5+ years of data management and marketing experience, with 2+ years direct experience with data management in a cloud environment either in an eCommerce environment or for a Database Management/Customer Insights firm\n",
      "\n",
      "Strong data analytics expertise, including experience translating customer KPIs into actionable marketing strategies that drive growth\n",
      "\n",
      "Experience with data analytics tools and technologies across data (Google Analytics, Omniture, SQL, R, SAS, Python), visualization (Tableau, QlikView, or PowerBI))\n",
      "\n",
      "Experience with data warehouses, Big Data and Data Lakes a plus\n",
      "\n",
      "Experience with Lean Startup, Design Thinking, and Agile Methodologies preferred, Collaborate to build an end-to-end, extendable customer data solution from defining requirements to data migration and creation of dashboards, ensuring data integrity, accuracy and compliance.\n",
      "entry --- Google\n",
      "substring --- We have data stretching back before the existence of Google.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals; ability to work with the business to understand available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Provide assistance, and resolve problems, using solid problem-solving skills, verbal/written communication\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Understanding of development practices such as testing, code design, complexity, and code optimization\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- If you're as passionate about your future as we are, join our team., \n",
      "\n",
      "KPMG is currently seeking a Sr Associate, Data Science to join our Ignition practice., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Work closely with various KPMG's Tax functional teams and clients to incorporate cognitive and NLP models and algorithms into both KPMG and client solutions\n",
      "\n",
      "Define and develop new Tax solutions leveraging approaches such as Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, image recognition, deep learning, Machine Learning, cognitive science and analytics\n",
      "\n",
      "Design and implement cognitive computing/AI applications using some combination of the following commercial and open source platforms and libraries such as Microsoft AI, Google AI, AWS AI, IBM Watson, Tensor flow, Keras, Spark, Mahout, Torch, Caffe, ScIkit-learn, and NLTK, \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "Minimum of five years of IT industry experience with at least three years of experience in one of the following domains of interest - Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, Image Recognition, Deep Learning, Machine Learning, Cognitive Science and Data Analytics\n",
      "\n",
      "MS or BS in Computer Science, Applied Statistics, Engineering, Science or other quantitative discipline with specialization and experience in Artificial Intelligence, Machine Learning, Natural Language Processing, Cognitive Science or other related areas\n",
      "\n",
      "Experience working with leading cognitive computing commercial and open source platforms and libraries such as IBM Watson, Google AI, Microsoft AI, AWS AI, or Apache Mahout\n",
      "\n",
      "Demonstrated expertise with analytics and cognitive engagements across design and implementation\n",
      "\n",
      "Excellent verbal and written communication skills with the ability to work with diverse teams in a highly matrixed environment, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals; ability to work with the business to understand available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Provide assistance, and resolve problems, using solid problem-solving skills, verbal/written communication\n",
      "\n",
      "Understanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Understanding of development practices such as testing, code design, complexity, and code optimization\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- Prior experience with Google Analytics and web analytics platforms such as Adobe Analytics, Test & Target, Maxymiser preferred.\n",
      "entry --- Google\n",
      "substring --- Proficiency with Google Analytics, Adobe Analytics, Test & Target, Maxymiser preferred.\n",
      "entry --- Google\n",
      "substring --- Prior experience with Google Analytics and web analytics platforms such as Adobe Analytics, Test & Target, Maxymiser preferred.\n",
      "entry --- Google\n",
      "substring --- Proficiency with Google Analytics, Adobe Analytics, Test & Target, Maxymiser preferred.\n",
      "entry --- Google\n",
      "substring --- Prior experience with Google Analytics and web analytics platforms such as Adobe Analytics, Test & Target, Maxymiser preferred.\n",
      "entry --- Google\n",
      "substring --- Proficiency with Google Analytics, Adobe Analytics, Test & Target, Maxymiser preferred.\n",
      "entry --- Google\n",
      "substring --- E- Strong verbal, presentation, and written skills\n",
      "\n",
      "E- Strong critical thinking and creative problem solving skills\n",
      "\n",
      "E- Strong planning and organizational skills\n",
      "\n",
      "E- Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets\n",
      "\n",
      "E- Proficiency in MS Office suite (Excel, Access, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail)\n",
      "\n",
      "E- Knowledge of statistical tests and procedures such as ANOVA, Chi-squared, Correlation, Regression, Student t-test, and Time Series\n",
      "\n",
      "P- Familiarity with Tableau , BI, Spotfire, or other data visualization software and techniques\n",
      "\n",
      "P- Proficiency with the SAS language and toolset (Enterprise Guide, Forecast Studio, etc.)\n",
      "entry --- Google\n",
      "substring --- ), \n",
      "\n",
      "E- Strong verbal, presentation, and written skills, \n",
      "\n",
      "E- Strong critical thinking and creative problem solving skills, \n",
      "\n",
      "E- Strong planning and organizational skills, \n",
      "\n",
      "E- Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets, \n",
      "\n",
      "E- Proficiency in MS Office suite (Excel, Access, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail), \n",
      "\n",
      "E- Knowledge of statistical tests and procedures such as ANOVA, Chi-squared, Correlation, Regression, Student t-test, and Time Series, \n",
      "\n",
      "P- Familiarity with Tableau , BI, Spotfire, or other data visualization software and techniques, \n",
      "\n",
      "P- Proficiency with the SAS language and toolset (Enterprise Guide, Forecast Studio, etc.\n",
      "entry --- Google\n",
      "substring --- \"[Note: By applying to this position your application is automatically submitted to the following locations: Seattle, WA, USA; New York, NY, USA; Mountain View, CA, USA; Pittsburgh, PA, USA, \n",
      "\n",
      "Research in machine intelligence has already impacted user-facing services across Google including Search, Maps and Google Now.\n",
      "entry --- Google\n",
      "substring --- Google Research & Machine Intelligence teams are actively pursuing the next generation of intelligent systems for application to even more Google products.\n",
      "entry --- Google\n",
      "substring --- To achieve this, we‚Äôre working on projects that utilize the latest techniques in Machine Learning (including Deep Learning approaches like Google Brain) and Natural Language Understanding., We‚Äôve already been joined by some of the best minds, and we‚Äôre looking for talented Research Scientists that have applied experience in the fields of Machine Learning, Natural Language Processing and Machine Intelligence to join our team.\n",
      "entry --- Google\n",
      "substring --- , We do research differently here at Google.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- E- Strong verbal, presentation, and written skills\n",
      "\n",
      "E- Strong critical thinking and creative problem solving skills\n",
      "\n",
      "E- Strong planning and organizational skills\n",
      "\n",
      "E- Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets\n",
      "\n",
      "E- Proficiency in MS Office suite (Excel, Access, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail)\n",
      "\n",
      "E- Knowledge of statistical tests and procedures such as ANOVA, Chi-squared, Correlation, Regression, Student t-test, and Time Series\n",
      "\n",
      "P- Familiarity with Tableau , BI, Spotfire, or other data visualization software and techniques\n",
      "\n",
      "P- Proficiency with the SAS language and toolset (Enterprise Guide, Forecast Studio, etc.)\n",
      "entry --- Google\n",
      "substring --- ), \n",
      "\n",
      "E- Strong verbal, presentation, and written skills, \n",
      "\n",
      "E- Strong critical thinking and creative problem solving skills, \n",
      "\n",
      "E- Strong planning and organizational skills, \n",
      "\n",
      "E- Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets, \n",
      "\n",
      "E- Proficiency in MS Office suite (Excel, Access, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail), \n",
      "\n",
      "E- Knowledge of statistical tests and procedures such as ANOVA, Chi-squared, Correlation, Regression, Student t-test, and Time Series, \n",
      "\n",
      "P- Familiarity with Tableau , BI, Spotfire, or other data visualization software and techniques, \n",
      "\n",
      "P- Proficiency with the SAS language and toolset (Enterprise Guide, Forecast Studio, etc.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- \"[Note: By applying to this position your application is automatically submitted to the following locations: Seattle, WA, USA; New York, NY, USA; Mountain View, CA, USA; Pittsburgh, PA, USA, \n",
      "\n",
      "Research in machine intelligence has already impacted user-facing services across Google including Search, Maps and Google Now.\n",
      "entry --- Google\n",
      "substring --- Google Research & Machine Intelligence teams are actively pursuing the next generation of intelligent systems for application to even more Google products.\n",
      "entry --- Google\n",
      "substring --- To achieve this, we‚Äôre working on projects that utilize the latest techniques in Machine Learning (including Deep Learning approaches like Google Brain) and Natural Language Understanding., We‚Äôve already been joined by some of the best minds, and we‚Äôre looking for talented Research Scientists that have applied experience in the fields of Machine Learning, Natural Language Processing and Machine Intelligence to join our team.\n",
      "entry --- Google\n",
      "substring --- , We do research differently here at Google.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- PhD from an accredited college/university is preferred\n",
      "\n",
      "Ability to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\n",
      "\n",
      "Solid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\n",
      "\n",
      "Fluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\n",
      "\n",
      "Ability to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- Google\n",
      "substring --- Other duties as assigned., Minimum Qualifications:\n",
      "\n",
      ", Master's degree in Analytics, Mathematics, Physics, Computer and Information Science, or Engineering\n",
      "\n",
      "5 - 10 years in Data Analytics\n",
      "\n",
      "5 - 7 years utilizing Statistical Software\n",
      "\n",
      "5 - 7 years in Large Datasets\n",
      "\n",
      "5 - 7 years in Data Visualization\n",
      "\n",
      "3 - 5 years in Predictive Modeling\n",
      "\n",
      "1 - 3 years in a Business Analyst role\n",
      "\n",
      "1 - 3 years in Consulting\n",
      "\n",
      "1 - 3 years in Research and Development, Preferred Qualifications:\n",
      "\n",
      ", Doctorate degree in Analytics, Mathematics, Physics, Computer and Information Science, or Engineering\n",
      "\n",
      "3 - 5 years in the Healthcare Industry\n",
      "\n",
      "3-5 years of experience leading Human Subjects Research projects\n",
      "\n",
      "Multiple peer-reviewed publications in high impact factor journals, Knowledge, Skills & Abilities:, \n",
      "\n",
      "Analysis of business problems/needs\n",
      "\n",
      "Analytical and Logical Reasoning/Thinking\n",
      "\n",
      "Collaborative Problem Solving\n",
      "\n",
      "Statistical Analysis\n",
      "\n",
      "Written & Oral Presentation Skills\n",
      "\n",
      "SAS, R, Python, SPSS or related, Referral Bonus Level: 3]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: Seattle, WA, USA; New York, NY, USA; Mountain View, CA, USA; Pittsburgh, PA, USA, \n",
      "\n",
      "Research in machine intelligence has already impacted user-facing services across Google including Search, Maps and Google Now.\n",
      "entry --- Google\n",
      "substring --- Google Research & Machine Intelligence teams are actively pursuing the next generation of intelligent systems for application to even more Google products.\n",
      "entry --- Google\n",
      "substring --- To achieve this, we‚Äôre working on projects that utilize the latest techniques in Machine Learning (including Deep Learning approaches like Google Brain) and Natural Language Understanding., We‚Äôve already been joined by some of the best minds, and we‚Äôre looking for talented Research Scientists that have applied experience in the fields of Machine Learning, Natural Language Processing and Machine Intelligence to join our team.\n",
      "entry --- Google\n",
      "substring --- , We do research differently here at Google.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- \"[Note: By applying to this position your application is automatically submitted to the following locations: Seattle, WA, USA; New York, NY, USA; Mountain View, CA, USA; Pittsburgh, PA, USA, \n",
      "\n",
      "Research in machine intelligence has already impacted user-facing services across Google including Search, Maps and Google Now.\n",
      "entry --- Google\n",
      "substring --- Google Research & Machine Intelligence teams are actively pursuing the next generation of intelligent systems for application to even more Google products.\n",
      "entry --- Google\n",
      "substring --- To achieve this, we‚Äôre working on projects that utilize the latest techniques in Machine Learning (including Deep Learning approaches like Google Brain) and Natural Language Understanding., We‚Äôve already been joined by some of the best minds, and we‚Äôre looking for talented Research Scientists that have applied experience in the fields of Machine Learning, Natural Language Processing and Machine Intelligence to join our team.\n",
      "entry --- Google\n",
      "substring --- , We do research differently here at Google.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- Experience developing scalable and automated data pipelines\n",
      "Machine learning experience in Python and/or R\n",
      "Experience with one or more cloud environments (AWS, Google Cloud Platform, Azure or other platforms)\n",
      "Practical knowledge applying analytical techniques such as time series regression, decision trees, segmentation, clustering, response modeling and factor analysis to real-world data.\n",
      "entry --- Google\n",
      "substring --- \"[The Google Cloud Platform team helps customers transform and evolve their business through the use of Google‚Äôs global network, web-scale data centers and software infrastructure.\n",
      "entry --- Google\n",
      "substring --- As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners., The Google Cloud Revenue Acceleration team (RevX) focuses on boosting business growth of Google Cloud using quantitative programs.\n",
      "entry --- Google\n",
      "substring --- You will also collaborate closely with Engineers, Program Managers and other stakeholders to implement model-based solutions, measure the effectiveness of programs, and drive customer growth and success., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- Perform statistical analyses and build machine learning solutions to support Google Cloud business needs.\n",
      "entry --- Google\n",
      "substring --- Experience with the Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- Our unique approach goes beyond the limitations of automation and offshoring to give you authentic, input and insight, from real people in real-world settings., \n",
      "\n",
      "Thousands of the world‚Äôs leading digital brands ‚Äì including Google, Uber, Michael Kors, Amazon, Nike, Slack, and FOX ‚Äì rely on Applause to delight customers, increase their top line and innovate faster., \n",
      "\n",
      "Applause has a winning culture, fantastic benefits and tons of potential for career growth., Key Responsibilities:, \n",
      "Uses best practices to develop statistical machine learning techniques to build models that address business needs\n",
      "Uses effective project planning techniques to break down basic and occasionally moderately complex projects into tasks and ensure deadlines are kept\n",
      "Uses and learns a wide variety of tools and languages to achieve results (e.g., Python, Scala, R, SAS)\n",
      "Collaborates with the team in order to improve the effectiveness of business decisions through the use of data and machine learning/predictive modeling\n",
      "Innovates on projects by using new modeling techniques or tools\n",
      "Contributes on a wide variety of projects\n",
      "Executes on modeling/machine learning projects effectively\n",
      "Communicates findings to team and leadership to ensure models are well understood and incorporated into business processes\n",
      "Works with leaders to ensure the project will meet their needs\n",
      "Reviews and evaluates on appropriateness of techniques, given current modeling practices, to senior leadership\n",
      ", Qualifications:, \n",
      "Have completed at least a Bachelor‚Äôs degree in a quantitative field such as computer science, data science, mathematics, statistics, or physics.\n",
      "entry --- Google\n",
      "substring --- That‚Äôs why:, Our infrastructure is in Google Cloud Platform,\n",
      "For research we leverage both Python and R,\n",
      "Our ETL pipelines and production models are in Python and Scala.\n",
      "entry --- Google\n",
      "substring --- In addition to troubleshooting on the customer side, we work with Sales, Product and Engineering teams within Google to develop better tools and services to improve our products based on the evolving needs of our users.\n",
      "entry --- Google\n",
      "substring --- As a cross-functional and global team, it's our job to help keep the lights on and the ads relevant., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.\n",
      "entry --- Google\n",
      "substring --- Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products.\n",
      "entry --- Google\n",
      "substring --- Work effectively with clients to align Google Marketing Platform attribution and analytic solutions with key organizational challenges and develop value-based roadmaps to solve client business issues on a continuous and repeatable basis.\n",
      "entry --- Google\n",
      "substring --- Communicate complex solutions to a variety of stakeholders in easily understandable language\n",
      "\n",
      "Be a contributing member of a scrum team that voluntarily accepts work\n",
      "\n",
      "Write code that meets standards and delivers desired functionality using agreed upon technology\n",
      "\n",
      "Demonstrate passion about using data assets to optimize systems and products\n",
      "\n",
      "Use and extend open source software to deliver solutions to company‚Äôs business partners Present solutions and ideas to other team members, IT leadership, and business leaders\n",
      "\n",
      "Employ a pragmatic approach to evaluate new algorithms and technologies for positive impact within the company\n",
      "\n",
      ", Requirements:\n",
      "\n",
      ", 2-5+ years of commercial experience in data science\n",
      "\n",
      "A demonstrable understanding of machine learning theory\n",
      "\n",
      "Extensive experience with Python and/or R\n",
      "\n",
      "Demonstrated experience with MSSQL\n",
      "\n",
      "Exceptional communication and presentation skills are a requirement\n",
      "\n",
      "Programming experience in JavaScript, C or C# for use in reading existing code or building prototypes (you do not have to have experience building production applications)\n",
      "\n",
      "Experience with Google Cloud Platform or Amazon Web Services, ElasticSearch\n",
      "\n",
      ", Bonus:\n",
      "\n",
      ", MS in Applied Mathematics, Statistics, or Computer Science\n",
      "\n",
      "Data Engineering\n",
      "\n",
      "Experience with Tensorflow, BigQuery, Tableau\n",
      "\n",
      ", Location\n",
      "\n",
      ", Position Type\n",
      "\n",
      ", The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.\n",
      "entry --- Google\n",
      "substring --- Extensive experience manipulating and analyzing complex data with SQL, Python and/or R. Knowledge of Google BigQuery and Java/Scala is a plus.\n",
      "entry --- Google\n",
      "substring --- Excellent communication skills\n",
      "\n",
      "Self-motivated, proactive, and able to work cooperatively in a team environment, \n",
      "\n",
      "Additional consideration given to candidates who bring experience with, or understanding of:, \n",
      "\n",
      "Managing and manipulating large data sets\n",
      "\n",
      "C#, Java, .Net, Tomcat\n",
      "\n",
      "Networking and/or mobile systems (TCP/IP stack, cellular, Wi-Fi, Android, iOS)\n",
      "\n",
      "Security (SIEM, UEBA, VPNs)\n",
      "\n",
      "Cloud deployment system (AWS, Azure, Google) and/or microservice architectures\n",
      "\n",
      "Splunk, Splunk MLT a plus, \n",
      "\n",
      "Who We Are:\n",
      "\n",
      "\n",
      "For over 17 years, we‚Äôve worked with a simple philosophy: help the connected world move more smoothly, seamlessly and productively.\n",
      "entry --- Google\n",
      "substring --- We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status]\"\n",
      "\"[gTech‚Äôs Product and Tools Operations team (gPTO) leverages deep user, operational, and technical insights to innovate Google's Ads products into customer experiences that are so intuitive (or automated) that they require no support at all.\n",
      "entry --- Google\n",
      "substring --- gPTO partners closely with gTech‚Äôs Support, Professional Services, Product Management, and Engineering teams to innovate and simplify our Ads products and build the productivity tools ecosystem for gTech users., The Customer Experience Lab conducts customer experience research on advertisers who are using Google‚Äôs Marketing Solutions.\n",
      "entry --- Google\n",
      "substring --- , The CX Lab conducts scaled research on Google's advertisers.\n",
      "entry --- Google\n",
      "substring --- We are looking for data scientists to research and analyze correlations between advertiser CSAT survey data and key data systems to determine key drivers, opportunities, and trends., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.\n",
      "entry --- Google\n",
      "substring --- Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products.\n",
      "entry --- Google\n",
      "substring --- Amazon, Cisco, Google, Microsoft, SAP and other leading businesses are all part of the MapR ecosystem.\n",
      "entry --- Google\n",
      "substring --- Work with data warehousing team to design optimal data architecture for BI tools\n",
      "\n",
      "Work as a client contact for analytics, partnering with various departments to identify priority dashboards and reports to better serve the company\n",
      "\n",
      "Design and build dashboards and automated reports with embedded visualizations\n",
      "\n",
      ", Qualifications:\n",
      "\n",
      ", Minimum of 4 years of experience\n",
      "\n",
      "Proven track record of identifying and highlighting key insights, signals, and trends deep within the underlying data\n",
      "\n",
      "Well-rounded individual with the ability to write code to query and transform both unstructured and structured data\n",
      "\n",
      "Experience publishing reports using visualization and presentation tools\n",
      "\n",
      "Should enjoy generating actionable insights by mining and modeling data and be passionate about answering challenging questions and telling stories with data and visualizations\n",
      "\n",
      "Self-motivated, attentive to detail, and driven to continuously improve analytics skill set\n",
      "\n",
      "SQL, SAS, Python, Big Query, Google Analytics, Excel, and Tableau\n",
      "\n",
      "SPSS and/or R\n",
      "\n",
      "Bachelor degree in Mathematics, Statistics, Econometrics, Actuarial Science or related quantitative discipline\n",
      "\n",
      ", _]\"\n",
      "\"[Our Data Scientists are pioneers in building the next generation of retail interconnected experience for homedepot.com by leveraging Artificial Intelligence and Statistics.\n",
      "entry --- Google\n",
      "substring --- Strong autonomy and team player, \n",
      "\n",
      "Preferred Qualifications, \n",
      "\n",
      "Experience with Google Cloud Platform (such as BigQuery, Compute Engine, Data Flow, ..)\n",
      "\n",
      "Experience with relational (SQL) and NoSQL Databases\n",
      "\n",
      "Experience with developing products deployed to production\n",
      "\n",
      "Experience in developing Search, Recommendation, Visual and/or Language applications, 50%-Design and develop algorithms and models to use against large datasets to create business insights\n",
      "\n",
      "20%-Establish scalable, efficient processes for large scale data analyses, model development and model implementation\n",
      "\n",
      "20%-Present analysis and resulting recommendations to senior management; Leverage data to present a compelling business case to optimize investments and operations\n",
      "\n",
      "10%-Communicate and educate technical and non-technical employees on analytics and data-driven decision making, This position reports to Director of Data Science, or Sr.\n",
      "entry --- Google\n",
      "substring --- Deep data science skills, at the interface between computer science and statistics, MS or equivalent experience with evidence of impact in data science applied to real life problems in a research setting ideally within a clinical research environment\n",
      "\n",
      "1 to 5 years of experience post MS or PhD\n",
      "\n",
      "Natural language processing experience preferred\n",
      "\n",
      "Python and R experience required\n",
      "\n",
      "JupyterHub, Sun Grid Engine, Google Cloud Platform, AWS experience preferred\n",
      "\n",
      "Experienced in data science methodologies and techniques, e.g.\n",
      "entry --- Google\n",
      "substring --- They will have an appetite for learning new technology with an eye for the value it can create., \n",
      "\n",
      "Responsibilites:, \n",
      "\n",
      "Work closely with in-house subject matter experts to thoroughly understand the business domain and use that knowledge to help define, design and implement machine learning systems\n",
      "\n",
      "Help define project goals and timelines\n",
      "\n",
      "Evaluate new architectures for feature extraction to optimize and extend machine learning models\n",
      "\n",
      "Take ownership of text analysis, image and form recognition projects\n",
      "\n",
      "Create systems for evaluating model accuracy and anomaly detection\n",
      "\n",
      "Work with development team to put models into product and scale them properly, \n",
      "\n",
      "Required Skills/Qualifications:, \n",
      "\n",
      "Development languages including Python, R and Javascript\n",
      "\n",
      "Machine learning frameworks such as Tensorflow and Keras\n",
      "\n",
      "Data Science algorithms such as decision trees, linear regression, clustering, word embeddings\n",
      "\n",
      "Cloud ML resources like Google Cloud Platform\n",
      "\n",
      ".NET Experience is a plus\n",
      "\n",
      "OCR Experience is a plus\n",
      "\n",
      "Experience implementing successful machine learning systems\n",
      "\n",
      "Creativity and willingness to be open and share ideas]\"\n",
      "\"[\n",
      "Experience with machine learning algorithms and development on Cloud platforms\n",
      "Experience with Python, R, and Java\n",
      "Ability to manipulate, integrate, and analyze large and complex data sets using SQL and no-SQL database platforms\n",
      "Ability to provide non-technical users with data-driven tools for implementing machine learning into workflows, as needed\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with health data sets, including electronic health records, clinical data, and claims data a plus\n",
      "Experience with developing machine learning, deep learning or natural language processing unstructured text data\n",
      "Experience with leading technical project teams\n",
      "MA or MS degree\n",
      "]\"\n",
      "\"[Engage with Actuaries in order to develop innovative BI solutions containing actuarial methodologies to drive business decisions across all of Actuarial and Underwriting.\n",
      "entry --- Google\n",
      "substring --- Maintenance and improvement of created platforms and/or models\n",
      "Writing client-facing reports and contributing to proposal work\n",
      "Work related travel as needed (2-3 times per quarter)\n",
      ", 3-5 years of data science/software development experience\n",
      "Strong background in Machine Learning and AI\n",
      "Solid training in probability and statistics\n",
      "Experience with managing big datasets\n",
      "Excellent communication and writing skills\n",
      "Proficiency in Python, R, Java, Tableau or similar\n",
      ", Experience with QA/NLP\n",
      "Experience with AWS, Google Cloud, etc.\n",
      "entry --- Google\n",
      "substring --- There's a good chance it reached you because of our technology., \n",
      "\n",
      "Taboola is the world's leading content discovery platform, serving 360B recommendations to over 1B unique visitors each month on the web's most innovative publisher sites, including NBC, USA Today, The Weather Channel, Tribune and Fox Sports., \n",
      "\n",
      "About You: You are a hyper-intelligent Data Scientist with a robust background in a big data environment., \n",
      "\n",
      "In this Job: You will build complex Data Science solutions for large-scale product initiatives, scaling up to a Petabyte of data., \n",
      "\n",
      "Requirements:, \n",
      "3+ years of experience as a Data Scientist, preferably in Big Data Environment\n",
      "2+ years of programming experience in Java/Scala and/or Python\n",
      "Hadoop stack (HIVE, Pig, Hadoop streaming) and MapReduce\n",
      "HBase or comparable NoSQL\n",
      "SQL & database experience\n",
      "Experience with Google products: Google Cloud Storage, Google Analytics and Google Big Query (a plus)\n",
      "Bachelor‚Äôs degree in quantitative or related field\n",
      ", Responsibilities:, \n",
      "Design and build predictive customer behavior models for targeting and personalization\n",
      "Implement Machine Learning and statistics-based algorithms for prediction and optimization, then deliver to production\n",
      "Build and maintain code to populate HDFS, Hadoop with log from Kafka or data loaded from SQL production systems\n",
      "Design, build and support algorithms of data transformation, conversion, computation on Hadoop, Spark and other distributed Big Data Systems\n",
      ", #LI - AM1, \n",
      "\n",
      "#GD]\"\n",
      "\"[\n",
      "\n",
      "Help lead day to day project execution including developing advanced analytics solutions, creating client deliverables, and project management\n",
      "\n",
      "Efficiently manage data from disparate sources, distilling into datasets prepared for modeling\n",
      "\n",
      "Create statistical models to support client projects, including marketing mix modeling, attribution, and purchase funnel analytics\n",
      "\n",
      "Prepare client facing material (example: PowerPoint slides and charts), distilling analytical insights effectively into stories for EI clients\n",
      "\n",
      "Effectively visualize data and analytical insights via Tableau and other mediums\n",
      "\n",
      "Proactively lead development of standardized code and processes that can be easily used by the larger team\n",
      "\n",
      "Support senior staff on thought leadership and development of new advanced analytics offerings for EI clients\n",
      "\n",
      "Support senior staff in business development, including the scoping of projects and development of client proposals\n",
      "\n",
      "Mentor other team members and provide training on analytical offerings throughout the organization, \n",
      "\n",
      "2+ years of professional experience in advanced analytics or related\n",
      "\n",
      "Bachelor‚Äôs degree in Analytics, Economics, Mathematics, Statistics or related field\n",
      "\n",
      "Academic background in econometrics or applied statistics and related technologies, including statistical concepts, (example: Time-Series Regression, Logistic Regression, Factor Analysis)\n",
      "\n",
      "Experience consulting business stakeholders to develop statistical solutions for business questions\n",
      "\n",
      "Experience managing workstreams against project deadlines\n",
      "\n",
      "Comfortable with prepping and visualizing data in Microsoft Office (Excel and PowerPoint)\n",
      "\n",
      "Experience in statistical programming in R, SAS, or Python ‚Äì experience in more than one language is a preferred\n",
      "\n",
      "Experience with Tableau or other data visualization tools\n",
      "\n",
      "Excellent organizational and communication skills, coupled with the ability to adapt to new conditions, assignments and deadlines\n",
      "\n",
      "Knowledge of marketing, market research, and economics]\"\n",
      "\"[\n",
      "\n",
      "Leverage data to perform intensive analysis across all areas of our business to drive growth strategies, including product development and rider engagement strategies\n",
      "\n",
      "Generate ideas for exploratory analysis to shape future projects and provide recommendations for actions\n",
      "\n",
      "Perform time-series analyses, hypothesis testing, and causal analyses to statistically assess relative impact and extract trends\n",
      "\n",
      "Build models to enhance understanding of user behavior and predict future performance of cohorts\n",
      "\n",
      "Design experiments and interpret the results to draw detailed and actionable conclusions\n",
      "\n",
      "Create dashboards and reports to regularly communicate results and monitor key metrics\n",
      "\n",
      "Present findings to senior management to inform business decisions\n",
      "\n",
      "Collaborate with cross-functional teams across disciplines such as product, engineering, operations, and marketing\n",
      ", \n",
      "\n",
      "Minimum 4 years of experience in a quantitative analysis role with emphasis on statistics\n",
      "\n",
      "BA/BS/MS in Math, Economics, Statistics, Engineering, Computer Science, or other quantitative field (advanced degrees are a plus)\n",
      "\n",
      "Excellent SQL skills and the ability to use tools such as Python, R, or Excel to work efficiently at scale with large data sets\n",
      "\n",
      "Advanced knowledge of experimentation and statistical methods\n",
      "\n",
      "Ability to deliver on tight timelines and move quickly while maintaining attention to detail\n",
      "\n",
      "Work closely with cross-functional teams to execute on decisions\n",
      "\n",
      "Self-driven with the ability to work in a self-guided manner\n",
      "\n",
      "Superb communication and organization skills]\"\n",
      "\"[\n",
      "\n",
      "Identify, analyze and pinpoint trends and patterns in our data sets that we can leverage to further our growth\n",
      "\n",
      "Communicate and present your findings to executives and key stakeholders\n",
      "\n",
      "Work closely with management to prioritize business and strategic objectives using a data-driven approach\n",
      "\n",
      "Interact with executives and managers to identify information needs based around the products and services we offer to track how they are being used by our clients\n",
      "\n",
      "Design and improve our data collection and database designs to optimize efficiency and improve the data quality\n",
      "\n",
      "Acquire data from internal and external data sources that can be used to enhance our data sets and improve analysis, Masters in Computer Science, Mathematics, Statistics\n",
      "\n",
      "5+ years' experience in a data science or data analysis role\n",
      "\n",
      "Working knowledge of mining and analyzing data sets to extract meaningful trends, producing meaningful and actionable reports\n",
      "\n",
      "Experience using statistical programming languages or toolkits for analyzing large, complex datasets\n",
      "\n",
      "Technical proficiency with optimizing data collection, database design, data mining and modeling/analysis\n",
      "\n",
      "Strong analytical skills, attention to detail and accuracy\n",
      "\n",
      "Expert problem solving skills and creative thinking ability\n",
      "\n",
      "Ability to distill and present key findings to managers and other stakeholders (both technical and non-technical individuals)\n",
      "\n",
      "Project management skills with experience planning and coordinating full project lifecycle for data and research focused projects]\"\n",
      "\"[\n",
      "\n",
      "Apply data science and machine learning to threat intelligence, network situational awareness, intrusion detection and prevention, incident response, and malware analysis.\n",
      "entry --- Google\n",
      "substring --- Statistics (Bayesian methods, experimental design, causal inference)\n",
      "\n",
      "Tableau, Looker\n",
      "\n",
      "Google Cloud Platform, At Square, our purpose is to empower ‚Äì within and outside of our walls.\n",
      "entry --- Google\n",
      "substring --- Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc\n",
      "Experience in visualizing data to stakeholders in a simple and concise manner through visualization software such as ggplot, D3,Tableau Qlinkview, Periscope, Business Objects, or other similar software.\n",
      "entry --- Google\n",
      "substring --- [Expert in enterprise data tranformation including data warehouse and data lake rationalization.Proven expertise in using combinations of supervised and unsupervised machine learning algorithms, predictive models, and statistical algorithms to provide insights into client datasets.Must be familiar with current link analysis and risk analysis tools.Deep knowledge of Data Science including Google Analytics and metrics, statistical analysis, machine learning and natural language processing, and data science, analytics, modeling and integration.Experience planning, organizing, facilitating, and collecting data from focus group and research/usability testing sessions.Data segmentation and data flow modeling.Knowledge of and experience working with Hadoop and Cloudera.Executing descriptive analyses, ranging from identifying product opportunities to understanding user behaviorExperience/expertise with Natural Language Processing (NLP), graph theory, Scala, and machine learning.Demonstrated ability building innovative data products (e.g., Artificial Intelligence, real-time services, such as personalization and commerce graphing using Big Data platforms with real-time data ingestion and processing).Establishing big data reporting and enterprise analytics platforms to analyze increasingly larger and more complex data sets.Skills at Identifying and correcting data quality issues and establishing a data governance framework to enforce data standards and improve accuracy using integrated internal and external disparate data sources., Developing machine-learning algorithms to improve predictions.Develop highly optimized, scalable automatic case matching logic on microservice/container technology.]\n",
      "entry --- Google\n",
      "substring --- Experience working with cloud platforms such as AWS, and Google Cloud Platform and distributed computing technologies such as Apache Spark.]\"\n",
      "entry --- Google\n",
      "substring --- Atos operates under the brands Atos, Atos Consulting, Atos Worldgrid, Bull, Canopy, Unify and Worldline., \n",
      "\n",
      "Please follow this link, Atos.net page, to learn more about the new Global Partnership with Google Cloud and Atos!\n",
      "entry --- Google\n",
      "substring --- How will Google Cloud and Atos‚Äô global partnership work together to deliver secure hybrid Cloud, machine learning, and collaboration solutions to the enterprise?\n",
      "entry --- Google\n",
      "substring --- AWS, Google)\n",
      "\n",
      "Experience with managing, cleaning and normalizing large, multi-dimensional datasets\n",
      "\n",
      "Knowledge and experience with electronic health records (EHRs)\n",
      "\n",
      "Knowledge of clinical data standards and ontologies including ICD, SNOMED, UMLS, etc.\n",
      "entry --- Google\n",
      "substring --- in Computer Science, Math, Engineering or related quantitative field.Work experience with SQL, Teradata, Google Big Query and/or other comparable database systems.Expert knowledge of R, Python or other statistical computing programming languages., Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neutral networks, etc.)\n",
      "entry --- Google\n",
      "substring --- Experience working across functions and influencing teams\n",
      "\n",
      "Continuous improvement mindset\n",
      "\n",
      "Experience with data modeling tools (e.g., SAP PA, Python, R, SAS, MS-Azure)\n",
      "\n",
      "Experience with business intelligence and data visualization tools (such as from Power BI, Google Analytics, Tableau, Domo, Qlikview)\n",
      "\n",
      "Data integration experience including extract, transform, load (ETL) processes\n",
      "\n",
      "Experience with databases and complex data queries\n",
      "\n",
      "Greenbelt certified\n",
      "\n",
      "Strong organizational skills\n",
      "\n",
      "Self-motivated and independent\n",
      "\n",
      "Excellent oral and written communication skills\n",
      "\n",
      "Ability to work in a rapidly changing environment\n",
      "\n",
      ", Location: St. Paul, MN\n",
      "\n",
      ", Sales Territory: N/A\n",
      "\n",
      ", Travel: May include up to 10% domestic/international\n",
      "\n",
      ", Relocation: Is not authorized\n",
      "\n",
      ", Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).]\"\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Identify opportunities to operate the marketplace more efficiently, working closely with business, product, and engineering leaders\n",
      "\n",
      "Build multivariate models to arrive at inferences or predict future behavior\n",
      "\n",
      "Develop algorithms that match owners with providers or solve other customer needs\n",
      "\n",
      "Design and analyze A/B user tests and marketplace experiments, often in partnership with product managers\n",
      "\n",
      "Deploy machine learning models at scale, writing production code in collaboration with machine learning platform engineers, \n",
      "\n",
      "SQL\n",
      "\n",
      "Python or R\n",
      "\n",
      "Google Analytics or similar user funnel analytics tools\n",
      "\n",
      "Tableau, Looker, or similar data visualization tools\n",
      "\n",
      "Data-informed decision making with rigorous split testing.\n",
      "entry --- Google\n",
      "substring --- Experience with Google Suite (Docs, Sheets, Slides, etc.\n",
      "entry --- Google\n",
      "substring --- )., \n",
      "\n",
      "Quantitative research and analysis skills including competence with statistical software (Python preferred)., \n",
      "\n",
      "Experience with Google Suite (Docs, Sheets, Slides, etc.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "you grok data and revel in analyzing it\n",
      "very hardworking\n",
      "excited to disrupt online advertising\n",
      "fascinated to learn more analysis techniques\n",
      "detail oriented\n",
      "self-motivator who contribute effectively with limited supervision\n",
      "enjoy sifting through large amounts of data\n",
      ", \n",
      "Retrieve and analyze data from cloud storage\n",
      "Identify key questions, problems, and KPIs to improve the experience of our users\n",
      "Help develop effective and scalable data models in our production environment and develop, build, and maintain a user-friendly version our production data in our data warehouse\n",
      "Proactively develop site performance reports and analysis such as segmentation analysis; highlight observations and business context to deliver actionable recommendations to business leads, not just data\n",
      "Participate in the design, set up, and evaluation of A/B and multivariate testing\n",
      "Provide access to data through dashboards and other analytical tools to empower your team through self-service\n",
      "Automate insights through alerting and anomaly detection\n",
      "Ensure quality and timeliness of deliverables that meet expectations while balancing business needs with the appropriate level of analytical rigor\n",
      ", \n",
      "Expert proficiency in python and web analytics tools including Omniture and Google Analytics\n",
      "Outstanding organizational skills and dedication to quality and integrity\n",
      "The ability to work collaboratively acting as a subject matter expert within a team environment to help define and meet measurement criteria and goals\n",
      "Experience building tools and automated processes to extract, clean, and distill data in a procedural language of your choice such as Python, Julia or R\n",
      "An understanding of A/B testing and other forms of statistical analysis using statistical packages similar to R, SAS, or Pandas\n",
      "Experience with analytical visualization tools such as Tableau, Looker, D3.js or similar tools\n",
      ", \n",
      "Data modeling, ETL and data pipeline development experience\n",
      "Advanced degree in statistics or other quantitative field\n",
      ", \n",
      "Python, C++, Django, React.js\n",
      "Apache Kafka, Nginx\n",
      "PostgreSQL, MySQL, Aerospike, Druid, Bigtable\n",
      "GCP, Linux, Kubernetes, Dockers, New Relic, Elasticsearch, Kibana\n",
      "]\"\n",
      "\"[Position Overview:, \n",
      "\n",
      "The Climate Corporation‚Äôs mission is to help the world‚Äôs farmers sustainably increase their productivity with digital tools.\n",
      "entry --- Google\n",
      "substring --- Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- Extensive experience directly querying multi-terabyte-sized data sets (with Hive and Presto) including clickstream data (like Google Analytics), third party data (like Facebook) and raw data ingested from non-standard platforms.\n",
      "entry --- Google\n",
      "substring --- science, engineering, economics, finance, statistics, or similar)., \n",
      "\n",
      "4+ years of work experience involving quantitative data analysis and complex problem solving (preferably focused on consumer-facing internet products)., \n",
      "\n",
      "Complete command of SQL, Excel, and either Python or R, along with some experience with Tableau and/or Mode., \n",
      "\n",
      "Extensive experience directly querying multi-terabyte-sized data sets (with Hive and Presto) including clickstream data (like Google Analytics), third party data (like Facebook) and raw data ingested from non-standard platforms., \n",
      "\n",
      "A strong understanding of concepts, terminology, and measurement issues related to web analytics along with a history of applying advanced analytical approaches to derive insights from the data., \n",
      "\n",
      "Strong written, verbal, and visual communication skills to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation., \n",
      "\n",
      "The skills to work cross-functionally and push business partners to focus on realistic goals and projects., Zillow Group is owned, fueled and grown by innovators who help people make better, smarter decisions around all things home.\n",
      "entry --- Google\n",
      "substring --- Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc...\n",
      ", Lead the design, implementation, and operation of a state-of-the-art ‚Äúbig data‚Äù analytics approach which is scalable and innovative in the way it extracts, manages and analyzes data\n",
      "Roughly 65% thought leadership and management and 35% hands-on working with data\n",
      "Assemble the right team, ask the right questions, and avoid mistakes that could derail a data science project.\n",
      "entry --- Google\n",
      "substring --- Experience solutioning in public cloud environments: AWS (preferred), Google Cloud, Azure., GoDaddy is proud to be an equal opportunity employer.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "Design, execute, and evaluate complex analyses of structured and unstructured data to solve complex business problems using cutting edge statistical techniques\n",
      "Adroitly navigate the tradeoffs between speed and feature completion, in order to deliver the right solution in the right time\n",
      "Import, clean, and analyze a variety of datasets in order to generate ad-hoc analyses and build long-running data products\n",
      "Work with our Associate Chief Health Officer, Chief Product Officer, and Engineering teams daily to provide decision support\n",
      "Build production data processes for risk segmentation, member cohorting, and risk assessment\n",
      "Document and simplify complex processes and tools\n",
      "Design reports and dashboards to steer our value-driven business lines, including traditional and non-traditional success metrics Work with our clinical operations team to design robust evaluation models\n",
      "Mentor and build a team of both direct reports and cross-functional partners across the organization - encouraging growth in both individual and company-wide data maturity\n",
      "Own our vendor relationships with top clinical data providers and analyst groups\n",
      ", \n",
      "You enjoy doing whatever it takes to execute on complex projects\n",
      "You have 3+ years of experience in a highly operational data science role\n",
      "You are a strong SQL programmer, with experience navigating and cleaning messy data at scale\n",
      "You demonstrate expertise across a range of data analysis, data visualization and machine learning toolsets (Python, R, SAS, SPSS, Scala, matplotlib, ggplot Hadoop, Spark)\n",
      "You have good applied statistics skills (hypothesis testing, experimental design)\n",
      "You have hands-on experience using machine learning techniques to solve real-world problems\n",
      "You have deep familiarity with a BI tool like Tableau, Looker, QlikView, Periscope, Mode, etc\n",
      "You have experience in a high growth technology company\n",
      "You have worked with healthcare data (administrative or clinical)\n",
      ", \n",
      "Deep expertise in one or many domains of healthcare data, including claims processing, EHR data, HIE/CCD data, HEDIS measures, Stars, RaF scoring, and risk segmentation\n",
      "Master's Degree or PhD in Epidemiology, Mathematics, Statistics, Biostatistics/Bioinformatics or a related field\n",
      "D3.js, seaborn, bokeh or other advanced data visualization experience\n",
      "Experience building data workflows on Google Cloud Platform\n",
      "Medical economics, actuarial, or finance/revenue cycle background\n",
      ", \n",
      "A resume and/or LinkedIn profile\n",
      "A short cover letter and link to any public portfolio or previous data analyses and visualization work\n",
      "]\"\n",
      "\"[\n",
      "35 GB of data ingest per day, supporting over 510\n",
      ", \n",
      "4 TB Microsoft SQL Server based data warehouse\n",
      "1.5 TB production Cassandra cluster\n",
      ", \n",
      "Apply machine learning to optimize ad selection for\n",
      ", \n",
      "Develop algorithms to take into account hundreds of\n",
      ", \n",
      "Interface with the Business Intelligence team to\n",
      ", \n",
      "Interface with Product Engineering team to ensure\n",
      ", \n",
      "Interface with Product Management to develop\n",
      ", \n",
      "Suggest and implement integration of first and third\n",
      ", \n",
      "Operationalizing the data science process ‚Äì\n",
      ", \n",
      "PhD in CS/Math/Statistics or equivalent experience\n",
      "Expert in machine learning methodologies\n",
      ", \n",
      "Familiar with Bayesian statistics\n",
      "AB testing, design of experiments\n",
      "Hands-on experience with R/Weka,\n",
      ", \n",
      "Familiarity with the digital media / advertising\n",
      ", \n",
      "Be an excellent communicator and a leader able to\n",
      ", \n",
      "NativeX offers competitive, performance based pay\n",
      ", \n",
      "Traditional benefits including Health, Dental and\n",
      ", \n",
      "Generous time off including paid time off starting\n",
      ", \n",
      "Ongoing growth and development opportunities\n",
      ", \n",
      "Work in an entrepreneurial, energetic work\n",
      "]\"\n",
      "\"[Data Scientist - 16008, \n",
      "\n",
      "Technology and Engineering - USA Needham, Massachusetts, \n",
      "\n",
      "Understanding marketing effectiveness is critical to the success of businesses across all verticals.\n",
      "entry --- Google\n",
      "substring --- You have interacted with clickstream data (e.g., command of Google Analytics) and raw data ingested from paid marketing channels (e.g., Adwords, Facebook) and have derived insights from those data sources to positively-influence the business.\n",
      "entry --- Google\n",
      "substring --- Natural language processing experience preferred\n",
      "\n",
      "Shiny, Spyre, Flask, WebDev and prototyping experience preferred\n",
      "\n",
      "JupyterHub, Sun Grid Engine, Google Cloud Platform, AWS experience preferred\n",
      "\n",
      "Experienced in data science methodologies and techniques, e.g.\n",
      "entry --- Google\n",
      "substring --- Web analytics ‚Äì working knowledge of SiteCatalyst or Google Analytics\n",
      "\n",
      "Modeling ‚Äì machine learning technique is a plus (i.e., Na√Øve Bayes, Random Forests, Deep Learning, Ensemble).\n",
      "entry --- Google\n",
      "substring --- More than a billion people rely on Google Maps services to explore the world and navigate their daily lives.\n",
      "entry --- Google\n",
      "substring --- Geo helps merchants get their businesses on Google, and more than a million developers use the power of Google Maps to enhance their apps and websites.\n",
      "entry --- Google\n",
      "substring --- Develop comprehensive understanding of Google data structures and metrics, advocating for changes where needed for both products development and sales activity.\n",
      "entry --- Google\n",
      "substring --- Research and develop analysis, forecasting and optimization methods to improve the quality of Google's user facing products; example application areas include ads quality, search quality, end-user behavioral modeling, and live experiments.\n",
      "entry --- Google\n",
      "substring --- Interact cross-functionally with a wide variety of leaders and teams, and work closely with Engineers and Product Managers to identify opportunities for design and to assess improvements for Google products.\n",
      "entry --- Google\n",
      "substring --- Data Analytics packages such as Pandas, Scikit-learn, Numpy or R.\n",
      "\n",
      "Cloud Technology Stacks from providers such as AWS and Google Cloud.\n",
      "entry --- Google\n",
      "substring --- Employees have the opportunity to gain invaluable experience and make a significant impact on the business outcomes of our clients and our company., \n",
      "\n",
      "Over the past years, Maven Wave has received the following awards and accolades:, \n",
      "\n",
      "Google Cloud North America Services Partner of the Year, 2018\n",
      "\n",
      "#21 Best Workplaces in Chicago, FORTUNE, 2018\n",
      "\n",
      "Great Place To Work Certification, Great Place to Work, 2017 & 2018\n",
      "\n",
      "Fast Fifty, Crain's Chicago Business, 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR), 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "Top Google Cloud Partner, Clutch, 2017\n",
      "\n",
      "Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine, 2016, 2017\n",
      "\n",
      "Top IT Services Companies, Clutch, 2015\n",
      "\n",
      "Google Global Rising Star Partner of the Year 2015, \n",
      "\n",
      "Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\n",
      "entry --- Google\n",
      "substring --- Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\n",
      "entry --- Google\n",
      "substring --- Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\n",
      "entry --- Google\n",
      "substring --- Experience in visualizing data to stakeholders in a simple and concise manner through visualization software such as ggplot, D3,Tableau Qlinkview, Periscope, Business Objects, or other similar software.Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc...\n",
      "Self-starter who can multi-task, prioritize, and manage a multitude of conflicting priorities against competing deadlines without breaking a sweat.\n",
      "entry --- Google\n",
      "substring --- More than a billion people rely on Google Maps services to explore the world and navigate their daily lives.\n",
      "entry --- Google\n",
      "substring --- Geo helps merchants get their businesses on Google, and more than a million developers use the power of Google Maps to enhance their apps and websites.\n",
      "entry --- Google\n",
      "substring --- Develop comprehensive understanding of Google data structures and metrics, advocating for changes where needed for both products development and sales activity.\n",
      "entry --- Google\n",
      "substring --- Research and develop analysis, forecasting and optimization methods to improve the quality of Google's user facing products; example application areas include ads quality, search quality, end-user behavioral modeling, and live experiments.\n",
      "entry --- Google\n",
      "substring --- Interact cross-functionally with a wide variety of leaders and teams, and work closely with Engineers and Product Managers to identify opportunities for design and to assess improvements for Google products.\n",
      "entry --- Google\n",
      "substring --- Extensive experience directly querying multi-terabyte-sized data sets (with Hive and Presto) including clickstream data (like Google Analytics), third party data (like Facebook) and raw data ingested from non-standard platforms.\n",
      "entry --- Google\n",
      "substring --- You are very experienced programming in Python, Java or R.\n",
      "You're familiar with tools like spaCy, scikit-learn, NLTK, Mallet, TensorFlow, PyTorch and all the others that didn't come up in our Google search.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "2+ years of experience with advanced analytical functions\n",
      "Experience with at least one statistical analytical programming language, including Python or R\n",
      "Experience with source control and dependency management software, including Git or Maven\n",
      "Experience with using relational databases, including MySQL\n",
      "Experience with identifying analytic insight in data, developing visualizations, and presenting findings to stakeholders\n",
      "Knowledge of object-oriented programming, including Java, C++, and various machine learning algorithms, their design, capabilities, and limitations\n",
      "Knowledge of statistical analysis technique\n",
      "Ability to build complex extraction, transformation, and loading (ETL) pipelines to clean and fuse data together\n",
      "Ability to obtain a security clearance\n",
      "BA or BS degree required\n",
      ", \n",
      "Experience with designing and implementing custom machine learning algorithms\n",
      "Experience with graph algorithms and semantic Web\n",
      "Experience with designing and setting up relational databases\n",
      "Experience with Big Data computing environments, including Hadoop\n",
      "Experience with Navy mission systems\n",
      "MA or MS degree in Mathematics, CS, or quantitative fields\n",
      "]\"\n",
      "\"[Google's projects, like our users, span the globe and require managers to keep the big picture in focus while being able to dive into the unique engineering challenges we face daily.\n",
      "entry --- Google\n",
      "substring --- As a Technical Program Manager at Google, you lead complex, multi-disciplinary engineering projects using your engineering expertise.\n",
      "entry --- Google\n",
      "substring --- You're equally at home explaining your team's analyses and recommendations to executives as you are discussing the technical trade-offs in product development with engineers., Research at Google addresses the most challenging problems in computer science, machine learning and other related fields.\n",
      "entry --- Google\n",
      "substring --- Our work helps Google Assistant understand and speak with users, helps self-driving cars move safely, and helps Google Images and Geo understand the content of images among other cases across the company.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Google\n",
      "substring --- Coding experience in Python is added bonus.Tagging/labeling/parsing/indexing unstructured text data.Processing text data indexed for Bibliometric Analysis Tool (BAT)Supervised and unsupervised clustering of text data; experience with Natural Language Processing, Coding experience in R is required; Coding experience in Python is added bonus.Graph Theory / Image Processing / Neural Networks, Experience with Big Data (parallel processing power and options for handling analysis of)Ability to understand retrieval processes in Microsoft SQL or experience working in SQL]\n",
      "\"[\n",
      "Experience in building machine learning infrastructure on AWS, Google Cloud, or Azure.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Identify opportunities to operate the marketplace more efficiently, working closely with business, product, and engineering leaders\n",
      "\n",
      "Build multivariate models to arrive at inferences or predict future behavior\n",
      "\n",
      "Develop algorithms that match owners with providers or solve other customer needs\n",
      "\n",
      "Design and analyze A/B user tests and marketplace experiments, often in partnership with product managers\n",
      "\n",
      "Deploy machine learning models at scale, writing production code in collaboration with machine learning platform engineers, \n",
      "\n",
      "SQL\n",
      "\n",
      "Python\n",
      "\n",
      "Probably at least one additional programming language / computational programming environment; e.g., R, Matlab, C++, etc\n",
      "\n",
      "Google Analytics or similar user funnel analytics tools\n",
      "\n",
      "Tableau, Looker, or similar data visualization tools\n",
      "\n",
      "Data-informed decision making with rigorous split testing.\n",
      "entry --- Google\n",
      "substring --- \"[Responsible for following the defined agile development processes including attending the required meetings with contribution towards the successful completion of the sprints..Collaborates with product management and customer delivery teams to ensure product requirements are clear on what customers expect and what the delivery teams should set as the right expectations with the customers.Communicate rigorously within the squad on goals, ongoing progress, milestones, and any issues.Support and follow the overall product architects, delivery architects, to drive and establish the architecture decisions and designs for the product.Leverage the DevOps team to ensure product can be automatically built, deployed, and tested using a CI/CD pipelines across all of the release cycles from dev to production.Mentor and develop required skills of other junior product developers., Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.Experience applying machine learning and predictive analytic techniques to large, complex data sets specializing in event data processingExperience with Machine Learning frameworksExpert in coding hands on in Python and RExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processingProven ability to develop resilient code (best practice error handling) that performs and scales for large enterprise needsDeep expertise in developing REST-based API's (json/yaml), Micro-services with RDBMS and NoSQLBachelor's degree in Computer Science or equivalent with specialization Machine Learning, Understanding of Public and Private Cloud Provider services, usage and delivery paradigmsWorking knowledge of cloud technologies and architectures, including Virtualization, APIs, Micro-services and Containers.5+ years experience delivering enterprise-class cognitive applications2+ years experience developing in Python and modern web-based languagesExcellent verbal and written communication abilities: must effectively communicate with technical and non-technical teamsHigh attention to detail and proven track record in taking ownership, driving results and moving with speed to implement ideas in a fast-paced online environmentWillingness to roll up your sleeves and do whatever is necessaryAbility to process and manage multiple priorities, Ph.D or Masters in Computer Science/Artificial Intelligence with specialization in Machine Learning.Knowledge of IT Service Management and IT Operations Management processes, tools and technologiesKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment modelsExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storageExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.,  Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.\n",
      "entry --- Google\n",
      "substring --- Knowledge of IT Service Management and IT Operations Management processes, tools and technologies\n",
      "\n",
      "Knowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment models\n",
      "\n",
      "Experience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storage\n",
      "\n",
      "Experience with Big Data architectures including Spark/Hadoop, HDFS, analytical processing\n",
      "\n",
      "Experienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.]\"\n",
      "entry --- Google\n",
      "substring --- Master's Degree or Ph.D. in Operational Research, Mathematics, Engineering, Statistics, Econometrics or related field - Preferred\n",
      "Experience with Big Data technologies like Hadoop, Spark, Hive, NoSQL, etc., and Cloud technologies (Google Cloud, Azure, etc.)\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "3+ years of experience as a data scientist\n",
      "Experience with building statistical models and developing machine learning algorithms\n",
      "Experience with data visualization\n",
      "Experience with managing data scientist team\n",
      "Experience with programming languages, including Python, R, Scala, or Java\n",
      "Experience with Big Data technologies, including HDFS, Hadoop, or Spark\n",
      "Experience with manipulating data and ETL in parallel processing and distributed compute environments\n",
      "Experience with designing and executing machine learning models and applications\n",
      "TS/SCI clearance\n",
      "MA or MS degree\n",
      ", \n",
      "2+ years of experience as a developer in Java, Python, R, or similar high-level languages\n",
      "2+ years of experience with designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results\n",
      "2+ years of experience in managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications\n",
      "Experience in working with Big Data storage, processing, and computation, including one or more of the following: Accumulo, Spark, Storm, Kafka, or MapReduce\n",
      "Ability to both manage and manipulate large data sets, develop data science approaches, and manage data science tasks\n",
      "Ability to leverage a wide variety of data science capabilities and languages\n",
      "Ability to exhibit flexibility, initiative, and innovation when dealing with ambiguous and fast-paced situations\n",
      "]\"\n",
      "\"[Responsible for following the defined agile development processes including attending the required meetings with contribution towards the successful completion of the sprints..Collaborates with product management and customer delivery teams to ensure product requirements are clear on what customers expect and what the delivery teams should set as the right expectations with the customers.Communicate rigorously within the squad on goals, ongoing progress, milestones, and any issues.Support and follow the overall product architects, delivery architects, to drive and establish the architecture decisions and designs for the product.Leverage the DevOps team to ensure product can be automatically built, deployed, and tested using a CI/CD pipelines across all of the release cycles from dev to production.Mentor and develop required skills of other junior product developers., Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.Experience applying machine learning and predictive analytic techniques to large, complex data sets specializing in even data processingExperience with Machine Learning frameworksExpert in coding hands on in Python and RExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processingProven ability to develop resilient code (best practice error handling) that performs and scales for large enterprise needsDeep expertise in developing REST-based API's (json/yaml), Micro-services with RDBMS and NoSQLBachelor's degree in Computer Science or equivalent with specialization Machine Learning, Understanding of Public and Private Cloud Provider services, usage and delivery paradigmsWorking knowledge of cloud technologies and architectures, including Virtualization, APIs, Micro-services and Containers.5+ years experience delivering enterprise-class cognitive applications2+ years experience developing in Python and modern web-based languagesExcellent verbal and written communication abilities: must effectively communicate with technical and non-technical teamsHigh attention to detail and proven track record in taking ownership, driving results and moving with speed to implement ideas in a fast-paced online environmentWillingness to roll up your sleeves and do whatever is necessaryAbility to process and manage multiple priorities, Ph.D or Masters in Computer Science/Artificial Intelligence with specialization in Machine Learning.Knowledge of IT Service Management and IT Operations Management processes, tools and technologiesKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment modelsExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storageExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.,  Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.\n",
      "entry --- Google\n",
      "substring --- Knowledge of IT Service Management and IT Operations Management processes, tools and technologies\n",
      "\n",
      "Knowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment models\n",
      "\n",
      "Experience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storage\n",
      "\n",
      "Experience with Big Data architectures including Spark/Hadoop, HDFS, analytical processing\n",
      "\n",
      "Experienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.]\"\n",
      "entry --- Google\n",
      "substring --- Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.\n",
      "entry --- Google\n",
      "substring --- Experience linking multiple data platforms with data visualization tools (e.g., Tableau)\n",
      "\n",
      "Experience with Public Cloud Platforms (AWS, Azure, Google Cloud Platform)\n",
      "\n",
      "Advanced knowledge of data management tools including SQL/RDBMS, NoSQL (e.g.\n",
      "entry --- Google\n",
      "substring --- Familiar with popular machine learning and artificial intelligence packages provided by Amazon AWS, Microsoft or Google (such as Azure, Sagemaker, GCP).\n",
      "entry --- Google\n",
      "substring --- Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\n",
      "\n",
      "Exposure to Google Machine Learning is a plus\n",
      "\n",
      "Experience with customer analytics concepts, such as CLV modeling, churn modeling, real-time customer evaluation, recommendation engine is a plus.\n",
      "entry --- Google\n",
      "substring --- Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\n",
      "\n",
      "Exposure to Google Machine Learning is a plus\n",
      "\n",
      "Experience with customer analytics concepts, such as CLV modeling, churn modeling, real-time customer evaluation, recommendation engine is a plus.\n",
      "entry --- Google\n",
      "substring --- You have the technical competence to perform more advanced analytics:\n",
      "Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\n",
      "Data visualization (such as Tableau, Qlik, D3, ggplot)\n",
      "Experience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google‚Äôs Cloud Platform\n",
      "Experience training and tuning statistical and machine learning models with libraries/frameworks such as sci-kit learn, tensorflow, pytorch or similar\n",
      "Familiarity with experimentation and A/B testing\n",
      "You are capable of tackling very loosely defined problems and thrive when working on a team which has autonomy in their day to day decisions.\n",
      "entry --- Google\n",
      "substring --- You are a communicative person that values building strong relationships with colleagues and multiple stakeholders, and have the ability to explain complex topics in simple terms., Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\n",
      "Data visualization (such as Tableau, Qlik, D3, ggplot)\n",
      "Experience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google‚Äôs Cloud Platform\n",
      "Experience training and tuning statistical and machine learning models with libraries/frameworks such as sci-kit learn, tensorflow, pytorch or similar\n",
      "Familiarity with experimentation and A/B testing\n",
      "]\"\n",
      "\"[This is your opportunity to join AXIS Capital ‚Äì a trusted global provider of specialty lines insurance and reinsurance.\n",
      "entry --- Google\n",
      "substring --- We are a late-stage startup backed by Capital G (Google Capital) where you will gain valuable experience in a fast-paced high-growth environment., \n",
      "\n",
      "Responsibilities, \n",
      "\n",
      "Mine large scale and high dimensional data, identify patterns, and visualize trends\n",
      "\n",
      "Create predictive models using supervised learning techniques to detect and stop the most sophisticated threats\n",
      "\n",
      "Innovate new semi-supervised and online learning techniques to enhance our threat detection capabilities and reduce nuisance false positives for our customers.\n",
      "entry --- Google\n",
      "substring --- Specifically, you will lead the development of fraud detection algorithms and systems that protect Square and its customers from fraud and financial loss., \n",
      "\n",
      "You will:, \n",
      "\n",
      "Creatively leverage both new and existing data to increase the effectiveness and efficiency of our risk infrastructure\n",
      "\n",
      "Work with engineers to design machine learning solutions that operate effectively at scale\n",
      "\n",
      "Partner with operatives to quickly respond to rapidly evolving threats\n",
      "\n",
      "Apply good software development practices and actively contribute to production code\n",
      "\n",
      "Help build the next generation of data products at Square, You have:, \n",
      "\n",
      "2-4 years of relevant industry experience\n",
      "\n",
      "A graduate degree in statistics, applied mathematics, computer science, physical sciences, or a similar technical field\n",
      "\n",
      "Experience developing and deploying machine learning / deep learning solutions\n",
      "\n",
      "The versatility to communicate clearly with both technical and non-technical audiences\n",
      "\n",
      "A willingness to solve problems using whichever tool is most appropriate for the situation, \n",
      "\n",
      "Technologies we use and teach:, \n",
      "\n",
      "Python (numpy, pandas, sklearn, xgboost, TensorFlow)\n",
      "\n",
      "MySQL, Hive\n",
      "\n",
      "Java\n",
      "\n",
      "Google Cloud Platform\n",
      "\n",
      "Tableau, Looker, At Square, our purpose is to empower ‚Äì within and outside of our walls.\n",
      "entry --- Google\n",
      "substring --- Learn how to use and navigate our various databases and write scripts using our data for various analyses\n",
      "\n",
      "Learn about our existing code-base and best practices\n",
      "\n",
      "Collaborate with other data scientists to help build our patient-physician matching products, Integrate into long-term multi-data-scientist ventures and deliver on one or several short-term individual projects\n",
      "\n",
      "Perform analyses that help us better understand patients and/or physicians, while helping you get familiarized with our data\n",
      "\n",
      "Spend time with Staff Physicians and other medical domain experts to learn about the world of healthcare\n",
      "\n",
      "Develop an understanding of both immediate business objectives as well as longer term company aspirations to develop intuition around prioritization and trade-offs between short-term deliverables and longer term R&D efforts, \n",
      "\n",
      "Develop creative solutions to diverse problems including engineering challenges, unstructured data messes, ontology development, and machine learning applications\n",
      "\n",
      "Lead and develop major projects from end-to-end encompassing planning, design, technical implementation, debugging, roll-out to Product & Engineering, testing, and iteration\n",
      "\n",
      "Operate at level of sophistication in statistics, machine learning, or computer science that is publication-worthy\n",
      "\n",
      "Regularly monitor pull requests, perform code reviews, and produce excellent peer reviews on projects prior to shipping to Product & Engineering\n",
      "\n",
      "Evaluate and experiment with new technologies and tools prior to wider adoption by the team\n",
      "\n",
      "Work closely with analysts, data scientists, product managers, and engineers, \n",
      "\n",
      "Minimum 2 years of industry production experience as a Data Scientist or Engineer\n",
      "\n",
      "Excellent verbal communications, including the ability to clearly and concisely articulate complex concepts to both technical and non-technical collaborators\n",
      "\n",
      "Degree(s) should be in a technical discipline such as Computer Science, Computational Biology, Engineering, Statistics, Physics, Math, quantitative social science\n",
      "\n",
      "Experience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\n",
      "\n",
      "Required: SQL, Python, R, linux shell scripting\n",
      "\n",
      "Desired: Scala, Java, or Ruby\n",
      "\n",
      "Experience with machine learning and computational statistics packages\n",
      "\n",
      "Experience with visualization tools\n",
      "\n",
      "Frequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\n",
      "\n",
      "Bonus Points: previous work on medical applications and/or with claims data]\"\n",
      "\"[At Yapstone, we approach payments with the same startup mentality that we had when we launched our first payment solution in 1999.\n",
      "entry --- Google\n",
      "substring --- Building on software and sensor technology developed at Google, Waymo is now launching the world‚Äôs first fully self-driving transportation service that will take members of the public from A to B at the touch of a button., \n",
      "\n",
      "Waymo takes an integrated approach to building the world‚Äôs first self-driving car, with researchers, product managers, and technical program managers working side by side.\n",
      "entry --- Google\n",
      "substring --- ), Google Cloud Platform, SQL-sever and postgres,)\n",
      "\n",
      "Fluency in statistical analysis, data visualization, data mining and cleansing, machine learning, etc.\n",
      "entry --- Google\n",
      "substring --- Experience with Google Cloud Platform (Dataflow, Beam, BigQuery, Tensorflow) and other big data technologies a plus.\n",
      "entry --- Google\n",
      "substring --- You preferably have experience with data pipeline tools like Apache Beam or even our open source API for it, Scio Experience with XGBoost, TensorFlow, or Google Cloud Platform is also a plus.\n",
      "entry --- Google\n",
      "substring --- Expert command of statistical analysis, algorithm development, and state-of-the-art tools and methodologies for data science\n",
      "\n",
      "5+ years creating predictive models using advance machine learning techniques\n",
      "\n",
      "2+ years managing a team of data scientists\n",
      "\n",
      "Expert command of SQL and R or Python as applied to data science\n",
      "\n",
      "Experience developing real-time production data pipelines\n",
      "\n",
      "Experience interacting with external clients is a plus, \n",
      "\n",
      "Perks and benefits:, \n",
      "\n",
      "People ‚Äì the best part of Zest\n",
      "\n",
      "Robust healthcare plans, matching 401K and unlimited vacation time\n",
      "\n",
      "Dog friendly office with lounge areas, video games and gigantic jigsaw puzzles\n",
      "\n",
      "On-site gym with yoga, salsa and other employee run fitness classes\n",
      "\n",
      "Generous family leave policy (6 month maternity leave/3 month paternity leave)\n",
      "\n",
      "Tuition reimbursement, conference allowance and Zest talks\n",
      "\n",
      "Complimentary massages, manicures, pedicures and more\n",
      "\n",
      "Daily catered lunches from LA‚Äôs best restaurants and fully stocked kitchen]\"\n",
      "\"[\n",
      "\n",
      "At least 3 years industry experience working as a full-time Data Scientist designing and implementing predictive models written in Python\n",
      "\n",
      "Seasoned in feature selection and feature engineering\n",
      "\n",
      "Experience training, tuning and optimizing ML models using scikit-learn\n",
      "\n",
      "Experience training, tuning and optimizing ML models using TensorFlow\n",
      "\n",
      "Experience defining, evaluating measuring the performance of competing models\n",
      "\n",
      "Experience partnering with ML Engineers to productionize models you have built, \n",
      "\n",
      "Experience building recommender systems\n",
      "\n",
      "Experience training models leveraging GPU driven frameworks\n",
      "\n",
      "Experience training models using Google Cloud ML or AWS SageMaker\n",
      "\n",
      "Experience optimizing models for production deployment\n",
      "\n",
      "Experience data mining using Splunk]\"\n",
      "\"[\n",
      "Advanced degree in machine learning or related field, or equivalent experience\n",
      "Experience applying machine learning techniques to real-world problems\n",
      "Comfort analyzing large, complex, high-dimensional datasets\n",
      "Ability to quickly assess a problem both qualitatively and quantitatively\n",
      "Strong passion for empirical research and answering hard questions with data\n",
      "Ability to present results and describe techniques in both technical and non-technical contexts\n",
      "Strong SQL skills\n",
      "Fluency in at least one scripting language, such as Python or Perl\n",
      "3 - 6 years of professional experience\n",
      ", \n",
      "Ph.D. in machine learning or related field\n",
      "Experience with Hadoop, HDFS, Pig, Hive, Spark, Impala\n",
      "Significant experience using a statistical computing package such as Python/Pandas/Scikitlearn, R, or MATLAB\n",
      "]\"\n",
      "\"[We are seeking professionals who are well versed in scalable data mining, machine learning techniques, and love to build analytics models.\n",
      "entry --- Google\n",
      "substring --- Knowledge of Google BigQuery and Java/Scala is a plus.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Experience working for Facebook, Amazon, LinkedIn or Google required\n",
      "\n",
      "Problem solver with a track record of addressing root-cause issues\n",
      "\n",
      "Big picture thinking combined with an exacting attention to detail\n",
      "\n",
      "Self-motivated and directed fast learner\n",
      "\n",
      "Ability to partner with business and technical groups in a cross-functional capacity, \n",
      "\n",
      "Using available data to address business questions or concerns.\n",
      "entry --- Google\n",
      "substring --- Degree(s) should be in a technical discipline such as Computer Science, Engineering, Statistics, Physics, Math, quantitative social science\n",
      "\n",
      "Work experience as an engineer highly desired\n",
      "\n",
      "Experience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\n",
      "\n",
      "Required: SQL, Python, R, linux shell scripting\n",
      "\n",
      "Desired: Scala, Java, or Ruby\n",
      "\n",
      "Experience with machine learning and computational statistics packages (sci-kit learn, nltk, statsmodels, networkx, gephi, arules, glmnet, bigrf, caret, igraph, MLLib, GraphX, MADlib, Weka, etc)\n",
      "\n",
      "Experience with visualization tools (seaborn, d3, plotly, bokeh, ggplot2, rCharts, networkD3, Shiny, Tableau, CartoDB, etc)\n",
      "\n",
      "Frequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\n",
      "\n",
      "Bonus Points for: experience with web application frameworks (Shiny, Flask, Tkinter, Ruby on Rails, Pyramid, Django, etc)\n",
      "\n",
      "Double Bonus Points: previous work on medical applications and/or with claims data]\"\n",
      "\"[Data Scientist - Marketing Analytics, \n",
      "\n",
      "San Francisco, CA, \n",
      "\n",
      "$130,000-$150,000, \n",
      "\n",
      "THE COMPANY, \n",
      "\n",
      "This emerging Direct to Consumer eCommerce brand is looking to add a Data Scientist (Marketing Analytics focused) to the team.\n",
      "entry --- Google\n",
      "substring --- Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\n",
      "\n",
      "Exposure to Google Machine Learning is a plus]\"\n",
      "\n",
      "\"[\n",
      "\n",
      "Lead a small team of data scientists to build products and services to delight our partners and customers.\n",
      "entry --- Google\n",
      "substring --- , \n",
      "\n",
      "Experience training machine learning models in a cloud computing environment such as: Amazon EC2, Google Cloud Platform, Microsoft Azure, etc.\n",
      "entry --- Google\n",
      "substring --- SQL or other querying languages\n",
      "\n",
      "Dashboard and visualization software (Tableau, D3, Mixpanel, Flurry, Google Analytics, etc.\n",
      "entry --- Google\n",
      "substring --- Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\n",
      "\n",
      "Exposure to Google Machine Learning is a plus, \n",
      "\n",
      "We are an Equal Opportunity Employer M/F/Disability/Vet and maintain a drug-free and smoke-free workplace.]\"\n",
      "entry --- Google\n",
      "substring --- Experience with cloud analytics platforms such as Microsoft Azure/AWS/Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- \"[We do research differently here at Google.\n",
      "entry --- Google\n",
      "substring --- You manage individual project priorities, deadlines, and deliverables, adapting to changes and setbacks in order to manage pressures, demonstrating and applying theories through research efforts to develop new and improved products, processes, or technologies., As a Research Scientist on the Google Cloud AI and Machine Learning (ML) team, you will be working on innovating and delivering the most advanced machine learning techniques to impact the world via Google Cloud.\n",
      "entry --- Google\n",
      "substring --- You‚Äôll have the opportunity to collaborate with the best AI talents in the company, both inside cloud as well as Google Research, DeepMind and other organizations.\n",
      "entry --- Google\n",
      "substring --- , The goal of Cloud ML is to innovate and deliver the best AI tech to impact the world via Google Cloud.\n",
      "entry --- Google\n",
      "substring --- We're developing Cloud ML on Google Cloud Platform, in close partnership with a number of teams across the company.\n",
      "entry --- Google\n",
      "substring --- We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\n",
      "entry --- Google\n",
      "substring --- We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\n",
      "entry --- Google\n",
      "substring --- Hadoop, Spark or Vertica) is required\n",
      "\n",
      "Minimum of 1-2 years implementing solutions in a cloud environment (AWS, Azure or Google)Prior experience leading technical teams of data scientists/engineers at various levels where you were responsible for providing project estimates for your work stream and assigning tasks to other team members\n",
      "\n",
      "Excellent written and oral communication skills; must be capable of effectively articulating technical concepts to executive level and business audiences\n",
      "\n",
      "Must have an undergraduate (BS) or postgraduate (MS/Ph.D.)\n",
      "entry --- Google\n",
      "substring --- Hadoop, Spark or Vertica) is required\n",
      "\n",
      "Minimum of 1-2 years implementing solutions in a cloud environment (AWS, Azure or Google)Prior experience leading technical teams of data scientists/engineers at various levels where you were responsible for providing project estimates for your work stream and assigning tasks to other team members\n",
      "\n",
      "Excellent written and oral communication skills; must be capable of effectively articulating technical concepts to executive level and business audiences\n",
      "\n",
      "Must have an undergraduate (BS) or postgraduate (MS/Ph.D.)\n",
      "entry --- Google\n",
      "substring --- And just happen to be Google Ventures backed as well.\n",
      "entry --- Google\n",
      "substring --- And just happen to be Google Ventures backed as well.\n",
      "entry --- Google\n",
      "substring --- Hadoop, Spark or Vertica) is required\n",
      "\n",
      "Minimum of 1-2 years implementing solutions in a cloud environment (AWS, Azure or Google) Prior experience mentoring & leading technical teams of junior data scientists where you were responsible for providing project estimates for your work stream and assigning tasks to other team members\n",
      "\n",
      "Excellent written and oral communication skills; must be capable of effectively articulating technical concepts to non-technical audiences\n",
      "\n",
      "Must have an undergraduate (BS) or postgraduate (MS/Ph.D.)\n",
      "entry --- Google\n",
      "substring --- )Link analysis and related topicsAnalytic software development in Python, Perl, R, Java, or other languages]\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \n",
      "\n",
      "As a Solutions Architect with a core focus on Machine Learning (ML), you'll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.\n",
      "entry --- Google\n",
      "substring --- In this role you will have a very unique opportunity to work hand-in-hand with customers and Google engineers to shape the future of ML on Google Cloud.\n",
      "entry --- Google\n",
      "substring --- Your passion for technology, learning, and solving problems, along with your enthusiasm for working with customers will empower a diverse audience of decision makers to embrace the Google Cloud to build what‚Äôs next for their businesses., \n",
      "\n",
      "As a member of this dynamic, exciting team, you will use your expertise in cloud technology to communicate directly with businesses of all types to help them seamlessly adopt Google products and solutions wherever they are on their cloud journey.\n",
      "entry --- Google\n",
      "substring --- You'll continuously explore and experiment with our advanced suite of products, partner tools, and third party applications to build and deploy cloud solutions that address customer use cases, all the while sharing valuable feedback with our product teams as you develop complex architectures, standard methodologies, and key strategies., \n",
      "\n",
      "Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- And our teams are dedicated to helping our customers ‚Äî developers, small and large businesses, educational institutions and government agencies ‚Äî see the benefits of our technology come to life., Facilitate deep technical discussions with customers, partners, and Googlers.\n",
      "entry --- Google\n",
      "substring --- Provide domain expertise around public cloud and enterprise technology, and effectively promote Google Cloud with customers, at conferences, and online.\n",
      "entry --- Google\n",
      "substring --- You will be a trusted partner in the team tackling the toughest and most impactful analytical problems while making the data accessible to the broader organization., \n",
      "\n",
      "Responsibilities include:\n",
      "\n",
      "Identify key questions, problems, and KPIs using your sharp business acumen and judgment, \n",
      "\n",
      "Conduct quantitative research and analysis requiring complex data retrieval that results in actionable insights and recommendations, \n",
      "\n",
      "Design and analyze rigorous a/b experiments, \n",
      "\n",
      "Analyze and share the results of product features and find opportunities to improve them, \n",
      "\n",
      "Work daily with product managers, engineers, and designers to discover and guide the most impactful product investments, \n",
      "\n",
      "Provide access to data through dashboards to empower your team, and look for opportunity to automate insights through alerting and anomaly detection, \n",
      "\n",
      "Qualifications:\n",
      "\n",
      "Passion for, and track record of leveraging data for business impact, preferably in a consumer facing digital environment, \n",
      "\n",
      "Ability to write complex and performant queries in your dialect of SQL to extract data from our Redshift cluster, \n",
      "\n",
      "Experience building tools and automated processes to extract, clean, and distill data in a procedural language of your choice such as Python, Julia or R, \n",
      "\n",
      "Understanding of A/B testing and other forms of statistical analysis using statistical packages similar to R, SAS, or Pandas, \n",
      "\n",
      "Excellent communication skills with the ability to distill complex problems into digestible insights, \n",
      "\n",
      "Effective data visualization skills with analytical tools such as Tableau, Looker, D3.js or other tools, \n",
      "\n",
      "Growth mindset; the ability to thrive in a dynamic and collaborative environment]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \n",
      "\n",
      "As a Solutions Architect with a core focus on Machine Learning (ML), you'll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.\n",
      "entry --- Google\n",
      "substring --- In this role you will have a very unique opportunity to work hand-in-hand with customers and Google engineers to shape the future of ML on Google Cloud.\n",
      "entry --- Google\n",
      "substring --- Your passion for technology, learning, and solving problems, along with your enthusiasm for working with customers will empower a diverse audience of decision makers to embrace the Google Cloud to build what‚Äôs next for their businesses., \n",
      "\n",
      "As a member of this dynamic, exciting team, you will use your expertise in cloud technology to communicate directly with businesses of all types to help them seamlessly adopt Google products and solutions wherever they are on their cloud journey.\n",
      "entry --- Google\n",
      "substring --- You'll continuously explore and experiment with our advanced suite of products, partner tools, and third party applications to build and deploy cloud solutions that address customer use cases, all the while sharing valuable feedback with our product teams as you develop complex architectures, standard methodologies, and key strategies., \n",
      "\n",
      "Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- And our teams are dedicated to helping our customers ‚Äî developers, small and large businesses, educational institutions and government agencies ‚Äî see the benefits of our technology come to life., Facilitate deep technical discussions with customers, partners, and Googlers.\n",
      "entry --- Google\n",
      "substring --- Provide domain expertise around public cloud and enterprise technology, and effectively promote Google Cloud with customers, at conferences, and online.\n",
      "entry --- Google\n",
      "substring --- \"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \n",
      "\n",
      "As a Solutions Architect with a core focus on Machine Learning (ML), you'll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.\n",
      "entry --- Google\n",
      "substring --- In this role you will have a very unique opportunity to work hand-in-hand with customers and Google engineers to shape the future of ML on Google Cloud.\n",
      "entry --- Google\n",
      "substring --- Your passion for technology, learning, and solving problems, along with your enthusiasm for working with customers will empower a diverse audience of decision makers to embrace the Google Cloud to build what‚Äôs next for their businesses., \n",
      "\n",
      "As a member of this dynamic, exciting team, you will use your expertise in cloud technology to communicate directly with businesses of all types to help them seamlessly adopt Google products and solutions wherever they are on their cloud journey.\n",
      "entry --- Google\n",
      "substring --- You'll continuously explore and experiment with our advanced suite of products, partner tools, and third party applications to build and deploy cloud solutions that address customer use cases, all the while sharing valuable feedback with our product teams as you develop complex architectures, standard methodologies, and key strategies., \n",
      "\n",
      "Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- And our teams are dedicated to helping our customers ‚Äî developers, small and large businesses, educational institutions and government agencies ‚Äî see the benefits of our technology come to life., Facilitate deep technical discussions with customers, partners, and Googlers.\n",
      "entry --- Google\n",
      "substring --- Provide domain expertise around public cloud and enterprise technology, and effectively promote Google Cloud with customers, at conferences, and online.\n",
      "entry --- Google\n",
      "substring --- Experience with BI / Big-data solutions (Hadoop, Google Cloud, Amazon Web Services Microsoft Azure)\n",
      "\n",
      "Experience with Microservice development is a plus\n",
      "\n",
      "Capable of guiding and inspiring team members, peers and stakeholders to drive the best possible practices\n",
      "\n",
      "Ability to think out-of-the-box and give pleasant surprises to end users over the data, Competencies, \n",
      "\n",
      "Excellent thought leadership in bioinformatics technology\n",
      "\n",
      "Strong customer and quality-focus is a must.\n",
      "entry --- Google\n",
      "substring --- You'll be a trusted partner in the team tackling the toughest and most impactful analytical problems., Responsibilities, Quantitative research and data analysis of partnerships, Complex data retrieval using SQL, Actionable insights and recommendations on relationships with existing partners and acquisition of new partners\n",
      "\n",
      "\n",
      "Analyze and present results of partner campaigns and make improvements, Build effective and scalable data models, Build and maintain production data within a data warehouse, Work with product managers, data and machine learning engineers to discover and guide the most impactful product investments, Design and analyze rigorous A/B experiments, Build dashboards and other analytical tools, Automate insights alerting anomaly detection, Requirements, Data leveraging for impact, preferably in customer facing retail or CPG space, SQL, and Python or R or SAS or Pandas, A/B testing, statistical analysis, Tableau, Looker, D3.js or similar tools, Data modeling, ETL and data pipeline development, Advanced degree in statistics or other quantitative field]\"\n",
      "[Responsibilities and Capabilities:, Coordinate the communication between the data science team and the development teams., Analyze data and study the system to provide meaningful insights on the product performance and the ways to improve it., Build predictive models to improve the advertising campaigns performances., Cross-collaborate with engineers on building statistical models, applying machine learning techniques for targeted solutions and effectively communicating the analysis and findings through interactive visualizations, documents and presentations., Cross-collaborate with the account management and sales teams to conduct dedicated studies for some of our big customers or demonstrate in client meetings, Some of the capabilities should include:, Strong interpersonal, oral and written communication and presentation skills, ability to communicate complex findings in a simple manner., Ability to communicate with Developers or Data-Analysts to describe complex algorithms in a simple manner., Enjoy discovering and solving problems; proactively seeking clarification of requirements and direction; being a self-starter who takes responsibility when required., Ability to explore different directions based on data and be able to quickly change direction based on the analysis., Minimum requirements:, 2+ years of work experience in a Data-Science team., Proven ability and experience in using data science, statistical computing, and modeling to improve business KPIs., Experience with statistical, predictive modeling, machine learning with big-data using tools like R, Hadoop, Spark, Strong mathematical skills., Solid communication skills,  Preferred Qualifications:, MS/ PhD in fields like computer science, mathematics, statistics, machine learning, operations research, data mining, AI., Understanding of public cloud design patterns and considerations in the areas of distributed systems, distributed storage systems, big-data, data mining, cluster computing., Basic understanding of the distributed concepts behind Hadoop and Spark Data-Analysis frameworks., Strong ability to learn new concepts quickly., PostgreSQL, Hadoop, Cassandra, Aerospike, Redis, LevelDB, Golang; Java; JavaScript; Python; C; C#, AWS; Google Cloud; OpenStack, NSQ, Kafka, Flume, GCP Pub/Sub, Consistently trying out new possibilities]\n",
      "\"[Principal Data Scientist, \n",
      "\n",
      "South Bay, \n",
      "\n",
      "Harnham are currently partnering with a well funded Series A start up based in the South Bay in their search for a Principal Data Scientist, \n",
      "\n",
      "With a high degree of flexibility and ownership, you will be working with a high performing, mission driven team, that is disrupting the way we understand, diagnose and treat numerous illnesses.\n",
      "entry --- Google\n",
      "substring --- Agile: Experience participating in Scrum based projects, \n",
      "\n",
      "Experience working with ML & AI technology platforms such as Google.AI, AWS, and or Azure a plus.\n",
      "entry --- Google\n",
      "substring --- You can find us in 27 cities across the U.S., U.K., and Canada., \n",
      "\n",
      "Job Title, \n",
      "\n",
      "Solution Principal ‚Äì Machine Learning, \n",
      "\n",
      "As a Solution Principal, you‚Äôll design and deliver innovative Machine Learning solutions on Amazon Web Services, Azure and Google Cloud using core cloud data science tools and other big data related technologies.\n",
      "entry --- Google\n",
      "substring --- You can find us in 27 cities across the U.S., U.K., and Canada., \n",
      "\n",
      "Job Title, \n",
      "\n",
      "Solution Principal ‚Äì Machine Learning, \n",
      "\n",
      "As a Solution Principal, you‚Äôll design and deliver innovative Machine Learning solutions on Amazon Web Services, Azure and Google Cloud using core cloud data science tools and other big data related technologies.\n",
      "entry --- Google\n",
      "substring --- and Ph.D are preferred)\n",
      "Strong written and verbal communication skills\n",
      ", Experience with sklearn, pandas, numpy or similar packages\n",
      "Familiarity with malware, host forensics, or network traffic analysis concepts\n",
      "Experience with Linux command line and bash scripting\n",
      "Experience with reverse engineering malware\n",
      "Experience with AWS infrastructure\n",
      "Experience with a deep learning frameworks such as TensorFlow, Theano, or MXNet\n",
      "Experience with GPU-accelerated computing and hardware (e.g., NVIDIA DGX-1)\n",
      "Experience using Hadoop and Spark\n",
      "Experience using relational and non-relational databases\n",
      "Experience with web frameworks to visualize large datasets\n",
      "]\"\n",
      "\"[\n",
      "Design and implement critical, highly scalable systems and algorithms to run analytics, workflow and machine learning\n",
      "Improve Scalability, Reliability and performance of our Streaming Data Pipelines built on top of Kafka and Spark\n",
      "Help drive the Design and Architecture of next generation Cloud Machine Learning platform\n",
      "Design methods to derive Data Insights via efficient and effective feature learning for challenging problems\n",
      ", \n",
      "You have experience designing and implementing large scale distributed systems for Stream and Batch processing\n",
      "Your idea of fun is reading the Google Millwheel paper, and you get excited debating the merits of Flink versus Spark\n",
      "You have designed creative models to derive actionable insights from complex datasets\n",
      "You have a passion for creating new products, including being comfortable with ambiguity\n",
      "BS/MS/PhD in Computer Science or equivalent work experience\n",
      "Strong background in computer science algorithms\n",
      "Contributions to relevant open source projects is a plus\n",
      "]\"\n",
      "\"[Senior Data Scientist, Senior Data Scientists on our team partner with product managers, SMEs and our clients to form a cross-functional team driving optimization of precious healthcare resources.\n",
      "entry --- Google\n",
      "substring --- Lead the data science aspect of multiple engagements at the same time\n",
      "Work on complex data sets from some of the world‚Äôs largest organizations\n",
      "Work in a multi-disciplinary environment mixing highly skilled people in data science, data engineering and design\n",
      "Build strong links with the academic world and constantly share ideas and stay ahead of the curve on the latest methods\n",
      "Help grow and shape an elite team of world-class data scientists\n",
      ", Requirements, \n",
      "Deep experience in statistical modeling, machine learning and deep learning techniques/frameworks\n",
      "Proven record of applying data science methods to business problems\n",
      "Strong presentation and communication skills, with a knack for explaining complex analytical concepts to people from other disciplines\n",
      "Programming experience in at least 2 of the following language: R, Python, Scala\n",
      "Educated to a PhD level in the field of Computer Science, Machine Learning, Applied Statistics or Mathematics\n",
      "Team leadership, mentoring and project management skills]\"\n",
      "[Required Skills: , - 4+ years as a Data Scientist, - Machine Learning, - Python/R and Google Cloud Platforms (or any other Cloud Platforms), Educational Qualification: , Bachelor‚Äôs Degree, or equivalent work experience., Job Type: Full-time, Salary: $150,000.00 to $210,000.00 /year, Experience:, Machine Learning: 1 year (Preferred)Google Cloud Platform: 1 year (Preferred)Python: 1 year (Preferred), Education:, Bachelor's (Required), Work authorization:, United States (Required)]\n",
      "\"[\n",
      "MS/PhD in a quantitative field e.g., Physics, Astronomy, Chemistry, CS, Math or have worked in Data Science, Quantitative Research or Software Development for 5 years.\n",
      "entry --- Google\n",
      "substring --- Experience writing production ready code is a plus\n",
      "Experience with GCP or other cloud platforms is a plus\n",
      ", If you are a true data enthusiast who wants to elevate yourself and your company to the next level then please send your Word resume to afagin@daleyaa.com for consideration., #LI-AF1]\"\n",
      "\"[\n",
      "Establish Life Science Analytics prototype platform ‚Äì Guiding the effort to produce a first prototype of the life sciences Analytics platform, in collaboration with other members of the team (biostatisticians and clinical data analysts) developing and embedding the first data science packages leveraging HealthCatalyst data for Life Science Analytics into a more generalizable framework that can be re-utilized and re-deployed to solve other similar problems, leveraging Google Datalab platform/Jupyter Notebooks.\n",
      "entry --- Google\n",
      "substring --- , \n",
      "Machine learning experience required\n",
      "Natural language processing experience preferred\n",
      "Shiny, Spyre, Flask, WebDev and prototyping experience preferred\n",
      "JupyterHub, Sun Grid Engine, Google Cloud Platform, AWS experience preferred\n",
      "Experienced in data science methodologies and techniques, e.g.\n",
      "entry --- Google\n",
      "substring --- Significant scientific background with prior experience in clinical research\n",
      "PhD in relevant domain highly preferred (Data Science, Machine Learning ideally applied to health-related insight generation)\n",
      "Ability to derive robust insights from complex RWD datasets\n",
      "Must have experience in performing data analysis utilizing statistical frameworks (R, SciPy) and ideally experienced already in using environments such as Jupyter Notebooks/Google Datalab\n",
      "Some data engineering experience (ETL, SQL) desirable\n",
      "Must be comfortable working in rapid prototyping environment, using agile approaches to guiding teams and projects\n",
      "Some understanding of drug development process and use of biomedical data for drug development and clinical trials design preferred\n",
      "Strong communication skills; ability to guide small projects, interacting with clients and internal management.\n",
      "entry --- Google\n",
      "substring --- [Adept at researching, testing, and analyzing.Review existing analytics to make informed data-driven recommendations for SEO improvements.Collaborate with internal teams to recommend and implement SEO improvements to a wide variety of sites.Keep current with trends and advancements in technology, SEO, UI/UX, Google algorithm updates, etc.Ability to manage several projects simultaneously in a fast-paced environment.Help prioritize projects for maximum impact in as short a time as possible.Assist SEO team with site audits through crawling tools and personal direct assessment to maintain best practices as well as diagnosis potential issues., A strong analytical mind, with demonstrated experience with SEO.A great communicator, boiling complex concepts down into clear, actionable instructions.A true collaborator, working with multiple stakeholders across teams to educate, influence, and execute.Willingness to dive in and research a problem from multiple points-of-view, provide supported conclusions, and lay out a clear go forward game plan.]\n",
      "entry --- Google\n",
      "substring --- Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "Primarily using R, write and maintain scripts to clean and organize raw data sets\n",
      "Create cross-sectional and longitudinal data sets from raw data files\n",
      "Create systems for assuring data quality and accuracy\n",
      "Create visualizations to help users understand and explore data\n",
      "Respond to organizational requests for data analysis\n",
      "Ensure consistency between data analyses, Google-based tools, and Tableau dashboards\n",
      ", \n",
      "Maintain repository of R scripts for automated overnight data processing and incorporate new analyses and descriptives as needed\n",
      "Support the integration of additional data sources into New Visions data warehouse and data tools\n",
      "Support the operationalizing of robust data quality assurance within data infrastructure\n",
      ", \n",
      "Collaborate with data users to understand their needs, build tools, and conduct analyses to support them\n",
      "Support schools and network leaders in launching tools and analyzing data within tools to make evidence-based decisions\n",
      "Provide analysis to Management Team, cross-network meetings, and other collaborative structures\n",
      "Develop mechanisms for collecting feedback and modifying analyses and data tools to reflect internal and external data priorities\n",
      ", \n",
      "Masters degree in public administration, public policy, education, statistics, economics, psychology, sociology, or related social science field.\n",
      "entry --- Google\n",
      "substring --- Highly proficient with Microsoft Excel and Google Apps.\n",
      "entry --- Google\n",
      "substring --- , Supports all aspects of data on-boarding, data cleansing, analytics, data interpretation and maintaining the analytic data warehouse., Consults with internal stakeholders on data requirements., Will work with unstructured data sets to identify information that can be used for predictive modeling/analytics, Implements best practices to deliver scalable marketing analytics in partnership with the segment analysts., Performing other duties as assigned or apparent., Qualifications, experience and personal specification, Google Analytics (or similar) guru & comfort with large record data sets\n",
      "Strong quantitative and analytic ability with attention to detail.\n",
      "entry --- Google\n",
      "substring --- , Google Analytics (or similar) guru & comfort with large record data sets, Strong quantitative and analytic ability with attention to detail., Strong problem solving ability including generating hypotheses, conducting root cause analysis and developing actionable recommendations., Willingness to do detailed work as well as higher level strategic analysis., Effective verbal and written communication skills with the ability to clearly and concisely articulate information to diverse audiences., Ability to build strong relationships with cross-functional teams and become a trusted business partner., Results oriented with the ability to organize and independently manage multiple projects simultaneously., Effective time management and prioritization skills including estimating appropriate time for tasks and deliverables, creating focus, eliminating roadblocks and consistently meeting deadlines., Strong decision making skills by incorporating a combination of analysis, experience and judgment., Qualifications, Bachelor‚Äôs degree in marketing, business, finance or other quantitative field.\n",
      "entry --- Google\n",
      "substring --- Experience with using web analytics tools such as Google Analytics.\n",
      "entry --- Google\n",
      "substring --- , Bachelor‚Äôs degree in marketing, business, finance or other quantitative field., Over three years of marketing analytics experience., Proficient at Excel, PowerPoint and Word, Tableau., Experience with statistical packages such as SAS and reporting packages., Experience with using web analytics tools such as Google Analytics., Experience with using CRM data from Salesforce., Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.\n",
      "entry --- Google\n",
      "substring --- Additionally, the analyst will be called upon to work directly with school leaders to interpret and act on their data, and to collaborate across all departments within the organization., \n",
      "\n",
      "ESSENTIAL JOB FUNCTIONS:, \n",
      "\n",
      "Clean, manipulate, organize and analyze student and school performance data, \n",
      "Primarily using R, write and maintain scripts to clean and organize raw data sets\n",
      "Create cross-sectional and longitudinal data sets from raw data files\n",
      "Create systems for assuring data quality and accuracy\n",
      "Create visualizations to help users understand and explore data\n",
      "Respond to organizational requests for data analysis\n",
      "Ensure consistency between data analyses, Google-based tools, and Tableau dashboards\n",
      ", Manage infrastructure for processing large data sets for use in NV data tools and analyses, \n",
      "Maintain repository of R scripts for automated overnight data processing and incorporate new analyses and descriptives as needed\n",
      "Support the integration of additional data sources into New Visions data warehouse and data tools\n",
      "Support the operationalizing of robust data quality assurance within data infrastructure\n",
      ", Collaborate with internal and external colleagues to infuse New Visions tools, structures and strategies with a data-driven approach, \n",
      "Collaborate with data users to understand their needs, build tools, and conduct analyses to support them\n",
      "Support schools and network leaders in launching tools and analyzing data within tools to make evidence-based decisions\n",
      "Provide analysis to Management Team, cross-network meetings, and other collaborative structures\n",
      "Develop mechanisms for collecting feedback and modifying analyses and data tools to reflect internal and external data priorities\n",
      ", REQUIRED EDUCATION AND EXPERIENCE:, \n",
      "Masters degree in public administration, public policy, education, statistics, economics, psychology, sociology, or related social science field.\n",
      "entry --- Google\n",
      "substring --- Highly proficient with Microsoft Excel and Google Apps.\n",
      "entry --- Google\n",
      "substring --- They will also filter and clean the data, identify and analyze trends along with working with data engineers and scientists to ensure identified trends are implemented to enable JetBlue Travel Products to become a digital disruptor., \n",
      "\n",
      "The Data Analyst can change priorities and focus to meet business demands, excels when working on complex projects, is motivated to deliver results, and exhibits the JetBlue values of Safety, Caring, Integrity, Fun, and Passion., Build and prototype analysis pipelines in order to provide insights at scale.Make business recommendations with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.Develop comprehensive understanding of data structures and metrics, advocating for changes that will improve product adoption and customer conversion.Run live experiments that drive key product decisions.Work with data engineers to embed the research into production pipelines.Partner with product management and marketing teams to identify opportunities, envision and design technology products.Assist with creating the data infrastructure and analytics environments.Participate in the DevOps practice as it pertains to data team.Partner with JetBlue Tech Ventures to identify, monitor, learn, experiment and share information about emerging technology that is relevant to JetBlue Travel Products.Other duties as assigned., Bachelor‚Äôs Degree in Computer Science or related technical field or equivalent practical experience with demonstrated capability to perform job responsibilities through four (4) previous years of experience and education.One (1) years‚Äô experience in an Analyst role.Good understanding of software engineering environments and standards.Experience managing Service Level Agreements (SLA‚Äôs) Interacting daily with people at different levels within the organization, including developing and maintaining ongoing relationships.Pass a ten (10) year background check and pre-employment drug test.Legally eligible to work in the country in which the position is located.Proficient in Python with numpy, pandas.Proficient with Jupyter notebooks, Datalab notebooks.Proficient in linear algebra and statistics.Familiar with DataStudio, Looker, Tableau.Familiar with basic SQL for structured and unstructured data.Familiar with cloud technologies, SAAS, IAAS.Familiar with ML concepts., Maintaining a public profile and building relationships throughout the organization.Three (3) years‚Äô experience in technology roles.Experience in writing software in one or more languages such as Java, Python, Go and/or JavaScript.Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud Platform., Regular attendance and punctuality.Potential need to work flexible hours and be available to respond on short-notice.Well-groomed and able to maintain a professional appearance.When working or traveling on JetBlue flights, and if time permits, all capable crewmembers are asked to assist with light cleaning of the aircraft.Organizational fit for the JetBlue culture, that is, exhibit the JetBlue values of Safety, Caring, Integrity, Passion, and Fun., Computer and other office equipment., Generally not required, or up to 10 pounds occasionally, 0 pounds frequently.\n",
      "entry --- Google\n",
      "substring --- [Engages with Google fellows, local Goodwill¬Æ team members, GII colleagues and other subject matter experts to coordinate implementation of the Google-supported Goodwill Impact Data Collaboration (IDC).Facilitates work on mission impact systems from implementation and enhancement.Prepares effective oral and written communications and materials to support alignment, collaboration and learning.Provides technical training to internal project team members and Goodwill member users.]\n",
      "entry --- Google\n",
      "substring --- Leverage Google Analytics and internal data to provide key insights by analyzing customer behavior.\n",
      "entry --- Google\n",
      "substring --- Skilled in SQL and Google Analytics.\n",
      "entry --- Google\n",
      "substring --- Experience with Google and Adobe analytics.\n",
      "entry --- Google\n",
      "substring --- You will be working with internal customers in all departments (marketing, finance, operations and customer service) to dig into data insights and develop operation and business metrics using a wide range of tools (Redshift, Looker, Tableau, etc)., \n",
      "\n",
      "Responsibilities, \n",
      "\n",
      "Own business intelligence and reporting of overall company KPIs and performance metrics by product, \n",
      "\n",
      "Build and utilize tools and processes that will scale our reporting and analytics capabilities and help shape the data roadmap\n",
      "\n",
      "Perform diagnostics and data-driven recommendations to improve overall performance\n",
      "\n",
      "Own business forecasts ‚Äì overall and by product\n",
      "\n",
      "Work with marketing, finance, operations, support teams to help shape and track business objectives with a data-driven approach\n",
      "\n",
      "Support all cross-functional teams by prioritizing and responding to ad hoc analytics needs, \n",
      "\n",
      "Qualifications, \n",
      "\n",
      "Bachelor‚Äôs degree in Computer Science, Engineering, Statistics or equivalent\n",
      "\n",
      "3 years in a previous position as a data analyst, ideally for a web or mobile-based business\n",
      "\n",
      "Proficient knowledge in SQL and relational databases\n",
      "\n",
      "Proficient knowledge in MS Excel or Google Sheets including formats, charts, tables, functions\n",
      "\n",
      "Experience in data visualization tools such as Tableau or Looker\n",
      "\n",
      "Demonstrated experience showing strong critical thinking and problem solving skills paired with a desire to take initiative\n",
      "\n",
      "Demonstrated experience working under pressure, both individually and collaboratively in a team environment\n",
      "\n",
      "Demonstrated organizational skills and customer focus]\"\n",
      "\"[\n",
      "\n",
      "For the 28th year, MSK has been named a top hospital for cancer by U.S. News & World Report.\n",
      "entry --- Google\n",
      "substring --- Google Analytics, Omniture, Chartbeat, Crimson Hexagon) and traffic patterns, as well as Social Media analytics platforms (i.e.\n",
      "entry --- Google\n",
      "substring --- Lucktastic is consistently ranked in the top 3 on Google Play Store‚Äôs lifestyle category (beating brands like Tinder, Zillow, and Starbucks) and are regularly in the Apple Store‚Äôs top 10.\n",
      "\n",
      ", Jump Ramp‚Äôs team of nearly 40 employees works out of an airy 11th-floor loft in Midtown Manhattan‚Äôs Fashion District, and includes action-figure collecting developers, tattooed fixed-bike-riding artists, Classic Rock-singing CSR reps, globe-trotting marketing and sales people, and two founders who keep their shirts untucked and their office door open.\n",
      "entry --- Google\n",
      "substring --- Highly proficient in MS Excel and/or Google Sheets.\n",
      "entry --- Google\n",
      "substring --- Assisting in the design and distribution of an Enterprise-wide Dimensional data warehouse., \n",
      "\n",
      "had some exposure to query writing using SQL\n",
      "\n",
      "will have a demonstrable affinity for logical thought\n",
      "\n",
      "will have a desire to work independently on individual tasks, while functioning as part of a team\n",
      "\n",
      "will have a desire to assist others, both as an interpreter and provider of data\n",
      "\n",
      "will have a demonstrable desire to continually learn and be able to apply new information\n",
      "\n",
      "a background or education in accounting is preferred but not required]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: Boulder, CO, USA; Mountain View, CA, USA, \n",
      "\n",
      "At gTech‚Äôs Users and Products team (gUP), our mission is to help users get the most out of Google.\n",
      "entry --- Google\n",
      "substring --- We represent the voice of Google's users and many of our partners globally, sharing insights with the larger Google organization to enable exceptional customer and product experiences.\n",
      "entry --- Google\n",
      "substring --- gUP builds innovative solutions that take user experience and engagement with Google to the next level, supporting users across products, countries, cultures, incomes, and identities.\n",
      "entry --- Google\n",
      "substring --- We advocate for users through partnerships with product areas at Google (and some Alphabet businesses), supporting Google‚Äôs consumer products ecosystem and enabling numerous launches for Google‚Äôs consumer products each year.\n",
      "entry --- Google\n",
      "substring --- You will be expected to focus on results, be a self-starter and demonstrate success in using analytics to drive the understanding, progression and excellence in product and operations., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.\n",
      "entry --- Google\n",
      "substring --- Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products.\n",
      "entry --- Google\n",
      "substring --- ), with a minor (or equivalent experience) in Computer Science, or Software engineering\n",
      "2-3 years‚Äô experience with programmatic data analysis (preferably using R); experience with time series analysis/forecasting or customer analytics a plus\n",
      "Experience working with real-world datasets, including joining disparate data sources, record linkage, data cleaning/reshaping/management, and descriptive data analysis; data visualization and automated reporting skills (such as RMarkdown or Shiny) a plus\n",
      "Experience writing relational database queries (preferably using Postgres SQL)\n",
      "Exposure to web analytics (such as Google Analytics or Adobe Analytics) and e-commerce fundamentals a big plus\n",
      "Strong verbal and written communication skills: able to produce professional-quality, insightful deliverables, and experience communicating analysis and insight to all levels of an organization\n",
      "Experience managing project ambiguity, complexity, and interdependencies in a methodical way\n",
      "Excellent attention to detail and a systematic approach to problem-solving, with strong data intuition\n",
      ", Founded in 2012, IXIS is rooted in innovative processes for data-driven digital experience and strategic online planning.\n",
      "entry --- Google\n",
      "substring --- Reporting to the Director of Data Management and working closely with the numerous stakeholders on both the Program and Development teams, the individual in this role is responsible for understanding our schema inside and out; understanding our existing data; understanding the universe of available data; and ultimately for turning data into reliable, trustworthy stories for all levels within the organization., Reporting (50%):, Produce reports on-demand for C-level, program, and development staff\n",
      "Reactively and proactively provide analytics from Google Analytics\n",
      "Represent reports visually using tools like Google Data Studio or others\n",
      "Be innovative and at-times experimental about sharing data using various clever means to keep the stories interesting\n",
      "Summarize and translate analytics\n",
      "Tease out trends in the data that might not be immediately obvious\n",
      "Work with teams in each region to understand unique trends; facilitate sharing of best practices for data use across organization\n",
      "Keep abreast of advances in analytics and data visualization\n",
      "Occasionally attend relevant events, meetups, and conferences\n",
      "Be forward-thinking - critical thinking about data is key!\n",
      "entry --- Google\n",
      "substring --- , Locate duplicates and assist in implementing means to prevent duplication\n",
      "Constantly promote and apply best practices in data management\n",
      "Spot check existing common reports and correct filtering or returned data errors\n",
      "Help identify and purge vestigial data\n",
      ", Become deeply familiar with the data structures and mechanisms at Facing History\n",
      "Recognize data that is unnecessary or not actionable and develop strategies to eliminate it\n",
      "Assist in creation and maintenance of systems maps and schema\n",
      "Identify areas for improvement in data storage and analysis\n",
      "Cross-train teammates and be transparent with expertise\n",
      "Identify data conflicts and misalignment and coordinate with the team on plans for improving data quality\n",
      "Identify redundancies\n",
      ", 3-5 years of experience required in analytics\n",
      "Google Analytics experience required\n",
      "Salesforce experience strongly preferred but not required\n",
      "EU privacy compliance law (GDPR) understanding preferred but not required\n",
      "Google Data Studio experience a plus\n",
      "HubSpot experience a plus\n",
      ", Qualified candidate must be:, Very detail-oriented with a focus on accuracy; this cannot be overstated for someone in an analyst role\n",
      "A strong communicator, both written and oral, and be comfortable with phone outreach on occasion\n",
      "Comfortable both producing and interpreting data\n",
      "Able to work collaboratively and at the same time be able to work independently for long periods of time\n",
      "Responsive and respectful to all requests but pragmatic around priorities\n",
      "Flexible and agile in approach as needs change and evolve\n",
      "Willing to experiment with and learn new technologies, and to share best practices]\"\n",
      "\"[\n",
      "Analyze and generate actionable insights from structured and unstructured data\n",
      "Analyze BBYO's progress in meeting accountability goals\n",
      "Data sleuthing and data set management: regularly query database for internal and external stakeholder requests, solving data mysteries and creating data resources for analysis.\n",
      "entry --- Google\n",
      "substring --- All other revenue cycle management as assigned by supervisor\n",
      ", Minimum two to three years of experience with revenue cycle functions; experience in healthcare financial analysis, revenue cycle processes, denials, and cash applications strongly desired\n",
      "Ability to demonstrate problem-solving, analytical, oral and written communication skills, and the ability to interact professionally with a diverse group\n",
      "Ability to engage in multiple initiatives simultaneously while working in a dynamic environment subject to impromptu changes in schedules and priorities\n",
      "Experience with data analysis and modeling to enable operational processes\n",
      "Proficient in Microsoft Office applications, including Visio, Word, Excel, Access, and Powerpoint\n",
      "Strong initiative ‚Äì establish goals and take responsibility for meeting them within defined timelines\n",
      ", Revenue Cycle functions & financial analysis: 3 years (Required)]\"\n",
      "\"[Track in-game behaviors/metrics and provide analysis and recommendations for product changes and/or enhancements\n",
      "Perform data analysis to support the operation and development of games\n",
      "Understand marketing and game metrics and apply knowledge to identify analytical requirements that drive business profitability\n",
      "Work with cross-functional teams to develop scheduled and ad hoc reports from a variety of sources for operations, marketing, and game design\n",
      "Analyze in-game monetization to identify opportunities for improvement\n",
      "Analyze marketing campaigns to determine efficiency and potential for optimization\n",
      ", A Bachelor‚Äôs degree in data analytics, statistics or related field, with a heavy statistics orientation\n",
      "3+ years relevant work experience\n",
      "Very strong knowledge of one or more statistical tools such as R, Stata, SAS or Minitab\n",
      "Strong knowledge of Excel, PowerPoint and SQL (experience with MySql and Vertica syntax preferred)\n",
      "Experience applying data mining techniques (i.e., classification, clustering, association mining, forecasting), statistics and information retrieval methods to large data sets\n",
      "Ability to write queries, pull and manipulate data sets and perform data analysis based on large data sets\n",
      "Experience analyzing data from a variety of sources and types, both internal and external\n",
      "Self-starter, able to work independently with a wide degree of latitude and creativity\n",
      "Strong interpersonal and communication skills\n",
      "Strong problem solving and analytical skills\n",
      "Solid quantitative background\n",
      "Proven track record in presenting complex results to users in an understandable manner\n",
      ", Tableau\n",
      "Google Analytics\n",
      "The mobile and online game industry\n",
      "Free to play MMO games\n",
      ", Please make sure that the durations of your education and employment on your resume are included in month/year format\n",
      "Salary will be commensurate with experience\n",
      "Only highly qualified candidates need apply and only candidates that meet the degree requirements will be considered\n",
      "Applicants must be legally able to work in the U.S. for KingsIsle]\"\n",
      "\"[Data Analyst, Community Reach Center (CRC) is an Integrated Health Care and Trauma Informed Care Community that serves a metropolitan area in Denver, CO. Our 500 employees offer a wide variety of services to individuals and families in schools, day-treatment, residential, hospital, and correctional facilities., We are seeking a Data Analyst to join our team who is committed to enhancing lives every day.\n",
      "entry --- Google\n",
      "substring --- PostgreSQL, MongoDB)\n",
      "\n",
      "Aptitude for problem solving\n",
      "\n",
      "Strong quantitative analysis skills\n",
      "\n",
      "Excellent written and spoken communication skills\n",
      "\n",
      "Good presentation skills\n",
      "\n",
      "Track record of learning new skills and putting them to use immediately\n",
      "\n",
      "Hunger for continued learning\n",
      "\n",
      "Sense of ownership and pride in your performance and that of the company\n",
      "\n",
      ", Things That Will Impress Us\n",
      "\n",
      ", Experience with eCommerce, Magento Commerce, and/or Magento BI\n",
      "\n",
      "Knowledge of Google Analytics\n",
      "\n",
      "Experience with data analysis\n",
      "\n",
      "Customer-facing experience\n",
      "\n",
      ", At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists .\n",
      "entry --- Google\n",
      "substring --- Expert in Microsoft Excel and Powerpoint (or equivalent)\n",
      "\n",
      "Experience with website reporting tools, such as Google Analytics, Adobe Analytics, or similar.\n",
      "entry --- Google\n",
      "substring --- \"[Security is at the core of Google's design and development process: it is built into the DNA of our products.\n",
      "entry --- Google\n",
      "substring --- , As a Project and Data Analyst, you'll deliver innovative solutions that help our entire team keep pace with Google‚Äôs rapidly changing landscape.\n",
      "entry --- Google\n",
      "substring --- You believe that great just isn't good enough, and constantly seek out opportunities to improve Google‚Äôs security services, by leveraging data.\n",
      "entry --- Google\n",
      "substring --- Prior experience in security is not a prerequisite for this position., From keeping Googlers safe and secure to managing disruptive events, the ability to anticipate, deter, detect, and act are the pillars of Google‚Äôs Global Security and Resilience Services (GSRS) team.\n",
      "entry --- Google\n",
      "substring --- As a member of GSRS you will help develop a culture where safety, security and resiliency are integrated into every facet of Google, including the creative process.\n",
      "entry --- Google\n",
      "substring --- You‚Äôll work on exciting brand and acquisition campaigns, perform site optimizations, monitor and run reporting, contribute to an online testing strategy and more., \n",
      "\n",
      "Day-to-day, your role includes:\n",
      "\n",
      ", Keeping a pulse on day-to-day performance data, including display media, site, search, email, and/or social campaigns\n",
      "\n",
      "Working in a variety of reporting systems and databases for the creation of recurring reports and dashboards\n",
      "\n",
      "Identifying nuances in data to optimize our clients‚Äô business\n",
      "\n",
      "Supporting marketing initiatives across project and campaign lifecycles, including measurement plans, primary and secondary research, and performance reporting\n",
      "\n",
      "Expanding industry knowledge and relevant skillsets through internal training, \n",
      "\n",
      "We‚Äôre looking for strong, impactful work experience, which typically includes:, \n",
      "\n",
      "A four-year college degree\n",
      "\n",
      "1-3 years of work experience in the social analytics space\n",
      "\n",
      "Passion for digital marketing, eagerness to learn in a constantly-changing space, and a natural curiosity\n",
      "\n",
      "Experience with Analytics across social channels and tactics (i.e., Facebook, Instagram, Twitter, Pinterest, Social Retargeting)\n",
      "\n",
      "Solid experience with display ad-serving, 1st party onboarding/targeting, brand study measurement partners, and Site Analytics\n",
      "\n",
      "Experience building real-time reporting/dashboarding, knowledge of quantitative and qualitative side of analytics\n",
      "\n",
      "Exposure and experience with Social Listening tools (i.e., Netbase, Brandwatch, Affinio, Crimson Hexagon)\n",
      "\n",
      "Extensive knowledge in data management, data mining, data integration\n",
      "\n",
      "Experience compiling measurement plans and identifying KPIs and optimization metrics\n",
      "\n",
      "Well-versed in Microsoft Office suite ‚Äì Excel, Word, PPT\n",
      "\n",
      "Someone who can work quickly and manage multiple tasks to completion\n",
      "\n",
      "The ability to quickly \"\"switch gears\"\" while remaining organized across multiple projects\n",
      "\n",
      "Strong oral/written communication skills\n",
      "\n",
      "Retail and/or beauty experience is a plus, Facebook\n",
      "\n",
      "Instagram\n",
      "\n",
      "Twitter\n",
      "\n",
      "Pinterest\n",
      "\n",
      "Google Analytics\n",
      "\n",
      "Adobe Omniture\n",
      "\n",
      "Netbase\n",
      "\n",
      "Brandwatch\n",
      "\n",
      "Affinio\n",
      "\n",
      "Crimson Hexagon\n",
      "\n",
      "DCM (DoubleClick), \n",
      "\n",
      "Got what it takes?\n",
      "entry --- Google\n",
      "substring --- [Work with resort marketing teams to ensure Google Tag Management is properly applied on their websites and Ecommerce engines ensuring accurate tracking, Help develop and manage acquisition funnels for all resorts ‚Äì on datarama, Work with Marketing teams to take advantage of guest data in our sequel azure database, Once in SQL, develop queries that provide insights to marketing teams as well as responding, Expertise in Google Tag Manager and utilizing tracking toolsExpertise in SQL and ability to write queriesExpertise in Microsoft Office applicationsGood listening and communication skills]\n",
      "\n",
      "\"[Clarivate Analytics clients are the trailblazers and risk takers who come up with life-changing ideas.\n",
      "entry --- Google\n",
      "substring --- Understanding of machine-learning and operations research\n",
      "\n",
      "Experience with Business Objects, Core Metrics, SQL, Google Analytics, or other analytical tools.\n",
      "entry --- Google\n",
      "substring --- The role serves as a key Marketing Analytics team member in measuring performance of marketing initiatives and making proactive recommendations that deliver the key performance goals of the agency‚Äôs clientele., Create custom reports and dashboards, audit performance on an on-going basis, and build automated reports where relevant\n",
      "\n",
      "Build and distribute repeatable reports and performance metrics/insights on client marketing campaigns\n",
      "\n",
      "Collect, maintain, manage, interpret and analyze data received from internal and external data sources\n",
      "\n",
      "Proficient with Excel when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\n",
      "\n",
      "Experience with data visualization and analytic dashboard development in Tableau\n",
      "\n",
      "Report requirements collection/analysis, writing SQL, extracting structured data sets, building reports\n",
      "\n",
      "Perform ad hoc analysis and data investigation/ discovery to identify and/or explain business and marketing trends or anomalies\n",
      "\n",
      "Analyze marketing channel and website performance data for assigned projects and develop recommendations on ways to further optimize for performance\n",
      "\n",
      "Work cross-functionally to help inform the agency and clients on key learnings from data analysis, Able to perform in a highly analytical role delivering actionable marketing campaign insights\n",
      "\n",
      "Ability to deep dive into performance data on a daily basis, drawing conclusions and making optimization recommendations\n",
      "\n",
      "Highly analytical, focused on informing performance optimization based on gathering and examining data from multiple sources\n",
      "\n",
      "Excel guru when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\n",
      "\n",
      "Deep knowledge of web analytics tools (Adobe Analytics, Google Analytics, Optimizely, etc.)\n",
      "entry --- Google\n",
      "substring --- Ability to adapt to evolving business requirements and objectives in a fast-paced environment, \n",
      "\n",
      "Bachelor‚Äôs degree in Marketing, Business or equivalent relevant experience\n",
      "\n",
      "Minimum of 1-2 years experience working with consumer databases and exposure to data-driven marketing programs\n",
      "\n",
      "Advanced skills with Excel, Visio, and PowerPoint\n",
      "\n",
      "Experience with online tracking and reporting tools such as Google Analytics, DoubleClick DART, and Omniture\n",
      "\n",
      "Proficiency with SQL\n",
      "\n",
      "Experience with Marketing Automation Platform, Marketo is preferred\n",
      "\n",
      "Report creation experience with business intelligence tools (e.g.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Understand the ad ecosystem including how an ad gets monetized\n",
      "\n",
      "Familiar with DFP, Google Analytics\n",
      "\n",
      "Familiar with spreadsheet tools such as Excel, Google Sheets\n",
      "\n",
      "Familiar with data visualization tools such as Tableau, Data Studio\n",
      "\n",
      "Able to write code in SQL\n",
      "\n",
      "Curious and numerical minded\n",
      "\n",
      "Ability to work cross-functionally with different teams with varying technical levels\n",
      "\n",
      "Great interpersonal skills\n",
      "\n",
      "Bachelor‚Äôs Degree, \n",
      "\n",
      "2 years of working experience in an analyst/quantitative role\n",
      "\n",
      "Experience with pulling reports and data out of DFP\n",
      "\n",
      "Familiarity with Salesforce\n",
      "\n",
      "Experience in BigQuery\n",
      "\n",
      "Attention to details\n",
      "\n",
      "Experience writing automation code in Python/R/AppScripts etc., \n",
      "\n",
      "Create a robust system of revenue reporting\n",
      "\n",
      "Be an expert on all things ads-related: how are we monetizing our inventory?\n",
      "entry --- Google\n",
      "substring --- Google Analytics), data visualization tools (i.e.\n",
      "entry --- Google\n",
      "substring --- Microsoft SQL Server Reporting Services, Visual Studio\n",
      "Tableau 10.5.5\n",
      "MS Excel, Google Sheets\n",
      "ETL solutions using SSIS, PGAgent\n",
      "Agile Development Methodology, Github, Jira, Fresh Service\n",
      ", Location: Waltham, MA, \n",
      "\n",
      "About StudentUniverse\n",
      "\n",
      ", StudentUniverse is a Boston-based technology company that provides exclusive travel discounts, rewards, and experiences for students, faculty and youth (18-25).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry --- Google\n",
      "substring --- Experience using Google Analytics and Google Tag Manager is a plus.\n",
      "entry --- Google\n",
      "substring --- Expert user of Microsoft and Google office suites.\n",
      "entry --- Google\n",
      "substring --- , JOB SPECIFIC KNOWLEDGE, SKILLS, AND EXPERIENCE, Bachelor‚Äôs degree in a highly analytical field such as marketing analytics, mathematics, economics, finance, information systems, or statistics\n",
      "3+ years of experience providing data insights to a marketing team\n",
      "Experience with creating predictive statistical models\n",
      "Experience writing SQL, MySQL, and Python scripts\n",
      "Knowledge of SAS, R, or another language with statistical capabilities\n",
      "Experience utilizing data from a variety of internal and external sources including, but not limited to: Google AdWords and Analytics, Microsoft Dynamics CRM, Marketing automation platforms, AWS, third-party databases, etc.\n",
      "entry --- Google\n",
      "substring --- The role serves as a key Marketing Analytics team member in measuring performance of marketing initiatives and making proactive recommendations that deliver the key performance goals of the agency‚Äôs clientele., Create custom reports and dashboards, audit performance on an on-going basis, and build automated reports where relevant\n",
      "\n",
      "Build and distribute repeatable reports and performance metrics/insights on client marketing campaigns\n",
      "\n",
      "Collect, maintain, manage, interpret and analyze data received from internal and external data sources\n",
      "\n",
      "Proficient with Excel when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\n",
      "\n",
      "Experience with data visualization and analytic dashboard development in Tableau\n",
      "\n",
      "Report requirements collection/analysis, writing SQL, extracting structured data sets, building reports\n",
      "\n",
      "Perform ad hoc analysis and data investigation/ discovery to identify and/or explain business and marketing trends or anomalies\n",
      "\n",
      "Analyze marketing channel and website performance data for assigned projects and develop recommendations on ways to further optimize for performance\n",
      "\n",
      "Work cross-functionally to help inform the agency and clients on key learnings from data analysis, Able to perform in a highly analytical role delivering actionable marketing campaign insights\n",
      "\n",
      "Ability to deep dive into performance data on a daily basis, drawing conclusions and making optimization recommendations\n",
      "\n",
      "Highly analytical, focused on informing performance optimization based on gathering and examining data from multiple sources\n",
      "\n",
      "Excel guru when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\n",
      "\n",
      "Deep knowledge of web analytics tools (Adobe Analytics, Google Analytics, Optimizely, etc.)\n",
      "entry --- Google\n",
      "substring --- Ability to adapt to evolving business requirements and objectives in a fast-paced environment, \n",
      "\n",
      "Bachelor‚Äôs degree in Marketing, Business or equivalent relevant experience\n",
      "\n",
      "Minimum of 1-2 years experience working with consumer databases and exposure to data-driven marketing programs\n",
      "\n",
      "Advanced skills with Excel, Visio, and PowerPoint\n",
      "\n",
      "Experience with online tracking and reporting tools such as Google Analytics, DoubleClick DART, and Omniture\n",
      "\n",
      "Proficiency with SQL\n",
      "\n",
      "Experience with Marketing Automation Platform, Marketo is preferred\n",
      "\n",
      "Report creation experience with business intelligence tools (e.g.\n",
      "entry --- Google\n",
      "substring --- Google Analytics), data visualization tools (i.e.\n",
      "entry --- Google\n",
      "substring --- Additional responsibilities include, but are not limited to: participating in the activities and discussions of various Board advisory committees and task forces; serving as the Board‚Äôs representative in relevant stakeholder meetings; and working cooperatively with Arizona Department of Education staff as directed., \n",
      "\n",
      "KNOWLEDGE, SKILLS AND ABILITIES (KSAs):, \n",
      "\n",
      "Knowledge Required:,  Knowledge of data and statistical analysis Knowledge of sound research practices General understanding of the Arizona public education system, \n",
      "\n",
      "Skills Required:,  Skilled in presenting highly effective written, visual and oral presentations on complex data to a wide variety of audiences Skill in Microsoft Office and Google Suite products, including Microsoft Excel and Google Sheets Knowledge and capable ability in one or more of the following: SPSS, SAS, or R Skilled in working on multiple complex projects simultaneously Skilled in working in high pressure environments Skilled in detailed oriented reports Skilled in analyzing and developing complex policy in a variety of areas Skilled in interpreting and applying federal and state codes and regulations, \n",
      "\n",
      "Abilities Required:\n",
      "\n",
      ",  Ability to perform and analyze complex calculations associated with technical properties of educational assessments and accountability measures Ability to develop and articulate potential policy recommendations in the areas of school accountability, assessment and research Ability to work collaboratively with stakeholder groups and other state agencies Ability to perform detailed work with a high degree of accuracy, \n",
      "\n",
      "SELECTIVE PREFERENCE:,  Master degree or doctorate in Education, Educational Administration, Educational Leadership, Research and Development.\n",
      "entry --- Google\n",
      "substring --- From seeing the big picture through to implementing the tags and ensuring the quality of the data collected., Ensuring our business has the data required to grow our online sales business., Background in web analytics or digital marketing\n",
      "\n",
      "Experience deploying marketing and/or analytics tracking tools\n",
      "\n",
      "Good understanding of JavaScript, HTML, and CSS\n",
      "\n",
      "Experience of Tag Management tools, preferably Google Tag Manager or Adobe Dynamic Tag Manager, \n",
      "\n",
      "Knowledge of Python, SQL\n",
      "\n",
      "Experience of DSP's and Digital Marketing Platforms\n",
      "\n",
      "Experience of Website Optimization]\"\n",
      "\"[The Division of Pediatric Critical Care in the Department of Pediatrics, University of Utah School of Medicine has an immediate opening for a Business Analyst.\n",
      "entry --- Google\n",
      "substring --- Google Analytics, etc.)\n",
      "entry --- Google\n",
      "substring --- Google Analytics, etc.\n",
      "entry --- Google\n",
      "substring --- Analytical/problem-solving skills.Strong communication and interpersonal skills to communicate effectively with all levels of staff; both verbally and in writing.Strong skills in analyzing and synthesizing large amounts of data for preparing sound and relevant proposals.Ability to multi-task with demanding time-frames.Ability to use discretion and maintain all confidentiality., Bachelors degree in related area and/or equivalent experience/training]\n",
      "\"[Fossil Group is seeking a passionate Data Analyst to join our Omni-Channel Marketing team., \n",
      "\n",
      "The ideal candidate will demonstrate:, \n",
      "\n",
      "- A strong understanding of the scientific method and its role in developing business insights and decision making process, \n",
      "\n",
      "- An aptitude communicating complex quantitative analysis in a clear, compelling, and actionable manner, \n",
      "\n",
      "- Ability to interpret the results of analyses and communicate findings to internal stakeholders and leadership by utilizing data discovery, visualization, and statistical techniques, \n",
      "\n",
      "- A natural curiosity to solve complex problems and a desire to learn new skills, \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "- Work closely with cross-functional team that includes CRM, eComm, marketing, brand teams and IT to improve overall digital investment efficiency through insights and analytics, \n",
      "\n",
      "- Collaborate with Global Partners to accommodate analytical needs, \n",
      "\n",
      "- Define campaign targeting/selection criteria, design A/B test and learn, multivariate testing, and perform related marketing effectiveness and incrementality assessments to inform future decisions, \n",
      "\n",
      "- Define and design analytical methodologies that result in weekly, monthly, and quarterly reporting that offers actionable recommendations based on data, \n",
      "\n",
      "- Conduct ad-hoc analyses that include basic ROI reports and in-depth conversion funnel insights, \n",
      "\n",
      "- Work with manager to identify opportunities to improve campaign analysis and reporting efficiencies, Your Skills, Required Skills and Experience:, \n",
      "\n",
      "- Demonstrated record of 1-3 years in customer data, analytics, and reporting function with emphasis on marketing, business intelligence, and data mining, \n",
      "\n",
      "- Experience with database marketing, CRM platforms, reporting and analysis design, measurement reporting based on relevant business metrics, \n",
      "\n",
      "- Academic degree in quantitative field, Advanced degree is a plus, \n",
      "\n",
      "- Familiarity with web analytics platforms such as Adobe Analytics, Google Analytics, etc., \n",
      "\n",
      "- Experience using SQL to manipulate data, \n",
      "\n",
      "- Experience using Python programming language, \n",
      "\n",
      "- Experience using data visualization tool, Tableau preferred]\"\n",
      "\"[Hub Data Analyst\n",
      "\n",
      "\n",
      "\n",
      "The Fund for Public Health in New York City, (FPHNYC) is a 501(c)3 non-profit organization that is dedicated to\n",
      "\n",
      "the advancement of the health and well-being of all New Yorkers.\n",
      "entry --- Google\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Google\n",
      "substring --- Basic understanding of marketing analytics\n",
      "Strong understanding of relational databases required with strong SQL skills\n",
      "Experience with Google Analytics and BigQuery preferred\n",
      "Proficiency in at least one programming language (Matlab, Python, R, Julia, etc.)\n",
      "entry --- Google\n",
      "substring --- The role serves as a key Marketing Analytics team member in measuring performance of marketing initiatives and making proactive recommendations that deliver the key performance goals of the agency‚Äôs clientele., Create custom reports and dashboards, audit performance on an on-going basis, and build automated reports where relevant\n",
      "\n",
      "Build and distribute repeatable reports and performance metrics/insights on client marketing campaigns\n",
      "\n",
      "Collect, maintain, manage, interpret and analyze data received from internal and external data sources\n",
      "\n",
      "Proficient with Excel when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\n",
      "\n",
      "Experience with data visualization and analytic dashboard development in Tableau\n",
      "\n",
      "Report requirements collection/analysis, writing SQL, extracting structured data sets, building reports\n",
      "\n",
      "Perform ad hoc analysis and data investigation/ discovery to identify and/or explain business and marketing trends or anomalies\n",
      "\n",
      "Analyze marketing channel and website performance data for assigned projects and develop recommendations on ways to further optimize for performance\n",
      "\n",
      "Work cross-functionally to help inform the agency and clients on key learnings from data analysis, Able to perform in a highly analytical role delivering actionable marketing campaign insights\n",
      "\n",
      "Ability to deep dive into performance data on a daily basis, drawing conclusions and making optimization recommendations\n",
      "\n",
      "Highly analytical, focused on informing performance optimization based on gathering and examining data from multiple sources\n",
      "\n",
      "Excel guru when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\n",
      "\n",
      "Deep knowledge of web analytics tools (Adobe Analytics, Google Analytics, Optimizely, etc.)\n",
      "entry --- Google\n",
      "substring --- Ability to adapt to evolving business requirements and objectives in a fast-paced environment, \n",
      "\n",
      "Bachelor‚Äôs degree in Marketing, Business or equivalent relevant experience\n",
      "\n",
      "Minimum of 1-2 years experience working with consumer databases and exposure to data-driven marketing programs\n",
      "\n",
      "Advanced skills with Excel, Visio, and PowerPoint\n",
      "\n",
      "Experience with online tracking and reporting tools such as Google Analytics, DoubleClick DART, and Omniture\n",
      "\n",
      "Proficiency with SQL\n",
      "\n",
      "Experience with Marketing Automation Platform, Marketo is preferred\n",
      "\n",
      "Report creation experience with business intelligence tools (e.g.\n",
      "entry --- Google\n",
      "substring --- Altair ProductDesign firmly advocates a user-centered, team-based design approach, and utilizes proprietary simulation and optimization technologies to help clients bring innovative, profitable products to market faster., \n",
      "\n",
      "Description:, \n",
      "Support Quality Engineering for data analysis\n",
      "Maintain Quality internal document databases to store and retrieve data\n",
      "Perform data collection and stratification from all internal and external sources\n",
      "Use Microsoft Office software to create reports, templates and PowerPoint presentations\n",
      "Assist Management to write procedures, meeting preparation and presentations\n",
      "Support Quality Projects utilizing World Class Manufacturing methodology\n",
      ", Requirements:, \n",
      "Supporting technical Quality Team at multiple manufacturing facilities to capture and process control internal/external quality performance data and presenting it in a user friendly format\n",
      "The data will be used at the department level, plant level and division level to lead the team toward contiuous quality improvements\n",
      "This position will be challenged with continuously identifying systems and methods for quicker and easier sharing of complex data from various sources and operating systems\n",
      ", Requirements:, \n",
      "Technical BS Degree\n",
      "SQL knowledge & strong knowledge of data collection systems with the ability to interface multiple electronic data sources into to a front end reporting system (QlikSense)\n",
      "Expert skills with Microsoft Office applications\n",
      "Strong communications - verbal & written\n",
      "Problem solving will be critical for the standardization and communization of multiple data collection systems\n",
      "Knowledge of the Industry 4.0 methodology and Google Suite operating systems is preferred\n",
      "Automotive manufacturing experience preferred\n",
      ", Driving and Travel Requirements:, \n",
      "May be required to drive a company car - valid drivers license and clean driving record required\n",
      "Previous supplier interface and leadership experience is a plus\n",
      "]\"\n",
      "\"[\n",
      "Collaborate with cross functional teams to analyze and optimize game systems and features.\n",
      "entry --- Google\n",
      "substring --- [Bachelor‚Äôs degree from an accredited college in an analytical disciplineExperience with parts of the data analytics pipeline, such as data collection, wrangling, cleaning, analysis, visualization, presentationExperience formulating and executing online researchWriting reports that follow logical guidelines (e.g., pyramid logic)Proven ability to think creatively about data analysisProven potential and/or desire to learn how to code using a scripting language such as Python or R and/or use APIs to access data and data analysis capabilities, Experience with open-source intelligence projectsExperience with machine learningExperience with consultingTeam player, enjoys working on a collaborative teamDetail-oriented with effective written and verbal communication skills with the ability to communicate at all levelsExperience with analytical tools such as Brainspace, Nuix, or TableauKnowledge of: aerospace and defense market, corporate finance, microeconomic factors associated with manufacturing]\n",
      "[Bachelor‚Äôs degree from an accredited college in an analytical disciplineExperience with parts of the data analytics pipeline, such as data collection, wrangling, cleaning, analysis, visualization, presentationExperience formulating and executing online researchWriting reports that follow logical guidelines (e.g., pyramid logic)Proven ability to think creatively about data analysisProven potential and/or desire to learn how to code using a scripting language such as Python or R and/or use APIs to access data and data analysis capabilities, Experience with open-source intelligence projectsExperience with machine learningExperience with consultingTeam player, enjoys working on a collaborative teamDetail-oriented with effective written and verbal communication skills with the ability to communicate at all levelsExperience with analytical tools such as Brainspace, Nuix, or TableauKnowledge of: aerospace and defense market, corporate finance, microeconomic factors associated with manufacturing]\n",
      "[Bachelor‚Äôs degree from an accredited college in an analytical disciplineExperience with parts of the data analytics pipeline, such as data collection, wrangling, cleaning, analysis, visualization, presentationExperience formulating and executing online researchWriting reports that follow logical guidelines (e.g., pyramid logic)Proven ability to think creatively about data analysisProven potential and/or desire to learn how to code using a scripting language such as Python or R and/or use APIs to access data and data analysis capabilities, Experience with open-source intelligence projectsExperience with machine learningExperience with consultingTeam player, enjoys working on a collaborative teamDetail-oriented with effective written and verbal communication skills with the ability to communicate at all levelsExperience with analytical tools such as Brainspace, Nuix, or TableauKnowledge of: aerospace and defense market, corporate finance, microeconomic factors associated with manufacturing]\n",
      "\"[\n",
      "\n",
      "Maintain the Customer Experience big data visualization roadmap\n",
      "\n",
      "Interview key stakeholders from the Customer Experience team to identify their requirements for data visualization and reporting\n",
      "\n",
      "Document stakeholder requirements, develop functional specifications, and design and deliver visualizations\n",
      "\n",
      "Act as a liaison between the Customer Experience team and the Data and Analytics team\n",
      "\n",
      "Participate in bi-weekly meetings with the Data and Analytics team to ensure adherence to best practices\n",
      "\n",
      "Develop SQL queries using Google BigQuery against Geotab‚Äôs big data environment\n",
      "\n",
      "Use Redash or Datalab for visualizations of data from existing datasets and create derivative datasets when required\n",
      "\n",
      "Ensure Geotab data standards are met by ensuring the the developed queries and dashboards coincide with the Customer Experience KPAs and KPIs\n",
      "\n",
      "Maintain released visualizations ‚Äî resolve issues and change requests as required\n",
      "\n",
      "Keep documentation up to date for all your areas of responsibility\n",
      "\n",
      "Continuous learningContribute to the Geotab staff blog on an annual basis, \n",
      "\n",
      "Bachelor‚Äôs degree in Computer Science, Math, Statistics, Engineering or related field\n",
      "\n",
      "Experience working with big data environments and understanding techniques to extract value out of very large data sets\n",
      "\n",
      "4+ years‚Äô experience using SQL (experience with Google BigQuery an asset)\n",
      "\n",
      "2+ years‚Äô experience with data science tools (experience with Datalab, Python, Pandas, NumPy an asset)\n",
      "\n",
      "2+ years‚Äô experience creating high-quality dashboards and data visualizations for internal consumption (experience with Redash an asset)\n",
      "\n",
      "Experience with database design and writing queries\n",
      "\n",
      "Familiarity with Customer Experience metrics an asset]\"\n",
      "[Perform application design, code development and testing utilizing JavaScript and jQueryUtilizing Quadient Ignite; work with client input files to ensure data is appropriately formatted and cleansed prior to moving over to letter composition side of departmentDesign reusable components, frameworks and librariesReview code and provide feedback relative to best practices and improving performanceTroubleshoot production support issues post-deployment and come up with solutions as requireWork very closely with the application team and drive solutionsDesign, execute, and modify programs utilizing the appropriate technologyUnderstanding the ramifications of programs and logical order of operationsContribute to the upkeep and consistency of internal documentation related to issues, resolutions, usage topics, and trainingMaintain confidentiality regarding the information being processed, stored or accessedProof composition output against data following to ensure accuracy of letter text, images and variable fieldsAssist in resolving internal/external inquiries related to input/output requirements, intended usage, strategic planning, and alignment of these elements to internal checks, controls, and quality assuranceTrack quality defects and ensure they are resolvedProvide general hands-on demonstrations of common process, 4-year degree in Computer Science or related experienceMust have demonstrated proficiency with JavaScriptDevelopment and support skills in at least one of the following software packages: Quadient Ignite (preferred), Postalsoft / Firstlogic Business Objects, BCC, or Group 1 / Pitney BowesReferenceable examples of developing custom code for applicationsExperience in data migration and integrationExperience integrating business processes across disparate systems using 3rd party toolsExpertise on various APIsPositive and consultative demeanor and strong work ethicAbility to interact with technical and non-technical resourcesExcellent verbal and written communications skills]\n",
      "\"[Data Analyst - Media Analytics - 11471, \n",
      "\n",
      "Analytics - USA Stamford, Connecticut, \n",
      "\n",
      "The Nielsen Company is a leading global information and measurement company that provides clients with a comprehensive understanding of consumers and consumer behavior., \n",
      "\n",
      "This role will closely collaborate with Nielsen‚Äôs Media Analytics practice.\n",
      "entry --- Google\n",
      "substring --- At TMS, we‚Äôre the agency AND the client!, \n",
      "\n",
      "What you‚Äôll do:, \n",
      "Establish reporting processes and implement regular reporting on all marketing initiatives\n",
      "Analyze and interpret data into thoughtful market strategy\n",
      "Acquire and manage data from both primary and secondary sources\n",
      "Identify, analyze, and interpret trends and correlation in large data sets\n",
      "Explore correlation and regression models in data sets\n",
      "Manage and design reporting dashboards for Executive view\n",
      "Assess the performance of tests, updates, and strategic optimizations, Requirements:\n",
      "\n",
      ", 2 years of experience as a data analyst or business data analyst\n",
      "Must have an advanced user understanding of Microsoft Excel and PowerPoint\n",
      "\n",
      "Proficient with Excel Tables and Pivot tables\n",
      "Proficient knowledge of Power Pivot, Power Query, and Power\n",
      "Statistical modelling experience\n",
      "Bachelor‚Äôs degree, related advanced degree a plus\n",
      "Ability to work under pressure with ambiguous or competing priorities\n",
      "Knowledge in website analytics tools such as Google Analytics\n",
      "Proficient computer skills, Microsoft Office Suite (Word, PowerPoint, Outlook, and Excel)\n",
      "Excellent analytical and time-management skills\n",
      "Strong project management skills with ability to supervise multiple projects\n",
      "Experience in Salesforce Marketing Cloud is a plus\n",
      "Experience in the mortgage industry is a plus, Proficient with Excel Tables and Pivot tables\n",
      "Proficient knowledge of Power Pivot, Power Query, and Power\n",
      "]\"\n",
      "\"[It‚Äôs Time For A Change‚Ä¶, \n",
      "\n",
      "Your Future Evolves Here, \n",
      "\n",
      "Evolent Health has a bold mission to change the health of the nation by changing the way health care is delivered.\n",
      "entry --- Google\n",
      "substring --- Advanced experience with Google Analytics.\n",
      "entry --- Google\n",
      "substring --- Google BigQuery a plus.\n",
      "entry --- Google\n",
      "substring --- , THE ROLE:, \n",
      "\n",
      "Perform deep data research across multiple departments providing key metrics and insight\n",
      "\n",
      "Communicate actively and effectively with analytical peers, business partners, and executive leadership, \n",
      "\n",
      "Drive end-to-end analytics: identify a problem, derive a solution, present your findings and finally drive a change in the business with quantifiable value\n",
      "\n",
      "Work closely with Financial Planning and Analytics to support monthly financial reporting & annual planning\n",
      "\n",
      "Support Business Development team to make informed pricing decisions with new partners\n",
      "\n",
      "Support Marketing Public Relations team to produce marketing that help the world see the service we provide our valued customers, \n",
      "\n",
      "REQUIREMENTS/CHARACTERISTICS:\n",
      ", \n",
      "\n",
      "Analytically driven\n",
      "\n",
      "Excellent time management and prioritization skills\n",
      "\n",
      "Intellectually curious & exhibits ability and desire to learn above and beyond what‚Äôs asked\n",
      "\n",
      "Strong communication and organizational skills\n",
      "\n",
      "Ability to thrive in a fast pace environment\n",
      "\n",
      "Bachelor's degree in Math, Finance, Economics, Stats or other quantitative field\n",
      "\n",
      "Recent Grad to 2 years of professional experience in another analytical role\n",
      "\n",
      "Hands on experience with MS PowerPoint, Excel, Tableau (or other visualization tool) and Google Big Query (or SQL) preferred, \n",
      "\n",
      "Care (for everyone): We show compassion and contribute to the well-being and growth of those around us.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Bachelor's degree from four year college or university; or two years related experience and/or training; and two plus years of experience; or equivalent combination of education and experience\n",
      "\n",
      "Demonstrated curiosity for analysis with large data sets, an attention to detail and an unparalleled work ethic\n",
      "\n",
      "Experience with Google Analytics, Adobe Analytics, Adobe Target and data management platforms strongly preferred.\n",
      "entry --- Google\n",
      "substring --- Survey tools such as Survey Monkey & Web Analytics such as Google Analytics.\n",
      "entry --- Google\n",
      "substring --- Manage multiple tasks/projects and deadlines simultaneously to meet internal and client data needs\n",
      ", QUALIFICATIONS, Bachelor‚Äôs degree required\n",
      "Advanced knowledge of reading and writing SQL queries\n",
      "Tableau, Excel and PowerPoint experience and strong presentation skills required\n",
      "Knowledge of Hub Spot, CRM integration, Survey Monkey and Google Analytics\n",
      "Excellent communication, facilitation, and interpersonal relations skills required\n",
      ", Experience with project management tools and methodologies required.]\"\n",
      "entry --- Google\n",
      "substring --- degree in communications, journalism, mathematics, business administration or a related field preferred\n",
      "Four to six years managing data analytics\n",
      "Advanced experience with Excel, Google Analytics/Omniture and native and aggregated social analytics platforms, including Sprout Social and Simply Measured\n",
      "Experience working with CRM systems, including Salesforce, to interpret data\n",
      "Experience working with content management systems, including Drupal\n",
      "]\"\n",
      "\"[\n",
      "Bachelors' degree in relevant field\n",
      "3+ years of experience with data analysis and data interpretation with Army and/or DOD data sources\n",
      "Applicant must be a U.S. citizen and have an active SECRET security clearance\n",
      ", \n",
      "Experience with Oracle and Microsoft Suite of software applications, highly desired\n",
      "Project Management Institute Professional (PMP), a plus\n",
      "]\"\n",
      "\"[o Gain understanding of business processes in their assigned business unit.\n",
      "entry --- Google\n",
      "substring --- Javascript coding skills: you need to be able to write snippets for custom event tracking for different softwares & tools we use, like Google Analytics or Active Campaign.\n",
      "entry --- Google\n",
      "substring --- Expert in Google Analytics and Tag Manager: you‚Äôll need to be able to manage, maintain and advance the analytics stack, and also be able to turn requests from marketing or product office into actionable implementation plans, then manage the process and valide the implementation.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "Partner with Customer Strategy Manager to understand the messaging requirements for upcoming initiatives\n",
      "Provide reliable estimates for lead time necessary to develop and execute against functional requirements\n",
      "Translate functional requirements into SQL and execute to pull lists for messaging campaigns\n",
      "Work collaboritavely to establish a stable, repeatable process for working within a cross-functional team to deliver manual user lists and actionable insights\n",
      "Act as a backup to Analytics partners to perform more complex data pulls based on ad-hoc requests as necessary\n",
      "Works closely with cross-functional teams: Content Strategy, Legal, Marketing (CRM), Product, and financial planning to deliver ad-hoc analysis\n",
      "Serve as POC to partner with Ops & CS teams to review service issues and customer make good programs\n",
      "Opportunity to expand responsibilities as internal capabilities develop to help define advertising segments, and to provide input on automated tools for trigger messaging\n",
      ", \n",
      "2-3 years experience\n",
      "Bachelor's degree required\n",
      "Experience in the MVPD or vMVPD space, or within TV | Studio | Entertainment Industry preferred\n",
      "Expert in SQL and Excel required\n",
      "Proficiency in Adobe Omniture, Conviva, Microstrategy, and other analytics tools preferred\n",
      "Ability to translate complex requirements for the delineation of distinct customer groups into executable SQL which can return lists of users to send tailored messaging\n",
      "Owner mentality and an entrepreneurial drive; proven ability to think big and influence others\n",
      "Self-starter with a bias for action; can make things happen in a fast-paced, dynamic environment\n",
      "Strong verbal and written communication skills across all levels of the organization\n",
      "High attention to detail and ability to manage multiple, competing priorities simultaneously\n",
      "Enjoy getting your hands dirty in day-to-day tasks and working in ambiguous environments\n",
      "Works on site at Vue offices in Los Angeles, CA\n",
      "Occasional travel to other office locations may be necessary\n",
      "]\"\n",
      "\"[\n",
      "Partner with marketing, product and engineering team to understand our customers and ultimately create a better shopping experience\n",
      "Design dashboards and reports to communicate business trends and opportunities\n",
      "Work closely with data engineering to validate data and ensure we have data points needed for analysis\n",
      "Enable self service analytics through BI enhancements\n",
      ", \n",
      "2+ years of related work experience in analytics\n",
      "Strong SQL skills\n",
      "Experience with at least one analytics & visualization tool such as Looker, Tableau, Mode\n",
      "Highly analytical and quantitative, with strong attention to detail\n",
      "Ability to communicate complex ideas effectively\n",
      "Bachelor's degree in Mathematics, Statistics, Economics, Business or quantitative focused study\n",
      "Proficiency with website analytics tools like Heap, Mixpanel or Google Analytics a plus\n",
      ", \n",
      "Comprehensive health benefits\n",
      "Equity\n",
      "401k plan\n",
      "Subsidized lunches and fully stocked kitchen\n",
      "Wellness benefits including in-office massage visits\n",
      "Quarterly product allotment -- a package of the world's best bras every 3 months!\n",
      "entry --- Google\n",
      "substring --- Familiarity with user funnel and digital marketing performance tracking\n",
      "Perfect and automate more advanced analytic requirements, including LTV, lead scoring and financial modeling\n",
      ", \n",
      "Proficiency in Excel and SQL required\n",
      "We prefer someone who has experience with Python and Google Analytics\n",
      "0 to 3 years of work experience in a data focused role\n",
      "Prior experience at a growth stage startup or software company a plus\n",
      "Bachelor‚Äôs Degree or equivalent experience required\n",
      "We love a strong Giphy game\n",
      "]\"\n",
      "\"[We are looking for an enthusiastic and technology-proficient Data Analyst who will work with terabytes of raw data, eliminate outliers, and share insights and KPIs based on the data analysis., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Participate in the design and development of analytical applications using an in-house data visualization product\n",
      "\n",
      "Create dashboards, SQL optimization\n",
      "\n",
      "Work with terabytes of raw data and eliminate outliers, Strong knowledge of any data visualization product, creating dashboards, and SQL optimization\n",
      "\n",
      "Experience working with terabytes of raw data\n",
      "\n",
      "Strong knowledge of basic statistics for data analysis\n",
      "\n",
      "Understanding the best practices in data quality and quality engineering\n",
      "\n",
      "Experience with version control systems, Git in particular\n",
      "\n",
      "Desire and ability for quick learning of new tools and technologies, \n",
      "\n",
      "Will be a plus:, \n",
      "\n",
      "Knowledge of internals (queries, transformations, data connectors)\n",
      "\n",
      "Knowledge of Unix-based operating systems (bash/ssh/ps/grep etc.)\n",
      "entry --- Google\n",
      "substring --- is strongly preferred (MBA a plus), Unlimited time off\n",
      "\n",
      "Flexible dress code\n",
      "\n",
      "Kitchen stocked with snacks\n",
      "\n",
      "Pet Insurance\n",
      "\n",
      "Catered meal on Fridays\n",
      "\n",
      "Health, dental and vision benefits\n",
      "\n",
      "401(k) with a company match\n",
      "\n",
      "Both paid maternity time and paid paternity time\n",
      "\n",
      "Dog-friendly Fridays\n",
      "\n",
      "]\"\n",
      "\"[Partner with Product and Engineering to proactively define what success means and ensure we‚Äôll have the data in place to measure against it\n",
      "\n",
      "Design and analyze A/B multivariate tests to drive KPI improvement\n",
      "\n",
      "Leverage internal and external analytics tools (Looker, Adobe) and SQL (Redshift) to access, manipulate, and analyze complex data sets\n",
      "\n",
      "Build data visualizations and cross-functional reporting that conveys key performance metrics, significant trends, and relationships across multiple data sources\n",
      "\n",
      "Be a resource for product owners and key stakeholders regarding data questions\n",
      "\n",
      "Translate business hypotheses into data capture requirements and validate tracking and measurement\n",
      "\n",
      "Collaborate across multiple teams to understand business needs, analyze complex data, and clearly communicate recommendations\n",
      "\n",
      "Monitor web analytics KPIs to ensure site traffic and conversion funnels are performant, 2-4 years experience in an analytical role, preferably in e-commerce\n",
      "\n",
      "Demonstrated analytical and problem-solving skills\n",
      "\n",
      "Proficiency in SQL a must\n",
      "\n",
      "Able to juggle multiple priorities at once, self-manage and self-prioritize\n",
      "\n",
      "Able to articulate complex technical problems to a non-technical audience Excellent communication skills\n",
      "\n",
      "Tableau experience a plus]\"\n",
      "\"[\n",
      "\n",
      "Perform recurring and ad hoc quantitative analysis to support day-to- day decision making\n",
      "\n",
      "Support reporting and analytics such as KPIs, financial reports and creating and improving dashboards\n",
      "\n",
      "Recap and analyze business results versus plan and forecast on a weekly, monthly, quarterly and ad-hoc basis\n",
      "\n",
      "Collaborate with non-quantitative stakeholders across Pond5 to empower data-driven decisions (an important aspect of our work is evangelizing analytical concepts and quantitative thinking throughout the organization)\n",
      "\n",
      "Contribute insights and drive innovation to help our team develop a 360-degree understanding of Pond5‚Äôs business\n",
      "\n",
      "Help translate this understanding into visualizations, metrics, and goals\n",
      "\n",
      "Interact with and present data findings to senior management\n",
      "\n",
      "Participate in strategy decisions and advise with regard to company goals, plans, and results, \n",
      "\n",
      "BS/BA in Mathematics, Statistics, Economics, Finance, Computer Science, or other quantitative areas of study\n",
      "\n",
      "2+ years of relevant work experience in analytical roles such as data science, business intelligence, corporate finance, investment banking, or quantitative consulting is preferred, though exceptional candidates without work experience will be considered\n",
      "\n",
      "Advanced quantitative analysis skills in Excel and SQL required\n",
      "\n",
      "Basic understanding of e-commerce concepts and metrics such as traffic, conversion rates, CPA, LTV, revenue retention, channel/cohort analysis as examples, is strongly preferred\n",
      "\n",
      "Exceptional problem solving and analytical skills\n",
      "\n",
      "Highly organized and detail oriented with exceptional communications skills; we value candor, constant feedback and constructive debate\n",
      "\n",
      "Experience with SQL, Google Analytics, Tableau Desktop, and ETL processes are preferred\n",
      "\n",
      "Experience using Python, R, VBA, macros, statistics or other programing / development are also nice to have, \n",
      "\n",
      "International team of 180 awesome people\n",
      "\n",
      "Competitive compensation and benefits\n",
      "\n",
      "Generous 401(k) program\n",
      "\n",
      "Daily office lunches\n",
      "\n",
      "Equipment needed for work\n",
      "\n",
      "Learn new things every day!]\"\n",
      "entry --- Google\n",
      "substring --- , \n",
      "\n",
      "Bachelor Degree in Data Science, Information Systems, Computer Science, Economics, Mathematics or similar\n",
      "\n",
      "2+ years of experience as a Business/Financial Analyst, BI Engineer or Data Analyst preferably with exposure to large complex data sources\n",
      "\n",
      "Proficient in SQL and Microsoft Excel\n",
      "\n",
      "Proven analytical and quantitative skills and an ability to use data and metrics to back up assumptions, develop business cases, and complete root cause analyses\n",
      "\n",
      "Quick learner with a strong data-driven and quantitative focus when solving problems\n",
      "\n",
      "Knowledge of fundamental relational database technology and terminology\n",
      "\n",
      "Proficient in converting large datasets into actionable business insights\n",
      "\n",
      "Experience using business intelligence reporting and visualization tools such as Tableau, Looker, Cognos, Domo, or others\n",
      ", \n",
      "\n",
      "Experience in payments, billing and subscriptions\n",
      "\n",
      "Experience with analytical software (Python, R) and solid grasp of common statistical methods and applications (A/B testing, probability, regression)\n",
      "\n",
      "Experience working with databases such as AWS Redshift\n",
      "\n",
      "Advanced understanding of data analysis and visualization techniques\n",
      "\n",
      "Familiarity with Google Analytics, web analytics, and funnel conversion concepts\n",
      "]\"\n",
      "\"[Responsible for analytic data needs of the business unit.\n",
      "entry --- Google\n",
      "substring --- As a Data Analyst with Geo Operations, you design and implement methodologies, dashboards and presentations, all while partnering with stakeholders across multiple functions and locations., Google's Consumer Hardware is looking for a Data Analyst to join its rapidly growing Reverse Logistics team.\n",
      "entry --- Google\n",
      "substring --- You are a strong team player who will interact with a global team, gather business requirements, and bring order to chaos by becoming and expert in the operation‚Äôs nuances, and creating and maintaining state-of-the-art data solutions, on Google dashboards for Tableau.\n",
      "entry --- Google\n",
      "substring --- You are a fast-learner and self-driven performer, who feels comfortable in a start-up environment, where everything needs to be built up from scratch., \n",
      "\n",
      "Google's mission is to organize the world's information and make it universally accessible and useful.\n",
      "entry --- Google\n",
      "substring --- Develop visualization based on user needs on Google dashboards or Tableau.\n",
      "entry --- Google\n",
      "substring --- Familiarity with web analytics (Google Analytics, Site Catalyst), statistical packages (SAS, R), and visualization tools (Qlikview, Tableau).\n",
      "entry --- Google\n",
      "substring --- \"[Note: By applying to this position your application is automatically submitted to the following locations: Boulder, CO, USA; Mountain View, CA, USA, \n",
      "\n",
      "At gTech‚Äôs Users and Products team (gUP), our mission is to help users get the most out of Google.\n",
      "entry --- Google\n",
      "substring --- We represent the voice of Google's users and many of our partners globally, sharing insights with the larger Google organization to enable exceptional customer and product experiences.\n",
      "entry --- Google\n",
      "substring --- gUP builds innovative solutions that take user experience and engagement with Google to the next level, supporting users across products, countries, cultures, incomes, and identities.\n",
      "entry --- Google\n",
      "substring --- We advocate for users through partnerships with product areas at Google (and some Alphabet businesses), supporting Google‚Äôs consumer products ecosystem and enabling numerous launches for Google‚Äôs consumer products each year.\n",
      "entry --- Google\n",
      "substring --- You will be expected to focus on results, be a self-starter and demonstrate success in using analytics to drive the understanding, progression and excellence in product and operations., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.\n",
      "entry --- Google\n",
      "substring --- Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products.\n",
      "entry --- Google\n",
      "substring --- , Responsibilities:\n",
      "\n",
      ", Maintain ongoing reporting that paints a picture of the ‚Äúpulse‚Äù of our business\n",
      "\n",
      "Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance\n",
      "\n",
      "Ability to understand the business operations as a whole and translate questions into effective analysis based on the goals behind the specific asks\n",
      "\n",
      "Communicate findings effectively and translate them into recommended actions appropriate for each area of the business\n",
      "\n",
      "Design and build automated reporting dashboards on our BI platform\n",
      "\n",
      ", Maintain ongoing reporting that paints a picture of the ‚Äúpulse‚Äù of our business\n",
      "\n",
      ", Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance\n",
      "\n",
      ", Ability to understand the business operations as a whole and translate questions into effective analysis based on the goals behind the specific asks\n",
      "\n",
      ", Communicate findings effectively and translate them into recommended actions appropriate for each area of the business\n",
      "\n",
      ", Design and build automated reporting dashboards on our BI platform\n",
      "\n",
      ", Qualifications:\n",
      "\n",
      ", Excellent verbal and written communication skills\n",
      "\n",
      "Comfortable deconstructing complex and open-ended problems which may not yield a clear cut solution\n",
      "\n",
      "Ability to work independently and to carry out assignments to completion based on the original goals with minimal supervision\n",
      "\n",
      "4-year degree in statistics or related field\n",
      "\n",
      "3+ years of experience in a data analyst role at an affiliate marketing, e-commerce company, or online publisher\n",
      "\n",
      "3+ years of experience using SQL is required\n",
      "\n",
      "1+ year of experience designing and building automated reporting dashboards with a data visualization tool such as Tableau or similar\n",
      "\n",
      "Proficient with statistical analysis tools such as R or similar\n",
      "\n",
      "Google Analytics certification or equivalent experience\n",
      "\n",
      "Demonstrated ability to work collaboratively in a multi-disciplinary team\n",
      "\n",
      "Strong interest in Wirecutter‚Äôs mission\n",
      "\n",
      ", Excellent verbal and written communication skills\n",
      "\n",
      ", Comfortable deconstructing complex and open-ended problems which may not yield a clear cut solution\n",
      "\n",
      ", Ability to work independently and to carry out assignments to completion based on the original goals with minimal supervision\n",
      "\n",
      ", 4-year degree in statistics or related field\n",
      "\n",
      ", 3+ years of experience in a data analyst role at an affiliate marketing, e-commerce company, or online publisher\n",
      "\n",
      ", 3+ years of experience using SQL is required\n",
      "\n",
      ", 1+ year of experience designing and building automated reporting dashboards with a data visualization tool such as Tableau or similar\n",
      "\n",
      ", Proficient with statistical analysis tools such as R or similar\n",
      "\n",
      ", Google Analytics certification or equivalent experience\n",
      "\n",
      ", Demonstrated ability to work collaboratively in a multi-disciplinary team\n",
      "\n",
      ", Strong interest in Wirecutter‚Äôs mission\n",
      "\n",
      ", Culture and benefits at The New York Times Company and Wirecutter:\n",
      "\n",
      ", Though Wirecutter has physical locations in both NYC and LA, the company promotes and encourages a remote workforce, so that our employees can work in flexible and comfortable ways.\n",
      "entry --- Google\n",
      "substring --- Utilize tools such as Power BI, Excel, MS SQL, Salesforce, system monitoring tools, automated testing, Google Analytics, Google Search Console, and similar tools.\n",
      "entry --- Google\n",
      "substring --- Experience understanding data from Google Analytics, Facebook Insights and other marketing dashboards.\n",
      "entry --- Google\n",
      "substring --- , Bachelor's degree in Computer Science/Analytics or equivalent experience and minimum 5 years of data analytics / business analytics experience strongly preferred\n",
      "\n",
      "Experience with standard clickstream analytics tools such as Adobe Analytics, Omniture, Google Analytics\n",
      "\n",
      "Experience with SQL for querying and reporting against large scale data sets\n",
      "\n",
      "Proven ability to manage stakeholder communications\n",
      "\n",
      "\n",
      ", Adobe Analytics toolset ‚Äì Workspace, Data Warehouse, Report Builder, Ad Hoc Analysis\n",
      "\n",
      "Experience with Redshift, Hive, Spark, Python and other tools which allow analysis and enable queries on large datasets in Hadoop and AWS\n",
      "\n",
      "Experience in digital analytics supporting large healthcare, e-commerce or financial services web sites\n",
      "\n",
      "Demonstrated knowledge of healthcare products, benefits, claims, and/or customer service or related experience is a plus\n",
      "\n",
      "\n",
      ", Problem solver with excellent analytical skills and ability to turn data into information and insights\n",
      "\n",
      "Strong communication and presentation skills with ability to create and deliver presentations and reports for senior management\n",
      "\n",
      "Should be resourceful, work well under pressure, and able to keep up in a fast-paced environment.\n",
      "entry --- Google\n",
      "substring --- Building on software and sensor technology developed at Google, Waymo is now launching the world‚Äôs first fully self-driving transportation service that will take members of the public from A to B at the touch of a button., \n",
      "\n",
      "Waymo takes an integrated approach to building the world‚Äôs first self-driving car, with researchers, product managers, and technical program managers working side by side.\n",
      "entry --- Google\n",
      "substring --- Experience with Modeling Techniques (linear regression, logistic regression, decision tree), Query Languages (SQL, Python), Automation (SQL Stored Procedures, SSIS, APIs), Reporting (Excel, .Net, MicroStrategy), prior management of a project in which a relational database was built and utilized for analysis, Google Analytics, and Data Mining experience\n",
      ", Ingram Micro Inc. is committed to creating a diverse environment and is proud to be an equal opportunity employer.\n",
      "entry --- Google\n",
      "substring --- S/he is experienced with Google Analytics, and works closely with the Marketing team to evaluate careers site data and prepares reports of findings relevant to audience, behavior, and acquisition.\n",
      "entry --- Google\n",
      "substring --- , Secret clearance is required\n",
      "\n",
      "Bachelor's degree required, additional years of experience may be substituted for a degree\n",
      "10 years of professional experience is required, including 2 years of supervisory experience\n",
      "\n",
      "Must be technically savvy\n",
      "Must have at least 1 year of experience with data analytics\n",
      "Must have a strong knowledge of statistics and the ability to translate statistical reports into easy-to-read formats\n",
      "\n",
      "Ability to complete tasks under tight deadlines\n",
      ", Experience with Google Analytics strongly desired\n",
      "Marketing experience\n",
      "State Department experience\n",
      "\n",
      "]\"\n",
      "\"[Who we are:, \n",
      "\n",
      "Over ten years ago, we launched AppFolio(NASDAQ: APPF) to revolutionize the way small and medium-sized businesses grow and compete.\n",
      "entry --- Google\n",
      "substring --- You will provide actionable insights and recommendations on all analytic and financial activities for area of business including agile ad hoc analysis and long term Project-based production of business insights., \n",
      "\n",
      "In addition to these core functions, your additional responsibilities will be to:, \n",
      "Collaborate with both internal stakeholders and external vendors involved in project definition, design and planning\n",
      "Develop hypotheses, gather data, brainstorm strategic options and create recommendations around strategic initiatives\n",
      "Own and rationalize marketing, web data and information across the organization\n",
      "Operate as a visualization lead and Subject Matter Expert across the organization\n",
      "Collect, Analyze and Synthesize complete information from disparate sources into a clear and compelling story in visualizations\n",
      "Build key success metrics to evaluate the impact of various projects, improvements and services that we provide\n",
      "Develop tactical analysis of our online business to strategically analyze current planning resources and develop actionable analysis, Required Qualifications:\n",
      "\n",
      ", Experience with range of Advanced Analytics techniques; statistical analysis skills; SQL, Tableau, Alteryx and other ETL/ELT knowledge and experience\n",
      "Google Analytics, A/B testing and multivariate testing\n",
      "Strong desire to tell analytical journeys and stories through the use of visualization tools\n",
      ", \n",
      "Preferred Qualifications:, \n",
      "Ability to effectively build relationships across the business at all levels\n",
      "Creative thinker who is intellectually curious with a demonstrated passionate about learning\n",
      "Self-starter, entrepreneurial, high-energy who can take initiative in a fast-moving environment\n",
      "Proficient in various programming languages, including SQL, R, and Python (and others)\n",
      "Develop critical business analysis skills - ability to hone in on real business impact and sorting through anecdotal reasoning, comfortable working with analysts and quantitative analysis\n",
      "Provide strong technical understanding of current and emerging internet technologies and the operations of a commercial Website\n",
      "Function as a highly effective leader in a matrix environment given the role of serving various business partners on the enterprise and business unit teams\n",
      "Identify and model data to support personalization across digital channels; collaborate with product management, development, digital marketing, and data science to implement and enhance personalization efforts.\n",
      "entry --- Google\n",
      "substring --- Use of Google Analytics and other analytic and statistical tools to provide in-depth statistical analyses to leverage data when making business decisions\n",
      "\n",
      "Communicate insights to key internal stakeholders and executive leadership team\n",
      "\n",
      "\n",
      ", Communicate insights to key internal stakeholders and executive leadership team\n",
      ", Education:, \n",
      "Bachelor's Degree Required (Concentration in a quantitative field preferred including Business, Engineering, Math, Statistics, Economics, Operations Research)\\\n",
      "Master's Degree Preferred]\"\n",
      "\"[Execute and enhance recurring business performance reporting packages and data analyses;\n",
      "\n",
      "Create SQL queries to facilitate extraction of data into reporting tools, such as Power BI;\n",
      "\n",
      "Analyze existing complex systems to understand and document data elements, relationships, data flow, dependencies and their related interfaces;\n",
      "\n",
      "Actively participate in cross-functional teams providing analysis expertise, offering original perspectives and challenging the conventional views;\n",
      "\n",
      "Perform other duties and assignments, as requested, Bachelor‚Äôs degree in Business Information Systems or equivalent related experience;\n",
      "\n",
      "Proven record of data management skills and experience with SQL;\n",
      "\n",
      "Advanced Microsoft Office knowledge and application skills;\n",
      "\n",
      "Ability to handle multiple assignments on a timely basis with a high degree of accuracy and attentiveness to details;\n",
      "\n",
      "Enthusiastic team player with a committed work ethic and strong problem-solving aptitude;\n",
      "\n",
      "High level of motivation and can-do attitude in a high-performance environment;\n",
      "\n",
      "Exceptional personal and professional integrity and trustworthiness\n",
      "\n",
      "Knowledge of network marketing business operations strongly preferred]\"\n",
      "\"[\n",
      "\n",
      "Efficiently prioritize to supplement day-to-day operations with data and processes that scale - provide teams with ad-hoc analysis, automated reports and dashboards, and self-service reporting tools that accurately reflect the health of their products and help them track their progress towards their goals.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "Own our data infrastructure and use Supermetrics and Google Spreadsheets to ensure uptime on all client reporting\n",
      "Bring new and innovative ideas to the table to help us become the best in the world at sharing insights with our clients; source new business intelligence tools like Tableau, Looker, Periscope, etc.\n",
      "entry --- Google\n",
      "substring --- You will provide actionable insights and recommendations on all analytic and financial activities for area of business including agile ad hoc analysis and long term Project-based production of business insights., \n",
      "\n",
      "In addition to these core functions, your additional responsibilities will be to:, \n",
      "Collaborate with both internal stakeholders and external vendors involved in project definition, design and planning\n",
      "Develop hypotheses, gather data, brainstorm strategic options and create recommendations around strategic initiatives\n",
      "Own and rationalize marketing, web data and information across the organization\n",
      "Operate as a visualization lead and Subject Matter Expert across the organization\n",
      "Collect, Analyze and Synthesize complete information from disparate sources into a clear and compelling story in visualizations\n",
      "Build key success metrics to evaluate the impact of various projects, improvements and services that we provide\n",
      "Develop tactical analysis of our online business to strategically analyze current planning resources and develop actionable analysis, Required Qualifications:\n",
      "\n",
      ", Experience with range of Advanced Analytics techniques; statistical analysis skills; SQL, Tableau, Alteryx and other ETL/ELT knowledge and experience\n",
      "Google Analytics, A/B testing and multivariate testing\n",
      "Strong desire to tell analytical journeys and stories through the use of visualization tools\n",
      ", \n",
      "Preferred Qualifications:, \n",
      "Ability to effectively build relationships across the business at all levels\n",
      "Creative thinker who is intellectually curious with a demonstrated passionate about learning\n",
      "Self-starter, entrepreneurial, high-energy who can take initiative in a fast-moving environment\n",
      "Proficient in various programming languages, including SQL, R, and Python (and others)\n",
      "Develop critical business analysis skills - ability to hone in on real business impact and sorting through anecdotal reasoning, comfortable working with analysts and quantitative analysis\n",
      "Provide strong technical understanding of current and emerging internet technologies and the operations of a commercial Website\n",
      "Function as a highly effective leader in a matrix environment given the role of serving various business partners on the enterprise and business unit teams\n",
      "Identify and model data to support personalization across digital channels; collaborate with product management, development, digital marketing, and data science to implement and enhance personalization efforts.\n",
      "entry --- Google\n",
      "substring --- Use of Google Analytics and other analytic and statistical tools to provide in-depth statistical analyses to leverage data when making business decisions\n",
      "\n",
      "Communicate insights to key internal stakeholders and executive leadership team\n",
      "\n",
      "\n",
      ", Communicate insights to key internal stakeholders and executive leadership team\n",
      ", Education:, \n",
      "Bachelor's Degree Required (Concentration in a quantitative field preferred including Business, Engineering, Math, Statistics, Economics, Operations Research)\\\n",
      "Master's Degree Preferred]\"\n",
      "\"[Position Description, \n",
      "\n",
      "Consults with internal organizations on global strategic initiatives or multi-business initiatives in two or more functional business areas\n",
      "\n",
      "Develops and directs one or more work streams of a cross-functional project to achieve desired results\n",
      "\n",
      "Develops tools that that support decision making and business cases\n",
      "\n",
      "Drives the execution of multiple business plans and projects\n",
      "\n",
      "Ensures business needs are being met\n",
      "\n",
      "Identifies and influences stakeholders\n",
      "\n",
      "Promotes and supports company policies, procedures, mission, values, and standards of ethics and integrity\n",
      "\n",
      "Provides supervision and development opportunities for associates, \n",
      "\n",
      "Minimum Qualifications, \n",
      "\n",
      "Bachelor of Science or Bachelor of Art and 3 years' data analytics experience OR 5 years' data analytics experience OR Master of Science or Master of Art and 1 years' data analytics experience., \n",
      "\n",
      "Additional Preferred Qualifications, 1 year's experience leading project teams to solve problems.\n",
      "entry --- Google\n",
      "substring --- Experience with Modeling Techniques (linear regression, logistic regression, decision tree), Query Languages (SQL, Python), Automation (SQL Stored Procedures, SSIS, APIs), Reporting (Excel, .Net, MicroStrategy), prior management of a project in which a relational database was built and utilized for analysis, Google Analytics, and Data Mining experience\n",
      ", Ingram Micro Inc. is committed to creating a diverse environment and is proud to be an equal opportunity employer.\n",
      "entry --- Google\n",
      "substring --- And that‚Äôs where you come in‚Ä¶, \n",
      "\n",
      "Your background includes:, \n",
      "3+ years of industry data analysis experience, with solid knowledge of statistical methods\n",
      "Bachelor‚Äôs Degree, preferably in a STEM discipline\n",
      "Expert SQL skills and experience querying very large data sets\n",
      "Proven ability to thrive using multiple mixed, varied, and inconsistent data sources\n",
      "Fundamental knowledge of project management methodologies\n",
      "Comfort presenting complicated material to diverse audiences\n",
      ", To take things a level up, it would be nice to have:, \n",
      "Experience with Google BigQuery, Tableau, JIRA and/or other project management software\n",
      "Experience working for a social or mobile game developer\n",
      "Experience working in the performance ad space\n",
      "Understanding of game design concepts and principles\n",
      "Master‚Äôs Degree\n",
      ", Joining a team of highly-motivated individuals inquisitive spirits who are always searching for the answers to hard questions.\n",
      "entry --- Google\n",
      "substring --- Experience managing various tagging and tracking platforms such as Adobe Marketing Cloud (Omniture), Tealium, Google Analytics, etc.\n",
      "entry --- Google\n",
      "substring --- Experience with the following technologies is desired: Hadoop, AWS, Tableau or other OLAP cube/data visualization, Oracle database, Adobe Marketing Cloud (Omniture), Google Analytics, Clicktale, ExactTarget/Salesforce (or similar ESP)\n",
      "\n",
      "Experience coordinating and communicating with internal and external stakeholders.\n",
      "entry --- Google\n",
      "substring --- The Senior Data Analyst position is ideal for a motivated and highly capable self-starter with sharp technical and business acumen., Other Duties:, Serve as the subject matter expert in working with multi-touch attribution and media mix modeling agency\n",
      "Assist in the creation of a data warehouse by identifying data streams and database requirements\n",
      "Use SQL queries and stored procedures to develop reports pertaining to web analytics, marketing campaign performance, customer interactions and other business and marketing performance metrics\n",
      "Manage SQL queries and stored procedures\n",
      "Develop, deploy and manage the implementation of data visualization and reporting tools including Tableau\n",
      "Create automated reports from various databases\n",
      "Mine data and provide intensive analysis of customer and business data and offer actionable insights\n",
      "Create ROI campaign tracking\n",
      "Analyze variance in terms of actual vs forecasted metrics across sales and service (on macro and micro levels)\n",
      "Analyze trends in terms of marketing and business operations\n",
      "Gather and confirm user requirements for various analytics projects\n",
      ", Qualifications:, Minimum 7 years‚Äô experience in data analysis\n",
      "Proficient in use of SQL server\n",
      "Expert knowledge of Tableau or similar data visualization tools\n",
      "Expert knowledge of Excel and other statistical tools such as SAS\n",
      "Extensive experience with budgeting and forecasting\n",
      "Extensive knowledge of marketing and web analytics including Google Analytics\n",
      "Proficiency in SSIS is preferred\n",
      "Strong analytical and problem solving skills\n",
      "Knowledge of multi-touch attribution and predictive modeling principles\n",
      "Effectively multi-task with planning and efficiency\n",
      "Strong email marketing analysis capability\n",
      ", We believe that taking care of employees is an important step in creating a positive workplace and a successful company.\n",
      "entry --- Google\n",
      "substring --- Google BigQuery a plus.\n",
      "entry --- Google\n",
      "substring --- Experience with front-end analytics tools, Google Analytics a plus.\n",
      "entry --- Google\n",
      "substring --- [Bachelor‚Äôs degree in a related field of study3+ years of experience with digital analytics or web analyticsStrong analytic and critical thinking skillsImpeccable attention to detailsProficiency with Google Analytics or OmnitureDemonstrates understanding of digital tracking and tagging QASQL, Python, R, or any coding experience a plusTableau or Microsoft PowerBI experience a plusComfortable and effective working in a dynamic and past-paced environment, with the ability to be flexibleMust have legal right to work in the United States]\n",
      "\"[Piper Companies is currently looking for a Customer Quality Data Analyst in West Chester, PA to work for one of the largest medical device companies globally focused on orthopaedic and neuro products and services., The consultant will be responsible for data ETL, database management and visualization/ analysis of data to support complaint excursion/ signal detection, management reporting (metrics)/ process monitoring, audit requests, and special projects associated with Customer Quality and business data., Responsibilities for the Customer Quality Data Analyst:, Perform data extraction and transformation to deliver operational reporting and predictive outcomes analysis\n",
      "Methodically documents assumptions, methods and results through code commentary and preparation of verification/ validation reports\n",
      "Works with internal customers to define required data sets/ views, assists in prioritization and planning including appropriate scheduling of tasks, properly contextualizing materials as appropriate (ex.\n",
      "entry --- Google\n",
      "substring --- This individual will dig into raw and processed data (backend DBs, Google Analytics, and event/message data), transform information into visualizations using Tableau, R, Excel, etc., and effectively articulate the story behind the data.\n",
      "entry --- Google\n",
      "substring --- Ability and willingness to learn structured and unstructured data systems\n",
      "\n",
      "\n",
      "Experience in developing business requirements for instrumentation with Google Analytics; ability to instrument in Google Tag Manager a plus\n",
      "\n",
      "\n",
      "Proficiency in effective report/dashboard design and standards\n",
      "\n",
      "\n",
      "Familiarity with data preparation, processing, classification, and forecasting\n",
      "\n",
      "\n",
      "Familiarity with the software product lifecycle\n",
      "\n",
      "\n",
      "Ability to write SQL and create data visualizations\n",
      "\n",
      "\n",
      "Experience with Amazon S3, Redshift, Athena, Google Tag Manager, Google Analytics, Google Big Query, Tableau, or JavaScript, are big pluses!\n",
      "entry --- Google\n",
      "substring --- Being a motivated self-starter, an evangelist for a data-driven culture, and desiring a deep understanding of customer needs., \n",
      "\n",
      "Ability and willingness to learn structured and unstructured data systems, \n",
      "\n",
      "Experience in developing business requirements for instrumentation with Google Analytics; ability to instrument in Google Tag Manager a plus, \n",
      "\n",
      "Proficiency in effective report/dashboard design and standards, \n",
      "\n",
      "Familiarity with data preparation, processing, classification, and forecasting, \n",
      "\n",
      "Familiarity with the software product lifecycle, \n",
      "\n",
      "Ability to write SQL and create data visualizations, \n",
      "\n",
      "Experience with Amazon S3, Redshift, Athena, Google Tag Manager, Google Analytics, Google Big Query, Tableau, or JavaScript, are big pluses!, \n",
      "\n",
      "A Bachelor‚Äôs degree or advanced degree in a technical, business, or math-based field, \n",
      "\n",
      "Experience interacting with individuals at all levels, good time management, and solid communication skills., \n",
      "\n",
      "Proven leadership ability to influence and inspire people indirectly, lead by example, and engage and effectively build multidisciplinary alliances, \n",
      "\n",
      "Ability to do some travel for planning and team meetings (20%) and frequently use web-based remote video and project collaboration tools, #LI-2KM, Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.\n",
      "entry --- Google\n",
      "substring --- Previous experience using web analytics tools (Google Analytics, etc.)\n",
      "entry --- Google\n",
      "substring --- click through rates, golden pathways, conversion analysis, and marketing effectiveness.Deliver quick turnarounds on dashboards, identify trends and/or issues within data sets, and make recommendations to influence business decisions and investments.Evaluate the effectiveness of marketing actions, recommend segmentation approaches and deliver actionable insights to improve customer lifetime value.Partner with IT, BI and Operations team to help identify and mend data gaps, source issues, and data inaccuracies.Present analytical results and insights to business partners to answer strategic questions and influence business decisions.Develop measurement plans/processes including multivariate A/B tests and experimental design to evaluate performance of marketing results., Bachelor degree in Mathematics, Computer Science or Marketing related quantitative field.Minimum of 2-3 years of experience in a data analytics capacity, experience with digital/online product strongly preferred.Understanding of relational database theory and proficiency in writing and understanding complex SQL code.Experience with Business Intelligence tools (Tableau, Alteryx & Cognos) and real time dashboard development.High proficiency in MS Excel and Web Analytics tools such as Adobe Analytics or Google Analytics.Working knowledge of Salesforce is a plus.Knowledge of statistical models and practical experience in predictive model development is a plus (R, Python, SAS, etc).Strong oral and written communicator with demonstrated experience translating analytics findings into business insights in order to influence business stakeholders to drive actionable decisions and optimize business performance.Excellent analytical and problem-solving skills with an exceptionally strong attention to detail.Curious, self-motivated thinker; always asks why and strives until the answer is clear.Strong organizational and time-management skills; ability to multi-task and prioritize responsibilities in line with business objectives, react to shifting priorities while adhering to deadlines.]\n",
      "entry --- Google\n",
      "substring --- Deliver data and data analysis on an ad-hoc basis using whatever tools are necessary for the task, \n",
      "\n",
      "Must Haves, \n",
      "\n",
      "Experience with Google Analytics or other Web Analytics tool, and A/B testing concepts Demonstrated capacity to clearly define product and business KPIs in support of company goals and strategies\n",
      "\n",
      "Excellent communication skills\n",
      "\n",
      "Deep understanding and empathy for users\n",
      "\n",
      "Willingness to get your hands dirty conducting data analysis, building dashboards, and supporting internal and external data requests\n",
      "\n",
      "Basic knowledge of SQL: its concepts and basic syntax, \n",
      "\n",
      "Nice to Haves, \n",
      "\n",
      "Experience with E-commerce concepts, things like Conversion rate, Customer Acquisition Costs, Attribution, etc.\n",
      "entry --- Google\n",
      "substring --- Experience with a Business Intelligence Dashboards tool (Tableau, Google Data Studio, Superset, or similar)\n",
      "\n",
      "Math or Statistical Background, i.e., can you talk through Distribution functions (Binomial, non-normal, student t-test), linear and non-linear models\n",
      "\n",
      "Exposure to A/B testing tools (Optimizely, Google Optimize, etc.)\n",
      "entry --- Google\n",
      "substring --- TrueCar offers a specialized digital marketplace and private targeted incentive solutions to help make that spend more efficient, while at the same time providing exclusive savings to the 6M+ consumers who visit our car buying service sites\n",
      "\n",
      ", ABOUT THE JOB:\n",
      "\n",
      ", Serve as the champion in data visualization techniques, analytics, dashboard design, and best practices for information delivery\n",
      "\n",
      "Own all aspects of analytics, reporting, design, and optimization insights for our all of our TrueCar OEM affinity partners\n",
      "\n",
      "Build, maintain and iterate on Tableau data visualizations\n",
      "\n",
      "Supervise creation of all visual reports in Tableau for internal and external clients that summarize findings clearly and effectively\n",
      "\n",
      "Collaborate with data engineering team to design data pipelines for Tableau Server\n",
      "\n",
      "Lead data analysis projects from the research phase to production\n",
      "\n",
      "Develop analytics and reporting capabilities for new OEM and Partner programs using Tableau and PowerPoint as they launch\n",
      "\n",
      "Track and measure optimization efforts using Google Analytics or Redshift/SQL\n",
      "\n",
      "Understand program results from key marketing and product initiatives and articulate the key drivers of program success or needs for improvement\n",
      "\n",
      "Leverage insights created by the OEM Partner & OEM team into actionable recommendations to improve program performance\n",
      "\n",
      "Must be well-spoken and comfortable with presenting to an executive audience\n",
      "\n",
      "Analyze digital marketing campaigns and provide cost analysis\n",
      "\n",
      ", WHAT YOU NEED:\n",
      "\n",
      ", 3 - 5+ years‚Äô experience working in an analytics role\n",
      "\n",
      "A passion for using data visualization to tell complex data stories\n",
      "\n",
      "Ability to communicate complex ideas to any audience, ranging from teammates to business executives\n",
      "\n",
      "3+ years of profession experience creating Tableau dashboards\n",
      "\n",
      "Experience with publishing and maintaining workbooks on Tableau Server\n",
      "\n",
      "3+ years of experience with database software (RedShift, Hive, SQL, MYSQL, ‚Ä¶)\n",
      "\n",
      "Experience with statistical programming software (Spark, R, Python preferred)\n",
      "\n",
      "Proficiency with Tableau Desktop and Server\n",
      "\n",
      "Bachelor‚Äôs Degree in Statistics, Data Science, Economics, CS, Engineering or related field\n",
      "\n",
      "Strong analytical background, with experience identifying trends and key takeaways from data\n",
      "\n",
      "Ability to analyze, organize, and integrate large amounts of complex data into clear and concise presentations and status reports\n",
      "\n",
      "Outstanding attention to detail and time-management skills\n",
      "\n",
      "Expert knowledge in Excel and PowerPoint required\n",
      "\n",
      "Experience tracking web metrics using Google Analytics\n",
      "\n",
      ", NICE TO HAVE:\n",
      "\n",
      ", Passion for the automotive and internet industries\n",
      "\n",
      "]\"\n",
      "\n",
      "\"[EBSCO Information Services (EIS) provides a complete and optimized research solution comprised of e-journals, e-books, and research databases ‚Äî all combined with the most powerful discovery service to support the information needs and maximize the research experience of our end-users.\n",
      "entry --- Google\n",
      "substring --- Deliver data and data analysis on an ad-hoc basis using whatever tools are necessary for the task, \n",
      "\n",
      "Must Haves, \n",
      "\n",
      "Experience with Google Analytics or other Web Analytics tool, and A/B testing concepts Demonstrated capacity to clearly define product and business KPIs in support of company goals and strategies\n",
      "\n",
      "Excellent communication skills\n",
      "\n",
      "Deep understanding and empathy for users\n",
      "\n",
      "Willingness to get your hands dirty conducting data analysis, building dashboards, and supporting internal and external data requests\n",
      "\n",
      "Basic knowledge of SQL: its concepts and basic syntax, \n",
      "\n",
      "Nice to Haves, \n",
      "\n",
      "Experience with E-commerce concepts, things like Conversion rate, Customer Acquisition Costs, Attribution, etc.\n",
      "entry --- Google\n",
      "substring --- Experience with a Business Intelligence Dashboards tool (Tableau, Google Data Studio, Superset, or similar)\n",
      "\n",
      "Math or Statistical Background, i.e., can you talk through Distribution functions (Binomial, non-normal, student t-test), linear and non-linear models\n",
      "\n",
      "Exposure to A/B testing tools (Optimizely, Google Optimize, etc.)\n",
      "entry --- Google\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Google\n",
      "substring --- This role includes heavy technical knowledge in implementing Google Tag Manager, gathering insights from Google Analytics and other analytics platforms as well as knowledge of the marketing life cycle and common marketing channels., General Responsibilities, Responsibilities are applicable based on the position focus/channel, Helps to identify, analyze/execute new and potential product/services, markets, and advertising opportunities.\n",
      "entry --- Google\n",
      "substring --- Experience using Google Analytics, Google Tag Manager, and implementing scripts\n",
      "\n",
      "\n",
      "Experience with utilizing and working with various data visualization tools\n",
      "\n",
      "\n",
      "Experience with various media api platforms such as Google Analytics/Adwords, Facebook, Linkedin etc\n",
      "\n",
      "\n",
      "Experience with design and development of reporting tools and\n",
      "\n",
      "\n",
      "Experience developing various forecasting and analytical models utilizing tools such as Excel\n",
      "\n",
      "\n",
      "Experience managing out-sourced vendors\n",
      ", 4-year degree from an accredited institution in Marketing or equivalent discipline OR appropriate combination of experience and education, \n",
      "\n",
      "Minimum of 3 years‚Äô experience serving in a data analyst capacity in marketing, finance, mathematics etc., \n",
      "\n",
      "Experience using Google Analytics, Google Tag Manager, and implementing scripts, \n",
      "\n",
      "Experience with utilizing and working with various data visualization tools, \n",
      "\n",
      "Experience with various media api platforms such as Google Analytics/Adwords, Facebook, Linkedin etc, \n",
      "\n",
      "Experience with design and development of reporting tools and, \n",
      "\n",
      "Experience developing various forecasting and analytical models utilizing tools such as Excel, \n",
      "\n",
      "Experience managing out-sourced vendors, Supervisory Responsibilities, None., Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.\n",
      "entry --- Google\n",
      "substring --- Our goal is to organize and produce data that's thoughtful, useful to sales teams and widely accessible., The Go-to-Market Operations (GtM) team ensures Google's complex and ever-evolving Ads business runs smoothly.\n",
      "entry --- Google\n",
      "substring --- Synthesize information to make it useful and available to partners and sales teams, and analyze it to understand how features impact clients and Google's ads business.\n",
      "entry --- Google\n",
      "substring --- Experience with Google Analytics, Snowplow, and Salesforce a plus\n",
      "Worked with data warehouses and DMPs\n",
      "Knowledge and experience with SQL\n",
      "Shown an ability to translate raw data into compelling, insightful analysis\n",
      ", \n",
      "AnalogFolk started in 2008 and has expanded offices across the world (London, Sydney, New York, Portland, Hong Kong and Shanghai)\n",
      "We make interactive experiences that create value for people and brands.\n",
      "entry --- Google\n",
      "substring --- \"[Must Have:, \n",
      "Oracle DBA\n",
      "Database Design and System Analysis\n",
      "Data Security\n",
      "Backup and Recovery\n",
      "Change Control Management\n",
      "Database Testing\n",
      ", Good to Have:, \n",
      "GigaSpaces XAP\n",
      "GigaSpaces InsightEdge\n",
      "Cloud Computing (Amazon AWS, Microsoft Azure or Google GCP)\n",
      "In-Memory Databases (other than GigaSpaces like Redis, etc.)\n",
      "entry --- Google\n",
      "substring --- Use tools such as Google Sheet, Tableau and many internal tools to work efficiently at scal, \n",
      "\n",
      "BS/MS in Engineering, Computer Science, Math, Economics, Statistics, or equivalent experience.\n",
      "entry --- Google\n",
      "substring --- business analytics preferred\n",
      "4+ year‚Äôs analytics experience, e-commerce preferred\n",
      ", Special skills required:\n",
      "\n",
      ", Data enthusiast with strong analytical, technical and communication skills\n",
      ", Advanced technical abilities including SQL, excel and clustering methods to extract insights across multiple databases\n",
      "Data visualization tools such as Tableau, Power BI\n",
      "Working knowledge of one or more of the following platforms:\n",
      "\n",
      "Web analytics tool (Adobe Site Catalyst or Google 360 Premium),\n",
      "CRM platform\n",
      "Loyalty platform\n",
      "A/B testing platform\n",
      "Email marketing platform (SalesForce Marketing Cloud is preferable)\n",
      "Ability to utilize both internal and syndicated data systems and access, interpret and draw accurate conclusions to make a case for a plan of action or decision.\n",
      "entry --- Google\n",
      "substring --- Ability to accurately forecast volume and/or track and complete the specific project to meaningful deadlines\n",
      ", Web analytics tool (Adobe Site Catalyst or Google 360 Premium),\n",
      "CRM platform\n",
      "Loyalty platform\n",
      "A/B testing platform\n",
      "Email marketing platform (SalesForce Marketing Cloud is preferable)\n",
      ", CAREER DEVELOPMENT\n",
      "\n",
      ", The role can advance depending on the individual‚Äôs passions and interests.\n",
      "entry --- Google\n",
      "substring --- Strong organizational skills and the ability to operate independently are required.US Person, Spreadsheet tools, e.g., MS ExcelDatabase systems (SQL and NO SQL based)Communication and visualizationDescriptive statistics and exploratory data analysisLanguages: R, Python, HTML, Javascript, SQL, C/C++Knowledge of business planning / financial management, applied analytics, and manufacturing operations, preferably in an Aerospace application.Strong continuous improvement background, such as Lean Six Sigma training preferredDemonstrated ability to learn new programs and approach new problems in an efficient methodical manner]\n",
      "\n",
      "\"[Use quantitative methodology and data insights to influence the direction of our product development and business decisions\n",
      "\n",
      "Partner with our product teams to define goals and identify key metrics for existing features and new releases\n",
      "\n",
      "Use data to discover and evaluate new product opportunities\n",
      "\n",
      "Mine our underlying data for trends in user behavior\n",
      "\n",
      "Identify gaps in our existing data infrastructure and develop corresponding solutions\n",
      "\n",
      "Develop data sets to empower operational and exploratory analyses\n",
      "\n",
      "Collaborate cross-functionally with Product, Data Science, Engineering, Marketing, and Customer Success to design, execute and iterate on product experiments\n",
      "\n",
      "Work with business intelligence tools such as Heap, Tableau, or Google Analytics to classify user populations and identify product usage trends\n",
      "\n",
      "Dive deep into raw data sets to identify user behaviors\n",
      "\n",
      "Build connectors between our existing data sets, business intelligence tools, and other systems to provide an integrated view of user behavior\n",
      "\n",
      "Dive deep into a raw data set to identify behavioral inflection points, and propose experiments to influence our users to a desired outcome\n",
      "\n",
      "Work cross functionally to construct, monitor, and measure a usability experiment\n",
      "\n",
      "Build a culture where we ask data-driven business questions, and update our company and product strategies based on the answers, Proven experience with using quantitative analysis to influence business and product decisions\n",
      "\n",
      "The ability to clearly and effectively communicate the business impact & results of complex analyses\n",
      "\n",
      "Minimum of 3 years experience writing production datasets OR building internal/production data tools for ETL, experimentation, or exploration in Python\n",
      "\n",
      "Bachelor's degree in Computer Science, Engineering or related field, or equivalent training, fellowship, or work experience\n",
      "\n",
      "A solid grasp of common statistical applications and methods (experimentation, probabilities, regression)\n",
      "\n",
      "Experience in software engineering a plusExperience in predictive modeling in big data environment is a plus\n",
      "\n",
      "\n",
      "OUR COMMITMENT TO DIVERSITY AND INCLUSION: At Hearsay we believe that diverse teams are the best teams.\n",
      "entry --- Google\n",
      "substring --- While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \n",
      "\n",
      "Facebook\n",
      "\n",
      "Twitter\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "Google\n",
      "\n",
      "More]\"\n",
      "\"[Title: Data Analyst\n",
      "Reports to: Research Director\n",
      "Classification: Exempt\n",
      "Location: New York\n",
      "Start Date: Immediately, \n",
      "\n",
      "Summary:\n",
      "\n",
      "The Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \n",
      "\n",
      "The Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets.\n",
      "entry --- Google\n",
      "substring --- While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \n",
      "\n",
      "Facebook\n",
      "\n",
      "Twitter\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "Google\n",
      "\n",
      "More]\"\n",
      "\"[The Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \n",
      "\n",
      "The Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets.\n",
      "entry --- Google\n",
      "substring --- You will partner with Google and vendor engineering teams to shape and develop REWS‚Äô data architecture.\n",
      "entry --- Google\n",
      "substring --- You can critically think through business problems and communicate to stakeholders the next., The Real Estate and Workplace Services (REWS) team creates inspiring spaces and innovative services that bring Google‚Äôs culture and values to life.\n",
      "entry --- Google\n",
      "substring --- We build and maintain all aspects of what keeps our Googley workspaces operating seamlessly across multiple cities and regions globally.\n",
      "entry --- Google\n",
      "substring --- We also manage the industry-leading services that help make Google a great place to work - from how we design healthy and collaborative workspaces, create energizing food experiences, provide convenient transportation and fitness options, to delivering inclusive environments where Google and our employees can thrive., Work closely with REWS management and their teams to understand their business problems and processes and how data can be applied to those problems and processes, and create appropriate analyses and tools to address them.\n",
      "entry --- Google\n",
      "substring --- AWS, Azure, Google Cloud etc.\n",
      "entry --- Google\n",
      "substring --- Optimize data within Google Forms\n",
      "\n",
      "Design surveys or advise teams on survey development to ensure proper data capture\n",
      "\n",
      "Ensure the integrity of data within the system\n",
      "\n",
      "Build predictive models to identify future trends and patterns\n",
      "\n",
      "Develop process maps and training plans for the team\n",
      "\n",
      "Develop, monitor, evaluate and manage metrics (OKRs, KPIs, etc.)\n",
      "entry --- Google\n",
      "substring --- Create automated systems to track performance metrics\n",
      "\n",
      "Identify and troubleshoot any issues or discrepancies\n",
      "\n",
      "Project coordination and management - manage multiple high priority tasks/projects simultaneously\n",
      "\n",
      "Track project performance, specifically to analyze the successful completion of short- and long-term goals, \n",
      "\n",
      "Integrate data from others sources into the system\n",
      "\n",
      "Consistently maintain and improve the system, \n",
      "\n",
      "Data Science / Statistics / Quantitative / Mathematics / Economics background\n",
      "\n",
      "Must have experience with Google Sheets, Excel, Tableau, SQL, Google Forms, Google Slides and/or PowerPoint\n",
      "\n",
      "Know at least one script language, such as Python or JavaScript\n",
      "\n",
      "Familiarity with database engines, such as SQL Server, \n",
      "\n",
      "Possess strong communication skills, and specifically an ability to take a complex problem and explain it very simply\n",
      "\n",
      "Be a teamplayer who enjoys cross-functional collaboration with colleagues and teams worldwide\n",
      "\n",
      "Be a technical expert - not only fix issues as they arise, but be a proactive adviser to your manager and the Global Security team\n",
      "\n",
      "Be driven and self-taught - seek solutions, identify gaps, create solutions and solve problems independently\n",
      "\n",
      "Possess high integrity - you will be responsible for handling and safeguarding sensitive data, and encounter potential exposure to incident reports.\n",
      "entry --- Google\n",
      "substring --- Actively partner and develop effective relationships with related groups in eCommerce management, eMarketing, product and tech to facilitate and manage efforts across teams to turn insights into practice on the site., Qualifications\n",
      "\n",
      "4-year Degree in Marketing, Finance, Economics, Mathematics or related areas of study\n",
      "\n",
      "4+ years experience working in data analytics or related areas\n",
      "\n",
      "2+ years experience using web analytics tools such as Adobe Analytics/Omniture, Google Analytics, or similar\n",
      "\n",
      "Proficient in web analytics fundamentals and website measurement strategy, \n",
      "\n",
      "Knowledge of data modeling (using SQL, Python, and/or Excel) to support our S&OP team's demand planning process\n",
      "\n",
      "Ability to construct custom queries using web analytics tools\n",
      "\n",
      "Good knowledge eMarketing activities such as SEM/SEO, remarketing/retention, targeted display, affiliates, etc.\n",
      "entry --- Google\n",
      "substring --- Experience managing various tagging and tracking platforms such as Adobe Marketing Cloud (Omniture), Tealium, Google Analytics, etc.\n",
      "entry --- Google\n",
      "substring --- Experience with the following technologies is desired: Hadoop, AWS, Tableau or other OLAP cube/data visualization, Oracle database, Adobe Marketing Cloud (Omniture), Google Analytics, Clicktale, ExactTarget/Salesforce (or similar ESP)\n",
      "\n",
      "Experience coordinating and communicating with internal and external stakeholders.\n",
      "entry --- Google\n",
      "substring --- Including A/B and multivariate testing\n",
      "\n",
      "Ability to develop data driven targeted and segmented contact strategies\n",
      "\n",
      "Proficient in digital analytics, including web analytics with tools like Adobe Analytics, Google Analytics and Webtrends\n",
      "\n",
      "Experienced in digital test design and implementation with current digital targeting tools (Adobe, Webtrends, X+1, etc.)\n",
      "entry --- Google\n",
      "substring --- Develop integrated reporting dashboards using data visualization tools like Spotfire, Crystal Xcelcius, Tableau\n",
      "\n",
      "Provide digital asset tagging instructions for website development and digital adverting content\n",
      "\n",
      "Understanding of the analytics discipline: including process, best practices, tools and techniques\n",
      "\n",
      "Solid presentation and client facing skills\n",
      "\n",
      "Excellent project management and implementation skills\n",
      "\n",
      "Service/client oriented\n",
      "\n",
      "Excellent verbal and written communication skills\n",
      "\n",
      "Versed in a range of industries, pharmaceutical and/or healthcare experience a plus, \n",
      "\n",
      "BA/BS degree required; MBA a plus\n",
      "\n",
      "3 - 5 years of experience in digital marketing analytics and database marketing\n",
      "\n",
      "Digital analytics (Adobe, Google Analytics, Webtrends, DoubleClick, Atlas, etc.\n",
      "entry --- Google\n",
      "substring --- The ideal candidate should be highly analytical and have a strong technical skill-set, with solid experience in a data extraction language (such as SQL) and experience working in the Salesforce environment., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Work cross-functionally with west region executives, marketing, member experience, real estate, sales ops and finance to analyze data, identify trends, implement optimization\n",
      "\n",
      "Leverage predictive analytics to support demand pipeline forecast, by segment, product and territory/market, to support 80% occupancy rate for new building openings\n",
      "\n",
      "Establish regional KPIs and benchmarks for growth acquisition and across multiple channels, including paid search/social, display, mobile, email marketing, and OOH campaigns\n",
      "\n",
      "Establish measurement framework for pilot programs on member experience, via both qualitative studies and quantitative approach, including using analytics to measure the impact of member interactions and satisfaction\n",
      "\n",
      "Execute accurate test design and evaluation ‚Äì including sampling techniques and determining statistical significance\n",
      "\n",
      "Own the reporting and dashboards of west region, with rigorous quality control and timely delivery\n",
      "\n",
      "Implement standard processes, data infrastructure, operational best practices for west region\n",
      "\n",
      "Develop recommendations for changes to investment and marketing strategy, optimize the efficacy of marketing spend based on quantitative analyses\n",
      "\n",
      "Execute on data strategy and implement technology to support hyper-segmentation, account-based marketing, and multi-touch attribution\n",
      "\n",
      "Lead the training processes on a range of marketing analytics and BI tools, and foster the data-driven culture across teams, Qualifications:, \n",
      "\n",
      "Strong quantitative, analytical, and problem solving skills\n",
      "\n",
      "4+ years experience within business/marketing/data analytics\n",
      "\n",
      "Flexibility and ability to adapt to evolving business objectives\n",
      "\n",
      "Expertise in a query language such as SQL or equivalent\n",
      "\n",
      "Experience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics\n",
      "\n",
      "Organized with strong problem solving skills, attention to detail, communication skills, and time management abilities\n",
      "\n",
      "Ability to manage multiple projects and deliver against aggressive deadlines\n",
      "\n",
      "Masters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable]\"\n",
      "\"[Partner with Business Developer team to maximize our marketplace health and performance through data-driven insights\n",
      "\n",
      "Present as appropriate to individuals throughout the organization and to Criteo clients externally (i.e.\n",
      "entry --- Google\n",
      "substring --- Experience with data extraction, manipulation and blending across different data sources (Google Analytics, DoubleClick for Publishers, SQL Server, Snowflake, AWS, Salesforce, flat files, etc).\n",
      "entry --- Google\n",
      "substring --- There will be extended periods of sitting and using a computer\n",
      "Travel, predominantly domestic, approximately 10-15%., \n",
      "A relevant university degree in a quantitative field such as Mathematics, Statistics, Business or Economics., \n",
      "2+ years of marketing and/or finance]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; New York, NY, USA, \n",
      "\n",
      "Businesses that partner with Google come in all shapes, sizes and market caps, and no one Google advertising solution works for all.\n",
      "entry --- Google\n",
      "substring --- Using your influencing and relationship-building skills, you provide Google-caliber client service, research and market analysis.\n",
      "entry --- Google\n",
      "substring --- You anticipate how decisions are made, persistently explore and uncover the business needs of Google's key clients and understand how our range of product offerings can grow their business.\n",
      "entry --- Google\n",
      "substring --- You have a deep industry understanding of the digital advertising industry, Google‚Äôs ad product suite, and a passion for using data in storytelling., Google‚Äôs Global Partnerships team works with a wide range of partners to bring the best of Google to power their business.\n",
      "entry --- Google\n",
      "substring --- The team partners with Publishers and App Developers of all sizes to promote their ad inventory, working with Google's broad range of partner solutions including AdSense, AdMob and Google Ad Manager, across mobile, display, and video formats, helping our partners and their audiences get the most out of the web.\n",
      "entry --- Google\n",
      "substring --- In addition, the Partnerships team supports Google‚Äôs own product teams with essential partnerships to help power Google‚Äôs user experiences in search, maps, travel, shopping, payments and more., Deliver yield management consulting, execution and outstanding results.\n",
      "entry --- Google\n",
      "substring --- Partner with customers to build the best strategy to increase profitability while respecting business rules by leveraging various Google offerings.\n",
      "entry --- Google\n",
      "substring --- Deep understanding of digital advertising industry and Google‚Äôs ad product suite in particular ad serving and yield management expertise.\n",
      "entry --- Google\n",
      "substring --- , Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\n",
      ", Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\n",
      ", Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\n",
      "Proficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\n",
      "Ability to digest and explain complex ideas to a diverse group of stakeholders\n",
      "Must be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\n",
      "Experience with digital media measurement and reporting platforms preferred as well as programming languages\n",
      "Experienced in effective dashboard designing with a focus on customizing to client needs\n",
      "Ability to work under pressure and manage multiple priorities\n",
      "Strong communication and presentation skills equally capable of interacting with peers and senior leaders\n",
      "Must be a team player but also have the ability to work independently]\"\n",
      "\"[We are looking for you - dynamic, best-in-class talent - to join the Initiative team as a Senior Analyst, Analytics.\n",
      "entry --- Google\n",
      "substring --- , Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\n",
      ", Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\n",
      ", Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\n",
      "Proficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\n",
      "Ability to digest and explain complex ideas to a diverse group of stakeholders\n",
      "Must be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\n",
      "Experience with digital media measurement and reporting platforms preferred as well as programming languages\n",
      "Experienced in effective dashboard designing with a focus on customizing to client needs\n",
      "Ability to work under pressure and manage multiple priorities\n",
      "Strong communication and presentation skills equally capable of interacting with peers and senior leaders\n",
      "Must be a team player but also have the ability to work independently]\"\n",
      "\"[Responsibilities for this role include, but are not limited to:, \n",
      "\n",
      "Building complex data sets from multiple data sources, both internally and externally.\n",
      "entry --- Google\n",
      "substring --- Ensure quality of implementation of Golden Gate replication from the source system to the PJM Information Warehouse / MOD., \n",
      "\n",
      "BS, Computer Science, Management Information Systems or equivalent work experience\n",
      "\n",
      "At least 5 years of experience data warehousing concepts and support tools with data modeling and data structure design/supporting Oracle 11g/12c in an AIX/UNIX environment: SAP PowerDesigner / Erwin or other data modeling tool, Oracle Enterprise Manager (OEM) and Various Oracle development tools (SQL*Plus, Toad)\n",
      "\n",
      "Ability to produce high-quality work products with attention to detail\n",
      "\n",
      "Ability to visualize and solve complex problems\n",
      "\n",
      "Ability to apply analytical and mathematical solutions\n",
      "\n",
      "Experience with conceptual and logical data modeling including developing and maintaining data model diagrams (ERD), facilitating structured data modeling meetings\n",
      "\n",
      "Experience designing and building business intelligence architectures including data marts, data warehouses, and reporting and analysis applications\n",
      "\n",
      "Experience with MS Suite of Business Intelligence Tools including SSIS, SSRS, SSAS\n",
      "\n",
      "Experience with SQL Tools, such as SQL Navigator, TOAD, SQL*Plus\n",
      "\n",
      "Experience with Oracle 11g database management system, \n",
      "\n",
      "MS, Computer Science\n",
      "\n",
      "Experience with PJM operations, markets, and planning functions\n",
      "\n",
      "Experience with Alteryx and SAS Experience with visualization and reporting tools such as Tableau, SAS Visual Analytics, Qlik etc Experience in end to end delivery and lifecycle of analytical business solutions]\"\n",
      "\"[The Day to Day:, \n",
      "\n",
      "Own, improve, and document WP Engine‚Äôs business financial data models\n",
      "\n",
      "Understand requirements from both internal and external stakeholders, gather data from various data sources, conduct business analysis, and provide quantitative insights through creation of dashboards and visualizations\n",
      "\n",
      "Work closely with Finance to translate manual data analysis into automated analytics, resulting in faster more meaningful data extraction for users\n",
      "\n",
      "Applying statistical expertise to analyze large data sets to build models that highlight business needs/challenges\n",
      "\n",
      "Develop and implement new ETL methods and/or tools to integrate new data sources\n",
      "\n",
      "Accessing data through SQL and other ETL processes to generate automated reports\n",
      "\n",
      "Perform technical analysis on data to measure underlying trends and behavior\n",
      "\n",
      "Enforcing data integrity and applying quality assurance best practices for data services\n",
      "\n",
      "Conduct deep-dive data analysis for business insights and recommendation utilizing both established dashboard/visualization tools and ad-hoc querying of internal databases\n",
      "\n",
      "Track and understand the economic and financial fundamentals of the Finance organization that are identified as part of overall company objectives, \n",
      "\n",
      "Your Expertise and Passion:, \n",
      "\n",
      "4-8 years of data oriented experience working in a fast-paced, hyper growth, start up environment\n",
      "\n",
      "Knowledge of SQL to write complex, highly-optimized queries across large volumes of data\n",
      "\n",
      "Undergraduate degree in Statistics, Economics, Mathematics, or Computer Science\n",
      "\n",
      "Ability to program in R, Python (preferred), or PHP\n",
      "\n",
      "Experience with ETL methods, data modeling, and automation\n",
      "\n",
      "Passion for reporting and analytics while working in an agile team to drive change\n",
      "\n",
      "Motivation to take ownership and work independently on multiple simultaneous projects\n",
      "\n",
      "Exceptionally strong analytical and problem solving skills, combined with strong business acumen\n",
      "\n",
      "Desire to use analytical skills to drive better financial outcomes for the Finance organization\n",
      "\n",
      "Business Intelligence experience is a plus., Compensation (We offer market competitive salaries)\n",
      "\n",
      "Stock Options (Every employee is an owner in the company)\n",
      "\n",
      "Health Benefits (100% Paid Employee Medical, Dental, and Vision)\n",
      "\n",
      "401(k) (Make the most of retirement)\n",
      "\n",
      "Life and Disability Insurance (100% Paid Life, STD, LTD and AD&D)\n",
      "\n",
      "Generous Vacation Time (Who doesn‚Äôt like time off)\n",
      "\n",
      "Transportation (Downtown parking or commuter reimbursement)\n",
      "\n",
      "Lunch (Provided Monday ‚Äì Thursday)\n",
      "\n",
      "Gym membership discount]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; New York, NY, USA, \n",
      "\n",
      "Businesses that partner with Google come in all shapes, sizes and market caps, and no one Google advertising solution works for all.\n",
      "entry --- Google\n",
      "substring --- Using your influencing and relationship-building skills, you provide Google-caliber client service, research and market analysis.\n",
      "entry --- Google\n",
      "substring --- You anticipate how decisions are made, persistently explore and uncover the business needs of Google's key clients and understand how our range of product offerings can grow their business.\n",
      "entry --- Google\n",
      "substring --- You have a deep industry understanding of the digital advertising industry, Google‚Äôs ad product suite, and a passion for using data in storytelling., Google‚Äôs Global Partnerships team works with a wide range of partners to bring the best of Google to power their business.\n",
      "entry --- Google\n",
      "substring --- The team partners with Publishers and App Developers of all sizes to promote their ad inventory, working with Google's broad range of partner solutions including AdSense, AdMob and Google Ad Manager, across mobile, display, and video formats, helping our partners and their audiences get the most out of the web.\n",
      "entry --- Google\n",
      "substring --- In addition, the Partnerships team supports Google‚Äôs own product teams with essential partnerships to help power Google‚Äôs user experiences in search, maps, travel, shopping, payments and more., Deliver yield management consulting, execution and outstanding results.\n",
      "entry --- Google\n",
      "substring --- Partner with customers to build the best strategy to increase profitability while respecting business rules by leveraging various Google offerings.\n",
      "entry --- Google\n",
      "substring --- Deep understanding of digital advertising industry and Google‚Äôs ad product suite in particular ad serving and yield management expertise.\n",
      "entry --- Google\n",
      "substring --- Experience with analytics tools such as Adobe Analytics or Google Analytics.\n",
      "entry --- Google\n",
      "substring --- , Data Analytics:, Very proficient in Google Search and other search engines.\n",
      "entry --- Google\n",
      "substring --- Awesome with Google Analytics, AdWords, and SQL?\n",
      "entry --- Google\n",
      "substring --- , \n",
      "Partner with Marketing Managers, Sales, and executives as a strategic thought partner to deliver key insights from web tracking metrics\n",
      "Study website behavior patterns to analyze and optimize business results and user experience\n",
      "Synthesize data from multiple sources, developing assumptions where needed, to drive customer insights and strategy development\n",
      "Coordinate with external partners and business stakeholders to develop actionable dashboards which present the end to end funnel metrics, contributing to the development of hypotheses and actions\n",
      "Collaborate with Marketing to measure impact of website strategy across all campaign channels and to refine strategy driven by data-based insights\n",
      "Work with stakeholders to develop learning plans with recommendations of analytics approaches, including A/B testing\n",
      "Ensure site tagging is implemented properly to provide visibility to impact and value of various initiatives and releases\n",
      ", \n",
      "5-8 years of experience in web analytics decision support and website optimization\n",
      "Deep subject matter expertise with Google Analytics and SQL; experience with Google AdWords, Google Webmaster tools and Google Tag Manager a plus\n",
      "Solid understanding of Paid Search, SEO, and other digital marketing channels such as Affiliate, Social, and Display\n",
      "Strong analytical and problem solving skills\n",
      "Experience with Tableau (or similar data visualization tools such as Spotfire, PowerBI, QlikView, etc.)\n",
      "entry --- Google\n",
      "substring --- Our goal is to organize and produce data that's thoughtful, useful to sales teams and widely accessible., The Go-to-Market Operations (GtM) team ensures Google's complex and ever-evolving Ads business runs smoothly.\n",
      "entry --- Google\n",
      "substring --- Synthesize information to make it useful and available to partners and sales teams, and analyze it to understand how features impact clients and Google's ads business.\n",
      "entry --- Google\n",
      "substring --- Our goal is to organize and produce data that's thoughtful, useful to sales teams and widely accessible., The Go-to-Market Operations (GtM) team ensures Google's complex and ever-evolving Ads business runs smoothly.\n",
      "entry --- Google\n",
      "substring --- Synthesize information to make it useful and available to partners and sales teams, and analyze it to understand how features impact clients and Google's ads business.\n",
      "entry --- Google\n",
      "substring --- Our goal is to organize and produce data that's thoughtful, useful to sales teams and widely accessible., The Go-to-Market Operations (GtM) team ensures Google's complex and ever-evolving Ads business runs smoothly.\n",
      "entry --- Google\n",
      "substring --- Synthesize information to make it useful and available to partners and sales teams, and analyze it to understand how features impact clients and Google's ads business.\n",
      "entry --- Google\n",
      "substring --- , Responsibilities:, \n",
      "\n",
      "Ensure marketing campaign funnels and customer behavior flows are tagged and tracked accurately for reporting and analysis purposes\n",
      "\n",
      "Set up standard processes, data infrastructure, operational best practices across global marketing organization\n",
      "\n",
      "Analyze data, identify trends, implement optimizations on a day to day basis across digital and offline marketing channels, building dashboards and delivering timely reports to support analyses\n",
      "\n",
      "Develop recommendations for changes to investment and marketing strategy, optimize the efficacy of marketing spend based on quantitative analyses\n",
      "\n",
      "Support product marketing, sales enablement, growth acquisition, and marketing automation seements on data needs and insights\n",
      "\n",
      "Implement technology in order to analyze sales funnel, lifetime value based on customer segmentation, \n",
      "\n",
      "Ensure marketing campaign funnels and customer behavior flows are tagged and tracked accurately for reporting and analysis purposes, \n",
      "\n",
      "Set up standard processes, data infrastructure, operational best practices across global marketing organization, \n",
      "\n",
      "Analyze data, identify trends, implement optimizations on a day to day basis across digital and offline marketing channels, building dashboards and delivering timely reports to support analyses, \n",
      "\n",
      "Develop recommendations for changes to investment and marketing strategy, optimize the efficacy of marketing spend based on quantitative analyses, \n",
      "\n",
      "Support product marketing, sales enablement, growth acquisition, and marketing automation seements on data needs and insights, \n",
      "\n",
      "Implement technology in order to analyze sales funnel, lifetime value based on customer segmentation, \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "Strong quantitative, analytical, and problem solving skills\n",
      "\n",
      "4+ years experience within business/marketing/data analytics\n",
      "\n",
      "Experience working in the Salesforce environment, understanding business products, journey flow and terminology\n",
      "\n",
      "Expertise in a query language such as SQL or equivalent\n",
      "\n",
      "Experience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics\n",
      "\n",
      "Experience in reporting on customer insights and LTV analysis\n",
      "\n",
      "Working knowledge in Google Tag Manager\n",
      "\n",
      "Working knowledge of ad trafficking/ad serving platforms including but not limited to Doubleclick etc.\n",
      "entry --- Google\n",
      "substring --- Ability to manage multiple projects and deliver against aggressive deadlines\n",
      "\n",
      "Masters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable\n",
      "\n",
      "Strong work ethic and intellectual curiosity, with laser focus on execution, \n",
      "\n",
      "Strong quantitative, analytical, and problem solving skills, \n",
      "\n",
      "4+ years experience within business/marketing/data analytics, \n",
      "\n",
      "Experience working in the Salesforce environment, understanding business products, journey flow and terminology\n",
      "\n",
      ", Expertise in a query language such as SQL or equivalent, \n",
      "\n",
      "Experience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics, \n",
      "\n",
      "Experience in reporting on customer insights and LTV analysis, \n",
      "\n",
      "Working knowledge in Google Tag Manager, \n",
      "\n",
      "Working knowledge of ad trafficking/ad serving platforms including but not limited to Doubleclick etc., \n",
      "\n",
      "Ability to manage multiple projects and deliver against aggressive deadlines, \n",
      "\n",
      "Masters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable, \n",
      "\n",
      "Strong work ethic and intellectual curiosity, with laser focus on execution]\"\n",
      "\"[\n",
      "\n",
      "Collaborating with BU Partners & exercising expertise in selecting methods & techniques to design, develop, implement, modify & support software products involving data movement of very large data sets and integration processes in preparation for analysis, data warehousing & operational data stores\n",
      "\n",
      "Develop ETL process on big data platforms & ensuring the data is available per the SLA\n",
      "\n",
      "Develop APIs to provide access to in-house and third-party data and enable analysis\n",
      "\n",
      "Collect, process, and interpret large data sets, identify and analyze features of interest such as key performance metrics for channel marketing strategies, what if scenarios, aggregations, filtering, statistical modeling\n",
      "\n",
      "Work on problems of complex scope requiring the synthesis of various inputs, analyzing large quantities of data & related products/services\n",
      "\n",
      "Assist in data model documentation, data dictionary, data flow, and data mapping for analysts\n",
      "\n",
      "Create new metrics and develop tools for monitoring and reporting\n",
      "\n",
      "Participate in complete end-to-end data warehousing & analytics work, including design, reviews, development, unit tests, and deployment\n",
      "\n",
      "Researching & POC of the latest tools & technologies required for software & data engineering tasks, \n",
      "\n",
      "4+ years of experience with data warehouse & software engineering background\n",
      "\n",
      "Using Data integration (ETL) Tools such as Informatica, Pentaho, ODI & SQLSERVER Technologies such as SSIS, SSAS & SSRS or equivalent\n",
      "\n",
      "Experience using scheduling & orchestration tools such as Tidal, Oozie or Control-M\n",
      "\n",
      "RDBMS expertise on Oracle, SQL Server, etc and MPP systems such as Netezza & Vertica\n",
      "\n",
      "Secure handling of sensitive information using Safenet, HSM, SSL, Access Control Lists (ACLs), encryption & key management\n",
      "\n",
      "Proficient in SQL, Unix and Perl\n",
      "\n",
      "Implementing big data analytical solutions using Hadoop, Hive and Pig\n",
      "\n",
      "Using Cloud based technologies such as Amazon s3, Redshift, EMR, DynamoDB, or RDS\n",
      "\n",
      "Programming & Automation skills in Python, Scala, Java or R using bigdata\n",
      "\n",
      "Maintaining centralized data cataloging/quality using technologies such as Informatica Data Quality (IDQ) or Alation\n",
      "\n",
      "Design and development of analytical reports and dashboards using Business Objects, QlikView, Tableau or similar visualization technologies is preferred\n",
      "\n",
      "Experience working with SaaS-based subscription metrics including conversion, retention and product usage is preferred]\"\n",
      "\"[Our client, One of the biggest Software Companies, is actively looking for a Data Analyst to join their growing team in San Jose, CA!, The Service Management Analyst will be responsible for analyzing macro trends across a Cloud Technology and Digital Media service landscape which includes a rich ecosystem of services supporting customers, businesses, and employees., A background in Incident, Problem, Change, and Release Management will provide the context necessary to analyze the datasets., Preferred Qualifications:, Analytical mindset and critical thinking ability\n",
      "Ability to use data to derive actionable insights (including skills in designing data models, collecting data, data preparation, data augmentation, data mining)\n",
      "Familiarity with Service Management and ITIL Framework (Incident Management, Problem Management, Change Management, Release Management)\n",
      "Ability to work with relational datasets and excel spreadsheets\n",
      "Ability to build partnerships with cross functional teams in order to achieve objectives and results\n",
      "Ability to work through failed attempts and look at it as a learning experience on the road to success\n",
      "Effectively communicate with leadership and technical personnel by ‚Äútranslating‚Äù and conveying ideas and insights between the two\n",
      ", Experience:, 3-5 years experience working with data models and conducting data analysis and applying insights learned from the data into working processes to achieve desired results\n",
      "SQL, Excel, Python, or Tableau Experience\n",
      ", The Offer:, Up to $65/hr DOE\n",
      "HSA Health Savings plan\n",
      ", Benefits:, Medical insurance\n",
      "401k\n",
      "Transportation benefits\n",
      "Paid Sick Time\n",
      ", Benefits & Perks, A competitive benefits package is offered complete with: health, transportation benefits, accrued sick-time off, and a 401k option.]\"\n",
      "entry --- Google\n",
      "substring --- , Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\n",
      ", Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\n",
      ", Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\n",
      "Proficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\n",
      "Ability to digest and explain complex ideas to a diverse group of stakeholders\n",
      "Must be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\n",
      "Experience with digital media measurement and reporting platforms preferred as well as programming languages\n",
      "Experienced in effective dashboard designing with a focus on customizing to client needs\n",
      "Ability to work under pressure and manage multiple priorities\n",
      "Strong communication and presentation skills equally capable of interacting with peers and senior leaders\n",
      "Must be a team player but also have the ability to work independently]\"\n",
      "\"[\n",
      "2+ years of experience with supporting or executing data building, data queries, modeling, or programming of complex analytical methods to support military applications\n",
      "2+ years of experience with analytical technologies used in enterprise reporting, including Tableau, Qlik, Looker, OBIEE, or equivalent\n",
      "1+ years of experience in working with data infrastructure approaches, including open data architectures, Cloud infrastructure, and Infrastructure as a Service, Platform as a Service, or Data as a Service\n",
      "1+ years of experience in working with Microsoft Excel to perform data analysis and data cleansing\n",
      "Active Secret clearance\n",
      "BS degree in Science, Technology, IT, Data Science, Engineering, Command and Control Research, or Mathematics or 6+ years of experience with operational research or assessment\n",
      ", \n",
      "Experience with leveraging varying data methods to inform qualitative and quantitative analyses, including SAS, SPSS, STATA, Python, and R\n",
      "Knowledge of basic concepts in computer science and data science, including machine learning and artificial intelligence a plus\n",
      "TS/SCI clearance\n",
      "]\"\n",
      "\"[Responsible for collaborating with the business analyst to develop business requirements and translating requirements into a technical solution\n",
      "\n",
      "Analyze and defines tasks, data flows, and dependencies\n",
      "\n",
      "Develop and maintain advanced reporting, analytics, dashboards and other BI solutions using Tableau and/or Alteryx\n",
      "\n",
      "Responsible for identifying and communicating design and scope issues to the stakeholders\n",
      "\n",
      "Conduct design reviews and oversee QA functions for the information delivery applications, including ensuring that system and integration test plans are developed and executed\n",
      "\n",
      "Create other technical deliverable artifacts needed for project implementation\n",
      "\n",
      "Develop and delivers knowledge transfer to the client, \n",
      "\n",
      "2+ years of background developing Data Visualization solutions using Tableau, PowerBI and/or Alteryx\n",
      "\n",
      "Excellent client interaction, problem solving & communication skills\n",
      "\n",
      "Understanding of data modeling techniques\n",
      "\n",
      "Experience working with relational databases (Oracle, SQL Server, Netezza, Teradata) is required\n",
      "\n",
      "Experience using Tableau, PowerBI and/or Alteryx for the creation of dashboards, standard reports and ad-hoc reports\n",
      "\n",
      "Experience working with multiple disparate data sources in Tableau and/or Alteryx\n",
      "\n",
      "Experience with advanced Tableau, PowerBI and Alteryx topics such as complex calculations, table calculations, parameters, geographic mapping, and performance optimization\n",
      "\n",
      "Familiar with Data Visualization best practices\n",
      "\n",
      "Travel to the client on a weekly basis is required.\n",
      "entry --- Google\n",
      "substring --- Are you self-motivated and have a passion for analytics, search and display advertising, and advanced campaign management?, \n",
      "\n",
      "PureCars is looking for an analytics-driven Digital Analytics Analyst to plan, implement, and analyze digital marketing campaigns in Google Analytics / Analytics 360 across our customers.\n",
      "entry --- Google\n",
      "substring --- You will manage and coordinate testing, analysis, and improvement of our Google Analytics implementations and be instrumental in guiding our customers through successful setup and deployment., \n",
      "\n",
      "You know you're the right candidate if you're passionate about implementing industry-leading best practices and design in your tagging and analytics measurement strategies.\n",
      "entry --- Google\n",
      "substring --- You won't accept anything less than helping our dealer customers measure the success of their digital campaigns against their business goals with easy to understand dashboards and reports., \n",
      "\n",
      "Responsibilities Include:, \n",
      "\n",
      "Operate as the subject matter expert on web analytics, tagging, audience and attribution technologies\n",
      "\n",
      "Work with a variety of software platforms, including Google AdWords, Google Analytics, Google Tag Manager, Bing Ads, DSPs, PPC and social media platforms\n",
      "\n",
      "Work with internal clients and stakeholders to understand, design, and implement analytics solutions tailed to our customers\n",
      "\n",
      "Implement best practices to address customer and product analytics and reporting needs via dashboard and custom report templates\n",
      "\n",
      "Track, prioritize, and manage analytics implementation initiatives across multiple teams; act as primary lead for analytics/tracking implementation efforts\n",
      "\n",
      "Partner with your product and development peers to develop processes to improve audience data capture and improve data collection capabilities\n",
      "\n",
      "Manage testing and debugging of analytics/tagging code\n",
      "\n",
      "Assist in reporting and ad-hoc analysis of data with performance teams\n",
      "\n",
      "Assist peer groups in the development of, and reporting on, additional KPIs and metrics illustrating the success of customers' digital campaigns, \n",
      "\n",
      "Qualifications, \n",
      "\n",
      "Required:, \n",
      "\n",
      "BA/BS in Marketing, Business, Computer Science, Finance, Statistics or related field\n",
      "\n",
      "5+ years of professional experience in data analytics using and implementing solutions like Google Analytics / Analytics 360, Firebase, and similar.\n",
      "entry --- Google\n",
      "substring --- Experience implementing customer installations with tag management systems such as Google Tag Manager and similar.\n",
      "entry --- Google\n",
      "substring --- Experience with A/B and multivariate testing\n",
      "\n",
      "Advanced Google Analytics and Google AdWords certified\n",
      "\n",
      "Positive attitude and entrepreneurial spirit, \n",
      "\n",
      "Preferred:, \n",
      "\n",
      "You have familiarity with audience, attribution, and optimization solutions such as Google Audience / Adometry, Google Optimize, Adobe Target, Oracle and Adobe Audience Managers.\n",
      "entry --- Google\n",
      "substring --- You love database and visualization solutions like SQL, Google Data Studio, and Tableau.\n",
      "entry --- Google\n",
      "substring --- Experience with behavioral / click-stream data (Adobe Analytics, Google 360) and extracting processed data from the applications with SQL- extending beyond the front-end of the application a must.\n",
      "entry --- Google\n",
      "substring --- Experience with behavioral / click-stream data (Adobe Analytics, Google 360) and extracting processed data from the applications with SQL- extending beyond the front-end of the application a must.\n",
      "entry --- Google\n",
      "substring --- Knowledge of Google BigQuery is a plus.\n",
      "entry --- Google\n",
      "substring --- *\n",
      "]\"\n",
      "[Establish overall approach to data strategy with given clients, including the ability to see growth potential within existing accountsOversee the design and management of research projectsUse foresight to build and provide value to clientDevelop and maintain all client relationshipsEnsure that all clients have a long-term Measurement Roadmap in place, leveraging best-in-class internal and external toolsEnsure appropriate staffing levels against staff planEffectively articulate the applications of media research tools and resourcesProvide staff with all the necessary tools and training to improve upon existing expertiseEnsure client service teams have fully optimized their media plans and developed rich and well thought out campaign strategiesWrite POVs on industry topicsSupport new business pitches, Data Visualization: Tableau, Omniscope, PowerBIWeb Analytics: Omniture, Google Analytics, WebtrendsAd Servers: DoubleClick, MediaMind, PointRoll, AtlasSyndicated Measurement: comScore, Nielsen, CompeteAd Effectiveness Research: comScore, Millward Brown Digital, Dimestore, Vizu, Research NowMicrosoft Office: Excel, Word, PowerPointFamiliarity with SAS, SPSS, R, Python a plus, Bachelors or advanced degree in Statistics, Economics, Business, Math, or Sciences is preferredMinimum of eight years‚Äô experience preferredExperience managing a mid-to-large size teamStrong analytic and problem solving skillsExcellent written, oral, and presentation communication abilitiesAbility to foster collaborative relationships with other cross-functional teamsAbility to manage and prioritize competing projects and deliverables]\n",
      "\"[\n",
      "Experience with using Tableau to aggregate and analyze data collected from various sources\n",
      "Experience with the Microsoft program suite\n",
      "Ability to synthesize and communicate organizational performance clearly based on information from disparate sources through oral and written formats\n",
      "Ability to communicate information to senior executives for decision making purposes\n",
      "TS/SCI clearance with a polygraph\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with performance management and identifying and defining performance measures to support an organization's mission and goals\n",
      "Knowledge of overall IC agency processes and policies\n",
      "Ability to execute projects and tasks with minimal guidance and supervision\n",
      "Possession of excellent oral and written communication skills\n",
      "Possession of excellent data gathering, analytical, and problem solving skills\n",
      "]\"\n",
      "\n",
      "\"[\n",
      "\n",
      "Partner with e-commerce leadership and cross-functional analytics teams to increase the sophistication of our e-commerce analytics and reporting capabilities and tools\n",
      "\n",
      "Use Google Analytics to measure and understand consumer behavior on site, ranging from pathing and funnel analysis to product interaction; perform deep dive analyses to identify pain points within the online experience and partner with product team to share results and devise technology solutions and enhancements to improve\n",
      "\n",
      "Establish executive dashboards to provide visibility into business performance and track progress on KPIs vs. goals; perform deep dives and build more sophisticated data models as needed to drive business prioritization and decision-making\n",
      "\n",
      "Prepare executive presentations, including e-commerce reporting, comprehensive business analyses, storylines to tie key strategic updates and action plans to financials & forecasts, and recommendations to senior management and the Board\n",
      "\n",
      "Serve as a thought leader and partner for e-commerce merchandising and product teams\n",
      "\n",
      "Manage and grow team of e-commerce data analysts, \n",
      "\n",
      "Develop a test and learn methodology to optimize our product pricing to drive optimal product category mix, maximize sell-through and profitability, and deliver the best possible value to our customers\n",
      "\n",
      "Partner with Product, Engineering, and internal analytics teams to devise plan for site personalization and implement a test-and-learn approach; seek and manage external consultants and related technology partners as needed to deliver on our business goals\n",
      "\n",
      "Evaluate current processes & tools; identify opportunities to drive efficiencies and deliver stronger outcomes for the business and manage related cross-functional implementation plans\n",
      "\n",
      "Improve and help mature process optimization between e-commerce and internal client-facing teams, including Sales and Customer Success; develop synergies between departments surrounding our e-commerce offering, ensuring efficiencies in the processes related to selling and managing accounts\n",
      "\n",
      "Serve as an e-commerce SME for clients, facilitating ongoing client business reviews, reporting, and related e-commerce analytics\n",
      "\n",
      "Manage and build team to support business optimization and client-facing initiatives, 10+ years of experience in analytical roles with 5+ years in a business analytics, strategy and/or optimization-focused role in a technology environment preferred\n",
      "\n",
      "Entrepreneurial leader ‚Äì ability to develop and lead strategy while getting down in the weeds with the team to drive fast and effective execution with limited resources\n",
      "\n",
      "Proven track record of taking ownership and driving results in an unstructured environment\n",
      "\n",
      "Collaborator who thrives on teamwork and has a demonstrated ability to accomplish goals by working cross-functionally; an evangelist who can get stakeholders on board with a plan and leverage cross-functional resources to get things done\n",
      "\n",
      "Player/Coach mentality and strong management skills; Experience recruiting and managing a high-performing team\n",
      "\n",
      "Desire to make an impact on business decisions with data; possess a balance of strong quantitative and analytical skills with a passion in business and leadership\n",
      "\n",
      "Appreciate the power of a data-driven environment and serve as a data evangelist to help grow and build a highly analytical culture around our e-commerce business and evolving needs\n",
      "\n",
      "Resourceful and creative problem solver ‚Äì proven ability to tackle complex challenges with limited resources\n",
      "\n",
      "Expert with Excel and SQL\n",
      "\n",
      "BA/BS with strong academic record, preferably in Economics, Mathematics, Statistics, or other quantitative discipline preferred\n",
      "\n",
      "MBA from a top tier school or similar degree desired]\"\n",
      "\"[Job Description\n",
      "\n",
      ", Major Job Responsibilities:\n",
      "\n",
      ", Works with internal business stakeholders and senior company management to define information needs, develop business cases and business intelligence reporting priorities\n",
      "\n",
      "Develops and implements business intelligence solutions and plans, assesses cost and ensures the plan supports both strategic and near term needs\n",
      "\n",
      "Proactively identifies future technology trends, challenges and impacts on the company's strategic agenda\n",
      "\n",
      "Creates and communicates clear and compelling vision and strategy and communicates vision to staff and business stakeholders\n",
      "\n",
      "Evaluates and recommends new products, maintain knowledge of emerging technologies\n",
      "\n",
      "Develops annual budgets, capital plans and system development plans and monitors performance against plans\n",
      "\n",
      "Responsible for supervising external consultants as needed\n",
      "\n",
      "Identifies, builds, and maintains enterprise analytics and reporting assets, deliverables and technology solutions\n",
      "\n",
      "Interfaces with all business units and executive leadership to ensure access to business metrics in an easy to consume and highly visual fashion\n",
      "\n",
      "Builds web based dashboards to report on key performance indicators\n",
      "\n",
      "Builds web based self-service modules to allow staff to generate enterprise reports in an ad hoc fashion\n",
      "\n",
      "Regularly ensures that enterprise reports are accurate, rich in actionable content, and useful\n",
      "\n",
      "Ensures that uniform enterprise-wide design standards, style and conventions are maintained\n",
      "\n",
      "Maintains awareness of and participates in data quality assurance, governance, curation, meta-tagging and definition efforts\n",
      "\n",
      "Training, mentoring and knowledge transfer with team members\n",
      "\n",
      ", Works with internal business stakeholders and senior company management to define information needs, develop business cases and business intelligence reporting priorities\n",
      "\n",
      ", Develops and implements business intelligence solutions and plans, assesses cost and ensures the plan supports both strategic and near term needs\n",
      "\n",
      ", Proactively identifies future technology trends, challenges and impacts on the company's strategic agenda\n",
      "\n",
      ", Creates and communicates clear and compelling vision and strategy and communicates vision to staff and business stakeholders\n",
      "\n",
      ", Evaluates and recommends new products, maintain knowledge of emerging technologies\n",
      "\n",
      ", Develops annual budgets, capital plans and system development plans and monitors performance against plans\n",
      "\n",
      ", Responsible for supervising external consultants as needed\n",
      "\n",
      ", Identifies, builds, and maintains enterprise analytics and reporting assets, deliverables and technology solutions\n",
      "\n",
      ", Interfaces with all business units and executive leadership to ensure access to business metrics in an easy to consume and highly visual fashion\n",
      "\n",
      ", Builds web based dashboards to report on key performance indicators\n",
      "\n",
      ", Builds web based self-service modules to allow staff to generate enterprise reports in an ad hoc fashion\n",
      "\n",
      ", Regularly ensures that enterprise reports are accurate, rich in actionable content, and useful\n",
      "\n",
      ", Ensures that uniform enterprise-wide design standards, style and conventions are maintained\n",
      "\n",
      ", Maintains awareness of and participates in data quality assurance, governance, curation, meta-tagging and definition efforts\n",
      "\n",
      ", Training, mentoring and knowledge transfer with team members\n",
      "\n",
      ", Supervisory Responsibilities:\n",
      "\n",
      ", Direct management responsibilities in accordance with the ministry‚Äôs policies and applicable laws, including interviewing, hiring, training, planning, assigning and directing work, appraising performance, rewarding and disciplining staff, addressing complaints, and resolving problems\n",
      "\n",
      ", Member Responsibilities: The following responsibilities apply to any employee who is also a member of the religious organization:\n",
      "\n",
      ", Partnership Development: Build and retain a team of prayer and financial partners that will sustain them during their entire Wycliffe ministry according to the Wycliffe Partnership Development policy\n",
      "\n",
      "Organizational Representative: Present the global ministry of Wycliffe and encourage interested individuals and churches to participate in this work\n",
      "\n",
      "Maintain an exemplary standard of ethics and conduct that reflects biblical principles\n",
      "\n",
      ", Partnership Development: Build and retain a team of prayer and financial partners that will sustain them during their entire Wycliffe ministry according to the Wycliffe Partnership Development policy\n",
      "\n",
      ", Organizational Representative: Present the global ministry of Wycliffe and encourage interested individuals and churches to participate in this work\n",
      "\n",
      ", Maintain an exemplary standard of ethics and conduct that reflects biblical principles\n",
      "\n",
      ", Minimum Skill Sets (KSAs):\n",
      "\n",
      " , Servant‚Äôs-heart attitude towards leadership and team relationships\n",
      "\n",
      "Excellent strategic vision and a global, enterprise mindset\n",
      "\n",
      "Exceptional communication, leadership, and people management skills\n",
      "\n",
      "Good judgment with strong problem-solving and decision-making skills\n",
      "\n",
      "Exceptional project management skills, including the ability to effectively utilize resources and manage multiple sub activities in a cross-functional environment\n",
      "\n",
      "Exceptional technical acumen with current and relevant knowledge of BI practices and technologies\n",
      "\n",
      "Good understanding of corporate policies, practices, and organizations\n",
      "\n",
      "Ability to forge strong partnerships with vendors, business partners and internal customers\n",
      "\n",
      "Ability to meet deadlines and produce quality results under pressure\n",
      "\n",
      "High energy self-starter\n",
      "\n",
      "Ability to interact with all levels of management, c-suite executives\n",
      "\n",
      "Excellent interpersonal skills that fosters a positive and collaborative work environment\n",
      "\n",
      "Proficient in business intelligence tools, developing and delivering scorecards, dashboards, trend data in partnership with the BI and Enterprise Architects\n",
      "\n",
      "Strong analytical and problem-solving skills\n",
      "\n",
      "Familiarity with database design concepts including OLAP, OLTP, ESB, system integration and Big-Data\n",
      "\n",
      "Familiarity with n-tier architecture, performance tuning, and application security\n",
      "\n",
      "Spiritual Bona Fide Occupational Qualification (BFOQ): Demonstrates desire and ability to support corporate Biblical and religious goals and participate in regular work related spiritual activities without mental reservation\n",
      ", Servant‚Äôs-heart attitude towards leadership and team relationships\n",
      "\n",
      ", Excellent strategic vision and a global, enterprise mindset\n",
      "\n",
      ", Exceptional communication, leadership, and people management skills\n",
      "\n",
      ", Good judgment with strong problem-solving and decision-making skills\n",
      "\n",
      ", Exceptional project management skills, including the ability to effectively utilize resources and manage multiple sub activities in a cross-functional environment\n",
      "\n",
      ", Exceptional technical acumen with current and relevant knowledge of BI practices and technologies\n",
      "\n",
      ", Good understanding of corporate policies, practices, and organizations\n",
      "\n",
      ", Ability to forge strong partnerships with vendors, business partners and internal customers\n",
      "\n",
      ", Ability to meet deadlines and produce quality results under pressure\n",
      "\n",
      ", High energy self-starter\n",
      "\n",
      ", Ability to interact with all levels of management, c-suite executives\n",
      "\n",
      ", Excellent interpersonal skills that fosters a positive and collaborative work environment\n",
      "\n",
      ", Proficient in business intelligence tools, developing and delivering scorecards, dashboards, trend data in partnership with the BI and Enterprise Architects\n",
      "\n",
      ", Strong analytical and problem-solving skills\n",
      "\n",
      ", Familiarity with database design concepts including OLAP, OLTP, ESB, system integration and Big-Data\n",
      "\n",
      ", Familiarity with n-tier architecture, performance tuning, and application security\n",
      "\n",
      ", Spiritual Bona Fide Occupational Qualification (BFOQ): Demonstrates desire and ability to support corporate Biblical and religious goals and participate in regular work related spiritual activities without mental reservation\n",
      ", Education & Experience:\n",
      "\n",
      ", Undergraduate degree, or equivalent experience in business analysis, new business development, business intelligence, data analytics and reporting\n",
      "\n",
      "Three years experience in information technology, information systems, data management, and/or business management\n",
      "\n",
      "Background in designing and implementing leading Business Intelligence packages such as MSBI, MicroStrategy, Sisense, Pentaho, Tableau, etc.\n",
      "entry --- Google\n",
      "substring --- Apply now., \n",
      "\n",
      "EOE/M/F/Veteran/Disability]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA, \n",
      "\n",
      "Whether you're on a consumer product (like Gmail, Search, Maps, Chrome, Android) or a business product (Google Ads, AdSense, Google Marketing Platform, Analytics), you take part in a complete marketing experience as you lead every facet of the product's journey.\n",
      "entry --- Google\n",
      "substring --- In this role, you'll be involved with product marketing strategy from beginning to end., \n",
      "\n",
      "Google has been at the forefront of data analytics and AI innovations and BigQuery is one of the most innovative and disruptive product offerings from Google in the data management space.\n",
      "entry --- Google\n",
      "substring --- In this role, you‚Äôll be responsible for driving product marketing for Google BigQuery and other data analytics solutions.\n",
      "entry --- Google\n",
      "substring --- Your mission, should you choose to accept it, is to make sure the world understands the value of BigQuery and Google Cloud data analytics solutions.\n",
      "entry --- Google\n",
      "substring --- , Success in this role will require the development of strong working relationships and interactions with customers, senior leaders, engineering teams, product management and other marketing groups across Google., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Design a Business Intelligence and Analytics strategy to enable tracking of business goals and reporting on business performance at scale, \n",
      "\n",
      "Build relationships with cross-functional stakeholders globally, gather requirements and deliver reporting/analytics solutions to meet those requirements, \n",
      "\n",
      "Develop and lead a team of high performing Business Analysts, \n",
      "\n",
      "Drive smart, informed decision-making and deliver on implementation of a world class BI function for Global Security, with strong synergies across Facebook, \n",
      "\n",
      "Collaborate on conceptualization and development of centralized tools (including dashboards) that the Global Security Leadership and teams can use to extract data/insights in an automated manner, \n",
      "\n",
      "Apply deep understanding of data flows and data definitions to creatively address complex issues, \n",
      "\n",
      "Understand Global Security/Physical Security Industry trends, and use these to inform analytics approaches, \n",
      "\n",
      "Apply your expertise in business analysis, data visualization and data-mining to tell the story behind numbers and derive actionable insights for Global Security leadership, \n",
      "\n",
      "Identify and analyze the most important metrics across program areas, \n",
      "\n",
      "Be able to conduct predictive analysis and be able to articulate implications for the business, \n",
      "\n",
      "Deliver presentations that are succinct and crisp, with a balance of high-level insights for executives, and detailed enough view for core teams, \n",
      "\n",
      "Improve reporting efficiency and standardization, \n",
      "\n",
      "Bachelor‚Äôs degree, \n",
      "\n",
      "8+ years of experience in Business Intelligence and/or Analytics, with experience of taking on roles with increasing responsibility, \n",
      "\n",
      "5+ years of Management experience and managing team size of 5+ analysts, report writers, etc., \n",
      "\n",
      "Experience in startup(s) as well as enterprises who have created solutions at scale, \n",
      "\n",
      "Knowledge of BI best practices/methodologies, \n",
      "\n",
      "Experience with relational structures, SQL, data warehouse and reporting techniques, \n",
      "\n",
      "Experience with data visualization tools, \n",
      "\n",
      "Experience leading programs from definition through interpretation and execution, \n",
      "\n",
      "Analytical experience solving problems using data to provide practical business insights, \n",
      "\n",
      "Communication experience including presentation experience, \n",
      "\n",
      "Master's Degree in an analytical field or business]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA, \n",
      "\n",
      "Whether you're on a consumer product (like Gmail, Search, Maps, Chrome, Android) or a business product (Google Ads, AdSense, Google Marketing Platform, Analytics), you take part in a complete marketing experience as you lead every facet of the product's journey.\n",
      "entry --- Google\n",
      "substring --- In this role, you'll be involved with product marketing strategy from beginning to end., \n",
      "\n",
      "Google has been at the forefront of data analytics and AI innovations and BigQuery is one of the most innovative and disruptive product offerings from Google in the data management space.\n",
      "entry --- Google\n",
      "substring --- In this role, you‚Äôll be responsible for driving product marketing for Google BigQuery and other data analytics solutions.\n",
      "entry --- Google\n",
      "substring --- Your mission, should you choose to accept it, is to make sure the world understands the value of BigQuery and Google Cloud data analytics solutions.\n",
      "entry --- Google\n",
      "substring --- , Success in this role will require the development of strong working relationships and interactions with customers, senior leaders, engineering teams, product management and other marketing groups across Google., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- \"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA, \n",
      "\n",
      "Whether you're on a consumer product (like Gmail, Search, Maps, Chrome, Android) or a business product (Google Ads, AdSense, Google Marketing Platform, Analytics), you take part in a complete marketing experience as you lead every facet of the product's journey.\n",
      "entry --- Google\n",
      "substring --- In this role, you'll be involved with product marketing strategy from beginning to end., \n",
      "\n",
      "Google has been at the forefront of data analytics and AI innovations and BigQuery is one of the most innovative and disruptive product offerings from Google in the data management space.\n",
      "entry --- Google\n",
      "substring --- In this role, you‚Äôll be responsible for driving product marketing for Google BigQuery and other data analytics solutions.\n",
      "entry --- Google\n",
      "substring --- Your mission, should you choose to accept it, is to make sure the world understands the value of BigQuery and Google Cloud data analytics solutions.\n",
      "entry --- Google\n",
      "substring --- , Success in this role will require the development of strong working relationships and interactions with customers, senior leaders, engineering teams, product management and other marketing groups across Google., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- Advanced Degree preferred but not required., 10+ years of professional level experience in a related role\n",
      "Relevant professional experience with an emphasis on Retail or Digital Commerce Business\n",
      "\n",
      "Experience leading a team and driving results, Demonstrated track record leading high performing and engaged teams\n",
      "\n",
      "Passion for business analytics and working with large amounts of data with demonstrated ability to use data to influence decision making\n",
      "Excellent communication and presentation skills to senior leadership\n",
      "Strong project management capabilities to manage multiple project streams with a focus on prioritization, resourcing and timely business impact\n",
      "Proven experience building positive working relationships and working successfully in cross-functional teams, including demonstrated success in managing and influencing without direct authority\n",
      "A strong understanding of advanced analytic techniques, particularly related to measuring consumer & business outcomes in a digital commerce setting\n",
      "Fluency in SQL\n",
      "Experience with clickstream tools including Adobe Analytics / Omniture, Google Analytics or Optimizely\n",
      "Experience with Business Intelligence, Analytics and Data Visualization tools, e.g.\n",
      "entry --- Google\n",
      "substring --- You will bring solid experience in implementing web analytics tools (Google Analytics/Adobe Analytics), the ability to leverage consumer data into insights, and a collaborative work ethic to the team!\n",
      "entry --- Google\n",
      "substring --- , In particular, you can expect to:, Implement your own digital analytics/web analytics tool kit and definite processesOrganize data trends and look at ways to unlock new consumer data sourcesBuild out a team of digital analysts and BI analysts, while working collaboratively with the existing marketing team, as well as Product, Tech and OperationsAnalyze data and deliver insight on site and media campaign performance, solving problems around pixel trackingPerform A/B testing and multivariate testing, \n",
      "\n",
      "Your Skills and Experience, Bachelor's Degree requiredWorking experience in a digital analytics or web analytics leadership positionWorking experience in analyzing data from digital platforms (Google Analytics, Adobe Analytics, DMPs, attribution tools, DCM)Experience in implementing web analytics toolsStrong client management and strategy delivery skillsDeep knowledge of cross-channel digital marketing campaignsExperience working collaboratively with marketing operations and technology teamsAbility to pitch findings and ideas to stakeholdersWorking exposure to R or Python preferred, \n",
      "\n",
      "SALARY AND BENEFITS, \n",
      "\n",
      "The successful candidate will secure a salary of $180,000 - $200,000 and benefits depending on experience]\"\n",
      "\"[VP Advanced Analytics\n",
      "Global Consultancy\n",
      "New York City\n",
      "$200,000 - $250,000 + benefits, \n",
      "\n",
      "Are you a \"\"purple unicorn\"\" with an entrepreneurial mindset who possesses not only a technical background in advanced analytics with the ability to predict customer behaviors across multiple channels and platforms, but also have a solid background in media analytics?\n",
      "entry --- Google\n",
      "substring --- Working on an advanced analytics platform that combines wider market, artificial and human intelligence to highlight the value to both new and existing clients of how it can make their marketing targeting more efficient and effective, increasing ROI across all communication channels\n",
      "\n",
      "Using your advanced analytics backgrounds in R/SAS, Python, SQL, Adobe Analytics and knowledge of DMPs/DSPs to aggregate and integrate multi-channel data and predict customer behaviors based on their engagement with advertising/marketing and purchasing trends\n",
      "\n",
      "Consult with the client as well as with wider stakeholders and teams internally to maximize the product, develop it further, and meet their data goals, \n",
      "\n",
      "YOUR SKILLS AND EXPERIENCE:, \n",
      "\n",
      "In order to be successful in this role you must have:, \n",
      "\n",
      "A degree in a numerate discipline such as Math, Stats, Economics or similar\n",
      "\n",
      "Proven capabilities in building and managing advanced analytics and data science teams who build predictive models including audience modelling and machine learning\n",
      "\n",
      "Strong quants background in SAS/R, SQL/Python and knowledge of web analytics tools including Adobe Analytics, Google Analytics, DMPs/DSPs\n",
      "\n",
      "Ability to engage with a wide variety of stakeholders at different levels, delivering insights and recommendations, \n",
      "\n",
      "BENEFITS:, \n",
      "\n",
      "As a VP Advanced Analytics, you can expect to earn up to $250,000 + benefits (depending on experience)]\"\n",
      "\"[Senior Technical Product Manager, Analytics, \n",
      "\n",
      "Why Zynga, \n",
      "\n",
      "Our mission at Zynga is to connect the world through games by building games around core social experiences to deliver deep player engagement, organic acquisition and long term retention.\n",
      "entry --- Google\n",
      "substring --- While we invest in our live games, we are also proud to be one of the first gaming companies innovating on emerging platforms such as Facebook Messenger and Google Play Instant., \n",
      "\n",
      "Come join us, thrive, take risks and dream big to shape the future of fastest growing gaming platform ‚Äì mobile., \n",
      "\n",
      "The Role, \n",
      "\n",
      "The Central Technology team at Zynga provides products and services that are foundational for building games across mobile and emerging platforms.\n",
      "entry --- Google\n",
      "substring --- You have a passion for Data products from cloud providers like Amazon Web Services (AWS), Google Cloud or Azure you might want to leverage to make a difference to our Analytics stack.\n",
      "entry --- Google\n",
      "substring --- Site Engagement/Site Experience Analytics including tagging to help drive product management\n",
      "\n",
      "Knowledge of Social Listening/Analytics - especially across YouTube\n",
      "\n",
      "Excellent knowledge of web analytics tools including Google Analytics and/or Adobe Analytics\n",
      "\n",
      "Advanced proficiency of Excel, along with other MS office products (Word, Powerpoint, Outlook).\n",
      "entry --- Google\n",
      "substring --- Proficient in querying, segmenting and modeling data from large datasets located in Google BigQuery and CRM databases.\n",
      "entry --- Google\n",
      "substring --- Site Engagement/Site Experience Analytics including tagging to help drive product management\n",
      "\n",
      "Knowledge of Social Listening/Analytics - especially across YouTube\n",
      "\n",
      "Excellent knowledge of web analytics tools including Google Analytics and/or Adobe Analytics\n",
      "\n",
      "Advanced proficiency of Excel, along with other MS office products (Word, Powerpoint, Outlook).\n",
      "entry --- Google\n",
      "substring --- Proficient in querying, segmenting and modeling data from large datasets located in Google BigQuery and CRM databases.\n",
      "entry --- Google\n",
      "substring --- Associate level3+ year(s) of managing parts of the client engagement, including: leading conversations to understand business context, building relationships with the client, identifying key business issues, structuring analysis, and managing the development and delivery of recommendations3+ year(s) of people management experienceExperience participating in the firm's recruiting activities, \n",
      "\n",
      "Skill Set, \n",
      "\n",
      "Required, Ability to structure analysis to solve complex business problemsAbility to package findings/recommendations from analysis in a coherent, impactful wayStrong presentation and communications skillsProficiency in analysis and business modeling using ExcelBasic understanding of statistics and A/B testing, \n",
      "\n",
      "Not required but nice to have, Experience working on engagements focused on online businessesExperience working on engagements focused on subscription businessesBasic to mid-level proficiency in data extraction using SQLWeb analytics tools like Google Analytics, OmniturePredictive modeling, regression analysis using R or Python]\"\n",
      "\"[Bachelor‚Äôs degree\n",
      "\n",
      "Minimum of 5 years of relevant Natural Resources industry experience\n",
      "\n",
      "Minimum of 5 years working in advanced analytics and business transformation\n",
      "\n",
      "Minimum of 5 years in strategy or management consulting\n",
      "\n",
      "Meet travel requirements, up to 80%, \n",
      "Bachelor‚Äôs degree in quantitative discipline (Engineering, Economics, Statistics, Operations Research, Computer Science)\n",
      "\n",
      "Masters or MBA\n",
      "\n",
      "PhD in Analytics, Statistic or other quantitative disciplines\n",
      "\n",
      "Exceptional presentation skills ‚Äì ability to convey technology and business value propositions\n",
      "\n",
      "Ability to understand and apply statistical methods and outputs to create client value in a business context\n",
      "\n",
      "Experience with evolving approaches and technologies such as Big Data, Artificial Intelligence, Machine Learning, Cognitive Systems, and Robotics\n",
      "\n",
      "Data management skills\n",
      "\n",
      "Data visualization skills\n",
      "\n",
      "Value based constructs, Proven ability to build, manage and foster a team-oriented environment\n",
      "\n",
      "Proven ability to work creatively and analytically in a problem-solving environment\n",
      "\n",
      "Desire to work in an information systems environment\n",
      "\n",
      "Excellent communication (written and oral) and interpersonal skills\n",
      "\n",
      "Excellent leadership and management skills, \n",
      "Your entrepreneurial spirit and vision will be rewarded, and your success will fuel opportunities for career advancement.\n",
      "entry --- Google\n",
      "substring --- Process Management - Excellent at figuring out the processes to get things done, understands efficient work flows\n",
      "Learning on the Fly - Learns quickly when facing new problems, relentless learner, open to change, improves, enjoys challenges and finding solutions\n",
      ", \n",
      "1-3 years of professional software development experience\n",
      "1+ years working with big data sets\n",
      "Experience with a host of tools including: Google Analytics, Adobe Analytics, Google Tag Manager and tag auditing tools such as ObservePoint.\n",
      "entry --- Google\n",
      "substring --- Analyzes code to find causes of errors and revise programs as needed., Required Qualifications, \n",
      "\n",
      "4+ years of Extensive experience with designing, developing, and ongoing support of a data warehouse environments\n",
      "\n",
      "2+ years hands on experience with ETL tools like Informatica\n",
      "\n",
      "4+ years of experience in SQL\n",
      "\n",
      "2 years+ experience working with the Hadoop ecosystem and tools\n",
      "\n",
      "Understanding and experience with cloud platforms and technologies like Azure, AWS, Google Cloud is preferred\n",
      "\n",
      "Experience with Teradata, a major plus\n",
      "\n",
      "Excellent scripting and programming skills using python or any other programming language\n",
      "\n",
      "Demonstrated ability to understand data architectures and systems\n",
      "\n",
      "Strong communication and customer relationship skills.\n",
      "entry --- Google\n",
      "substring --- We leverage the Google Cloud Platform (including Google Dataflow, Bigtable, and BigQuery) for processing data as well as build our own analysis tools.\n",
      "entry --- Google\n",
      "substring --- The types of things you‚Äôll do:\n",
      ", Work with Apache Beam, Airflow, Google Dataflow, BigTable, and BigQuery to build the next generation of the Censys data processing pipeline\n",
      "\n",
      "Design automated solutions for building, testing, monitoring, and deploying ETL pipelines in a continuous integration environment\n",
      "\n",
      "Work with application engineers to develop internal APIs and data solutions to power Censys product offerings\n",
      "\n",
      "Coordinate with backend engineering team to analyze data in order to improve the quality and consistency of our data\n",
      ", \n",
      "Desired Qualifications\n",
      ", Bachelor's degree in Computer Science or related field, or equivalent experience\n",
      "\n",
      "3+ years of full-time, industry experience\n",
      "\n",
      "Deep understanding of relational as well as NoSQL data stores (e.g., Snowflake, Redshift, BigTable, Spark) and approaches\n",
      "\n",
      "Hands-on experience building data processing pipelines (e.g, in Storm, Beam)\n",
      "\n",
      "Proficiency with object-oriented and/or functional languages (e.g.\n",
      "entry --- Google\n",
      "substring --- Process Management - Excellent at figuring out the processes to get things done, understands efficient work flows\n",
      "Learning on the Fly - Learns quickly when facing new problems, relentless learner, open to change, improves, enjoys challenges and finding solutions\n",
      ", \n",
      "1-3 years of professional software development experience\n",
      "1+ years working with big data sets\n",
      "Experience with a host of tools including: Google Analytics, Adobe Analytics, Google Tag Manager and tag auditing tools such as ObservePoint.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- #CJ]\"\n",
      "\"[The Google Cloud team helps companies, schools, and government seamlessly make the switch to Google products and supports them along the way.\n",
      "entry --- Google\n",
      "substring --- Your relationships with customers are crucial in helping Google grow its Google Cloud business and in bringing our product portfolio into companies around the world., Our Analytics and Data Science team is responsible for the data needs of the Google Suite support services, a large global support team for customers around the globe.\n",
      "entry --- Google\n",
      "substring --- , In this role, you will use your knowledge of data processing, technical systems, and project management to enhance our existing data and machine learning platforms for internal and customer facing use cases., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- Familiarity with Google Cloud Platform (e.g.\n",
      "entry --- Google\n",
      "substring --- Experience writing and executing complex SQL queries\n",
      "\n",
      "Experience managing and optimizing SQL databases\n",
      "\n",
      "Experience with development in one or more of the following Python, R, Scala, SQL\n",
      "\n",
      "Experience with data processing frameworks and data warehouses such as Hadoop, Spark, Redshift\n",
      "\n",
      "\n",
      "Bonus points for:\n",
      "\n",
      "Experience working with healthcare data\n",
      "\n",
      "Experience with Looker, Tableau and other BI tools\n",
      "\n",
      "Experience with DataBricks analysis platform\n",
      "\n",
      "Experience with building and operating data pipelines\n",
      "\n",
      "Experience with machine learning]\"\n",
      "\"[Providing actionable reporting on how our users are engaging with our productsBringing data thinking to our projects by attaching metrics to our processesMaintaining, improving, and scaling our internal processes and learnings around data thinking, collecting and, reporting, Measurement Strategy: Define problems and solutions and attach metrics (KPIs) or other views of data that reflect how those problems can be being solvedSpecifications: Designing the specification for event tags (Segment.io, Mixpanel, Google Analytics) fired from the front end/back end, or queries that can enable those metrics or views of data to be calculatedReporting: Design and build a dashboard that displays those metrics and continues to iterate through ad-hoc reporting and meetings with stakeholders, Consume and report on external data sets, primarily logs (i.e., Sumo Logic)Consult and build business intelligence dashboards that are part of our products shipped to customers (Birst or Infor Business Intelligence), and work with the team to build a corporate-wide design system for these dashboardsAssist in non-quant researchContribute to storytelling, UX and product strategy, \n",
      "\n",
      "We are looking for an engineer or data wizard first, a data analyst second, and designer as a value-add., Bachelor‚Äôs degree in Engineering or computer scienceAbility to rapidly execute against building data models and dashboards.\n",
      "entry --- Google\n",
      "substring --- (Google Data Studio, Birst, and other tooling)Data analyst with the innate curiosity to uncover interesting/differentiating insights for a projectExcellent communication skillsExcellent attention to detailAbility to manage multiple projects concurrently and prioritize workload to meet deadlinesExperience with/understanding of the requirements for designing enterprise software/mobile applications, Data visualization and storytelling (i.e., Nate Silver, Zach Lowe, Hans Rosling or Kirk Goldsberry)Ability to execute on mixed method projects combining quant and qualThe North Star: Scale our data practice as an independent service to Infor, backed by the power of designExperience running regressions, or using Python to mung, transform and analyze dataSelf-motivated and monitoringEager to contribute, 2-3+ years of related job experience, General office environmentNo special physical demandsSome stress may occur at timesAbility to work across multiple time zones (requires some meetings before/after regular business hours to accommodate), \n",
      "\n",
      "Hook & Loop designs and builds products that scale user experience into the enterprise.\n",
      "entry --- Google\n",
      "substring --- This role collaborates heavily with their matrix partners in JetBlue‚Äôs IT, JetBlue Tech Ventures and external business partners., \n",
      "\n",
      "The data engineer can change priorities and focus to meet business demands, excels when working on complex projects, is motivated to deliver results, and exhibits the JetBlue values of Safety, Caring, Integrity, Passion , and Passion., Design, develop and manage data management products from conception to retirementEnsure that the data engineering team delivers with consistency, high quality and predictabilityCreate and promote a work environment focused on engineering excellence to attract, develop and encourage a culture of technical innovationPartner with product management and marketing teams and help develop the product vision and roadmapCreate the JBTP data infrastructure and analytics environments, understand the data and provide support for key business decisionsParticipate in the DevOps practice as it pertains to data engineeringHelp establish frameworks, design and integration patterns as well as guide the software development performed by business partnersHelp manage a collection of external technology products used to deliver business productsPartner with JetBlue Tech Ventures to identify, monitor, learn, experiment and share information about emerging technology that is relevant to JetBlue Travel Products.Other duties as assigned, Bachelor‚Äôs Degree in Computer Science or related technical field or equivalent practical experience with demonstrated capability to perform job responsibilities through four (4) previous years of combined experience and educationThree (3) years‚Äô experience in an engineering roleGood understanding of software engineering environments and standardsDeep understanding of Internet technologies, protocols and methodologies for delivering web-based productsExperience managing Service Level AgreementsExperience interacting daily with people at different levels within the organization, including developing and maintaining ongoing relationshipsMust pass a ten (10) year background check and pre-employment drug testLegally eligible to work in the country in which the position is located, Experience maintaining a public profile and building relationships throughout the organizationFive (5) years‚Äô experience in technology rolesExperience in writing software in one or more languages such as Java, Python, Go and/or JavaScriptExperience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud Platform., Regular attendance and punctualityPotential need to work flexible hours and be available to respond on short-noticeWell-groomed and able to maintain a professional appearanceWhen working or traveling on JetBlue flights, and if time permits, all capable crewmembers are asked to assist with light cleaning of the aircraftOrganizational fit for the JetBlue culture, that is, exhibit the JetBlue values of Safety, Caring, Integrity, Passion, and Fun, Computer and other office equipment, Generally not required, or up to 10 pounds occasionally, 0 pounds frequently.\n",
      "entry --- Google\n",
      "substring --- Experience with Java (Python a plus)\n",
      "\n",
      "Exposure to cloud based technologies like Google Cloud Platform, AWS.\n",
      "entry --- Google\n",
      "substring --- Upon completing our initial assessments of these tools, you‚Äôll assist with the implementation and deployment of the solutions we collectively decide upon., Extract data from multiple data sources, such as SQL, MongoDB, Google Analytics, and other platform APIs, and load them into a centralized data warehouse to facilitate unified reporting.\n",
      "entry --- Google\n",
      "substring --- Your contribution will be critical to helping Pairwise meet a set of aggressive targets and building a culture where science and engineering can be fun., Minimum of Bachelors degree in Computer Science, Engineering or related fields\n",
      "\n",
      "Minimum of 5+ years of experience (Masters or Doctoral thesis work counts as work experience)\n",
      "\n",
      "Strong track record of building and deploying modern engineering tools in the cloud (AWS, Azure, Google Cloud)\n",
      "\n",
      "Proficiency with MySql, Postgres or noSQL technologies\n",
      "\n",
      "Advanced Knowledge with Python or R and one object-oriented programming language\n",
      "\n",
      "Demonstrated ability to deliver tools in a cross functional environment\n",
      "\n",
      "Experience with building and maintaining APIs\n",
      "\n",
      "Proficiency with data modeling and data architecture]\"\n",
      "\"[\n",
      "You'll work closely with our technology operations and engineering teams to understand business needs and design/maintain scalable data models.\n",
      "entry --- Google\n",
      "substring --- Experience with the Hortonworks sandbox environment]\"\n",
      "\"[Data Engineer, \n",
      "\n",
      "As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.\n",
      "entry --- Google\n",
      "substring --- Mentor others in using analytics tools\n",
      "\n",
      "Evaluate and enhance existing reports and dashboards\n",
      "\n",
      "Define and document business requirements for new metrics and reports\n",
      "\n",
      "Ensure accuracy and integrity of data and reporting applications through detailed analysis, efficient coding, writing clear documentation processes, identifying and resolving problems as they arise\n",
      "\n",
      "Review and write complex SQL queries and develop stored procedures and functions in SQL\n",
      "\n",
      "Perform ongoing monitoring and refinement of reports and BI solutions\n",
      "\n",
      "Ability to work effectively within competing deadlines with minimal guidance\n",
      "\n",
      "Interact professionally and collaborate with a diverse group including executives, managers, and subject matter experts, 4 or more years of quality experience using SQL Server, SSRS, SSAS, Azure, and SSIS\n",
      "\n",
      "Strong knowledge of relational and multi-dimensional database architecture\n",
      "\n",
      "Experience creating and maintaining documentation following standard creation and change control processes\n",
      "\n",
      "Proficient oral and written communication skills\n",
      "\n",
      "Ability to lead a meeting and present to small audiences\n",
      "\n",
      "Experience integrating Power BI into web applications]\"\n",
      "\"[\n",
      "\n",
      "Assist with data collection and optimization of storage approaches\n",
      "\n",
      "Provide support for scalable batch or real-time data processing for discovery and model creation\n",
      "\n",
      "Implement scalable APIs for utilizing analytics results (e.g., utilizing models produced)\n",
      "\n",
      "Collaborate with data scientists and help them evaluate the computation/data requirements for discovery and the deployed solution\n",
      "\n",
      "Design, build, operationalize, and scale some of the largest data pipelines in the world\n",
      "\n",
      "Advise on and manage big data infrastructure\n",
      "\n",
      "Architect and develop data ingestion pipelines\n",
      "\n",
      "Develop proofs of concept with emerging technologies\n",
      "\n",
      "Assist with data preparation, \n",
      "\n",
      "Bachelor's degree in Computer Science or a related technical field\n",
      "\n",
      "3 years of experience as a Software Engineer or closely related position\n",
      "\n",
      "3 years of of experience with the following:\n",
      "\n",
      "Designing, integrating, and optimizing distributed data-processing pipelines\n",
      "\n",
      "Utilizing database technologies, including: SQL and No-SQL (e.g., Hadoop, Splunk, Spark, Samza, MySQL, Postgres, MongoDB, Sqlite, Neo4j, Apache Giraph), within a cloud environment\n",
      "\n",
      "Writing data processing code in Go, Java, Python, Scala, or other high-performance languages\n",
      "\n",
      "Using distributed and fault-tolerant computing and map/reduce processing techniques\n",
      "\n",
      "Utilizing Linux/UNIX systems\n",
      "\n",
      "Systems-level debugging\n",
      "\n",
      "Building REST APIs for analytics services\n",
      "\n",
      "Working with or in support of multiple open source communities\n",
      "\n",
      "Optimizing critical components in applications for efficiency using C or C++\n",
      "\n",
      "Utilizing cloud deployment and virtualization and containerization technologies (e.g, Docker, Ansible, Terraform and Vagrant)\n",
      "\n",
      "1 year of experience with the following:\n",
      "\n",
      "Machine learning libraries, such as Google CloudML, DataFlow, DataLab, TensorFlow, SciKit Learn, Mahout, and MLib\n",
      "\n",
      "Optimizing advanced SQL queries\n",
      "\n",
      "Working in an agile environment with SCRUM and PODS]\"\n",
      "\"[\n",
      "Design, develop, automate, monitor and maintain Extract Transform Load (ETL) data movement applications using our preferred ETL tools and techniques.\n",
      "entry --- Google\n",
      "substring --- Knowledge of machine learning platforms such as Amazon, IBM Watson, Azure, Google Predict, BigML\n",
      "Strong trouble-shooting skills.\n",
      "entry --- Google\n",
      "substring --- Provide expertise in building for scale, including potentially migrating data warehouse operations to a cloud service such as Google Compute Engine, Snowflake, and/or other platforms\n",
      "\n",
      "Advise and train members of the team to maximize overall productivity and effectiveness of the team\n",
      "\n",
      "Identify skills gaps and silos on the team and advocate for resolution\n",
      "\n",
      "Participate in and contribute to scrum meetings i.e.\n",
      "entry --- Google\n",
      "substring --- Experience migrating a SQL Server DW to a cloud provider such as AWS, Google Cloud Services and Snowflake\n",
      "\n",
      "Demonstrated knowledge of Unix/Linux, object-oriented programing, relational database technologies, database performance and tuning, distributed computing tech (Hadoop, spark), RESTful API\n",
      "\n",
      "Proven experience mentoring engineers in DW best practices and development\n",
      "\n",
      "Hands-on proficiency with SQL, SSIS, and ETL jobs, including stored procedures\n",
      "\n",
      "Hands-on proficiency in working with cloud services such as Amazon Web Services, Google Compute Engine, and Snowflake\n",
      "\n",
      "Experience with quality assurance and testing in a relational database environment.\n",
      "entry --- Google\n",
      "substring --- , As a data engineer, you will:\n",
      "\n",
      ", Run and support a production enterprise data platform\n",
      "\n",
      "Design and develop data models\n",
      "\n",
      "Work with languages like Java, Python, Go, Bash, and SQL\n",
      "\n",
      "Build batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google‚Äôs BigQuery, Dataproc, and Pub/Sub\n",
      "\n",
      "Develop processes for automating, testing, and deploying your work\n",
      "\n",
      ", About You\n",
      "\n",
      ", To thrive in this role, you are excited about data and motivated to learn new technologies.\n",
      "entry --- Google\n",
      "substring --- Python or shell scripting)\n",
      "\n",
      "Preferred experience working with either a Map Reduce or an MPP system\n",
      "\n",
      "Preferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure\n",
      "\n",
      "Experience to analyze data to identify deliverables, gaps, and inconsistencies]\"\n",
      "\"[Your consulting projects will include integrating data in a virtual manner for operational and/or informational purposes - Integration of 100+ data sources for a Customer Service Multichannel IT Infrastructure; implementation of Logical Data Warehouses and Virtual Datamarts to enable modern Business Intelligence solutions, Integration Layers for Hadoop-based Data Lakes, and support for Agile Operational Reporting on a diverse Big Data infrastructure are just a few flavours of your future projects.\n",
      "entry --- Google\n",
      "substring --- Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google Cloud Platform ‚Äòbig data‚Äô technologies.\n",
      "entry --- Google\n",
      "substring --- Work with data and analytics experts to strive for greater functionality in our data systems., \n",
      "\n",
      "Knowledge of Meta and Master Data Management\n",
      "\n",
      "Familiar with Google Cloud Platform Service cloud services like: Cloud Sql, BigQuery, DataFlow, DataPrep, AppEngine\n",
      "\n",
      "Knowledge of stream-processing systems: i.e.\n",
      "entry --- Google\n",
      "substring --- Amazon, Cisco, Google, Microsoft, SAP and other leading businesses are all part of the MapR ecosystem.\n",
      "entry --- Google\n",
      "substring --- Experience with at least 2 of the following data ecosystem elements such as Hbase, MongoDB, Cassandra, and/or CouchDB; graph databases such as Neo4j; Hadoop, MapReduce, and/or Spark; AWS, Google Cloud, and/or Azure\n",
      "Minimum of 3 years of fluency in a JVM language such as Java or Scala, or demonstrated mastery of another language\n",
      "Excellent data management and software development practice\n",
      "The ability and desire to coach and learn from other excellent practitioners\n",
      "Exceptional verbal and written communication, interpersonal and problem-solving skills such as required to negotiate scope and resources, manage projects, and synchronize activities with team members, stakeholders, and management, \n",
      "Experience with Platform-as-a-Service software such as Cloud Foundry or Kubernetes; demonstrated experience building cloud native applications\n",
      "Knowledge of data science practices, to better steer our efforts to support them through the infrastructure we create\n",
      "Public contributions to conference presentations, community forums (e.g.\n",
      "entry --- Google\n",
      "substring --- Preferably including DoubleClick, Google Analytics, AdWords and Google Tag-Manager and stream data into environments such as BigQuery\n",
      "\n",
      "Responsible for the management of multiple processes and applications, performance reporting and error checking\n",
      "\n",
      "Responsible for the management of all data created within client applications, the structure of data held and the views of data created\n",
      "\n",
      "Responsible for recommending the correct technologies to be used and in the most cost effective manner\n",
      "\n",
      "Responsible for the design and creation of data led strategies which provide clients with opportunities to leverage their data for greater insight or performance\n",
      "\n",
      "Provide thought leadership with regards to best practice and use of the google cloud platform, \n",
      "\n",
      "BS Degree\n",
      "\n",
      "Data Engineering/ BI Development/ Data Warehousing experience.\n",
      "entry --- Google\n",
      "substring --- Knowledge of server-less infrastructure beneficial\n",
      "\n",
      "Ability to scope a project based on a technical brief and work with the DevOps and QA teams to provide a detailed project plan including:, \n",
      "\n",
      "Data Flow Diagrams for process flow\n",
      "\n",
      "Database Schemas & Normalisation\n",
      "\n",
      "Recommended software / plugins / architecture\n",
      "\n",
      "Scalable environment architecture suggestions\n",
      "\n",
      "Hosting, storage, load balancing and caching suggestions\n",
      "\n",
      "Performance considerations\n",
      "\n",
      "Security considerations\n",
      "\n",
      "Assumptions & Exclusions\n",
      "\n",
      "A complete and accurate estimate for the project, \n",
      "\n",
      "Ability to assess new business and respond with a full list of targeted questions to ensure accurate estimates are created\n",
      "\n",
      "Ability to research solutions to technical problems\n",
      "\n",
      "Experience scheduling/automating scripts\n",
      "\n",
      "Experience with streaming data beneficial\n",
      "\n",
      "Experience on Linux command line and Bash scripting\n",
      "\n",
      "Experience with Git/GitHub\n",
      "\n",
      "Experience with Amazon/Google Cloud services.\n",
      "entry --- Google\n",
      "substring --- Experience with Dataflow, Google PubSub or other queuing software beneficial\n",
      "\n",
      "Good experience of parsing data formats such as XML/JSON and using 3rd party API‚Äôs\n",
      "\n",
      "Experience with Curl / similar beneficial\n",
      "\n",
      "Solid Python programming skills.\n",
      "entry --- Google\n",
      "substring --- Preferably including DoubleClick, Google Analytics, AdWords and Google Tag-Manager and stream data into environments such as BigQuery\n",
      "\n",
      "Responsible for the management of multiple processes and applications, performance reporting and error checking\n",
      "\n",
      "Responsible for the management of all data created within client applications, the structure of data held and the views of data created\n",
      "\n",
      "Responsible for recommending the correct technologies to be used and in the most cost effective manner\n",
      "\n",
      "Responsible for the design and creation of data led strategies which provide clients with opportunities to leverage their data for greater insight or performance\n",
      "\n",
      "Provide thought leadership with regards to best practice and use of the google cloud platform, BS Degree\n",
      "\n",
      "Data Engineering/ BI Development/ Data Warehousing experience.\n",
      "entry --- Google\n",
      "substring --- Knowledge of server-less infrastructure beneficial\n",
      "\n",
      "Ability to scope a project based on a technical brief and work with the DevOps and QA teams to provide a detailed project plan including:, \n",
      "\n",
      "Data Flow Diagrams for process flow\n",
      "\n",
      "Database Schemas & Normalisation\n",
      "\n",
      "Recommended software / plugins / architecture\n",
      "\n",
      "Scalable environment architecture suggestions\n",
      "\n",
      "Hosting, storage, load balancing and caching suggestions\n",
      "\n",
      "Performance considerations\n",
      "\n",
      "Security considerations\n",
      "\n",
      "Assumptions & Exclusions\n",
      "\n",
      "A complete and accurate estimate for the project, \n",
      "\n",
      "Ability to assess new business and respond with a full list of targeted questions to ensure accurate estimates are created\n",
      "\n",
      "Ability to research solutions to technical problems\n",
      "\n",
      "Experience scheduling/automating scripts\n",
      "\n",
      "Experience with streaming data beneficial\n",
      "\n",
      "Experience on Linux command line and Bash scripting\n",
      "\n",
      "Experience with Git/GitHub\n",
      "\n",
      "Experience with Amazon/Google Cloud services.\n",
      "entry --- Google\n",
      "substring --- Experience with Dataflow, Google PubSub or other queuing software beneficial\n",
      "\n",
      "Good experience of parsing data formats such as XML/JSON and using 3rd party API‚Äôs\n",
      "\n",
      "Experience with Curl / similar beneficial\n",
      "\n",
      "Solid Python programming skills.\n",
      "entry --- Google\n",
      "substring --- Python or shell scripting)\n",
      "\n",
      "Preferred experience working with either a Map Reduce or an MPP system\n",
      "\n",
      "Preferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure\n",
      "\n",
      "Experience to analyze data to identify deliverables, gaps, and inconsistencies]\"\n",
      "\"[\n",
      "Deliver end-to-end analytics projects, including data ingest, data transformation, data science, and data visualization\n",
      "Design and deploy databases and data pipelines to support analytics projects\n",
      "Clearly document datasets, solutions, findings and recommendations to be shared internally & externally\n",
      "Learn and apply tools and technologies proficiently, including:\n",
      "Languages: SQL (standard and DB-specific), Python, R, Spark/Scala, Bash\n",
      "Frameworks: Hadoop, Spark, AWS\n",
      "Tools/Products: Data Science Studio, Alteryx, Jupyter, RStudio, Tableau, PowerBI\n",
      "Build compelling visualizations and dashboards that address the analytic needs of the end-user/customer\n",
      "Performance optimization for queries and dashboards\n",
      "Develop and deliver clear, compelling briefings to internal and external stakeholders on findings, recommendations, and solutions\n",
      "Analyze client data & systems to determine whether requirements can be met\n",
      "Test and validate data pipelines, transformations, datasets, reports, and dashboards built by team\n",
      "Develop and communicate solutions architectures and present solutions to both business and technical stakeholders\n",
      "Provide end user support to other data engineers and analysts\n",
      ", \n",
      "Expertise in SQL and Python.\n",
      "entry --- Google\n",
      "substring --- You have 3 years‚Äô experience and working knowledge of Lambda and Kappa architecture in a cloud environment (AWS, Google, Azure)\n",
      "\n",
      "You have a deep understanding of SDLC, Agile methodologies, metadata, data modeling, and designing databases\n",
      "\n",
      "Working knowledge on Linux/Unix Operating systems\n",
      "\n",
      "Strong scripting skills - Python (a huge plus), Bash , Shell etc.\n",
      "entry --- Google\n",
      "substring --- , You have 3 years‚Äô experience and working knowledge of Lambda and Kappa architecture in a cloud environment (AWS, Google, Azure)\n",
      "\n",
      ", You have a deep understanding of SDLC, Agile methodologies, metadata, data modeling, and designing databases\n",
      "\n",
      ", Working knowledge on Linux/Unix Operating systems\n",
      "\n",
      ", Strong scripting skills - Python (a huge plus), Bash , Shell etc.\n",
      "entry --- Google\n",
      "substring --- , Skills & Responsibilities:, Expert in data architecture development, data policy formation, data asset management, data modeling, and data taxonomy creation\n",
      "Must be able to draw insights from structured and unstructured information\n",
      "Competent in information systems design and information visualization techniques\n",
      "Excellent verbal and written communication skills\n",
      "Ability to challenge and convince the various stakeholders involved in any project\n",
      "Working knowledge of usability design and data warehousing techniques\n",
      "Ability to perform business domain analysis and business process modeling\n",
      "Proficient understanding of distributed computing principles\n",
      "Proficient with cloud data warehouse technologies, such as AWS RedShift and/or Google BigQuery\n",
      "Experience with MySQL and PostgreSQL databases\n",
      "Good knowledge of data warehouse querying tools, such as SQL, AWS QuickSight and Google Data Studio\n",
      "Good knowledge of business intelligence tools, such as Jaspersoft and/or Tableau\n",
      "Ability to solve any ongoing data issues that arise throughout the data processing lifecycle\n",
      "Knowledge of various ETL techniques and frameworks, such as Matillion and/or Talend\n",
      "Experience with integration of data from multiple data sources\n",
      "Experience with integrating machine learning toolkits into data infrastructure\n",
      "Experience with Big Data technologies to support future growth\n",
      ", Success Criteria, Advanced Analytical Thinking and Problem Solving skills\n",
      "Solid experience in architecture, advanced reporting and dashboards\n",
      "Experience working with data warehouses is required\n",
      "Strong SQL skills and experience with performance tuning are required\n",
      "‚ÄúGet it done‚Äù attitude\n",
      "Superior Communication and Business-Technical Interaction skills\n",
      "Good understanding of data modeling concepts and data relationships\n",
      ", To qualify, you must possess the following skills:, Bachelor‚Äôs degree in computer science, management information systems, or a related discipline\n",
      "More than five years of experience in data architecture or minimum five to seven years of experience as data analyst, business intelligence analyst, or equivalent roles\n",
      "Proven experience with ETL tools\n",
      "Professional or educational experience in software development\n",
      "Excellent communication and data analysis skills\n",
      "Excellent knowledge of SQL, R, and Python for performing data transformation and analysis\n",
      ", Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer., All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.]\"\n",
      "entry --- Google\n",
      "substring --- Most importantly, you‚Äôll work and collaborate with a nimble, autonomous, cross-functional team of makers, breakers, doers, and disruptors who love to solve real problems and meet real customer needs., \n",
      "\n",
      "The person we're looking for:, \n",
      "\n",
      "has a sense of intellectual curiosity and a burning desire to learn\n",
      "\n",
      "is self-driven, actively looks for ways to contribute, and knows how to get things done\n",
      "\n",
      "is deliriously customer-focused\n",
      "\n",
      "values data and truth over ego\n",
      "\n",
      "has a strong sense of engineering craftsmanship, takes pride in the code they write\n",
      "\n",
      "believes that good software development includes good testing, good documentation, and good collaboration\n",
      "\n",
      "has great communication and reasoning skills, including the ability to make a strong case for technology choices, Basic Qualifications:, Bachelor‚Äôs degree or Military ExperienceAt least 1 year of experience with leading big data technologies such as Spark, Cassandra, Hadoop, HDFS, PostgreSQL, Redshift, and MongoDBAt least 2 years of professional experience with data engineering concepts, \n",
      "\n",
      "Preferred Qualifications:, 2+ years experience with AWS cloud2+ years of experience in Java, Scala, or Python2+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python2+ years of experience building data pipelinesAt least 1 year of Cloud (AWS, Azure, Google) development experienceExperience with Streaming and/or NoSQL implementation (Mongo, Cassandra, etc.)\n",
      "entry --- Google\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.\n",
      "entry --- Google\n",
      "substring --- Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.\n",
      "entry --- Google\n",
      "substring --- Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- Experience developing in AWS, Google cloud, or Azure (Azure preferred).\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- We are looking for sharp, disciplined, and self-motivated individuals who have a passion for utilizing the cloud solutions from Amazon Web Services, Microsoft Azure, and Google Cloud Platform to solve real business problems for our customers., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Work as part of a team, to design and develop cloud data solutions.\n",
      "entry --- Google\n",
      "substring --- Be versed in Amazon Web Services, Google Cloud Platform and/or Microsoft Azure cloud solutions, architecture, related technologies and their interdependencies.\n",
      "entry --- Google\n",
      "substring --- Deep product knowledge and understanding of Microsoft Azure, AWS, Google Cloud.\n",
      "entry --- Google\n",
      "substring --- Cloud ‚Äì AWS, Azure, Google, Languages/Libraries ‚Äì Python, Java, Scala, Spark, Kafka, Hadoop, HDFS, Parquet.\n",
      "entry --- Google\n",
      "substring --- Cloud ‚Äì AWS, Azure, Google, As used in this posting, ‚ÄúDeloitte‚Äù means Deloitte Consulting LLP, a subsidiary of Deloitte LLP.\n",
      "entry --- Google\n",
      "substring --- Job Description includes:\n",
      ", Experience in defining Data standards, Data governance and lineage, and Data migration between data base technologies\n",
      "\n",
      "Define standards for data tagging into a data lake following industry best practices\n",
      "\n",
      "Define Metadata standards\n",
      "\n",
      "Guide programs related to data standardization, data stewardship and master data management\n",
      "\n",
      "Ability to work with large amounts of data: facts, figures, and number crunching\n",
      "\n",
      "Familiarity with establishing Master Data Management and Reference Data repositories\n",
      "\n",
      "Facilitate data meetings\n",
      "\n",
      "Build data assessment metrics\n",
      "\n",
      "Familiar with ETL/ELT best practices in the creation of the database\n",
      "\n",
      "Working knowledge of message queuing, stream processing, and highly scalable big data stores\n",
      "\n",
      "Develop and drive data governance, quality and analytics initiatives are executed successfully to provide appropriate data, information & analysis to various business functions/departments\n",
      "\n",
      "Communicate effectively, both orally and written, to varied levels of the organization to include technical personnel, business managers, and senior leadership, Required Experience, Data architecture experience; experience including but not limited to metadata management, reference and master data management, data warehousing and business intelligence management and document and content management\n",
      "\n",
      "Breadth in established and emerging data technologies\n",
      "\n",
      "Strong critical thinking and problem solving skills\n",
      "\n",
      "Experience with relational SQL and NoSQL databases\n",
      "\n",
      "Ability to conceive and portray the big data picture\n",
      "\n",
      "Ability to astutely operate in the organization: well respected and influential, able to emphasize methodology, modeling, and governance, technologically and politically neutral, articulate, persuasive, and a good salesperson, and enthusiastic, Education Requirements, Bachelor‚Äôs Degree (preferred Master‚Äôs) in Computer Science, Information Systems, Data Analysis, Systems Engineering, Applied Mathematics/Statistics, Operation Research, or other physical science/engineering fields, Desired Requirements, Experience with Big Data solutions\n",
      "\n",
      "Hands on experience working with AWS products (S3, Redshift, EC2, RDS, Aurora, Glacier), certifications recommended\n",
      "\n",
      "Data intelligence (i.e., data mining and profiling) Data governance to establish guidelines and processes for a data management program for the enterprise is a plus\n",
      "\n",
      "Data Analytics\n",
      "\n",
      "Knowledge/familiarity with DAMA and the Data Management Body of Knowledge, Security Clearance Level, Must be able to obtain and maintain a US Department of Defense SECRET Security Clearance]\"\n",
      "\"[\n",
      "Analyze information from various sources to identify options and communicate recommendations\n",
      "\n",
      "Present information that summarizes overall application or technology status and trends for business level review\n",
      "\n",
      "Review the work of others to provide design or programming recommendations and guide work to completion\n",
      "\n",
      "Mentor and coach others to enhance professional and technical skills\n",
      "\n",
      "Analyze requirements for software programs or application enhancements\n",
      "\n",
      "Create detailed programming specifications\n",
      "\n",
      "Write or modifies code for complex software programs, components or applications\n",
      "\n",
      "Support and clarify direction in times of change to minimize confusion or disruption to business processes\n",
      "\n",
      "Review documentation and ensure standards are being met\n",
      "\n",
      "On-call hours and limited travel may be required, \n",
      "Bachelor's degree in an Information Technology discipline or related field (Computer Science, Software Engineering) and six years of work experience designing, programming, and supporting software programs or applications\n",
      "\n",
      "Instead of a degree, eight years of related work experience designing, programming, and supporting software programs or applications may be accepted, \n",
      "In-depth knowledge of computer coding/programming languages and software development concepts in a large IT environment\n",
      "\n",
      "An understanding of Kafka, NiFi, Spark Streaming and IoT architectures and concepts\n",
      "\n",
      "Experience in developing applications in Spark\n",
      "\n",
      "Hortonworks or Cloudera certification\n",
      "\n",
      "Familiarity with capabilities within AWS, Azure, or Google Cloud Services\n",
      "\n",
      "Hands on experience with HBase, Cassandra, or other NoSQL database\n",
      "\n",
      "Understanding of version control systems, particularly GIT\n",
      "\n",
      "In-depth knowledge of data structures, data management practices, system interaction patterns and interfaces\n",
      "\n",
      "In-depth knowledge of vendor software integration and interaction patterns\n",
      "\n",
      "Advanced analytical, technical troubleshooting, diagnosing and problem-solving skills\n",
      "\n",
      "Negotiation skills and ability to influence others by educating and sharing information\n",
      "\n",
      "Interpersonal skills and ability to motivate and inspire others to achieve goals and accomplish work\n",
      "\n",
      "Coaching skills and ability to assist others in learning new technical and professional capabilities\n",
      "\n",
      "Listening, verbal and written communications skills with the ability to translate technical information into understandable terms to a variety of audiences\n",
      "\n",
      "Presentation skills and ability to present information in various ways to meet audience needs\n",
      "\n",
      "Uses a variety of techniques to demonstrate product expectations and prevent production problems, \n",
      "Annual gainshare bonus of up to 30% of your salary; Progressive rewards each of us with an annual bonus based on company performance\n",
      "\n",
      "401k which includes dollar-for-dollar company match of up to 6%\n",
      "\n",
      "Dedication to work/life balance which includes flexible work arrangements and tools to support your lifestyle\n",
      "\n",
      "Commitment to IT innovation through initiatives like our Business Innovation Garage where professionals can test new ideas, technology and prototypes\n",
      "\n",
      "Dynamic company culture that encourages engagement, supports Employee Resource Groups, values your input and embraces a relaxed atmosphere\n",
      "\n",
      "Onsite gym and wellness programs with discounts & rewards\n",
      "\n",
      "Healthcare onsite and standard benefits (medical, dental, vision)\n",
      "\n",
      "Relocation assistance to Northeast Ohio or Colorado Springs available\n",
      "\n",
      "Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\n",
      "\n",
      "Learn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk, Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\n",
      "\n",
      "Learn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk]\"\n",
      "\"[Data Engineer- Solution Design, \n",
      "\n",
      "Data Engineers will report into MapR‚Äôs Professional Services Organization.\n",
      "entry --- Google\n",
      "substring --- Amazon, Cisco, Google, Microsoft, SAP and other leading businesses are all part of the MapR ecosystem.\n",
      "entry --- Google\n",
      "substring --- 1 to 2 years of experience on cloud platforms such as Google, AWS, or Azure, Education, 4-year degree in data science, data analysis, computer programming, healthcare or related field of study, or equivalent work experience.\n",
      "entry --- Google\n",
      "substring --- \"[Analyze information from various sources to identify options and communicate recommendations\n",
      "\n",
      "Present information that summarizes overall application or technology status and trends for business level review\n",
      "\n",
      "Review the work of others to provide design or programming recommendations and guide work to completion\n",
      "\n",
      "Mentor and coach others to enhance professional and technical skills\n",
      "\n",
      "Analyze requirements for software programs or application enhancements\n",
      "\n",
      "Create detailed programming specifications\n",
      "\n",
      "Write or modifies code for complex software programs, components or applications\n",
      "\n",
      "Support and clarify direction in times of change to minimize confusion or disruption to business processes\n",
      "\n",
      "Review documentation and ensure standards are being met\n",
      "\n",
      "On-call hours and limited travel may be required, Bachelor's degree in an Information Technology discipline or related field (Computer Science, Software Engineering) and six years of work experience designing, programming, and supporting software programs or applications\n",
      "\n",
      "Instead of a degree, eight years of related work experience designing, programming, and supporting software programs or applications may be accepted, In-depth knowledge of computer coding/programming languages and software development concepts in a large IT environment\n",
      "\n",
      "An understanding of Kafka, NiFi, Spark Streaming and IoT architectures and concepts\n",
      "\n",
      "Experience in developing applications in Spark\n",
      "\n",
      "Hortonworks or Cloudera certification\n",
      "\n",
      "Familiarity with capabilities within AWS, Azure, or Google Cloud Services\n",
      "\n",
      "Hands on experience with HBase, Cassandra, or other NoSQL database\n",
      "\n",
      "Understanding of version control systems, particularly GIT\n",
      "\n",
      "In-depth knowledge of data structures, data management practices, system interaction patterns and interfaces\n",
      "\n",
      "In-depth knowledge of vendor software integration and interaction patterns\n",
      "\n",
      "Advanced analytical, technical troubleshooting, diagnosing and problem-solving skills\n",
      "\n",
      "Negotiation skills and ability to influence others by educating and sharing information\n",
      "\n",
      "Interpersonal skills and ability to motivate and inspire others to achieve goals and accomplish work\n",
      "\n",
      "Coaching skills and ability to assist others in learning new technical and professional capabilities\n",
      "\n",
      "Listening, verbal and written communications skills with the ability to translate technical information into understandable terms to a variety of audiences\n",
      "\n",
      "Presentation skills and ability to present information in various ways to meet audience needs\n",
      "\n",
      "Uses a variety of techniques to demonstrate product expectations and prevent production problems, Annual gainshare bonus of up to 30% of your salary; Progressive rewards each of us with an annual bonus based on company performance\n",
      "\n",
      "401k which includes dollar-for-dollar company match of up to 6%\n",
      "\n",
      "Dedication to work/life balance which includes flexible work arrangements and tools to support your lifestyle\n",
      "\n",
      "Commitment to IT innovation through initiatives like our Business Innovation Garage where professionals can test new ideas, technology and prototypes\n",
      "\n",
      "Dynamic company culture that encourages engagement, supports Employee Resource Groups, values your input and embraces a relaxed atmosphere\n",
      "\n",
      "Onsite gym and wellness programs with discounts & rewards\n",
      "\n",
      "Healthcare onsite and standard benefits (medical, dental, vision)\n",
      "\n",
      "Relocation assistance to Northeast Ohio or Colorado Springs available\n",
      "\n",
      "Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\n",
      "\n",
      "Learn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk, Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\n",
      "\n",
      "Learn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk]\"\n",
      "\"[Where good people build rewarding careers., Think that working in the insurance field can‚Äôt be exciting, rewarding and challenging?\n",
      "entry --- Google\n",
      "substring --- You can find us in 27 cities across the U.S., U.K., and Canada., \n",
      "\n",
      "Job Title, \n",
      "\n",
      "Data Engineer, \n",
      "\n",
      "As a Data Engineer, you‚Äôll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core cloud data warehouse tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.\n",
      "entry --- Google\n",
      "substring --- Python, Hive, Spark)\n",
      "\n",
      "Willingness to travel up to 50%, at peak times of projects, \n",
      "\n",
      "Qualifications, \n",
      "\n",
      "3+ years of related work experience in Data Engineering or Data Warehousing\n",
      "\n",
      "Hands-on experience with leading commercial Cloud platforms, including AWS, Azure, and Google\n",
      "\n",
      "Proven experience with data warehousing, data ingestion, and data profiling\n",
      "\n",
      "Proficient in SQL\n",
      "\n",
      "Strong aptitude for learning new technologies and analytics techniques\n",
      "\n",
      "Highly self-motivated and able to work independently as well as in a team environment\n",
      "\n",
      "Understanding of agile project approaches and methodologies\n",
      "\n",
      "Proficient in a source code control system, such as Git\n",
      "\n",
      "Proficient in the Linux shell, including utilities such as SSH, \n",
      "\n",
      "Preferred Experience, \n",
      "\n",
      "Familiarity with implementing analytics solutions with one or more Hadoop distributions (Cloudera, Hortonworks, MapR, HDInsight, EMR)\n",
      "\n",
      "Familiarity with streaming data ingestion\n",
      "\n",
      "Proficient in Python and/or Java\n",
      "\n",
      "Consulting experience\n",
      "\n",
      "Familiarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression)]\"\n",
      "\n",
      "\"[As a key member of an Agile development and/or support team, the Senior Data Engineer performs technical design, development, modification, implementation, maintenance and support of applications using existing and emerging technologies such as Microsoft SSIS ETL, SQL Server, Data Warehousing and Data Integration.\n",
      "entry --- Google\n",
      "substring --- The engineer support and collaborate with our data engineers, researchers, report writers and data analysts., \n",
      "\n",
      "Responsibilities, \n",
      "\n",
      "Implement, secure and maintain the advanced data analytics platform\n",
      "\n",
      "Implement, secure and maintain the front-end interface to platform\n",
      "\n",
      "Design, implement and automate data flows to and from the platform\n",
      "\n",
      "Work with partners and vendors on data integration projects\n",
      "\n",
      "Create data models for analytics applications\n",
      "\n",
      "Assist in the Data Warehouse ETL design and implementation\n",
      "\n",
      "Assist in resolution of production issues and root cause analyses, \n",
      "\n",
      "Technical Qualifications and Experience, \n",
      "\n",
      "3+ years with Python analytics platform, Python notebooks and Data Science libraries\n",
      "\n",
      "3+ years‚Äô experience with ETL tools: SSIS (preferred), Informatica, Talend\n",
      "\n",
      "3+ years‚Äô experience with RESTFul APIs and Web Services: JSON and XML\n",
      "\n",
      "3+ years‚Äô experience with RDMS databases: SQL Server, Postgres, Oracle\n",
      "\n",
      "Strong expertise in SQL scripting required\n",
      "\n",
      "Strong expertise in Python scripting required\n",
      "\n",
      "Experience integrating large datasets, many 100Gbs to several Terabytes required\n",
      "\n",
      "Experience with Linux and Windows Server Operating Systems required\n",
      "\n",
      "Strong expertise in a programming language such as Java/Scala or C# a big plus\n",
      "\n",
      "Experience with web front scripting such Javascript, HTML and CSS a big plus\n",
      "\n",
      "Experience supporting researchers in bioinformatics a big plus\n",
      "\n",
      "Experience with statistics, machine learning and deploying predictive models a big plus (R, Python, Matlab, Spark)\n",
      "\n",
      "Experience with SAS, administration and SAS language a plus\n",
      "\n",
      "Experience with public cloud a plus: AWS, Google Cloud, Azure\n",
      "\n",
      "Experience with Big Data technology a plus: Hadoop, Spark, AWS EMR, Hive, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entry --- Google\n",
      "substring --- Experience in Google Cloud Services strongly preferred.\n",
      "entry --- Google\n",
      "substring --- Experience in Google Cloud Services strongly preferred.\n",
      "entry --- Google\n",
      "substring --- Experience with Agile methodologies (Scrum)\n",
      "\n",
      "Experience working with large data processing platforms like Apache Beam, Apache Spark, or Apache Hadoop MapReduce (Google Cloud Dataflow a plus).\n",
      "entry --- Google\n",
      "substring --- Experience with Google Analytics is a plus\n",
      "\n",
      "Strong technical aptitude and a willingness to learn and adapt to new and evolving technologies\n",
      "\n",
      "Excellent communication skills\n",
      "\n",
      "Team Skills: facilitation, presentation & group dynamics, \n",
      "\n",
      "Much has changed since our start in 1912, but the important things remain the same.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "3 years of experience with Big Data, systems, including Hadoop, Hive and Pig\n",
      "Experience with ETL tools including but not limited to NiFi and StreamSets\n",
      "Experience with Java\n",
      "Experience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services\n",
      "Ability to obtain a security clearance\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with Agile software development\n",
      "Possession of excellent oral and written communication skills\n",
      "BS degree in CS, Computer Information Systems, Information Systems, or a related field\n",
      "]\"\n",
      "\"[1.\n",
      "entry --- Google\n",
      "substring --- If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\n",
      "entry --- Google\n",
      "substring --- and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.\n",
      "entry --- Google\n",
      "substring --- We partner with companies to push the boundaries of what‚Äôs possible‚Äîtogether., \n",
      "\n",
      "Job Title: Data Engineer, \n",
      "\n",
      "As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other big data related technologies.\n",
      "entry --- Google\n",
      "substring --- Our customers include some of the nation‚Äôs largest hospitals including Stanford, UCSF, NewYork-Presbyterian, the University of Texas MD Anderson Cancer Center, and more\n",
      "Our team includes veteran executives and the brightest minds from Google, McKinsey, Stanford, MIT, Duke, Berkeley, UIUC, and more.\n",
      "entry --- Google\n",
      "substring --- Additional specific qualifications include:, \n",
      "Experience architecting, implementing and successfully operationalizing large scale data solutions in production environments using Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, EMR, Kinesis, BigQuery, DataProc, Azure Data Lake, etc.\n",
      "entry --- Google\n",
      "substring --- , Experience architecting, implementing and successfully operationalizing large scale data solutions in production environments using Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, EMR, Kinesis, BigQuery, DataProc, Azure Data Lake, etc., Experience building performant data models at scale for Hadoop/NoSQL ecosystem of data stores to support different business consumption patterns off a centralized data platform., Experience creating data pipelines using Spark/MR/ETL processing, including Java, Python, Scala, Talend; for data analysis of production Big Data applications., Experience industrializing data lakes or real-time platforms for an enterprise enabling business applications and usage at scale., Experience designing and implementing relational data models working with RDBMS and understanding of the challenges in these environments., Responsibilities, \n",
      "\n",
      "The candidate will work closely with other professionals within various departments to develop data solutions to support the business.\n",
      "entry --- Google\n",
      "substring --- Transition data storage to Cloud environments (Google or Azure).\n",
      "entry --- Google\n",
      "substring --- , Act as a focal point for vetting requirements and prioritizing work streams for data solutions with business and IT partners., Ensure adherence to approach of using self-service data solutions to enable others to be successful in data wrangling, data blending, and data delivery via services., Develop business data catalogs and data marketplaces on top of next generation data platforms., Transition data storage to Cloud environments (Google or Azure)., Coordinate the build and maintenance of data pipelines and services for use by multiple business areas.\n",
      "entry --- Google\n",
      "substring --- Customer engagement reports & dashboards to support the Sales & Marketing team, pulling data from Google Analytics and our CMS & entitlement databases to show who is (or isn‚Äôt!)\n",
      "entry --- Google\n",
      "substring --- Experience architecting and developing end-to-end enterprise scale Big Data analytical solutions in serverless environments such as Google Cloud Platform\n",
      "\n",
      "Experience with Cloud Dataflow, BigQuery, Hadoop/Spark, and Tableau\n",
      "\n",
      "Experience implementing ETL processes in Big Data analytical solutions using a variety of sources (Text, databases, JSON, XML, etc..)\n",
      "\n",
      "2-3 years of experience in statistical and database languages (e.g., Python, R, advanced SQL)\n",
      "\n",
      "2-3 years of experience working with Big Data, data mining or machine learning, data visualization to draw actionable insights\n",
      "\n",
      "3+ years of experience programming in Java and Unix shell scripts\n",
      "\n",
      "2-3 years of experience with Agile and Scrum development\n",
      "\n",
      "Familiar with Apache BEAM SDK\n",
      "\n",
      "Working knowledge of basic financial concepts: P&L, margins, pricing, etc.\n",
      "entry --- Google\n",
      "substring --- A Masters degree in Computer Science, Mathematics or related technical field is a plus., \n",
      "\n",
      "Experience architecting and developing end-to-end enterprise scale Big Data analytical solutions in serverless environments such as Google Cloud Platform, \n",
      "\n",
      "Experience with Cloud Dataflow, BigQuery, Hadoop/Spark, and Tableau, \n",
      "\n",
      "Experience implementing ETL processes in Big Data analytical solutions using a variety of sources (Text, databases, JSON, XML, etc..), \n",
      "\n",
      "2-3 years of experience in statistical and database languages (e.g., Python, R, advanced SQL), \n",
      "\n",
      "2-3 years of experience working with Big Data, data mining or machine learning, data visualization to draw actionable insights, \n",
      "\n",
      "3+ years of experience programming in Java and Unix shell scripts, \n",
      "\n",
      "2-3 years of experience with Agile and Scrum development, \n",
      "\n",
      "Familiar with Apache BEAM SDK, \n",
      "\n",
      "Working knowledge of basic financial concepts: P&L, margins, pricing, etc., \n",
      "\n",
      "Prior experience in financial modeling is a plus., \n",
      "\n",
      "Excellent oral and written communication skills, including the ability to communicate complex findings in a structured and clear manner to a non-technical audience]\"\n",
      "\"[Build data expertise and own data quality for all data pipelines you build\n",
      "\n",
      "Track events that are critical to drive business values\n",
      "\n",
      "Work with new data models that provide intuitive analytics\n",
      "\n",
      "Move data from large scale data warehouse and data storage both internally and externally\n",
      "\n",
      " Develop new systems and tools to enable folks to consume and understand data faster\n",
      "\n",
      "Use your expert coding skills across a number of languages from Python, Java and PHP\n",
      "\n",
      "Work across multiple teams in high visibility roles and own the solution end-to-end, \n",
      "\n",
      "2+ years of Java and/or Python development experience is necessary\n",
      "\n",
      "2+ years of SQL (mySQL, Hive, etc) experience is required\n",
      "\n",
      "3+ years of experience with dimensional data modeling & schema design in Data Warehouses\n",
      "\n",
      "2+ years of experience in ETL design, implementation and maintenance (Pentaho, Elastic Search)\n",
      "\n",
      "100% passionate for reliable data pipelines and intuitive user interfaces\n",
      "\n",
      "Ability to write well-abstracted, reusable code components\n",
      "\n",
      "Excellent communication skills including the ability to identify and communicate data driven insights\n",
      "\n",
      "BS or MS degree in Computer Science or a related technical field]\"\n",
      "\"[Build comprehensive summary presentations to executive and technical teamsStrong analytical, planning, and organizational skills with an ability to manage competing demandsStrong experience in data exploration and visualization with large data sets, MS in Computer Science, Computer Engineering or Bachelors with equivalent experience is requiredExperience in Java, C, C++ a plusExperience and solid understanding of Scala, Spark, TeraData, SQL & SQL-like languagesStrong Hadoop skills (hive, spark, scala)Good coding skills to clean data sets for ingest and tool development (i.e.\n",
      "entry --- Google\n",
      "substring --- Curiosity that drives you to continually learn new things., \n",
      "\n",
      "BONUS, \n",
      "\n",
      "Experience with Google BigQuery.\n",
      "entry --- Google\n",
      "substring --- X was formerly known as Google[x]., Partner cross-functionally with software engineers, aerospace engineers, flight operations/business teams to design, develop and deliver data pipelines that drive scalable operational excellence\n",
      "Define data sources and implement a customized real time, reliable system\n",
      "Monitor, validate and maintain data pipelines to ensure consistent performance\n",
      ", \n",
      "Bachelor's degree in Computer Science, Mathematics, related technical field or equivalent practical experience\n",
      "5 years of experience in data engineering in a cloud based environment\n",
      "Experience with data analysis tools (such as SQL, PLX and with data processing algorithms such as Flume, MapReduce)\n",
      "Coding experience with one or more of the following languages: Java, C++, Python, Go and/or JavaScript\n",
      ", \n",
      "Experience developing pipelines using Google proprietary backend and frontend tools\n",
      "eCommerce experience]\"\n",
      "\"[\n",
      "\n",
      "Work with others to define, and propose for approval, a modern data platform design strategy and matching architecture and technology choices to support it, with the goals of providing a highly scalable, economical, observable, and operable data platform for storing and processing very large amounts of data within tight performance tolerances.\n",
      "entry --- Google\n",
      "substring --- Come join a friendly, seasoned team and a great company as we change the world., \n",
      "\n",
      "What you‚Äôll do, \n",
      "\n",
      "Build ETL code to populate our Google BigQuery data warehouse with Apache Airflow scheduled batch updates from our Sansar Virtual Reality platform\n",
      "\n",
      "Develop real-time ETL apps using Google DataFlow (Java or Python) to provide critical insights into the business\n",
      "\n",
      "Maintain, improve, troubleshoot, and evaluate real-time data processing systems such as PubSub, Kafka, and Stackdriver\n",
      "\n",
      "Work closely with our Data Architect, Product Managers, and Analysts to design and model new tables to meet constantly-evolving analytics needs\n",
      "\n",
      "Liaise with our systems engineers, Google support, and our consulting partners to quickly assess the impact of production system changes to existing data warehouse processes\n",
      "\n",
      "Other duties may be assigned, \n",
      "\n",
      "What you need, \n",
      "\n",
      "Extensive Real Time Data Engineering experience - we are not looking for a Data Analyst or Scientist.\n",
      "entry --- Google\n",
      "substring --- Prior experience with Google DataFlow and/or Spark is a big plus.\n",
      "entry --- Google\n",
      "substring --- Bachelor‚Äôs Degree in a computer/database related field or equivalent professional experience., \n",
      "\n",
      "What you‚Äôll learn, \n",
      "\n",
      "Advanced real-time processing concepts\n",
      "\n",
      "Advanced data modeling\n",
      "\n",
      "Google Compute Platform tools and methods\n",
      "\n",
      "Pioneer our use of graph databases]\"\n",
      "\"[Data Engineer - Yahoo Sports\n",
      "\n",
      "\n",
      "\n",
      "A Little About Us:\n",
      "\n",
      "\n",
      "\n",
      "We are sports fans.\n",
      "entry --- Google\n",
      "substring --- Technical Experience and Expertise:\n",
      "\n",
      "Big data technologies such as Hive, Hadoop, MapReduce, PIG, Google BigQuery, Oozie, etc.\n",
      "entry --- Google\n",
      "substring --- , Technical Experience and Expertise:\n",
      "\n",
      ", Big data technologies such as Hive, Hadoop, MapReduce, PIG, Google BigQuery, Oozie, etc.\n",
      "entry --- Google\n",
      "substring --- Solid understanding of computer science fundamentals like algorithms and data structures\n",
      "\n",
      "Familiarity with MySQL (or other RDBMS) is a nice to have\n",
      "\n",
      ", Big data technologies such as Hive, Hadoop, MapReduce, PIG, Google BigQuery, Oozie, etc.\n",
      "entry --- Google\n",
      "substring --- This role is key to activating our innovative solutions and the role requires an individual who can work with other analysts and business users to create solutions which integrate with our marketing technology stack., \n",
      "\n",
      "In this role, the Marketing Data Engineer will:, \n",
      "\n",
      "Integrate data from various third-party and first-party data sources, including but not limited to Google Analytics 360, YouTube, LinkedIn, Facebook, Twitter, SFDC and Hubspot\n",
      "Collaborate with our team of in-house RPA engineers to automate API integrations and tedious process around marketing data collectionResponsible for all extract, transform and load (ETL) processes and the creation of applications that can connect to remote APIs.\n",
      "entry --- Google\n",
      "substring --- Salesforce and Google Cloud Platform experience preferred.Good experience of parsing data formats such as XML/JSON and using 3rd party API‚ÄôsSold Python programming skills - experience scheduling/automating scriptsStrong analytical and problem-solving skills, strategic thinker and visionary, self-motivatedProven ability to work cross functionallyAn understanding of how data can benefit the wider business, and how to translate technical requirements to non-technical stakeholdersPrevious experience and successful track record of learning new tools and technologiesGood time management and ability to work on concurrent assignments with different priorities - Ability to work in a fast-paced, iterative development environment with short turn-around times\n",
      ", 3+ years experience with schema design and dimensional data modeling (marketing attribution)Data Rock Star.\n",
      "entry --- Google\n",
      "substring --- Salesforce and Google Cloud Platform experience preferred.Good experience of parsing data formats such as XML/JSON and using 3rd party API‚ÄôsSold Python programming skills - experience scheduling/automating scriptsStrong analytical and problem-solving skills, strategic thinker and visionary, self-motivatedProven ability to work cross functionallyAn understanding of how data can benefit the wider business, and how to translate technical requirements to non-technical stakeholdersPrevious experience and successful track record of learning new tools and technologiesGood time management and ability to work on concurrent assignments with different priorities - Ability to work in a fast-paced, iterative development environment with short turn-around times, \n",
      "\n",
      "Preferred Experience:, \n",
      "\n",
      "Experience with statistical analysis of marketing initiatives, or a history of collaboration with data scientists for statistical analysis.\n",
      "entry --- Google\n",
      "substring --- AWS Kinesis/Lambda, GC Pub/Sub)\n",
      "Cloud infrastructure devops to support deployment and data management\n",
      "Excellent communication skills both written and verbal\n",
      ", Python, Javascript, Node.js, MongoDB, BigQuery\n",
      "Infrastructure management on Amazon Web Services and Google Cloud Platform\n",
      "Docker container deployment on Kubernetes\n",
      "RESTful Web Service API development\n",
      "Mobile development in Android and iOS\n",
      "Experience in games or fast paced company such as growth phase startup\n",
      "Git, GitHub, Perforce, Jenkins, Splunk]\"\n",
      "\"[\n",
      "Work with computational and research scientists to understand common analysis use cases and data access needs.\n",
      "entry --- Google\n",
      "substring --- Experience deploying high-performance data backends in the cloud with Amazon Web Services, Heroku, Google Cloud Platform, or a similar service.\n",
      "entry --- Google\n",
      "substring --- Built software with technologies like ElasticSearch, GraphQL, and Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- Experience with Google Analytics API and Facebook Business Manager API is a plus., \n",
      "\n",
      "Ready to Grow: The BI team is the engine driving Sun Basket's stupendous growth, and you are eager and ready for this job to get bigger over time.\n",
      "entry --- Google\n",
      "substring --- This role is key to activating our innovative solutions and the role requires an individual who can work with other analysts and business users to create solutions which integrate with our marketing technology stack., \n",
      "\n",
      "In this role, the Marketing Data Engineer will:, \n",
      "\n",
      "Integrate data from various third-party and first-party data sources, including but not limited to Google Analytics 360, YouTube, LinkedIn, Facebook, Twitter, SFDC and Hubspot\n",
      "Collaborate with our team of in-house RPA engineers to automate API integrations and tedious process around marketing data collectionResponsible for all extract, transform and load (ETL) processes and the creation of applications that can connect to remote APIs.\n",
      "entry --- Google\n",
      "substring --- Salesforce and Google Cloud Platform experience preferred.Good experience of parsing data formats such as XML/JSON and using 3rd party API‚ÄôsSold Python programming skills - experience scheduling/automating scriptsStrong analytical and problem-solving skills, strategic thinker and visionary, self-motivatedProven ability to work cross functionallyAn understanding of how data can benefit the wider business, and how to translate technical requirements to non-technical stakeholdersPrevious experience and successful track record of learning new tools and technologiesGood time management and ability to work on concurrent assignments with different priorities - Ability to work in a fast-paced, iterative development environment with short turn-around times\n",
      ", 3+ years experience with schema design and dimensional data modeling (marketing attribution)Data Rock Star.\n",
      "entry --- Google\n",
      "substring --- Salesforce and Google Cloud Platform experience preferred.Good experience of parsing data formats such as XML/JSON and using 3rd party API‚ÄôsSold Python programming skills - experience scheduling/automating scriptsStrong analytical and problem-solving skills, strategic thinker and visionary, self-motivatedProven ability to work cross functionallyAn understanding of how data can benefit the wider business, and how to translate technical requirements to non-technical stakeholdersPrevious experience and successful track record of learning new tools and technologiesGood time management and ability to work on concurrent assignments with different priorities - Ability to work in a fast-paced, iterative development environment with short turn-around times, \n",
      "\n",
      "Preferred Experience:, \n",
      "\n",
      "Experience with statistical analysis of marketing initiatives, or a history of collaboration with data scientists for statistical analysis.\n",
      "entry --- Google\n",
      "substring --- AWS, Azure, Google Cloud etc.)\n",
      "entry --- Google\n",
      "substring --- Identify impact and opportunities to reuse data structures through services oriented architecture (Data as a Service ‚Äì Daas)\n",
      "\n",
      "Leading data engineering teams for large BI, Cloud and / or ERP projects, \n",
      "\n",
      "Preferred Skills:, \n",
      "\n",
      "Focus in Oil & Gas with Hadoop technology stack\n",
      "\n",
      "AWS, MS Azure and other Cloud RDBMS experience is a PLUS\n",
      "\n",
      "Experience with Enterprise Architecture Tools (Mega, Troux, IBM, Opentext etc)\n",
      "\n",
      "Data Archiving, Disaster Recovery and DBA, \n",
      "\n",
      "Professional Skills:, \n",
      "\n",
      "Eagerness to contribute in a team-oriented environment\n",
      "\n",
      "Ability to work creatively and analytically in a problem-solving environment\n",
      "\n",
      "Desire to work in an information systems environment\n",
      "\n",
      "Excellent leadership, communication (written and oral) and interpersonal skills]\"\n",
      "\"[Data Engineer Consultant, \n",
      "\n",
      "As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.\n",
      "entry --- Google\n",
      "substring --- in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.Proficiency developing in one or more languages such as C++, Python or Java.Self-starting, requiring minimal supervision with strong problem-solving skills.Excellent communication and teamwork skills., \n",
      "\n",
      "DESIRED QUALIFICATIONS:, Hands-on experience with Cloud environments, such as AWS, Google Cloud, or AzureExperience with Cloudera, Job Function\n",
      "\n",
      ", R&D, ___________________________________________________________________________________, \n",
      "\n",
      "Privacy Statement, \n",
      "\n",
      "***Keysight is an Equal Opportunity Employer.\n",
      "entry --- Google\n",
      "substring --- Familiarity with cloud infrastructure such as Amazon AWS, Google Cloud Platform, Microsoft Azure (AWS preferred)\n",
      "\n",
      "Experience designing and building APIs, especially using Swagger (Open API)\n",
      "\n",
      "BS in Computer Science or equivalent technical domain\n",
      "\n",
      "4+ years experience in software development or IT organizations\n",
      "\n",
      ", Working with wicked smart, super cool people in a campus-like atmosphere\n",
      "\n",
      "Working on leading edge technologies in cloud micro-services, big data, and IoT\n",
      "\n",
      "Competitive salary, benefits, and retirement plan\n",
      "\n",
      "Easy commute right off Mass Pike\n",
      "\n",
      "A culture of excellence, respect, opportunity and passion for innovation\n",
      "\n",
      "]\"\n",
      "\"[Design, implement and deploy custom applications using real-time data streams and/or big data platforms\n",
      "\n",
      "Collect, create, and structure data sets from disparate sources to be able to leverage them for machine learning applications\n",
      "\n",
      "Build data pipelines to ingest, transform, and analyze data in artificial intelligence and analytics systems\n",
      "\n",
      "Design data architectures that address specific client needs, using combinations of relational databases, No-SQL databases, and unstructured file stores in both cloud and on-premise settings\n",
      "\n",
      "Develop solutions and iterate rapidly\n",
      "\n",
      "Ensure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts., Minimum 2 years of hands-on technical experience implementing or supporting big data or real-time analytics solutions\n",
      "\n",
      "High level of competence in SQL, Python and/or scripting languagesBachelor‚Äôs Degree or Associate‚Äôs Degree with 6 years of work experience or equivalent work experience of 12 years, Ability to travel about 10% of the time, Experience with delivering Big Data Solutions in the cloud with AWS, Azure or Google CloudAbility to configure and support API and OpenSource integrationsExperience administering Hadoop or other Data Science and Analytics platforms using the technologies aboveExperience working with DevOpsDesigning ingestion, low latency, visualization clusters to sustain data loads, Experience developing solutions utilizing any of the following:]\"\n",
      "[Job Summary, Join Accenture Digital and leave your digital mark on the world, enhancing millions of lives through digital transformation.\n",
      "entry --- Google\n",
      "substring --- Experience with Kafka and Yarn or Mesos\n",
      "\n",
      "Experience with AWS services (Athena, Glue, Redshift, Kinesis) or Google cloud services (BigQuery, BigTable)\n",
      "\n",
      "BA/BS or above in Computer Science or a related field\n",
      "\n",
      "Experience with NoSQL databases and key-value stores, such as Cassandra, Redis\n",
      "]\"\n",
      "\"[\n",
      "\n",
      "Build and improve NLP/ML models at hearth of AgentIQ product\n",
      "\n",
      "Build and improve infrastructure to support NLP/ML modeling, experimentation and deployment\n",
      "\n",
      "Take ownership of NLP/ML trainer tools and data processing pipelines\n",
      "\n",
      "Brainstorm and prototype algorithmic improvements\n",
      "\n",
      "Develop customer specific and general machine intelligence\n",
      "\n",
      "Contribute to deploying/monitoring/debugging models in production\n",
      "\n",
      "Take ownership of NLP/ML trainer tools and data processing pipelines\n",
      "\n",
      "Collaborate with platform teams on developing new tools and features needed for NLP/ML development and deployment\n",
      "\n",
      "Create and maintain documentation\n",
      "\n",
      "Provide internal training on applicable topics\n",
      ", \n",
      "\n",
      "Passion for improving ML/NLP models and making them more robust and scalable\n",
      "\n",
      "Thrive in a diverse, dynamic environment that leverages multiple tools and languages\n",
      "\n",
      "The ability to communicate effectively with thoughtfulness and maturity\n",
      "\n",
      "Make technology decisions that are best for the business of Agent IQ\n",
      "\n",
      "Experience building large, production-quality NLP, speech, or deep learning systems\n",
      "\n",
      "Strong software engineering and interpersonal skills\n",
      "\n",
      "Ability and desire to quickly pick up on new topics and techniques\n",
      "\n",
      "Ability to take an idea from conception and prototyping to deployment in production\n",
      "\n",
      "Masters degree or equivalent in ML/NLP or related field\n",
      ", \n",
      "\n",
      "AWS/GCP hosted infrastructure\n",
      "\n",
      "Linux\n",
      "\n",
      "Python\n",
      "\n",
      "Tensorflow\n",
      "\n",
      "Node.js\n",
      "\n",
      "Docker\n",
      "\n",
      ", \n",
      "\n",
      "Competitive salary + equity\n",
      "\n",
      "Full medical/dental/vision benefits\n",
      "\n",
      "Unlimited PTO policy\n",
      "\n",
      "Tons of snacks in the office and all-you-can-drink coffee\n",
      "\n",
      "Convenient office within a 3 minute walk from BART/Muni Underground\n",
      "\n",
      "Google apps, Dropbox, Drive, Slack, Mac (or PC) everything\n",
      "\n",
      "Agent IQ swag\n",
      "\n",
      "Commuter benefits\n",
      "\n",
      "Great teammates]\"\n",
      "\"[At Capital One, we‚Äôre building a leading information-based technology company.\n",
      "entry --- Google\n",
      "substring --- \"[Data Engineer Consultant, \n",
      "\n",
      "As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other big data related technologies.\n",
      "entry --- Google\n",
      "substring --- with Flask\n",
      "\n",
      "Experience in test automation and ensuring data quality across multiple datasets used for analytical purposes\n",
      "\n",
      "Experience with Lambda Architecture or other Big Data architectural best practices\n",
      "\n",
      "A graduate degree in Computer Science or similar discipline\n",
      "\n",
      "Commit code to open source projects\n",
      "\n",
      "Experience with test automation and continuous delivery, \n",
      "\n",
      "Experience with Tableau\n",
      "\n",
      "Experience with Machine Learning\n",
      "\n",
      "Have worked with Data Scientists]\"\n",
      "\"[\n",
      "3 years of experience with Big Data, systems, including Hadoop, Hive and Pig\n",
      "Experience with ETL tools including NiFi and StreamSets\n",
      "Experience with Java\n",
      "Experience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services\n",
      "Secret clearance\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with Agile software development\n",
      "Possession of excellent oral and written communication skills\n",
      "BS degree in CS, Computer Information Systems, Information Systems, or a related field\n",
      "]\"\n",
      "\"[Born and built 100% in the cloud, Zscaler operates a massive, global cloud security architecture, delivering the entire gateway security stack as a service.\n",
      "entry --- Google\n",
      "substring --- In this role, you will be working across industry sectors such as retail, finance, healthcare and high-tech and you'll get an opportunity to solve some of the most challenging business problems., \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "5+ years of demonstrated data engineering experience\n",
      "\n",
      "3+ years of experience with Big Data Technologies like Hadoop or Hive\n",
      "\n",
      " 2+ years of experience scripting using Perl, Python, Ruby, or other programming languages\n",
      "\n",
      "Advanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases\n",
      "\n",
      "3+ years‚Äô experience in custom ETL design, implementation and maintenance\n",
      "\n",
      "Preferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure\n",
      "\n",
      "Bachelor‚Äôs degree in CS or related discipline preferred]\"\n",
      "\"[(NYSE: WRK) partners with our customers to provide differentiated paper and packaging solutions that help them win in the marketplace.\n",
      "entry --- Google\n",
      "substring --- \"[At Google, we work at lightning speed.\n",
      "entry --- Google\n",
      "substring --- You listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation.\n",
      "entry --- Google\n",
      "substring --- Whether battling large system processes or leveraging our homegrown suite of Google products for Googlers themselves, you help Googlers work faster and more efficiently., As part of the Google Technology Solution (GTS) Data and Business Intelligence team, you will help build out a data platform that will support our users in Google Cloud business and the needs of executives for data and insights.\n",
      "entry --- Google\n",
      "substring --- , As an Application Data Engineer, you will develop solutions to high visibility data challenges in one of the fastest growing businesses within Google., Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running.\n",
      "entry --- Google\n",
      "substring --- From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible.\n",
      "entry --- Google\n",
      "substring --- Improve the data stack using the latest and greatest innovations in Google's internal and external Google Cloud Platform stack.\n",
      "entry --- Google\n",
      "substring --- Extensive experience working with AWS, Google components.\n",
      "entry --- Google\n",
      "substring --- Proven experience modeling large datasets in distributed databases such as Apache Cassandra\n",
      "\n",
      "Knowledge of at least one NoSQL database such as Neo4j, CouchDB, etc., \n",
      "Experience with Platform-as-a-Service software such as Cloud Foundry or Kubernetes\n",
      "\n",
      "Demonstrated experience building cloud native applications in a public cloud such as AWS, Google Cloud or Azure\n",
      "\n",
      "Experience contributing to open source projects\n",
      "\n",
      "Experience with stream processing, e.g.\n",
      "entry --- Google\n",
      "substring --- Cloud Computing Experience (e.g AWS, Google Cloud, Azure).\n",
      "entry --- Google\n",
      "substring --- Strong knowledge of cloud-based object storage/processing platforms (AWS or Google).\n",
      "entry --- Google\n",
      "substring --- , Strong Candidates will also have:, \n",
      "Zapier, Slack API, Netsuite ERP/SOAP API, Google API.\n",
      "entry --- Google\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Google\n",
      "substring --- You will play a key role in the architecture, design and development of the data pipeline using Big Data Technologies on AWS/Google Cloud.\n",
      "entry --- Google\n",
      "substring --- , Key Responsibilities:\n",
      "\n",
      ", Build and validate large-scale batch and real-time data pipelines with Big Data Technologies such as Talend Real-Time Big Data Platform, Python, Spark, Hadoop, Hive, Pig, Redshift, Snowflake, NoSQL DB on AWS/Google Cloud\n",
      "\n",
      "Evaluate, configure and implement new technologies, methodologies and architecture design patterns to build data processing ETL pipeline\n",
      "\n",
      "Design and Develop processes for data discovery, modeling, mining and archival\n",
      "\n",
      "Collaborate with data analytics team to ensure the integrity and availability of the data necessary for the business analytics & reporting\n",
      "\n",
      "Think strategically & bring new ideas to build the ETL pipeline architecture and how to scale it with the business as it grows\n",
      "\n",
      "Build reusable components and framework to speed up the data pipeline development\n",
      "\n",
      "Provide guidance/ directions to the data engineers team and implement best practices as well as standards across all the data pipelines\n",
      "\n",
      ", Education & Technical Experience Requirements:\n",
      "\n",
      ", Bachelor‚Äôs in computer science, science, or similar field of study\n",
      "\n",
      "8+ years of Data Warehousing, OLAP, SQL Queries, ETL/ELT design and development experience\n",
      "\n",
      "3+ years of experience with AWS services including S3, Redshift, EMR, Lambda and RDS\n",
      "\n",
      "3+ years of solid experience in developing and performance tuning the data pipeline with Hadoop, Hive, Spark, Talend Big Data Platform\n",
      "\n",
      "3+ years of experience in programming languages such as Python, Scala, R, Java or C#\n",
      "\n",
      "2+ years of experience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka\n",
      "\n",
      "2+ years of experience in columnar databases such as RedShift, Snowflake as well as NoSQL databases such as MongoDB, DynamoDB\n",
      "\n",
      "Self-starter and highly motivated to add value to the team and platform using innovations around data and data solutions\n",
      "\n",
      "Experience in dealing with the structured, semi-structured and unstructured datasets\n",
      "\n",
      "Excellent communication skills to collaborate with the data engineering, analytics and science teams\n",
      "\n",
      "Experience in Social Media Datasets such as Twitter, YouTube, Facebook, Instagram is a plus\n",
      "\n",
      "Experience in Google Clickstream, DFP, or Adobe Analytics datasets is a plus\n",
      "\n",
      "Experience in dealing with the Media content subscription-based datasets is a plus\n",
      "\n",
      "Experience in creating restful API‚Äôs is a plus\n",
      "\n",
      "Experience in AI, machine learning and statistics is a plus\n",
      "\n",
      "Experience in Media and Entertainment Industry is a plus\n",
      "\n",
      ", _]\"\n",
      "\"[\n",
      "3 years of experience with Big Data, systems, including Hadoop, Hive, and Pig\n",
      "Experience with ETL tools, including NiFi and StreamSets\n",
      "Experience with Java\n",
      "Experience with using Cloud services, including Amazon Web Services (AWS), Azure, or Google Cloud\n",
      "Top Secret clearance\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with Agile software development\n",
      "Possession of excellent oral and written communication skills\n",
      "BS degree in CS, Computer Information Systems, Information Systems, or a related field\n",
      "]\"\n",
      "\n",
      "\"[Are passionate about working on cutting edge, high profile projects and are motivated by delivering solutions on an aggressive schedule\n",
      "Aren‚Äôt satisfied with status quo, insatiably curious, and regularly look for creative ways to solve problems and help your team meet commitments\n",
      "Love learning new technologies and sharing them with your team\n",
      "Have a keen interest in using any and all appropriate tools, especially Cloud-based and Open Sourced, to solve the problem at hand\n",
      "Have strong verbal and written communication skills, and enjoy participating in dynamic, face-paced collaborations with customers, vendors, and other engineering teams to solve complex business problems together\n",
      "Use your experience and leadership skills to motive your teammates to deliver high quality results in a fast-paced work environment\n",
      ", Work within a team of like-minded professionals to design, build and deploy critical business and mission data-centric applications in a production environment\n",
      "Design and implement appropriate data extraction, transform, and load (ETL) processes to properly prepare data, ensuring data quality and accuracy, for consumption by business and mission applications\n",
      "Identify, retrieve, manipulate, relate and/or exploit multiple structured data sets from various sources\n",
      "Design and implement data storage, sharing, and dissemination environment, ensuring support for all relevant agency and community policies\n",
      "Engineer suitable data management and governance procedures and provide production support when required\n",
      "Design and develop automation workflows, perform unit tests and conduct reviews to make sure your work is rigorously designed, elegantly coded, and effectively tuned for platform performance, and assess the overall quality of all delivered components\n",
      ", Master's Degree preferred, or a Bachelor‚Äôs degree and 4 years‚Äô experience, or 10 years of specialized experience\n",
      "Minimum 4 years‚Äô experience working on complex data/database projects as a data analyst, data architect, or database engineer\n",
      "TS Clearance with ability to obtain an SCI and CI poly\n",
      ", Certified Data Management Professional (CDMP), Microsoft Certified Solutions Associate (Business Intelligence) or equivalent certification(s) strongly desired\n",
      "Experience building n-tier web-based applications using SQL and non-SQL back-ends\n",
      "Experience with large-scale data processing tools, such as Spark, NiFi, Hadoop, Kafka, etc.\n",
      "entry --- Google\n",
      "substring --- , 3+ years of hands on experience with building productionized data ingestion and processing pipelines using Java, Spark, Scala, Python\n",
      "\n",
      "2+ years of hands on experience designing and implementing production grade data warehousing solutions on large scale data technologies such as Teradata, Oracle or DB2\n",
      "\n",
      "Experience of large scale Data Migration from on premise to cloud data warehouses\n",
      "\n",
      "Expertise and excellent understanding of Snowflake Internals and integration of Snowflake with other data processing and reporting technologies\n",
      "\n",
      "Excellent presentation and communication skills, both written and verbal\n",
      "\n",
      "Ability to problem solve and architect in an environment with unclear requirements\n",
      ", Bachelor's degree in Computer Science, Engineering, Technical Science or 3+ years of technical architecture and build experience with large scale solutions\n",
      "\n",
      "Minimum 1 year of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders\n",
      "\n",
      "Experience in building data ingestion pipeline using Talend, Informatica\n",
      "\n",
      "Experience in working with AWS, Azure and Google data services\n",
      "\n",
      "Experience with dev-ops tools\n",
      "\n",
      "Prior experience in working with a consulting firm in client facing projects.]\"\n",
      "entry --- Google\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Google\n",
      "substring --- Must be willing and able to pass a counterintelligence (CI) polygraph examination\n",
      ", Python\n",
      "Linux\n",
      "Elasticsearch, NoSQL, Hadoop ecosystem, or similar big data technology\n",
      ", Interest In:\n",
      "\n",
      "Building data services and APIs\n",
      "Leveraging event-driven architecture concepts\n",
      "Scaling systems on AWS\n",
      "Pair programming\n",
      "Experience with:\n",
      "\n",
      "Working on a cross functional team\n",
      "Google's Protobuf data format\n",
      "Amazon Web Services - EMR, DynamoDB, SQS, SNS\n",
      "DevOps best practices - Jenkins\n",
      "Comfortable with:\n",
      "\n",
      "Agile development\n",
      "Hands on system engineering tasks\n",
      "Module development\n",
      ", Building data services and APIs\n",
      "Leveraging event-driven architecture concepts\n",
      "Scaling systems on AWS\n",
      "Pair programming\n",
      ", Working on a cross functional team\n",
      "Google's Protobuf data format\n",
      "Amazon Web Services - EMR, DynamoDB, SQS, SNS\n",
      "DevOps best practices - Jenkins\n",
      ", Agile development\n",
      "Hands on system engineering tasks\n",
      "Module development\n",
      "]\"\n",
      "\"[At Capital One, we‚Äôre building a leading information-based technology company.\n",
      "entry --- Google\n",
      "substring --- Comp Science, Math, Engineering) or related experience\n",
      "\n",
      "2+ years of collective experience in data engineering, data analysis, data warehousing, data integration or business intelligence, in a similarly sized organization\n",
      "\n",
      "2+ years of experience architecting, building and administering big data and real-time streaming analytics architectures in both on premises and cloud environments (AWS, Azure, Google) leveraging technologies such as Hadoop, Spark, S3, EMR, Aurora, DynamoDB, Redshift, Neptune, Cosmos DB\n",
      "\n",
      "1+ years of experience architecting, building and administering large-scale distributed applications\n",
      "\n",
      "1+ years of experience with Linux operations and development, including basic commands and shell scripting\n",
      "\n",
      "2+ years of experience with execution of DevOps methodologies and Continuous Integration/Continuous Delivery within a large scale data delivery environment\n",
      "\n",
      "Software development experience in least two or more of following languages: Java, Python, Scala, Node.js\n",
      "\n",
      "Expertise in usage of SQL for data profiling, analysis and extraction, Preferred Qualifications:, \n",
      "\n",
      "Master‚Äôs Degree in a technical field (e.g.\n",
      "entry --- Google\n",
      "substring --- Over the past years, Maven Wave has received the following awards and accolades:, \n",
      "\n",
      "Google Cloud North America Services Partner of the Year, 2018\n",
      "\n",
      "#21 Best Workplaces in Chicago, FORTUNE, 2018\n",
      "\n",
      "Great Place To Work Certification, Great Place to Work, 2017 & 2018\n",
      "\n",
      "Fast Fifty, Crain's Chicago Business, 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR), 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "Top Google Cloud Partner, Clutch, 2017\n",
      "\n",
      "Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine, 2016, 2017\n",
      "\n",
      "Top IT Services Companies, Clutch, 2015\n",
      "\n",
      "Google Global Rising Star Partner of the Year 2015, \n",
      "\n",
      "We are looking for a skilled Big Data / Cloud Data Engineer to join our team.\n",
      "entry --- Google\n",
      "substring --- The ideal candidate has extensive experience building and implementing complex data solutions in the Cloud (AWS, Microsoft, and/or Google).\n",
      "entry --- Google\n",
      "substring --- Investigating, recommending and implementing data ingestion and ETL performance improvements\n",
      "\n",
      "Document data ingestion and ETL program designs, present findings, conduct peer code reviews\n",
      "\n",
      "Develop and execute test plans to validate code\n",
      "\n",
      "Work in a collaborative, agile environment, \n",
      "\n",
      "Requirements:, \n",
      "\n",
      "Bachelor's degree in a technical or quantitative field with preferred focus on Computer Science or Information Systems\n",
      "\n",
      "4+ years experience building complex ETL programs with one of the following Informatica, DataStage, Spark, Dataflow, etc\n",
      "\n",
      "Expert in data extraction experience\n",
      "\n",
      "3+ years experience developing complex SQL\n",
      "\n",
      "Experience using Cloud Storage and computing technologies such as BigQuery, RedShift, Snowflake\n",
      "\n",
      "Experience configuring and developing big data solutions in a Cloud environment (AWS, Microsoft, or Google)\n",
      "\n",
      "3+ years experience programming in Python, and/or Java\n",
      "\n",
      "3+ years with UNIX shell scripting\n",
      "\n",
      "2+ years experience with Git\n",
      "\n",
      "2+ years experience in data quality testing; adept at writing test cases and scripts, presenting and resolving data issues\n",
      "\n",
      "2+ years experience developing complex technical and ETL programs within a Hadoop ecosystem (Hadoop, YARN, Hive, Pig, Sqoop, Spark)\n",
      "\n",
      "2+ years implementing and programming data ingestion and ETL programs with large datasets (10+ Terabyte analytical environment)\n",
      "\n",
      "Experience with integration of data from multiple data sources\n",
      "\n",
      "Experience developing and implementing streaming data ingestion solutions\n",
      "\n",
      "3+ years working with relational database technologies\n",
      "\n",
      "3+ years investigating, recommending and implementing solutions that resolve data quality issues\n",
      "\n",
      "Demonstrated independent problem solving skills and ability to develop solutions to complex analytical/data-driven problems\n",
      "\n",
      "Demonstrated experience developing data analytics solutions within AWS and/or Google Cloud Platform\n",
      "\n",
      "Must be able to communicate complex issues in a crisp and concise fashion to multiple levels of management\n",
      "\n",
      "Excellent interpersonal skills necessary to work effectively with colleagues at various levels of the organization, \n",
      "\n",
      "Check out our Data Team!]\"\n",
      "entry --- Google\n",
      "substring --- Experience in data integration automation via Google DataFlow, Apache Beam, Spark, AWS EMR, etc.\n",
      "entry --- Google\n",
      "substring --- a huge plus., Career Path, We hire Data Engineers at our Associate to Director career stages., Available locations, Arlington; Atlanta; Chicago; Newport Beach, CA; San Luis Obispo, CA; Sydney; Toronto]\"\n",
      "\"[You yearn to be part of cutting edge, high profile projects and are motivated by delivering world-class solutions on an aggressive scheduleYou are not intimidated by challenges, thrive under pressure, passionate about your craft, and focused on delivering exceptional resultsYou love to learn new technologies and mentor junior analysts to raise the bar on your teamPassionate about intuitive and engaging user interfaces, as well as new/emerging concepts and techniques, Develop sustainable data driven solutions with new data technologies to meet the needs of our organization and business customersBuild robust end-to-end systems with an eye on the long term maintenance and support of the applicationLeverage reusable code modules to solve problems across the team and organizationHandle multiple functions / roles for the projects / Agile teamsWork with established standards across the team and organizationUnderstand complex multi-tier, multi-platform systemsContribute to building a framework of a significant complexityWork with internal team of data engineers (both full-time associates and/or third party resources), At least 5 years coding, or at least 5 years experience in data warehousing or at least 5 years in unstructured data environmentsAt least 2 years experience in Azure cloud technologies AzureAt least 2 years experience in big data technologies (Cassandra, , HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, Zookeeper, or similar)2+ years of experience with Agile engineering practices\n",
      ", 1+ years experience in Azure cloud technologies AWS, MapR, Cloudera, Google Cloud5+ years experience with NoSQL implementation (Mongo, Cassandra, etc.\n",
      "entry --- Google\n",
      "substring --- Over the past years, Maven Wave has received the following awards and accolades:, \n",
      "\n",
      "Google Cloud North America Services Partner of the Year, 2018\n",
      "\n",
      "#21 Best Workplaces in Chicago, FORTUNE, 2018\n",
      "\n",
      "Great Place To Work Certification, Great Place to Work, 2017 & 2018\n",
      "\n",
      "Fast Fifty, Crain's Chicago Business, 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR), 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "Top Google Cloud Partner, Clutch, 2017\n",
      "\n",
      "Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine, 2016, 2017\n",
      "\n",
      "Top IT Services Companies, Clutch, 2015\n",
      "\n",
      "Google Global Rising Star Partner of the Year 2015, \n",
      "\n",
      "We are looking for a skilled Big Data / Cloud Data Engineer to join our team.\n",
      "entry --- Google\n",
      "substring --- The ideal candidate has extensive experience building and implementing complex data solutions in the Cloud (AWS, Microsoft, and/or Google).\n",
      "entry --- Google\n",
      "substring --- Investigating, recommending and implementing data ingestion and ETL performance improvements\n",
      "\n",
      "Document data ingestion and ETL program designs, present findings, conduct peer code reviews\n",
      "\n",
      "Develop and execute test plans to validate code\n",
      "\n",
      "Work in a collaborative, agile environment, \n",
      "\n",
      "Requirements:, \n",
      "\n",
      "Bachelor's degree in a technical or quantitative field with preferred focus on Computer Science or Information Systems\n",
      "\n",
      "4+ years experience building complex ETL programs with one of the following Informatica, DataStage, Spark, Dataflow, etc\n",
      "\n",
      "Expert in data extraction experience\n",
      "\n",
      "3+ years experience developing complex SQL\n",
      "\n",
      "Experience using Cloud Storage and computing technologies such as BigQuery, RedShift, Snowflake\n",
      "\n",
      "Experience configuring and developing big data solutions in a Cloud environment (AWS, Microsoft, or Google)\n",
      "\n",
      "3+ years experience programming in Python, and/or Java\n",
      "\n",
      "3+ years with UNIX shell scripting\n",
      "\n",
      "2+ years experience with Git\n",
      "\n",
      "2+ years experience in data quality testing; adept at writing test cases and scripts, presenting and resolving data issues\n",
      "\n",
      "2+ years experience developing complex technical and ETL programs within a Hadoop ecosystem (Hadoop, YARN, Hive, Pig, Sqoop, Spark)\n",
      "\n",
      "2+ years implementing and programming data ingestion and ETL programs with large datasets (10+ Terabyte analytical environment)\n",
      "\n",
      "Experience with integration of data from multiple data sources\n",
      "\n",
      "Experience developing and implementing streaming data ingestion solutions\n",
      "\n",
      "3+ years working with relational database technologies\n",
      "\n",
      "3+ years investigating, recommending and implementing solutions that resolve data quality issues\n",
      "\n",
      "Demonstrated independent problem solving skills and ability to develop solutions to complex analytical/data-driven problems\n",
      "\n",
      "Demonstrated experience developing data analytics solutions within AWS and/or Google Cloud Platform\n",
      "\n",
      "Must be able to communicate complex issues in a crisp and concise fashion to multiple levels of management\n",
      "\n",
      "Excellent interpersonal skills necessary to work effectively with colleagues at various levels of the organization, \n",
      "\n",
      "Check out our Data Team!]\"\n",
      "entry --- Google\n",
      "substring --- Over the past years, Maven Wave has received the following awards and accolades:, \n",
      "\n",
      "Google Cloud North America Services Partner of the Year, 2018\n",
      "\n",
      "#21 Best Workplaces in Chicago, FORTUNE, 2018\n",
      "\n",
      "Great Place To Work Certification, Great Place to Work, 2017 & 2018\n",
      "\n",
      "Fast Fifty, Crain's Chicago Business, 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR), 2014, 2015, 2016, 2017, 2018\n",
      "\n",
      "Top Google Cloud Partner, Clutch, 2017\n",
      "\n",
      "Fastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine, 2016, 2017\n",
      "\n",
      "Top IT Services Companies, Clutch, 2015\n",
      "\n",
      "Google Global Rising Star Partner of the Year 2015, \n",
      "\n",
      "We are looking for a skilled Big Data / Cloud Data Engineer to join our team.\n",
      "entry --- Google\n",
      "substring --- The ideal candidate has extensive experience building and implementing complex data solutions in the Cloud (AWS, Microsoft, and/or Google).\n",
      "entry --- Google\n",
      "substring --- Investigating, recommending and implementing data ingestion and ETL performance improvements\n",
      "\n",
      "Document data ingestion and ETL program designs, present findings, conduct peer code reviews\n",
      "\n",
      "Develop and execute test plans to validate code\n",
      "\n",
      "Work in a collaborative, agile environment, \n",
      "\n",
      "Requirements:, \n",
      "\n",
      "Bachelor's degree in a technical or quantitative field with preferred focus on Computer Science or Information Systems\n",
      "\n",
      "4+ years experience building complex ETL programs with one of the following Informatica, DataStage, Spark, Dataflow, etc\n",
      "\n",
      "Expert in data extraction experience\n",
      "\n",
      "3+ years experience developing complex SQL\n",
      "\n",
      "Experience using Cloud Storage and computing technologies such as BigQuery, RedShift, Snowflake\n",
      "\n",
      "Experience configuring and developing big data solutions in a Cloud environment (AWS, Microsoft, or Google)\n",
      "\n",
      "3+ years experience programming in Python, and/or Java\n",
      "\n",
      "3+ years with UNIX shell scripting\n",
      "\n",
      "2+ years experience with Git\n",
      "\n",
      "2+ years experience in data quality testing; adept at writing test cases and scripts, presenting and resolving data issues\n",
      "\n",
      "2+ years experience developing complex technical and ETL programs within a Hadoop ecosystem (Hadoop, YARN, Hive, Pig, Sqoop, Spark)\n",
      "\n",
      "2+ years implementing and programming data ingestion and ETL programs with large datasets (10+ Terabyte analytical environment)\n",
      "\n",
      "Experience with integration of data from multiple data sources\n",
      "\n",
      "Experience developing and implementing streaming data ingestion solutions\n",
      "\n",
      "3+ years working with relational database technologies\n",
      "\n",
      "3+ years investigating, recommending and implementing solutions that resolve data quality issues\n",
      "\n",
      "Demonstrated independent problem solving skills and ability to develop solutions to complex analytical/data-driven problems\n",
      "\n",
      "Demonstrated experience developing data analytics solutions within AWS and/or Google Cloud Platform\n",
      "\n",
      "Must be able to communicate complex issues in a crisp and concise fashion to multiple levels of management\n",
      "\n",
      "Excellent interpersonal skills necessary to work effectively with colleagues at various levels of the organization, \n",
      "\n",
      "Check out our Data Team!]\"\n",
      "entry --- Google\n",
      "substring --- Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, The following is required to be considered for this role:, Bachelors degree in Computer Science, Engineering, Data Science, Mathematics, OR a degree with technology, analytics, or quantitative focused curriculum\n",
      "5+ years of experience with database management and programming languages (SQL, Python, Java, .NET, C++, Java Script, Scala, Perl, or Ruby, etc)\n",
      "3+ years of experience in numerous databases (Oracle, Teradata, MySQL, etc), Big Data platforms (Hadoop, Hive, Spark, etc) and/or Cloud-based platforms and ERPs (AWS, Azure, Google Cloud, SAP S4 Hanna, etc)\n",
      "1+ years of experience with software/web development (including automation), data science and/or advanced statistical modeling, including predictive analysis, forecasting, regression, experimentation (multivariate is a plus), data mining, sequential/time-series, supervised and unsupervised models, etc\n",
      ", PREFERRED QUALIFICATIONS, Your resume will stand out if you have:, Master‚Äôs or PhD in the above fields\n",
      "Expertise with data visualization tools (including Tableau, Dash, RShiny, D3.js, Microstrategy, etc) and creating automated interactive dashboards and reports for business customers that are robust in knowledge and simplistic in usage\n",
      "Ability to develop data models and data pipelines to enable analysts and data scientists access to a vast array of data sources from numerous locations\n",
      "Expertise in computer programming, APIs, macro/function design and automation (Chron Jobs) in order to streamline statistical models and business processes for the organization\n",
      "Expertise in software development, notably developing GUIs for non-technical staff members we have little to no experience with data and analytics, in order to collect data, conduct analysis, run simulations and other activities\n",
      "Strong ability to communicate with analytics staff across the organization and develop innovative solutions to simplify their work processes and increase productivity\n",
      "Strong ability to work with Senior Leadership across an organization to design and drive optimal data strategy across the company\n",
      "Experience leading teams of data engineers, developers, data scientists, data analysts and/or others to develop robust technical solutions and software to optimize a business\n",
      "Able to provide a GitHub or coding portfolio of prior data engineering, data science, computer programming and statistical work and projects\n",
      "Strong desire to explore various data sources to uncover hidden opportunities for the organization\n",
      "Self-directed, detail & team oriented with highly developed problem solving and analytical skills\n",
      "Excellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\n",
      ", Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Architect and implement high performance data pipelines for distributed systems and data analytics for deep learning teams\n",
      "\n",
      "Use infrastructure as code to build, deploy, operate, and maintain big data analytics infrastructure\n",
      "\n",
      "Orchestrate large PB sized data storage and compute clusters across bare-metal and cloud\n",
      "\n",
      "Deploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform\n",
      "\n",
      "Create and maintain optimal data and model dataOps pipeline architecture\n",
      "\n",
      "Assemble large, complex data sets that meet functional / non-functional business requirements\n",
      "\n",
      "Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Architect and implement high performance data pipelines for distributed systems and data analytics for deep learning teams\n",
      "\n",
      "Use infrastructure as code to build, deploy, operate, and maintain big data analytics infrastructure\n",
      "\n",
      "Orchestrate large PB sized data storage and compute clusters across bare-metal and cloud\n",
      "\n",
      "Deploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform\n",
      "\n",
      "Create and maintain optimal data and model dataOps pipeline architecture\n",
      "\n",
      "Assemble large, complex data sets that meet functional / non-functional business requirements\n",
      "\n",
      "Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Architect and implement high performance data pipelines for distributed systems and data analytics for deep learning teams\n",
      "\n",
      "Use infrastructure as code to build, deploy, operate, and maintain big data analytics infrastructure\n",
      "\n",
      "Orchestrate large PB sized data storage and compute clusters across bare-metal and cloud\n",
      "\n",
      "Deploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform\n",
      "\n",
      "Create and maintain optimal data and model dataOps pipeline architecture\n",
      "\n",
      "Assemble large, complex data sets that meet functional / non-functional business requirements\n",
      "\n",
      "Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.\n",
      "entry --- Google\n",
      "substring --- Experience with AWS and Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- , Experience with AWS and Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.\n",
      "entry --- Google\n",
      "substring --- Experience with cloud platforms such as Amazon Web Services (AWS) and/or Google Cloud Platform (GCP)\n",
      "\n",
      "Experience with power engineering and power-related data.\n",
      "entry --- Google\n",
      "substring --- Google BigQuery and Google Cloud Platform experience preferred.\n",
      "entry --- Google\n",
      "substring --- Minimum of 3 years of experience with cloud architectures, e.g., AWS (preferred), Azure, Google Cloud.\n",
      "entry --- Google\n",
      "substring --- \"[Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another.\n",
      "entry --- Google\n",
      "substring --- As a software engineer, you will work on a specific project critical to Google‚Äôs needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve.\n",
      "entry --- Google\n",
      "substring --- Most importantly, you‚Äôll work and collaborate with a nimble, autonomous, cross-functional team of makers, breakers, doers, and disruptors who love to solve real problems and meet real customer needs., \n",
      "\n",
      "The person we're looking for:, \n",
      "\n",
      "has a sense of intellectual curiosity and a burning desire to learn\n",
      "\n",
      "is self-driven, actively looks for ways to contribute, and knows how to get things done\n",
      "\n",
      "is deliriously customer-focused\n",
      "\n",
      "values data and truth over ego\n",
      "\n",
      "has a strong sense of engineering craftsmanship, takes pride in the code they write\n",
      "\n",
      "believes that good software development includes good testing, good documentation, and good collaboration\n",
      "\n",
      "has great communication and reasoning skills, including the ability to make a strong case for technology choices, Basic Qualifications:, Bachelor‚Äôs degree or Military ExperienceAt least 1+ years‚Äô experience with leading big data technologies such as Spark, Cassandra, Hadoop, HDFS, PostgreSQL, Redshift, and MongoDBAt least 2 years of professional experience with data engineering concepts, \n",
      "\n",
      "Preferred Qualifications:, 2+ years experience with AWS cloud2+ years of experience in Java, Scala, or Python2+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python2+ years of experience building data pipelinesAt least 1 year of Cloud (AWS, Azure, Google) development experienceExperience with Streaming and/or NoSQL implementation (Mongo, Cassandra, etc.)\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "5+ years of experience with Big Data, systems, including Hadoop, Hive and Pig\n",
      "5+ years of experience with ETL tools including NiFi and StreamSets\n",
      "Experience with Java\n",
      "3+ years of experience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services\n",
      "Secret clearance\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with Agile software development\n",
      "Possession of excellent oral and written communication skills\n",
      "BS degree in CS, Computer Information Systems, Information Systems, or a related field\n",
      "]\"\n",
      "\"[You will lead and guide technical aspects of small- and medium-sized project delivery through the entire project lifecycle ‚Äì from requirements gathering, analysis, design, development, testing, deployment, audit and post-production support.\n",
      "entry --- Google\n",
      "substring --- : No\n",
      "Travel: Yes, 25 % of the Time]\"\n",
      "\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Seattle, WA, USA, \n",
      "\n",
      "As a Cloud Data Engineer, you will guide customers on how to ingest, store, process, analyze and explore/visualize data on the Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- , In this role you are the Google Engineer working with Google's most strategic Cloud customers.\n",
      "entry --- Google\n",
      "substring --- Together with the team you will support customer implementation of Google Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring and much more., \n",
      "\n",
      "The Google Cloud Platform team helps customers transform and evolve their business through the use of Google‚Äôs global network, web-scale data centers and software infrastructure.\n",
      "entry --- Google\n",
      "substring --- Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law., Schedule: Full-time, Shift: Day, Job Category: Information Technology, Location: Washington-Renton, Other Location(s): Oregon-Portland, Oregon-Beaverton, Req ID: 194036]\"\n",
      "\"[\n",
      ", \n",
      "\n",
      "Act as a thought leader and mentor: teaching, training, and guiding using the latest ML tools, methods, and software integration techniques\n",
      "\n",
      "Facilitate or participate in business needs fulfillment through machine learning implementation ideation/discovery sessions with business stakeholders and subject matter experts, \n",
      "\n",
      "Establish repeatable methods for the entire machine learning lifecycle (discovery/ideation to production hardening and launch)\n",
      "\n",
      "Document and teach cloud technologies and machine learning tools to adjacent team members (data scientists, big data engineers, and architects)\n",
      "\n",
      "Document architecture patterns for machine learning and data engineering pipelines and models, \n",
      "\n",
      "Experience with Amazon-AWS and Google Cloud ML toolsets\n",
      "\n",
      "Experience with Cloudera Big Data tools (Impala, Kudu, Parquet, HDFS, Sqoop, Flume, Spark, Kafka, Data Science Workbench, etc.)\n",
      "entry --- Google\n",
      "substring --- Create pipelines: and know what‚Äôs the right infrastructure, both in terms of storage and in terms of computing at massive scale, that can run scoring or predictions on new data., 5-8 years of related professional experience\n",
      "\n",
      "Bachelor‚Äôs Degree in related field and Masters or higher a plus\n",
      "\n",
      "Strong analyst background; generated insights and business recommendations\n",
      "\n",
      "Strong project consultative background; creating project requirements\n",
      "\n",
      "Strong experience creating ETLs and pipelines (streaming vs. batch; low vs. high frequency pipelines), using tools such as AirFlow, ApacheNiFi, Kafka\n",
      "\n",
      "Strong experience wrangling, exploring and cleaning structured and unstructured data\n",
      "\n",
      "Strong data visualization skills using Tableau or open-source tools\n",
      "\n",
      "Ability to code from Python/R to Java/Scala/Spark\n",
      "\n",
      "Experience with collaboration tools such as Bitbucket, GitHub, Teams, or Jira\n",
      "\n",
      "Experience with various data sources (on-premises vs. cloud; database vs. files)\n",
      "\n",
      "Experience with various data environments (on-premises vs. cloud; database vs. data lake; small vs. medium vs. big data), such as Google, AWS, Oracle, or Hadoop\n",
      "\n",
      "Friendly, fun, conscientious, curious and out-of-the box mindset\n",
      "\n",
      "Ability to ask questions and figure out what‚Äôs the right data and data science solution, in a collaborative team environment that follows an agile data science process\n",
      "\n",
      "A subject matter expert leading hands-on with technical know-how, determining methods and procedures on new projects, and providing leadership to other engineers\n",
      "\n",
      "Strong written and verbal communication skills with internal and external clients]\"\n",
      "[Job Summary, External Role / Title: Big Data Engineer - AWS & Hadoop, Internal Role / Title: Technology Architect, Job ID: 32890BR, Work Locations: Across cities in USA., Wanted: Global Innovators to Help Us Build Tomorrow‚Äôs Enterprise, As a Technology Architect, you will provide top-notch solution design and implementations; assist in defining scope and sizing of work; develop Proof of Concepts, innovate in solution development, solve problems and support Infosys brand., Locations for this position can be most cities in US.\n",
      "entry --- Google\n",
      "substring --- Above all, your work will influence the way people experience music., Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- Maintain internal Alloy logic to automate the interpretation of data across channels through the unified Alloy data model, \n",
      "\n",
      "Strong knowledge of Python and SQL, especially in data wrangling and ETL applications\n",
      "\n",
      "Familiarity with Java is a plus\n",
      "\n",
      "Experience in interpreting and manipulating supply chain-related datasets (Point-of-sale, logistics/EDI, product master)\n",
      "\n",
      "Working knowledge of Selenium and other web-scraping tools, \n",
      "\n",
      "Google Cloud Platform\n",
      "\n",
      "Postgres, Redis\n",
      "\n",
      "Python, modern Java, React]\"\n",
      "\"[In this role, the candidate will be responsible for performing data engineering duties such as planning, developing, Testing, maintaining and monitoring systems.\n",
      "entry --- Google\n",
      "substring --- Daily maintenance of database infrastructure, mainly checking daily / nightly scheduler jobs, backup/recovery and replication\n",
      "\n",
      "Understand business objectives and design services that couple business logic with code components for scalability and reusability\n",
      "\n",
      "Proficient in designing efficient and robust ETL workflows\n",
      "\n",
      "Create, or support creation of, required reports in response to business user needs\n",
      "\n",
      "Monitor and report for critical production data systems\n",
      "\n",
      "Support multiple data Systems in a production environment, including DSS, OLTP, NOSQL and Big data services\n",
      "\n",
      "Able to work with Cloud Computing environments\n",
      "\n",
      "Proactively monitor as well as troubleshoot problems escalated by the business / QA / Analytics / Development team in a timely manner\n",
      "\n",
      "Respond to and resolve SQL database access and performance issues\n",
      "\n",
      "Candidate will be on-call and maybe required to work over weekend at times, and will be part of a team in automating daily tasks using automated out-of-box solution or Shell/Perl scripting., \n",
      "\n",
      "Data Engineer Requirements:, \n",
      "\n",
      "3-4 years‚Äô experience related to ORACLE DB Administration on Unix/Linus in a mid-to-large-scale computing environment\n",
      "\n",
      "Strong understanding of database structures, concepts, principles, and practices\n",
      "\n",
      "Experience in AWS or Google Cloud Computing Environment\n",
      "\n",
      "Strong Working knowledge of any NoSQL systems such as Cassandra, MongoDB or DynamoDB and Elasticsearch\n",
      "\n",
      "Working knowledge of Big Data system such as Hadoop, MapReduce, Hive or Spark along with Resource management using YARN or Mesos\n",
      "\n",
      "Proficient in Python, Java and/or R\n",
      "\n",
      "Experience in migrating from RDBMS to NoSQL systems\n",
      "\n",
      "Strong SQL (ANSI or other standard SQL) writing skills is a must\n",
      "\n",
      "Understanding of UNIX/Linux/Perl or bash Shell scripting language\n",
      "\n",
      "Ability to architect highly scalable distributed systems\n",
      "\n",
      "Hands-on experience with PySpark or PyTorch\n",
      "\n",
      "Working knowledge of Apache Kafka or AWS SQS with Kinesis Data Firehose\n",
      "\n",
      "Working knowledge of in-memory computing systems such as Redis, NuoDB, VoltDB or GridGain]\"\n",
      "\"[This Data Engineer will join other extremely passionate engineers who share a common interest in distributed systems, performance, scale, and solving problems with software and data.\n",
      "entry --- Google\n",
      "substring --- Hadoop, Spark, Apache Beam, Flink), Understand trade offs among data formats such as CSV, JSON, Avro, Parquet\n",
      "\n",
      "Experience with stream processing technologies such as Apache Beam, Spark Streaming, Flink, Kafka Streams\n",
      "\n",
      "ETL experience on AWS using EMR, Firehose, Lambda\n",
      "\n",
      "ETL experience on Google Cloud using Dataproc, Cloud Functions, Dataflow\n",
      "\n",
      "Experience using a data warehouse such as Redshift or BigQuery\n",
      "\n",
      "Familiar with messaging systems such as Kinesis, Kafka, PubSub\n",
      "\n",
      "Familiar with automation tools such as Apache Airflow, Luigi, AWS Data Pipeline, \n",
      "\n",
      "Competitive base salary plus meaningful equity\n",
      "\n",
      "Comprehensive benefits (Medical, Dental, Vision, 401k)\n",
      "\n",
      "Flexible Paid Time Off, \n",
      "\n",
      "Daily catered lunches\n",
      "\n",
      "Dog friendly office\n",
      "\n",
      "Collaborative, fun team]\"\n",
      "\"[\n",
      "\n",
      "As a result, Trianz is focusing on three important themes in our engagement model with clients., \n",
      "\n",
      "Crystallize business impact from a top management point of view\n",
      "\n",
      "Help Clients achieve results from strategy-by making execution predictable through innovative execution techniques\n",
      "\n",
      "Create a positive, enriching partnership experience in everything we do, \n",
      "\n",
      "Cloud\n",
      "\n",
      "Analytics\n",
      "\n",
      "Digitization\n",
      "\n",
      "Infrastructure\n",
      "\n",
      "Security, \n",
      "\n",
      "Job Description, \n",
      "\n",
      "Strong data engineer able to:, Create and maintain optimal data pipeline architecture,Assemble large, complex data sets that meet functional / non-functional business requirements,Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources,Work with stakeholders including Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs,Experience building and optimizing data pipelines, architectures and data sets,A successful history of manipulating, processing and extracting value from large disconnected datasets., \n",
      "\n",
      "A plus:, Experience in creating reports and dashboards in Tableau., \n",
      "\n",
      "Technologies we use:, \n",
      "\n",
      "Dataswarm (data pipeline framework in Python), Hive, Presto, Python, Scuba (in-memory database), SQL, Oracle, Tableau, \n",
      "\n",
      "Trianz is growing above the average of the professional services industry.\n",
      "entry --- Google\n",
      "substring --- S/He will be responsible for supporting product development for key ad sales research solutions and initiatives, and in addition to the team‚Äôs Product Managers, will also support the data needs of three Sr. Data Scientists., \n",
      "\n",
      "Build distributed, high-volume data pipelines to power new product features based on analytics and machine-learning\n",
      "\n",
      "Build applications that are AWS-ready\n",
      "\n",
      "Identify and solve data pipeline issues as they arise\n",
      "\n",
      "Serve as point between Advertising Science and MTS (IT/Cloud-Engineering department) in support of our data products\n",
      "\n",
      "Develop, test, and maintain data architectures to ensure data availability\n",
      "\n",
      "Work closely with external product vendors to set up back-ends of Advertising Science products, BS/MS/PhD in a STEM field\n",
      "\n",
      "Experience building data pipelines from scratch and architected solutions for data science and analytics\n",
      "\n",
      "Fluent in scalable cloud computing technologies (AWS, Google Cloud Compute, Azure).\n",
      "entry --- Google\n",
      "substring --- Mentors data scientists in pioneering techniques and business acumen, \n",
      "Required Qualifications:, \n",
      "\n",
      "Cloud solution implementation experience with Azure Data Lake and Spark preferred\n",
      "\n",
      "Minimum 8 years hands-on experience with SQL\n",
      "\n",
      "At least one year of experience in scripting languages such as Python\n",
      "\n",
      "Demonstrated experience in a cloud-based -computing environment such as AWS, Azure, or Google Cloud Platform\n",
      "\n",
      "Big data processing techniques, preferred\n",
      "\n",
      "Can work independently in ambiguous environment, \n",
      "\n",
      "About Logic20/20.\n",
      "entry --- Google\n",
      "substring --- , \n",
      "Great team: Founded by successful veterans of Yahoo, Zynga, and eBay\n",
      "Huge market: Disrupting a massive, growing $35+ billion market for CRMs\n",
      "Funding: Raised $53M for our Series C from top-tier investors like Norwest Venture Partners\n",
      "Our CRM has been awarded: G2Crowd #1 in Customer Satisfaction Summer Rankings, Google Best New Tech Partner of the Year\n",
      "Impact: A fun, transparent, and exciting start-up culture that empowers its people to make a huge impact.\n",
      "entry --- Google\n",
      "substring --- Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]\n",
      "\"[\n",
      "Spark, working in RDDs and DataFrames/Datasets API (with emphasis on DataFrames) to query and perform data manipulation\n",
      "Spark Structured Streaming\n",
      "Experience building large scale Spark applications, ideally with either Batch processing and/or Streaming processing\n",
      "Scala would be ideal but a solid knowledge of Java is also acceptable\n",
      "Experience in SparkSQL (Broadcast Joins)\n",
      "Experience with cloud computing platforms, we use AWS (Kinesis, S3, Lambda, DynamoDB)\n",
      "Has experience with ANSI SQL relational database (Oracle, SQL, Postgres, MySQL)\n",
      ", \n",
      "Linux common working knowledge, including navigating through the file system and simple bash scripting\n",
      "General knowledge of distributed systems and distributed data processing frameworks\n",
      "Experience with Storm, Kafka, or Cassandra is a plus\n",
      "Knowledge about agile software processes\n",
      "]\"\n",
      "\"[\n",
      "Own relevant source systems analysis activities spanning multiple source systems including the MySQL databases that underpin our service, cloud based email delivery systems, Google analytics, Amazon Marketplaces and enterprise systems such as NetSuite financials and Laboratory Information Systems.\n",
      "entry --- Google\n",
      "substring --- Write complex ETL processes and frameworks for analytics and data management\n",
      "\n",
      "Implement large-scale real-time streaming data processing pipelines\n",
      "\n",
      "Work inside a team of industry experts on cutting-edge Big Data technologies to develop solutions for deployment at a massive scale, \n",
      "\n",
      "Requirements:, \n",
      "\n",
      "Hadoop v2, MapReduce, HDFS on Google Cloud\n",
      "\n",
      "Building stream-processing systems, using solutions such as Storm or Spark-Streaming\n",
      "\n",
      "Big Data querying tools, such as Pig, Hive, and Impala\n",
      "\n",
      "Integration of data from multiple data sources\n",
      "\n",
      "Spark, Scala, Java, Python, Bash, BigQuery, Azkaban, Airflow, and Dataflow\n",
      "\n",
      "NoSQL databases, such as HBase, Cassandra, MongoDB\n",
      "\n",
      "Messaging systems Kafka, RabitMQ, etc., \n",
      "\n",
      "What will be a plus:, \n",
      "\n",
      "Knowledge of Unix-based operating systems (bash/ssh/ps/grep etc.)\n",
      "entry --- Google\n",
      "substring --- Above all, your work will impact the way the world experiences art., Build large-scale batch and real-time data pipelines with data processing frameworks like Scio, Storm or Spark and the Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- Getting the answers you need to solve a problem from Google, finding the right person to ask, or digging deep technically\n",
      "Mentoring junior developers.\n",
      "entry --- Google\n",
      "substring --- Mentors data scientists in pioneering techniques and business acumen, \n",
      "Required Qualifications:, \n",
      "\n",
      "Cloud solution implementation experience with Azure Data Lake and Spark preferred\n",
      "\n",
      "Minimum 8 years hands-on experience with SQL\n",
      "\n",
      "At least one year of experience in scripting languages such as Python\n",
      "\n",
      "Demonstrated experience in a cloud-based -computing environment such as AWS, Azure, or Google Cloud Platform\n",
      "\n",
      "Big data processing techniques, preferred\n",
      "\n",
      "Can work independently in ambiguous environment, \n",
      "\n",
      "About Logic20/20.\n",
      "entry --- Google\n",
      "substring --- Our Data Management Platform (DMP) is now ingesting thousands of GB's of data from our online marketing sources:\n",
      ", \n",
      "\n",
      "Display Advertising\n",
      "\n",
      "Social Advertising\n",
      "\n",
      "Email marketing\n",
      "\n",
      "Online Job Postings\n",
      "\n",
      "Career Web Sites\n",
      ", Display Advertising, Social Advertising, Email marketing, Online Job Postings, Career Web Sites, Amongst many other things, Symphony Talent will be using this data to produce the following:, \n",
      "\n",
      "Multi source attribution analytics\n",
      "\n",
      "Predictive Analytics\n",
      "\n",
      "Client facing Analytics - via our SaaS portal\n",
      "\n",
      "Integration with external vendors and clients (Google, Facebook, Twitter, Indeed etc)\n",
      ", Multi source attribution analytics, Predictive Analytics, Client facing Analytics - via our SaaS portal, Integration with external vendors and clients (Google, Facebook, Twitter, Indeed etc), About the Role:\n",
      "\n",
      "\n",
      "We are looking for a \"\"generalist\"\" engineer, that will primarily be responsible for collecting, storing, processing, and analyzing huge sets of data.\n",
      "entry --- Google\n",
      "substring --- Experience with Google Cloud Platform or related cloud services.\n",
      "entry --- Google\n",
      "substring --- , \n",
      "ETL: Apache Airflow\n",
      "Container: Docker/Kubernetes\n",
      "API: gRPC/Tensorflow Serving/Flask(REST)\n",
      "Database: Google Datastore/MySQL/Google Spanner\n",
      "Distributed Processing: Apache Beam/Apache Spark\n",
      "Machine Learning: Tensorflow/Keras/Scikit-Learn, etc.\n",
      "entry --- Google\n",
      "substring --- Cloud: Google Cloud(BigQuery/ML Engine/Google Dataflow/Google Dataproc, etc.)\n",
      "entry --- Google\n",
      "substring --- Detect data/analytics quality issues and implement bug fixes and data validation for prevention\n",
      "\n",
      "Help understand our day to day operations for continuous improvement of production systems, \n",
      "\n",
      "2+ years experience with Big Data technologies (we‚Äôre hiring all experience levels)\n",
      "\n",
      "Experience with Scala/Java, Spark, Kafka, or demonstrated ability to pick up new technology quickly\n",
      "\n",
      "Fundamental knowledge about databases and strong SQL skills\n",
      "\n",
      "Familiar with Google Cloud ecosystem such as BigQuery, GCS, DataProc, etc\n",
      "\n",
      "Enjoys working collaboratively; CK‚Äôs values include empathy and helpfulness\n",
      "\n",
      "Able to estimate and meet deadlines\n",
      "\n",
      "Excellent verbal and written communication skills, \n",
      "\n",
      "Experience working with cloud technologies\n",
      "\n",
      "Experience scaling data throughput or building low latency streaming pipelines\n",
      "\n",
      "Experience solving for data quality]\"\n",
      "\"[\n",
      "\n",
      "Architect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake\n",
      "\n",
      "Design, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights\n",
      "\n",
      "Be a technical leader for the team; guide technical and architectural designs for the major team initiatives; mentor junior members of the team\n",
      "\n",
      "Build data expertise, and partner with data scientists and product engineers to define and standardize business rules and maintain high-fidelity data\n",
      "\n",
      "Define and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently\n",
      "\n",
      "Work cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches, \n",
      "\n",
      "5+ years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science\n",
      "\n",
      "Strong software engineering skills and at least one scripting language (e.g., Python)\n",
      "\n",
      "Proficient with relational databases and SQL\n",
      "\n",
      "Familiarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred\n",
      "\n",
      "Ability to communicate technical concepts clearly and concisely\n",
      "\n",
      "Independence and passion for innovation and learning new technologies, Data Warehousing for Business Intelligence Specialization]\"\n",
      "\"[**THIS POSITION REQUIRES AN ACTIVE TS/SCI **, \n",
      "\n",
      "BI&A seeking DataEngineer with data transformation (ETL) experience working with latest industry tools., \n",
      "\n",
      "DUTIES ENTAIL:, Work with a teammate on data integration requirements.Write code on ETL platform to transform data to a suitable formats as defined by IC ITE initiatives.Add features to ETL platform to shorten timelines for future data integration efforts.Develop, maintain code, and integrate software into a fully functional software system.Participate in daily scum meetings, sprint retrospectives, and other agile processes.Work with external teams to validate data ingest.Provide and maintain documentation of system architecture, development, and enhancements., \n",
      "\n",
      "EDUCATION:, Bachelor‚Äôs Degree and 6 or more years‚Äô experience or Master's Degree with 3 or more years' experience from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry., \n",
      "\n",
      "REQUIRED EXPERIENCE:, 6+ years of software development experienceDemonstrated understanding of high scale cloud architectureLinux/Unix experienceObject Oriented programming languagePossess strong verbal and written communication skillsPossess strong analytical skills, with excellent problem solving abilities in the face of ambiguity, \n",
      "\n",
      "DESIRED EXPERIENCE:, Expertise in data ingestion, data transformation (ETL), and data modeling.Experience with Java, Ruby, or PythonExperience in Agile/SCRUM enterprise-scale software development3 years‚Äô experience working with batch-processing and tools (eg, Nifi, Midpoint, MapReduce, Yarn, Pig, Hive, HDFS, Oozie)1 year working with Restful web services Experience with code development, deployment, versioning, and build tools (eg, Eclipse, git, svn, maven, Jenkins)Experience working with tools in the stream-processing (eg, Storm)Experience developing applications that work with NoSQL stores (eg, ElasticSearch, Hbase, Cassandra, MongoDB, CouchDB)Working in cloud architecture with AWS EC2, RDS, S3, VPC, Elastic Search, \n",
      "\n",
      "BI&A is an Equal Opportunity Employer.\n",
      "entry --- Google\n",
      "substring --- ZestFinance was founded in 2009 by Douglas Merrill and a team of former Google employees with the mission of making fair and transparent credit available to everyone., \n",
      "\n",
      "We are committed to diversity in hiring, professional development, and everyday discussion.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "\n",
      "Collaborate with Data Analysts, Product Managers, and Engineers to design a high-quality PostgreSQL Data Warehouse schema and solution\n",
      "\n",
      "Work within the company‚Äôs Agile process and systems to prioritize projects into sprints\n",
      "\n",
      "Implement Amazon Cloud (AWS) services for data connectors, ELT, data cleansing, data summarization, and automated data QA\n",
      "\n",
      "Update and create scripts in Python, Node.js, and similar languages\n",
      "\n",
      "Import data from sources including PostgreSQL, Mixpanel, Google Analytics, Amazon Kinesis, and Zendesk\n",
      "\n",
      "Create, monitor, and maintain a job scheduling system\n",
      "\n",
      "Build automated tests to ensure data quality\n",
      "\n",
      "Establish best practices and standards for data definitions and quality\n",
      "\n",
      "Publish and maintain a Data Dictionary, \n",
      "\n",
      "Bachelor‚Äôs degree in computer science, mathematics, engineering or related discipline\n",
      "\n",
      "5+ years of relevant Data Warehouse work experience\n",
      "\n",
      "Track record of building Data Warehouses that enable accurate and easy analyses\n",
      "\n",
      "Exceptional database and schema design skills including Star and Snowflake schema design\n",
      "\n",
      "Master of DDL, DML, and query SQL\n",
      "\n",
      "Ability to scale systems and performance tune\n",
      "\n",
      "PostgreSQL and Mixpanel experience is preferred]\"\n",
      "\"[Passion: The Kinsa team is driven towards a goal that is bigger than themselves, they have a real passion in working toward a solution for a widespread social issue.\n",
      "entry --- Google\n",
      "substring --- Expert in python\n",
      "\n",
      "Expert working with cloud platforms (AWS, Google Cloud, etc)\n",
      "\n",
      "Experience with Airflow or other workflow management software\n",
      "\n",
      "Ability to define data model and data storage strategies, including knowledge of distributed data systems\n",
      "\n",
      "Ability to manage multiple/competing priorities and make the right tradeoffs and timely delivery of features\n",
      "\n",
      "Experience or familiarity with geography, geometry and GIS systems\n",
      "\n",
      "Experience working with satellite/remote imagery\n",
      "\n",
      "Relevant education (Coding Bootcamp, and/or Bachelors in Computer Science) or equivalent experience, \n",
      "\n",
      "WHAT‚ÄôS YOUR STYLE, \n",
      "\n",
      "A developer who loves the speed of a start-up and won‚Äôt quit until the job is done with quality, whatever it takes\n",
      "\n",
      "A team-player with a good sense of humor and the ability to work on multiple projects under a tight schedule\n",
      "\n",
      "Someone with strong communication skills, excellent ability to analyze and diagnose, good planning and work management skills, and great attention to detail, WHAT'S IN IT FOR YOU, \n",
      "\n",
      "The opportunity to join a fast growing startup that is out to disrupt the insurance and real estate markets\n",
      "\n",
      "Competitive salary\n",
      "\n",
      "Generous early stage equity\n",
      "\n",
      "The coolest office space in Jack London\n",
      "\n",
      "Benefits\n",
      "\n",
      "Our culture is awesome!\n",
      "entry --- Google\n",
      "substring --- 2+ years of experience in data ingestion and storage systems for big data environment using at least one of the COTS integration tools, like - Snap Logic, webMethods, TIBCO, Talend, Informatica, and/or custom scripting in Python/Java\n",
      "2+ years of MUST have experience in using Apache Beam / Google Dataflow / Apache Spark in creating end-to-end data pipelines\n",
      "2+ years of data engineering experience with big data environments and writing map-reduce jobs using Java/ Scala or Python.\n",
      "entry --- Google\n",
      "substring --- Experience troubleshooting and taking responsibility for small features, from design to user delivery\n",
      "Enthusiasm for the field and professional development/improvement outside the day to day job\n",
      "2+ years of experience in report development using various reporting tools like Tableau, Power BI, OBIEE\n",
      ", Skills and Abilities, \n",
      "Experience with connecting and integrating with at least one of the platform - Google Cloud, Microsoft Azure, Amazon AWS and/or various Data providers, like - Facebook or Tweeter, API integration and Big Data technologies (Hadoop, Map Reduce)\n",
      "Expert level knowledge in at least 2 of these technologies - Relational Databases, Analytical Databases and NoSQL databases\n",
      "Expert knowledge in SQL development\n",
      "Expertise in building data integration and preparation tools using cloud technologies (like Snap logic, Google Dataflow, Cloud Data prep, Python etc.)\n",
      "entry --- Google\n",
      "substring --- You'll build large scale batch and streaming pipelines across many product lines and datasets, with frameworks like Apache Beam, Storm, and Google Cloud Platform, enabling us to build high impact features for the next generation our indoor location platform.\n",
      "entry --- Google\n",
      "substring --- Programming / Scripting (Python, Java, C/C++, Scala, Bash, Korn Shell)\n",
      "\n",
      "Linux / Windows (Command line)\n",
      "\n",
      "Big Data (Hadoop, Flume, HBase, Hive, Map-Reduce, Oozie, Sqoop, Spark)\n",
      "\n",
      "Cloud Platforms (AWS, Azure, Google Cloud Platform)\n",
      "\n",
      "Data Concepts (ETL, near-/real-time streaming, data structures, metadata and workflow management)\n",
      "\n",
      "Data Integration Tools (Ab Initio, DataStage, Informatica, SSIS, Talend)\n",
      "\n",
      "Databases (DB2, HANA, Netezza, Oracle, Redshift, Teradata, Vertica)\n",
      "\n",
      "Markup Languages (JSON, XML, YAML)\n",
      "\n",
      "Code Management Tools (Git/GitHub, SVN, TFS)\n",
      "\n",
      "DevOps Tools (Chef, Docker, Puppet, Bamboo, Jenkins)\n",
      "\n",
      "Testing / Data Quality (TDD, unit, regression, automation)\n",
      "\n",
      "Solving complex data and technology problems\n",
      "\n",
      "Leading technical teams of 2+ consultants\n",
      "\n",
      "Ability to design components of a larger implementation\n",
      "\n",
      "Excellent communication to narrate data driven insights and technical approach\n",
      "\n",
      "Must reside in the San Francisco, CA bay area\n",
      "]\"\n",
      "\"[\n",
      "\n",
      "Own the entire end-to-end execution from requirements gathering from key stakeholders to building scalable, efficient, and reliable data marts which provide our business partners with clarity into the complexities of our platform\n",
      "\n",
      "Create maintainable, scalable data processing pipelines in PostgresSQL, Python, and other data processing language in the data platform running in AWS\n",
      "\n",
      "Define, develop, and operate functional data marts/cubes with common open source and SaaS based data processing and management tools like embulk, airflow, rundeck, Spark, Informatica, etc.\n",
      "entry --- Google\n",
      "substring --- Orchestrate large PB sized data storage and compute clusters across bare-metal and cloud\n",
      "Deploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform.\n",
      "entry --- Google\n",
      "substring --- Knowledge of distributed systems as it pertains to data storage and computing\n",
      "Strong problem-solving skills and capability to understand and set direction for complex technology integration\n",
      "Experience and/or interest in designing and building Artificial intelligence solutions using third party API‚Äôs such as Microsoft Azure, Amazon Machine Learning, Google ML, IBM Watson etc\n",
      "Experience and/or interest in working with open source eco-system components such as Tensorflow, Scikit learn, Hadoop, Apache Spark, Apache Flume and Apache Kafka.\n",
      "entry --- Google\n",
      "substring --- Required Skills & Experience\n",
      ", \n",
      "\n",
      "Strong python scripting skills\n",
      "\n",
      "Expertise in building out data pipelines and infrastructure\n",
      "\n",
      "Familiarity with AWS\n",
      "\n",
      "Experience with distributed stream processing (Kafka, Spark), \n",
      "\n",
      "Benefits\n",
      ", \n",
      "\n",
      "Strong equity package\n",
      "\n",
      "Medical/dental/vision\n",
      "\n",
      "Mission-driven team]\"\n",
      "\"[\n",
      "Setting up new integrations with external data providers from around the world which often requires detective work, Google Translate-ing, working with meteorologists, and reverse engineering\n",
      "Building reliable and resilient services, that report performance and quality metrics and trigger alerts when things go wrong\n",
      "writing services and utilities that rapidly ensure the quality of the data being received and transforms it into a usable form.\n",
      "entry --- Google\n",
      "substring --- Helping build a storage and caching system that facilitates both a deep archive of data that can explored and fast-moving real-time data that is accessible to thousands of users\n",
      ", \n",
      "Strong experience with scientific Python, particularly NumPy and Pandas\n",
      "Built systems on Linux and cloud platforms, preferably Google Cloud Platform (GCP) or Amazon Web Services (AWS)\n",
      "Worked with both relational databases (preferably Postgres/PostGIS) and some sort of Non-SQL database (preferably MongoDB)\n",
      "Familiarity with automated deployments and continuous integration\n",
      "Knowledge of service-oriented and/or microservice architectures\n",
      "Experience building services that interface via message queues, RPC, or REST interfaces\n",
      "A passion for automated testing\n",
      "Experience with parallel processing systems (joblib, Dask, Ray, Spark, Hadoop)\n",
      ", \n",
      "Bachelor‚Äôs degree in Computer Science, Computer Engineering, or similar, or equivalent experience\n",
      "4+ years of relevant experience\n",
      ", \n",
      "Experience with geospatial data, especially gridded data (GRIB, GeoTIFF, NetCDF, BUFR)\n",
      "Experience with other scientific Python libraries or frameworks (SciPy, sklearn, skimage, xarray, Numba, etc.)\n",
      "entry --- Google\n",
      "substring --- Data is already at the heart of both our ads & subscription businesses and you will be core to our ongoing growth., \n",
      "\n",
      "Our Stack, \n",
      "\n",
      "Custom, high-performance client-side javascript streams data from each users‚Äô browsers into our systems\n",
      "\n",
      "It is collected/enriched by OpenResty/Nginx\n",
      "\n",
      "Streamed into fluentd\n",
      "\n",
      "Streamed to kinesis & elasticsearch\n",
      "\n",
      "Events pushed to Google Analytics, exported to BigQuery, \n",
      "\n",
      "Requirements:, \n",
      "\n",
      "3-5+ years software engineering experience, specifically with:\n",
      "\n",
      "Streaming systems (ideally Fluentd and/or Logstash)\n",
      "\n",
      "ElasticSearch & Kibana\n",
      "\n",
      "Spark, Vowpal Wabbit, Mahout\n",
      "\n",
      "AWS, Docker (ideally docker-compose/convox/ECS)\n",
      "\n",
      "Ruby, OpenResty/Lua, Elixir/Erlang, R and/or Python\n",
      "\n",
      "Strong blend of technical and creative skills\n",
      "\n",
      "Experience working closely with engineering teams, researchers and business leaders\n",
      "\n",
      "Strong communication, and demonstrated ability to contribute to multiple projects, team goals and deadlines\n",
      "\n",
      "Detail oriented, analytical, and experienced with web technologies\n",
      "\n",
      "Experience working with distributed development teams and over communicating about progress and challenges to hit business goals\n",
      "\n",
      "An insatiable appetite to transform education through data., \n",
      "\n",
      "Streaming systems (ideally Fluentd and/or Logstash)\n",
      "\n",
      "ElasticSearch & Kibana\n",
      "\n",
      "Spark, Vowpal Wabbit, Mahout\n",
      "\n",
      "AWS, Docker (ideally docker-compose/convox/ECS)\n",
      "\n",
      "Ruby, OpenResty/Lua, Elixir/Erlang, R and/or Python, \n",
      "\n",
      "About Chegg:, \n",
      "\n",
      "As the leading student-first connected learning platform, Chegg's Student Hub makes higher education more affordable and more accessible, all while improving student outcomes.\n",
      "entry --- Google\n",
      "substring --- You'll build large scale batch and streaming pipelines across many product lines and datasets, with frameworks like Apache Beam, Storm, and Google Cloud Platform, enabling us to build high impact features for the next generation our indoor location platform.\n",
      "entry --- Google\n",
      "substring --- Together, we are on a quest to change banking for good., \n",
      "\n",
      "Senior Data Engineer, We are seeking a leader to help build Capital One‚Äôs next generation of data products and capabilities., \n",
      "\n",
      "On any given day you will:, \n",
      "\n",
      "Provide guidance to business and tech partners on best methods to engineer data processes\n",
      "\n",
      "Build data pipeline frameworks to automate high-volume and real-time data delivery\n",
      "\n",
      "Develop applications from ground up using a modern technology stack such as Scala, Spark, Java, Postgres, Python, Angular JS, and NoSQL\n",
      "\n",
      "Engineer capabilities and pipelines for big data and machine learning solutions\n",
      "\n",
      "Work directly with Product Owners and customers to deliver data products in a collaborative and agile environment, Responsibilities:, \n",
      "\n",
      "Lead and engineer sustainable data driven solutions with current new data technologies to meet the needs of our organization and business customers\n",
      "\n",
      "Recruit, manage, and retain a team of talented engineers\n",
      "\n",
      "Influence peer teams and leadership to ensure our technology culture is one where engineers proudly do their best work every day\n",
      "\n",
      "Raise the bar for technical excellence\n",
      "\n",
      "Master new technologies rapidly as needed to progress varied initiatives\n",
      "\n",
      "Break down complex data issues and resolve them\n",
      "\n",
      "Understand complex multi-tier, multi-platform systems, Basic Qualifications:, \n",
      "\n",
      "Bachelor‚Äôs Degree or military experience\n",
      "\n",
      "At least 3 years of backend software engineering experience\n",
      "\n",
      "At least 1 year of experience in cloud technologies AWS, Azure or Google Cloud, Preferred Qualifications:, \n",
      "\n",
      "Master's Degree\n",
      "\n",
      "1+ years of machine learning experience\n",
      "\n",
      "3+ years of experience with Agile engineering practices\n",
      "\n",
      "3+ years of experience with the Big Data stack EMR, Spark, Databricks\n",
      "\n",
      "3+ years of experience in at least one scripting language Python, Perl, JavaScript, or Shell\n",
      "\n",
      "3+ years of experience with UNIX/Linux, Capital One will not consider sponsoring a new qualified applicant for employment authorization for this position.]\"\n",
      "entry --- Google\n",
      "substring --- Extensive SQL query and R/Python script development experience\n",
      "\n",
      "General consulting skills including: analysis and problem solving, written and verbal communication, and team collaboration\n",
      "\n",
      "Bachelor‚Äôs Degree in a technical field such as Computer Science, Engineering from a four-year-college or university\n",
      ", 2+ year of experience with equivalent Amazon Web or Google Cloud Platform services\n",
      "\n",
      "Experience with NoSQL environments such as Azure Cosmos DB, MongoDB or Cassandra\n",
      "\n",
      "History of working successfully with cross-functional engineering teams\n",
      "\n",
      "Understanding of advanced analytics, machine learning\n",
      "\n",
      "Experience with IoT based solutions\n",
      "\n",
      "]\"\n",
      "\"[Are you excited about being in a start-up and being in the cyber security industry?\n",
      "entry --- Google\n",
      "substring --- Relevant certifications considered but not required., \n",
      "\n",
      "Technical Requirements, \n",
      "Experience with distributed computing technologies including Hadoop, HBase, Cassandra, Elasticsearch and Apache Spark\n",
      "Development experience with Java, C++, Scala, Groovy, Python, and/or shell scripting\n",
      "Experience with data warehousing tools and technologies\n",
      "Ability to work within UNIX/Linux operating systems\n",
      "AWS experience a plus\n",
      ", Company Benefits, \n",
      "6 weeks PTO\n",
      "\n",
      "Paid Overtime\n",
      "Annual Bonuses\n",
      "10% Employer 401k Contribution\n",
      "Health/Vision/Dental/Disability/Life Insurance\n",
      "Annual Training and Tuition Budgets\n",
      "Technology/Fitness/Communications Reimbursement\n",
      "Charity Matching Program\n",
      ", EOE/M/F/Vet/Disabled]\"\n",
      "\"[The Curbside Engineering team is looking for highly motivated engineers to help build the next generation mobile commerce platform., \n",
      "\n",
      "As part of a dynamic team environment you will:, Architect and develop processing pipelines that convert data to useful information consumed by internal and external processesDevelop web services that make data available in real-time for in-product applicationsBuild monitoring and debugging tools to analyze the data pipelinesDesign data schemas and manage operational scalability of data modelsCollaborate with product to build new features and infrastructureMentor junior engineers and provide technical leadership within the development teamParticipate in code reviews and write unit, integration and load tests as necessary, \n",
      "\n",
      "Requirements, Demonstrated proficiency in Python, Clojure, Java or GoHands-on experience with Big Data technologies (e.g Hadoop, Hive, HBase, Spark, Kafka, Storm, Cassandra, Columnar Databases or Graph Databases)Track record working with data from multiple sources ‚Äì willingness to dig-in and understand the data and to leverage creative thinking to deliver resultsStrong database fundamentals including SQL, performance and schema designExperience with cloud computing platforms like AWS, Google Cloud or Microsoft AzureKnowledge of the tooling for deployment, monitoring and site reliabilityAbility to work well in a team environment and be able to effectively drive cross-team solutions that have complex dependencies and requirementsExcellent communication and problem solving skills, MS or BS in Computer Science or related technical field or equivalent practical experience5+ years of industry experience working on building scalable ETL pipelines, data warehousing and schema modeling, \n",
      "\n",
      "Preferred Qualifications, Functional programming experience, All your information will be kept confidential according to EEO guidelines.]\"\n",
      "entry --- Google\n",
      "substring --- Then I have the right opportunity for you!, \n",
      "\n",
      "The Company:, \n",
      "\n",
      "Our Google-backed client has recently closed 30M in funding, located in the Bay Area specializes in autonomous vehicles.\n",
      "entry --- Google\n",
      "substring --- and multithreading\n",
      "\n",
      ", Cloud-based services (Google Cloud, Amazon Web Services)\n",
      "\n",
      ", Relational SQL and NoSQL databases, graphical database (e.g.\n",
      "entry --- Google\n",
      "substring --- Together, we are on a quest to change banking for good., \n",
      "\n",
      "Manager, Data Engineer, We are seeking a leader to help build Capital One‚Äôs next generation of data products and capabilities., \n",
      "\n",
      "On any given day you will:, \n",
      "\n",
      "Provide guidance to business and tech partners on best methods to engineer data processes\n",
      "\n",
      "Build data pipeline frameworks to automate high-volume and real-time data delivery\n",
      "\n",
      "Develop applications from ground up using a modern technology stack such as Scala, Spark, Java, Postgres, Python, Angular JS, and NoSQL\n",
      "\n",
      "Engineer capabilities and pipelines for big data and machine learning solutions\n",
      "\n",
      "Work directly with Product Owners and customers to deliver data products in a collaborative and agile environment, Responsibilities:, \n",
      "\n",
      "Lead and engineer sustainable data driven solutions with current new data technologies to meet the needs of our organization and business customers\n",
      "\n",
      "Recruit, manage, and retain a team of talented engineers\n",
      "\n",
      "Influence peer teams and leadership to ensure our technology culture is one where engineers proudly do their best work every day\n",
      "\n",
      "Raise the bar for technical excellence\n",
      "\n",
      "Master new technologies rapidly as needed to progress varied initiatives\n",
      "\n",
      "Break down complex data issues and resolve them\n",
      "\n",
      "Understand complex multi-tier, multi-platform systems, Basic Qualifications:, \n",
      "\n",
      "Bachelor‚Äôs Degree or military experience\n",
      "\n",
      "At least 3 years of backend software engineering experience\n",
      "\n",
      "At least 1 year of experience in cloud technologies AWS, Azure or Google Cloud, Preferred Qualifications:, \n",
      "\n",
      "Master's Degree\n",
      "\n",
      "1+ years of People Management experience\n",
      "\n",
      "1+ years of machine learning experience\n",
      "\n",
      "3+ years of experience with Agile engineering practices\n",
      "\n",
      "3+ years of experience with the Big Data stack EMR, Spark, Databricks\n",
      "\n",
      "3+ years of experience in at least one scripting language Python, Perl, JavaScript, or Shell\n",
      "\n",
      "3+ years of experience with UNIX/Linux, Capital One will not consider sponsoring a new qualified applicant for employment authorization for this position.]\"\n",
      "entry --- Google\n",
      "substring --- AWS, Google) and on-premise deployments\n",
      "Working knowledge of containers (e.g.\n",
      "entry --- Google\n",
      "substring --- 3+ years of experience architecting, building and administering big data and real-time streaming analytics architectures in both on premises and cloud environments (AWS, Azure, Google) leveraging technologies such as Hadoop, Spark, S3, EMR, Aurora, DynamoDB, Redshift, Neptune, Cosmos DB\n",
      "\n",
      "4+ years of experience architecting, building and administering large-scale distributed applications\n",
      "\n",
      "3+ years of experience with Linux operations and development, including basic commands and shell scripting\n",
      "\n",
      "4+ years of experience with execution of DevOps methodologies and Continuous Integration/Continuous Delivery within a large scale data delivery environment\n",
      "\n",
      "Software development experience in least three or more of following languages: Java, Python, Scala, Node.js\n",
      "\n",
      "Expertise in usage of SQL for data profiling, analysis and extraction, Preferred Qualifications:, \n",
      "\n",
      "2+ years of experience with advanced analytics and machine learning concepts and technology implementations (Tensorflow, H20)\n",
      "\n",
      "3+ years of experience with NoSQL implementations (Mongo, Cassandra, HBase)\n",
      "\n",
      "3+ years of experience implementing serverless architecture leveraging AWS Lambda or similar technology\n",
      "\n",
      "2+ years of experience with data visualization tools such as Tableau and PowerBI\n",
      "\n",
      "Expert understanding of the Hadoop ecosystem (e.g.\n",
      "entry --- Google\n",
      "substring --- 3+ years of experience architecting, building and administering big data and real-time streaming analytics architectures in both on premises and cloud environments (AWS, Azure, Google) leveraging technologies such as Hadoop, Spark, S3, EMR, Aurora, DynamoDB, Redshift, Neptune, Cosmos DB\n",
      "\n",
      "4+ years of experience architecting, building and administering large-scale distributed applications\n",
      "\n",
      "3+ years of experience with Linux operations and development, including basic commands and shell scripting\n",
      "\n",
      "4+ years of experience with execution of DevOps methodologies and Continuous Integration/Continuous Delivery within a large scale data delivery environment\n",
      "\n",
      "Software development experience in least three or more of following languages: Java, Python, Scala, Node.js\n",
      "\n",
      "Expertise in usage of SQL for data profiling, analysis and extraction, Preferred Qualifications:, \n",
      "\n",
      "2+ years of experience with advanced analytics and machine learning concepts and technology implementations (Tensorflow, H20)\n",
      "\n",
      "3+ years of experience with NoSQL implementations (Mongo, Cassandra, HBase)\n",
      "\n",
      "3+ years of experience implementing serverless architecture leveraging AWS Lambda or similar technology\n",
      "\n",
      "2+ years of experience with data visualization tools such as Tableau and PowerBI\n",
      "\n",
      "Expert understanding of the Hadoop ecosystem (e.g.\n",
      "entry --- Google\n",
      "substring --- Expertise with the AWS platform is a plus!, \n",
      "\n",
      "Responsibilities, \n",
      "\n",
      "Build design, develop, test, deploy, maintain and enhance full-stack software solutions\n",
      "\n",
      "Provide technical leadership to the Data Warehouse organization, as well as the Shutterfly teams who use Shutterfly‚Äôs Enterprise Data Warehouse\n",
      "\n",
      "With your technical expertise own and manage project priorities, deadlines and deliverables\n",
      "\n",
      "Always with a customer focus, evangelize the benefits of existing solutions and new technologies to drive the use and push the technology of the Data Warehouse forward\n",
      "\n",
      "Work closely with Data Operations to improve CI/CD pipelines, as well as continually improving the operation and performance of the Data Warehouse\n",
      "\n",
      "Work across multiple teams in high visibility roles and own solutions end-to-end, \n",
      "\n",
      "Qualifications, \n",
      "\n",
      "Expert knowledge of one of the following languages: Python, Java\n",
      "\n",
      "10+ years of hands on experience in software development, including design, implementation, debugging, support, and building scalable system software and/or Services\n",
      "\n",
      "Deep understanding of distributed, message driven systems\n",
      "\n",
      "Strong at applying data structures, algorithms, and object oriented design, to solve challenging problems\n",
      "\n",
      "Experience working with REST and RPC service patterns and other client/server interaction models\n",
      "\n",
      "Experience working in the AWS Services Ecosystem or relevant Cloud Infrastructures such as Google Cloud or Azure\n",
      "\n",
      "Bachelor‚Äôs degree in Computer Science or equivalent]\"\n",
      "\"[Extensive experience building RESTful APIs, preferably in Java 8/J2EE., Expertise with micro services design and development, including API and cloud based platforms and technologies such as containers a plus., Write code and set coding standards / best practices within the team.\n",
      "entry --- Google\n",
      "substring --- \"[\n",
      "Languages: Python\n",
      "Batch and Stream Processing with Beam, Data Bricks, Dataflow, Kinesis, BigTable\n",
      "Data Warehousing: BigQuery, Google Storage\n",
      "Experience building and managing efforts in both batch and streaming data processing pipelines with technology like Beam, Spark, etc.\n",
      "entry --- Google\n",
      "substring --- Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]\n",
      "\"[Design, construct, install, test and maintain highly scalable data management systems\n",
      "Bring structure to large, disparate sources of data ranging from highly structured market data through to fully unstructured text\n",
      "Build high-performance algorithms, prototypes, predictive models and proof of concepts\n",
      "Design and structure a research environment flexible enough for creative research whilst stable enough to generate investment ideas\n",
      "Integrate new data management technologies and software engineering tools into existing structures\n",
      "Recommend ways to improve data reliability, efficiency and quality\n",
      "Collaborate with data analysts and modelers on project goals, Python\n",
      "Database architectures and storage structures (Parquet)\n",
      "Hadoop-based technologies (Spark, HDFS)\n",
      "Analytics workbenches (Jupyter, AWS Sagemaker, Domino Data Lab)\n",
      "Data mining, statistical analysis and machine learning (Pandas, Keras)\n",
      "Docker containers\n",
      "AWS and Google Cloud, Creative Problem-Solving: Approaching data organization challenges with a clear eye on what is important; employing the right approach/methods to make the maximum use of time and human resources.\n",
      "entry --- Google\n",
      "substring --- , \n",
      "\n",
      "Responsibilities, \n",
      "\n",
      "You will design and develop Data life cycle management such as Ingestion, pipeline development, data at rest strategy, Archive and Migration solution\n",
      "\n",
      "Work with the Chief Architect and other engineering groups to align with company product design paradigm\n",
      "\n",
      "Provide design mentorship and review the work of other specialists\n",
      "\n",
      "Able to work with Nutanix Global (mainly India and USA) engineering and multi-functional team, \n",
      "\n",
      "Qualifications and Experience, \n",
      "\n",
      "BS/MS degree in Computer science or equivalent (PhD degree a plus)\n",
      "\n",
      "8+ years of product platform development with 4+ years of data life cycle management\n",
      "\n",
      "Experience with building a data pipeline development framework\n",
      "\n",
      "Hands-on development in at least one of the programming languages: Java, Python/Golang and C++\n",
      "\n",
      "Knowledge of storage/file system and its meta data\n",
      "\n",
      "Strong development experience in Linux/Unix OS platform\n",
      "\n",
      "Hands-on experience working with version control / DevOps tools ‚Äì Git, Gerrit and Jenkins, \n",
      "\n",
      "Pluses, \n",
      "\n",
      "Understanding of any of the cloud computing technology ‚Äì AWS / Google Cloud / Azure / VMWare\n",
      "\n",
      "Knowledge in any of the area such as - Splunk, Spark, Kafka, Elasticsearch and its component, Apache/Tomcat server, Flask framework is a plus\n",
      "\n",
      "Experience in Message Bus (RabbitMQ, Kafka), Elastic Search, Cassandra and Zookeeper.\n",
      "entry --- Google\n",
      "substring --- RPC, REST, JSON, XML, SOAP)\n",
      "\n",
      "Experience with NoSQL databases and key-value stores, such as Cassandra, Redis, \n",
      "\n",
      "Experience with recommender, or search/ranking systems\n",
      "\n",
      "Experience with Kafka and Yarn or Mesos\n",
      "\n",
      "Experience with AWS services (Athena, Glue, Redshift, Kinesis) or Google cloud services (BigQuery, BigTable)\n",
      "\n",
      "BA/BS or above in Computer Science or a related field]\"\n",
      "\"[\n",
      "Build scalable and reliable near real time data pipeline on cloud (AWS and GCP) that collects, transforms, loads and curates data from various internal and external data sources\n",
      "Build a scalable distributed data store that will be central source of truth\n",
      "Own data quality for the pipelines you build and make them auditable\n",
      "Build self service tools that helps our data consumers to extract, analyze and visualize data faster\n",
      "Evaluate new technologies and build prototypes for continuous improvements in Data Engineering\n",
      "Partner with Infrastructure and Engineering teams to ensure instrumentation, logging and monitoring is in place\n",
      "Implement Machine learning algorithms\n",
      ", \n",
      "Extensive experience in using big data technologies such as Spark, Kafka, Hadoop, HBase and Hive or their equivalents\n",
      "Experience with AWS and/or GCP\n",
      "5+ years of experience with Java, Scala and Python\n",
      "5+ years of experience with SQL (MySQL, Redshift, etc)\n",
      "3+ years of experience in building and monitoring near real time scalable ETL pipelines\n",
      "Experience with shell scripting\n",
      "Excellent written and verbal communication skills\n",
      "BS or MS in Computer Science or related technical field\n",
      ", \n",
      "Experience with Machine learning algorithms will be a huge plus.\n",
      "entry --- Google\n",
      "substring --- If you are a Senior Engineer or Manager, looking for a step up and the chance to really make an impact on businesses across the nation, this could be the role for you., \n",
      "\n",
      "The Role:, \n",
      "\n",
      "As Analytics Engineer Manager, your responsibilities will include:, \n",
      "\n",
      "Mentor and lead data engineers\n",
      "\n",
      "Participate in strategic discussions for continued advancement of data infrastructure\n",
      "\n",
      "Design, build and launch robust data pipelines and platform to ingest data and deployment of ML products/model\n",
      "\n",
      "Design, build and launch highly scalable analytic tools\n",
      "\n",
      "Partner with other teams and intern stakeholder to gather requirements, \n",
      "\n",
      "Your Skills & Experience:, \n",
      "\n",
      "Bachelor's degree or high qualification in Computer Sciences or relevant degree\n",
      "\n",
      "Production level code in Python is a must\n",
      "\n",
      "Strong commercial experience in Spark and Kafka is essential\n",
      "\n",
      "Experience with Google Cloud Platform or AWS is a must\n",
      "\n",
      "Strong communication skills\n",
      "\n",
      "Demonstrable ability to work with real-time data sets and reducing latency, \n",
      "\n",
      "Benefits:, \n",
      "\n",
      "Salary is $150,000 - $180,000, + bonus + equity]\"\n",
      "\"[Senior Data Engineer, \n",
      "\n",
      "San Francisco Bay Area, CA, \n",
      "\n",
      "$160,000 - $180,000 + Bonus + Equity + Benefits, \n",
      "\n",
      "Feel that your everyday work is not making a big impact on people's lives?\n",
      "entry --- Google\n",
      "substring --- , Require Skills & Experience:, \n",
      "\n",
      "Bachelor's or Master's degree in Electrical or Mechanical Engineer or Physics\n",
      "\n",
      "Strong experience with Apache Spark/Spark streaming\n",
      "\n",
      "Experience building out pipelines for API's\n",
      "\n",
      "Experience in production level code\n",
      "\n",
      "Experience working in the cloud (AWS or Google)\n",
      "\n",
      "Kafka experience a plus, \n",
      "\n",
      "Benefits:, \n",
      "\n",
      "$160,000 - $180,000\n",
      "\n",
      "New amazing office\n",
      "\n",
      "Full medical, dental, vision]\"\n",
      "\"[\n",
      "\n",
      "Work with your team to determine product direction and customer needs\n",
      "\n",
      "Develop and improve the service layers that connect the data backend to web apps\n",
      "\n",
      "Share knowledge, methodologies and best practices amongst the product engineering team and other teams\n",
      "\n",
      "Participate in a team-wide on-call rotation to keep the systems ticking along\n",
      "\n",
      "Mentor Software Engineers and Interns, \n",
      "\n",
      "Bachelor's or Master‚Äôs degree in Computer Science, related field and 5+ years of software development experience\n",
      "\n",
      "Exceptional experience in programming with Java.\n",
      "entry --- Google\n",
      "substring --- The Google-backed company is expanding their engineering efforts to enable more precise weather forecasting.\n",
      "entry --- Google\n",
      "substring --- Programming / Scripting (Python, Java, C/C++, Scala, Bash, Korn Shell)\n",
      "\n",
      "Linux / Windows (Command line)\n",
      "\n",
      "Big Data (Hadoop, Flume, HBase, Hive, Map-Reduce, Oozie, Sqoop, Spark)\n",
      "\n",
      "Cloud Platforms (AWS, Azure, Google Cloud Platform)\n",
      "\n",
      "Data Concepts (ETL, near-/real-time streaming, data structures, metadata and workflow management)\n",
      "\n",
      "Data Integration Tools (Ab Initio, DataStage, Informatica, SSIS, Talend)\n",
      "\n",
      "Databases (DB2, HANA, Netezza, Oracle, Redshift, Teradata, Vertica)\n",
      "\n",
      "Markup Languages (JSON, XML, YAML)\n",
      "\n",
      "Code Management Tools (Git/GitHub, SVN, TFS)\n",
      "\n",
      "DevOps Tools (Chef, Docker, Puppet, Bamboo, Jenkins)\n",
      "\n",
      "Testing / Data Quality (TDD, unit, regression, automation)\n",
      "\n",
      "Solving complex data and technology problems\n",
      "\n",
      "Leading technical teams of 2+ consultants\n",
      "\n",
      "Ability to design components of a larger implementation\n",
      "\n",
      "Excellent communication to narrate data driven insights and technical approach\n",
      "]\"\n",
      "\"[Senior Data Engineer- E-commerce Start-Up, \n",
      "\n",
      "San Francisco, Bay Area, \n",
      "\n",
      "$1650,000-$185,000 (cap varies by expertise) + equity, \n",
      "\n",
      "Will support Visa transfer, \n",
      "\n",
      "Harnham has partnered with a dominant San Francisco based start-up that has been taking over a trillion dollar U.S. market by storm.\n",
      "entry --- Google\n",
      "substring --- , Understand the capabilities of our current system and enhance it to support the capabilities of this new pipeline\n",
      "Work with other groups within the organization to set up and configure big data clusters and assist with data volumetrics as well as hardware and software needs\n",
      "Research, design and assist in building tools that can be utilized to analyze the data by internal users and support staff\n",
      "Maintain systems to ensure they are highly available\n",
      ", 3+ years of current Java development experience\n",
      "Proven experience with a range of big data architectures, including Hadoop, HBase or other big data frameworks\n",
      "Experience building large scale distributed data processing systems\n",
      "Solid understanding of data structures, algorithms & object-oriented design concepts\n",
      "A passion for big data technologies and a flexible, creative approach to problem solving\n",
      "Excellent communication skills\n",
      ", Experience with languages such as Python/Perl\n",
      "Experience developing software using agile methodologies\n",
      "Working knowledge of development tools such as debuggers, memory profilers, and performance analysis\n",
      ", Apply Now]\"\n",
      "\"[Located in Pleasanton, this predictive analytics start-up that uses machine learning models and their client's CRM data to provide sales and marketing insights is looking for a hands-on contractor with expertise in Hadoop and Java to join their team for up to 18 months., In this role, you'll be working very hands-on with both the Hadoop and Spark ecosystems, Java, and Google's Cloud Platform to support the big name clients of this company.\n",
      "entry --- Lawrence Livermore National Laboratory\n",
      "substring --- \"[Science and Technology on a Mission!, \n",
      "\n",
      "For more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., We are looking for a Postdoctoral Researcher to perform research in the area of data analysis and machine learning with a goal to develop new techniques, analyze and steer multi-scale simulations in a large-scale parallel workflow.\n",
      "entry --- Lawrence Livermore National Laboratory\n",
      "substring --- Eligible candidates are recent PhDs within five years of the month of the degree award at time of hire date., About Us, \n",
      "\n",
      "Lawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE).\n",
      "entry --- Lawrence Livermore National Laboratory\n",
      "substring --- DOD Secret Clearance preferred]\"\n",
      "\"[\n",
      "CB\n",
      "]\"\n",
      "\"[Science and Technology on a Mission!, \n",
      "\n",
      "For more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., We have multiple openings for Postdoctoral Research Staff Members to engage in the research, design, and deployment of machine learning and statistical methods to solve important data and science problems stemming from the Laboratory's mission spaces.\n",
      "entry --- Lawrence Livermore National Laboratory\n",
      "substring --- Eligible candidates are recent PhDs within five years of the month of the degree award at time of hire date., About Us, \n",
      "\n",
      "Lawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE).\n",
      "entry --- Lawrence Livermore National Laboratory\n",
      "substring --- \"[Science and Technology on a Mission!, \n",
      "\n",
      "For more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., Research, design, implement and apply a variety of advanced data science methods in multiple application areas (such as material science, high energy physics, predictive medicine, cybersecurity, climate modeling) in a collaborative scientific environment.Identify and define moderately complex problems stemming from national security applications; scope, plan, and propose advanced analysis methodologies; collect and analyze data; and document results in technical reports and peer-reviewed publications.Consult with programmatic sponsors and funding agencies and foster research collaborations with academia and industry.Author grant proposals, including proposal presentations and preparation of proposals.Perform other duties as assigned., Conduct independent research projects to establish future research directions.Lead small to mid-sized projects in advanced data science methodologies and tools and their application to mission-related science, serving as a primary technical contact., Ph.D. in Computer Science, Statistics, Machine Learning, Mathematics or related field or the equivalent combination of education and related experience.Experience working in a collaborative, multidisciplinary, scientific environment and contribute to diverse application areas.Broad experience developing, implementing, and applying advanced statistical and machine learning models and algorithms.Demonstrated research ability, as documented by publications, reports, and presentations.Broad analytical and problem-solving skills necessary to craft creative solutions and solve complex problems with limited direction.Comprehensive programming skills in at least one prototyping language Python/R/MATLAB, as well as one of C/C++/Fortran to enable high-dimensional data analysis on high performance computing (HPC) platforms.Proficient verbal and written communication skills to effectively collaborate in a team environment, to present and explain technical information, document work, prepare and present proposals and research papers, and provide advice to management., Record of successful proposal writing and program development, and experience leading research and development in support of programs or R&D.\n",
      "entry --- Lawrence Livermore National Laboratory\n",
      "substring --- Lab employees and external candidates may be considered for these positions., About Us, \n",
      "\n",
      "Lawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE).\n",
      "entry --- Splunk\n",
      "substring --- At Splunk, we‚Äôre committed to our work, customers, having fun and most importantly to each other‚Äôs success.\n",
      "entry --- Splunk\n",
      "substring --- Learn more about Splunk careers and how you can become a part of our journey!, Splunk is looking for highly motivated college students to join our team.\n",
      "entry --- Splunk\n",
      "substring --- As an intern, you will work on a real project (or a few) and have an opportunity to enjoy our dynamic, startup-like environment., \n",
      "\n",
      "You will experience Splunking and what defines our culture while honing the skills which separate our development teams from others.\n",
      "entry --- Splunk\n",
      "substring --- Our goal is both to support your growth and development while empowering you for a successful start to your career., \n",
      "\n",
      "As a Machine Learning Intern you will be responsible for ‚Ä¶, \n",
      "\n",
      "Achieving data science and software engineering goals set by you and your mentor\n",
      "\n",
      "Learning about Splunk, both the product and the company\n",
      "\n",
      "Working and socializing with the other interns as well as full-timers, Minimum Qualifications:\n",
      "\n",
      ", Strong interest in state-of-art Machine Learning techniques.\n",
      "entry --- Splunk\n",
      "substring --- Splunk flourishes with disruption and diversity.\n",
      "entry --- Splunk\n",
      "substring --- Familiarity with Big Data tools such as Splunk, Hadoop, Spark, etc.\n",
      "entry --- Splunk\n",
      "substring --- \"[\n",
      "Experience with designing and implementing machine learning, data mining, statistics, or graph algorithms in an academic or professional work environment\n",
      "Experience with Splunk\n",
      "Experience with Tableau\n",
      "Ability to program in an object-oriented language, including Java or C++ and Python\n",
      "Ability to obtain a security clearance\n",
      "BA or BS degree in Statistics, Mathematics, CS, or EE\n",
      ", \n",
      "Experience with the development of Hadoop, MapReduce, or HDFS\n",
      "MA or MS degree a plus\n",
      "]\"\n",
      "\"[Position Description, \n",
      "\n",
      "A Staff Data Scientist is responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions.\n",
      "entry --- Splunk\n",
      "substring --- Proficiency with SQL like relational database technology\n",
      "\n",
      "Experience using one or more advanced analytic software: numpy, scipy, pandas, R, SPARK\n",
      "\n",
      "Experience with one or more data storage and manipulation technology:Hadoop, Azure Data Lake\n",
      "\n",
      "Demonstrates the ability to transform ambiguous business problem to a technical problem and communicate the technical result to non-technical audience\n",
      "\n",
      "Self-driven and demonstrates the ability to drive project across multi-discipline teams, \n",
      "\n",
      "Data engineering experience is highly desirable\n",
      "\n",
      "Experience with a general-purpose programming language (C++, C#, Java, javascript) is a plus\n",
      "\n",
      "Industry Experience with one or more of the deep learning frameworks (CNTK, MXNet, TensorFlow, Caffe/Caffe2, PyTorch) is a plus\n",
      "\n",
      "Experience with the following is a plus: Splunk, Azure Kusto, Azure Machine Learning Studio and TLC, Jupyter]\"\n",
      "\"[Partners with our Marketing Engagement, In-Product Discovery, and Machine Learning Teams to drive cross-sell, upsell and retention outcomes\n",
      "\n",
      "Creates and deploys advanced statistical models and analyses from relational data sources to power initiatives and programs\n",
      "\n",
      "Presents technical findings in a summarized form to non-technical audiences; translates complex quantitative data into succinct actionable insights\n",
      "\n",
      "Designs, implements and measures results for A/B and multivariate tests; drives end to end test process from launch, to readout, to recommendation, to retest\n",
      "\n",
      "Measures and reports on actual performance vs target; performs analysis to identify root cause drivers of variances\n",
      "\n",
      "Develops and maintains reports and dashboards to track performance\n",
      "\n",
      "Conducts research projects, including surveys, to produce actionable customer insights\n",
      "\n",
      "Works with members of multiple departments to understand processes, data and reporting requirements, At least 2 years of experience in an analytical role in a business environment.\n",
      "entry --- Splunk\n",
      "substring --- Experience with Distributed Data platforms (HDFS, Elasticsearch, Splunk, Casandra).\n",
      "entry --- Splunk\n",
      "substring --- Education\n",
      "\n",
      "\n",
      "Bachelors or above in Operations Research, Math, Statistics, Computer Science, Physics and Economics\n",
      "]\"\n",
      "\"[\n",
      "5+ years of experience\n",
      "Predictive modeling (eg: neural networks, logistic regression, variable reduction, imputation)\n",
      "Statistical Analysis with R, Python, or other scripting language\n",
      "Linux command line (eg: Bash, AWK, Perl, Sed)\n",
      "Familiar with RDBMS concepts\n",
      "Data visualization (eg: ggplot, Python, Splunk, Tableau, Excel)\n",
      "Proven quick self-directed learner\n",
      "Good communication skills\n",
      "Team Player\n",
      "BA or BS in Math, Computer Science, Engineering, Physics, or a related field\n",
      "Exposure to the areas of AI, ML, and Data Science with an ability and desire to grow\n",
      ", \n",
      "Machine learning libraries (eg: Tensor Flow, Keras)\n",
      "Hadoop (Hive, Impala, MapReduce)\n",
      "Cloud (AWS, Azure)\n",
      "IT Infrastructure Engineering exposure\n",
      "Regular expressions\n",
      "Infrastructure components (e.g.\n",
      "entry --- Splunk\n",
      "substring --- Diagnosis and Tuning experience, with Applications or Infrastructure Components\n",
      "Predictive modeling (eg: Bayesian inference, time series forecasting, signal detection, queuing optimization, clustering, survival analysis)\n",
      "Splunk Machine Learning Toolkit, Data visualization in Splunk\n",
      "Ability to code in an Object Oriented Language such as Java or C++\n",
      "Data transformation and Conformal Mapping/Decomposition\n",
      "]\"\n",
      "\"[\n",
      "Work with your team members (analysts, developers, project managers and data scientists) to understand the problem space and design a solution that meets the customer's needs\n",
      "Work directly with the customer to gain information and share results\n",
      "Provide technical/analytics leadership\n",
      "Perform data assessment, cleaning, and analysis\n",
      "Develop the analytics required for the solution\n",
      "Create production-ready code, test, document and deploy\n",
      ", \n",
      "MS or PhD in quantitative discipline (e.g.\n",
      "entry --- Splunk\n",
      "substring --- \"[\n",
      "access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "a chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\n",
      "participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      ", \n",
      "Experience in working with R and Python\n",
      "Experience in working with Tableau and Microsoft packages\n",
      "Ability to develop, test, and implement a data, as needed\n",
      "Ability to work with data workflow via SQL queries\n",
      "Ability to work with Java and MATLAB\n",
      "Ability to obtain a security clearance\n",
      "Scheduled to obtain a BA or BS degree in Winter 2018 or Spring 2019\n",
      "]\"\n",
      "\"[Take data driven decisions through experimentation.\n",
      "entry --- Splunk\n",
      "substring --- \"[\n",
      "access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "a chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\n",
      "participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      ", \n",
      "Experience with statistical analysis, modeling and simulation\n",
      "Experience programming in Matlab, R, Python, or other statistical and mathematical language\n",
      "Ability to interpret results and disseminate results to a non-technical audience\n",
      "Ability to work closely with people of various quantitative and qualitative backgrounds\n",
      "Ability to explore academic research and apply and modify it to meet the needs of the client\n",
      "TS/SCI clearance\n",
      "BA or BS degree in mathematics, statistics, operations research, or other quantitative field\n",
      ", \n",
      "Knowledge of human factors methods is a plus\n",
      "Possession of excellent analytic skills\n",
      "]\"\n",
      "\"[Develop in-depth knowledge of several Staples business processes and systems environment\n",
      "Work closely with key business partners to understand critical, complex, data-driven business and operations challenges, and then apply analytical methods to solve them ‚Äì resulting in a significant, positive impact on the Staples‚Äô bottom-line.\n",
      "entry --- Splunk\n",
      "substring --- Excellent communication skills\n",
      "\n",
      "Self-motivated, proactive, and able to work cooperatively in a team environment, \n",
      "\n",
      "Additional consideration given to candidates who bring experience with, or understanding of:, \n",
      "\n",
      "Managing and manipulating large data sets\n",
      "\n",
      "C#, Java, .Net, Tomcat\n",
      "\n",
      "Networking and/or mobile systems (TCP/IP stack, cellular, Wi-Fi, Android, iOS)\n",
      "\n",
      "Security (SIEM, UEBA, VPNs)\n",
      "\n",
      "Cloud deployment system (AWS, Azure, Google) and/or microservice architectures\n",
      "\n",
      "Splunk, Splunk MLT a plus, \n",
      "\n",
      "Who We Are:\n",
      "\n",
      "\n",
      "For over 17 years, we‚Äôve worked with a simple philosophy: help the connected world move more smoothly, seamlessly and productively.\n",
      "entry --- Splunk\n",
      "substring --- \"[Splunk‚Äôs Guild of Data Science has been tasked with helping Splunk build smarter software and make data-driven decisions.\n",
      "entry --- Splunk\n",
      "substring --- You will contribute to Splunk‚Äôs privacy and compliance efforts.\n",
      "entry --- Splunk\n",
      "substring --- Schedule, facilitate and provide training in support of compliance auditing activities., Demonstrated experience with Splunk, creating scripts to pull identified data from Splunk on an ongoing or recurrent basis; and monitoring application and server logs to ensure continued logging to Splunk., Demonstrated experience coding/scripting in one or more of the following: Perl, Python, HTML, SQL, or JavaScript., Working knowledge of appropriate analytic methods and methodological tools in one or more of the following areas, a.)\n",
      "entry --- Splunk\n",
      "substring --- At Splunk, we‚Äôre committed to our work, customers, having fun and most importantly to each other‚Äôs success.\n",
      "entry --- Splunk\n",
      "substring --- Learn more about Splunk careers and how you can become a part of our journey!, \n",
      "\n",
      "The Data Scientist role involves working on all the stages of the data science pipeline, including acquiring and understanding the data, modeling various algorithms, performing evaluation of the performance of algorithms, and also implementing these solutions in a commercial product either as standalone code or in existing ML frameworks like Spark/MLlib., \n",
      "\n",
      "You will become an expert on the product data, including how it is collected and processed\n",
      "\n",
      "You will explore the data and answer questions about the data to improve our understanding of the potential of the data\n",
      "\n",
      "You will closely interact with product management and engineering to derive requirements for what solutions should be implemented in the product\n",
      "\n",
      "You will rapidly prototype, and evaluate statistical and machine learning solutions\n",
      "\n",
      "You will collaborate with engineering to implement these solutions in production\n",
      "\n",
      "You will communicate your results and explain your solutions to technical and non-technical stakeholders, \n",
      "\n",
      "You have experience with Python scikit-learn, Spark/MLlib, or an equivalent framework ‚Äì required\n",
      "\n",
      "You have the ability to code in Python, Java or Scala - required\n",
      "\n",
      "You have the ability to evaluate and tune statistical and machine learning solutions ‚Äì required\n",
      "\n",
      "You have experience working with large datasets, preferably using tools like SQL, Spark, Hadoop, MapReduce, Pig, or Hive ‚Äì preferred, \n",
      "\n",
      "A constant stream of new things for you to learn.\n",
      "entry --- Splunk\n",
      "substring --- \"[\n",
      "Access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "A chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\n",
      "Participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      ", \n",
      "2+ years of experience with one or more scripting or scientific languages, including Python, R, C++ or Java\n",
      "2+ years of experience in working with a wide range of predictive and decision models and tools for developing such models\n",
      "2+ years of experience with Big Data programming technologies, including Hadoop, Spark, MapReduce, Accumulo, Cassandra, HBase, R, Mahout, Pig, or Hive\n",
      "2+ years of experience with applying various machine learning techniques and understanding the key parameters that affect their performance\n",
      "Experience with Microsoft Excel and Access\n",
      "Knowledge of relevant statistical measures, including confidence intervals, significance of error measurements, and development and evaluation data sets\n",
      "Ability to obtain a security clearance\n",
      "BS degree\n",
      ", \n",
      "Experience with using statistical software applications, including SAS, R, MATLAB, SPSS, or Stata\n",
      "Experience with developing statistical and simulation models\n",
      "Experience in one or more natural language processing topics, including tagging, syntactic parsing, word sense disambiguation, topic modeling, contextual text mining, and application of deep learning to NLP\n",
      "Experience with developing experimental and analytic plans for data modeling processes, use of excellent baselines, and determine cause and effect relationships accurately\n",
      "BS degree in Operations Research, Data Science, Applied Mathematics, CS, Engineering, or a related technical field preferred; MS degree in Operations Research, Data Science, Applied Mathematics, CS, Physics, Statistics, Engineering, or a related technical field a plus\n",
      "]\"\n",
      "\"[OVERVIEW, \n",
      "\n",
      "As a member of our R&D organization, your work will directly and rapidly impact our award winning Conversant One-to-One Relationship Engine.\n",
      "entry --- Splunk\n",
      "substring --- on-time and in-budget delivery.Experience with BI / Big-data solutions (Splunk / Hadoop) is a plusExperience with Microservice development in SpringCloud is a plusExperience with Angular development is a plus.Experience in and understanding of a wide variety of telemetric processes (governance, measurement, etc.\n",
      "entry --- Splunk\n",
      "substring --- \"[\n",
      "access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "a chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\n",
      "participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      ", \n",
      "8+ years of experience with data science and analytics\n",
      "Experience with analytics project management\n",
      "E xperience with federal health market and finance agencies\n",
      "Experience with using R or Python to analyze data and create data-driven visualizations\n",
      "Knowledge of machine learning, data mining, and statistics\n",
      "Ability to integrate data environments, including SQL, HDFS, or Hadoop into analytics workflows\n",
      "Ability to create reports and present findings based on statistical analysis and develop persistent monitoring applications for statistical or machine learning processes\n",
      "Ability to obtain a security clearance\n",
      "MA or MS degree in Mathematics, Statistics, or CS\n",
      "]\"\n",
      "\"[As a SENIOR DATA SCIENTIST within our Personalized HealthCare (PHC) function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access., You will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions.\n",
      "entry --- Splunk\n",
      "substring --- on-time and in-budget delivery.Experience with BI / Big-data solutions (Splunk / Hadoop) is a plusExperience with Microservice development in SpringCloud is a plusExperience with Angular development is a plus.Experience in and understanding of a wide variety of telemetric processes (governance, measurement, etc.\n",
      "entry --- Splunk\n",
      "substring --- Experience developing advanced analytic queries using Spark, MapR, Splunk or Elk., \n",
      "\n",
      "Even better if you have:, \n",
      "\n",
      "Master‚Äôs degree in Computer Science, Cybersecurity, Mathematics or equivalent.\n",
      "entry --- Splunk\n",
      "substring --- Experience developing advanced analytic queries using Spark, MapR, Splunk or Elk., \n",
      "\n",
      "Even better if you have:, \n",
      "\n",
      "Master‚Äôs degree in Computer Science, Cybersecurity, Mathematics or equivalent.\n",
      "entry --- Splunk\n",
      "substring --- Passion for Rockstar Games and our titles., \n",
      "\n",
      "Experience with Vertica, Splunk and Hadoop, an asset.\n",
      "entry --- Splunk\n",
      "substring --- \"[\n",
      "access to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\n",
      "a chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\n",
      "participation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\n",
      ", \n",
      "Experience with machine learning, data mining, statistics, or graph algorithms in an academic environment or internship\n",
      "Experience with using R, Perl, Python, SAS, or SPSS for data analysis\n",
      "Knowledge of an object-oriented language, including Java, C++, C#, or Python\n",
      "Knowledge of Hadoop, MapReduce, or HDFS\n",
      "Ability to obtain a security clearance\n",
      "BA or BS degree\n",
      ", \n",
      "MA or MS degree preferred; PhD degree a plus\n",
      "]\"\n",
      "\"[\n",
      "Solid understanding of machine learning algorithms and principles\n",
      "Strong hands-on coding skills including prototyping languages such as Python and Java\n",
      "Great team player with excellent communication skills\n",
      "MS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields with strong mathematical background\n",
      "Experience with probabilistic models, time series, deep neural networks, supervised and unsupervised learning, natural language processing.\n",
      "entry --- Splunk\n",
      "substring --- Self-motivated, work well both independently and as part of an agile team., \n",
      "\n",
      "Preferred Experience:, \n",
      "\n",
      "Master‚Äôs degree required in a quantitative discipline such as Mathematics, Statistics, Economics, Engineering, Operations Research, Computer Science\n",
      "\n",
      "Preferred experience with console development for current platforms\n",
      "\n",
      "Have a clear understanding of Big Data tools mainly being Splunk, Hadoop, and Spark\n",
      "\n",
      "Experience with Visualization tools and platforms., \n",
      "\n",
      "Crystal Dynamics is an EOE and M/F/D/V employer.]\"\n",
      "entry --- Splunk\n",
      "substring --- Passion for Rockstar Games and our titles., \n",
      "\n",
      "Experience with Vertica, Splunk and Hadoop, an asset.\n",
      "entry --- Splunk\n",
      "substring --- Expert command of statistical analysis, algorithm development, and state-of-the-art tools and methodologies for data science\n",
      "\n",
      "5+ years creating predictive models using advance machine learning techniques\n",
      "\n",
      "2+ years managing a team of data scientists\n",
      "\n",
      "Expert command of SQL and R or Python as applied to data science\n",
      "\n",
      "Experience developing real-time production data pipelines\n",
      "\n",
      "Experience interacting with external clients is a plus, \n",
      "\n",
      "Perks and benefits:, \n",
      "\n",
      "People ‚Äì the best part of Zest\n",
      "\n",
      "Robust healthcare plans, matching 401K and unlimited vacation time\n",
      "\n",
      "Dog friendly office with lounge areas, video games and gigantic jigsaw puzzles\n",
      "\n",
      "On-site gym with yoga, salsa and other employee run fitness classes\n",
      "\n",
      "Generous family leave policy (6 month maternity leave/3 month paternity leave)\n",
      "\n",
      "Tuition reimbursement, conference allowance and Zest talks\n",
      "\n",
      "Complimentary massages, manicures, pedicures and more\n",
      "\n",
      "Daily catered lunches from LA‚Äôs best restaurants and fully stocked kitchen]\"\n",
      "\"[\n",
      "\n",
      "At least 3 years industry experience working as a full-time Data Scientist designing and implementing predictive models written in Python\n",
      "\n",
      "Seasoned in feature selection and feature engineering\n",
      "\n",
      "Experience training, tuning and optimizing ML models using scikit-learn\n",
      "\n",
      "Experience training, tuning and optimizing ML models using TensorFlow\n",
      "\n",
      "Experience defining, evaluating measuring the performance of competing models\n",
      "\n",
      "Experience partnering with ML Engineers to productionize models you have built, \n",
      "\n",
      "Experience building recommender systems\n",
      "\n",
      "Experience training models leveraging GPU driven frameworks\n",
      "\n",
      "Experience training models using Google Cloud ML or AWS SageMaker\n",
      "\n",
      "Experience optimizing models for production deployment\n",
      "\n",
      "Experience data mining using Splunk]\"\n",
      "\"[\n",
      "Advanced degree in machine learning or related field, or equivalent experience\n",
      "Experience applying machine learning techniques to real-world problems\n",
      "Comfort analyzing large, complex, high-dimensional datasets\n",
      "Ability to quickly assess a problem both qualitatively and quantitatively\n",
      "Strong passion for empirical research and answering hard questions with data\n",
      "Ability to present results and describe techniques in both technical and non-technical contexts\n",
      "Strong SQL skills\n",
      "Fluency in at least one scripting language, such as Python or Perl\n",
      "3 - 6 years of professional experience\n",
      ", \n",
      "Ph.D. in machine learning or related field\n",
      "Experience with Hadoop, HDFS, Pig, Hive, Spark, Impala\n",
      "Significant experience using a statistical computing package such as Python/Pandas/Scikitlearn, R, or MATLAB\n",
      "]\"\n",
      "\"[We are seeking professionals who are well versed in scalable data mining, machine learning techniques, and love to build analytics models.\n",
      "entry --- Splunk\n",
      "substring --- At Splunk, we‚Äôre committed to our work, customers, having fun and most meaningfully to each other‚Äôs success.\n",
      "entry --- Splunk\n",
      "substring --- Learn more about Splunk careers and how you can become a part of our journey!, \n",
      "\n",
      "The Data Scientist role involves working on all the stages of the data science pipeline, from acquiring and understanding the data, modeling various algorithms, performing evaluation of the performance of algorithms but also implementing these solutions in a commercial product either as standalone code or in existing ML frameworks like Spark/MLib.\n",
      "entry --- Splunk\n",
      "substring --- Understanding of PKI and PKI/E using CAC, SSL/TLS, OpenSSL, NSS\n",
      "\n",
      "Network and System Monitoring: Nagios/Icinga2, Splunk, Elastic Search, LogStash, Kibana, syslog, syslog-ng, rsyslog, snmp\n",
      "\n",
      "Server/Node Provisioning: Red Hat Kickstart, Windows Imaging Format (WIM), Cobbler, PXE, Packer, CloudFormation, SaltStack, Puppet, Chef, Ansible\n",
      "\n",
      "Firewalls: IPTables, FirewallD, MS Forefront, AWS VPC, AWS Security Groups, AWS NACL\n",
      "\n",
      "Network/OS Troubleshooting utilities:TCPDump, WireShark, nslookup, netstat, watch, htop, strace, route, ifconfig\n",
      "\n",
      "Cloud/IaaS/PaaS and Virtualization Technologies:VMware (vSphere, vCenter, ESXi, Fusion), Vagrant, VirtualBox, Virtualization using Hypervisors type 1-2 KVM/XEN, RHEV, Open Stack, Hyper-V, AWS (EC2, C2S, S3,VPC), Microsoft Azure\n",
      "\n",
      "CND Tools for log-based telemetry: Splunk, NMap, TCPdump, WireShark, Elastic Search, LogStash, Kibana\n",
      "\n",
      "ICD 503 Security Compliance:eEye Retina, McAfee Enterprise Policy Orchestrator (ePO), Host Based Security System (HBSS), XCCDF, STIG, SRR, Security Checklists, SCAP compliance tools such as openSCAP, ACAS and commercial Nessus, HubbleStack\n",
      "\n",
      "Knowledge of static and dynamic vulnerability analyses tools such as: Threadfix, HP Fortify, SonarQube, OWASP ZAP, Arachni, Amazon Inspector, CoreOS Clair, Twistlock, OpenScap, \n",
      "\n",
      "Knowledge of pentesting platforms such as: Kali, BurpSuite]\"\n",
      "\n",
      "\"[As a Research Scientist on the machine learning team, you will be helping to build the core machine learning building blocks upon which computer vision, speech, and other application specific API‚Äôs can be built.\n",
      "entry --- Splunk\n",
      "substring --- Self-motivated, work well both independently and as part of an agile team., Preferred experience with console development for current platforms\n",
      "\n",
      "Have a clear understanding of Big Data tools mainly being Splunk, Hadoop, and Spark\n",
      "\n",
      "Experience with Visualization tools and platforms.]\"\n",
      "entry --- Splunk\n",
      "substring --- ), \n",
      "\n",
      "Rewards:, \n",
      "\n",
      "Voted 2018 IoT Company of the Year by Compass Intelligence\n",
      "\n",
      "Work with the Best and Brightest Talent\n",
      "\n",
      "Stable, High Growth and Profitable Company\n",
      "\n",
      "Comprehensive Benefits (Medical, Dental, Vision, 401K Plan)\n",
      "\n",
      "Wellness Programs, Learning and Development Opportunities\n",
      "\n",
      "Happy Hours, Car Washes Onsite, Local Food Trucks, Fun Team Building Events\n",
      "\n",
      "Employee Discounts on Spireon Products and Services\n",
      "\n",
      "Spireon Connections and Spireon University for ongoing learning and development]\"\n",
      "[Experience in data analysis, including data preparation and modeling, with expertise in statistical approaches, operational analysisDemonstrated knowledge of software tools, including Microsoft Office products, business intelligence tools such as Tableau, data ingestion tools such as Talend, and analysis tools such as Stata, R, Matlab, and Splunk.General experience with data reporting, dashboard design, and other situational awareness tools.Experience with decision support and communicating results that inform data-driven decisions in military operation]\n",
      "\"[Serve as technical lead in analysis and reporting efforts that support the Health Plan‚Äôs Clinical and Provider teams, programs and quality activities.\n",
      "entry --- Splunk\n",
      "substring --- Strong technical, communication, political and negotiation skills will be required., \n",
      "\n",
      "Skills required:, \n",
      "\n",
      "Ability to collect and aggregate data from multiple databases while validating the data integrity and accuracy\n",
      "\n",
      "Skilled Excel user with pivot tables, slicers, graphing, formulas, macros, & integration of data connectors\n",
      "\n",
      "Data visualization & Business Intelligence tools systems such as Looker, EasyBi, Power BI, Tableau\n",
      "\n",
      "Coding languages such as VBA, Java, Ruby, C#, PHP, Python, HTML, JavaScript, SQL queries in both MySQL & MSSQL\n",
      "\n",
      "Monitoring tools such as Cloud Watch, Alertsite & Zabbix\n",
      "\n",
      "Code Repositories such at GitHub\n",
      "\n",
      "Log aggregation, analytics & monitoring tools such as Elastic & Splunk\n",
      "\n",
      "Linux & Windows system administration in cloud environments such as AWS, Applies advanced subject matter knowledge to solve complex business issues and is regarded as a subject matter expert.\n",
      "entry --- Splunk\n",
      "substring --- Strong technical, communication, political and negotiation skills will be required., \n",
      "\n",
      "Skills required:, \n",
      "\n",
      "Ability to collect and aggregate data from multiple databases while validating the data integrity and accuracy\n",
      "\n",
      "Skilled Excel user with pivot tables, slicers, graphing, formulas, macros, & integration of data connectors\n",
      "\n",
      "Data visualization & Business Intelligence tools systems such as Looker, EasyBi, Power BI, Tableau\n",
      "\n",
      "Coding languages such as VBA, Java, Ruby, C#, PHP, Python, HTML, JavaScript, SQL queries in both MySQL & MSSQL\n",
      "\n",
      "Monitoring tools such as Cloud Watch, Alertsite & Zabbix\n",
      "\n",
      "Code Repositories such at GitHub\n",
      "\n",
      "Log aggregation, analytics & monitoring tools such as Elastic & Splunk\n",
      "\n",
      "Linux & Windows system administration in cloud environments such as AWS, Applies advanced subject matter knowledge to solve complex business issues and is regarded as a subject matter expert.\n",
      "entry --- Splunk\n",
      "substring --- Minimum 4 years full-time, analytics-relevant work experience (experience in the digital industry is preferred, SQL proficiency is required)\n",
      "\n",
      "Keen intellectual curiosity and ability to structure & solve difficult problems with minimal supervision\n",
      "\n",
      "Passion for translating ‚Äòdata-speak‚Äô into relevant, compelling stories\n",
      "\n",
      "Background in any of the following preferred: Tableau, Vertica, Hive/Hadoop, R, Python, Pentaho, Kettle\n",
      "\n",
      "Exceptional attention to detail coupled with an ability to see the big picture\n",
      "\n",
      "Thorough conceptual and practical understanding of relational databases, data architecture/governance, and real-world application of statistical concepts (particularly in a testing context)\n",
      "\n",
      "Effective presentation and public speaking skills with the ability to present and defend complex analysis both internally and externally to both technical and non-technical audiences ‚Äì and a passion for making the\n",
      "\n",
      "Must have the combination of technical skills, passion for learning, and the soft skills to work with all personality types in a dynamic environment]\"\n",
      "\"[\n",
      "3+ years of experience with developing and deploying scalable machine learning or artificial intelligence algorithms\n",
      "Experience with data mining techniques for large-scale datasets, including both structured and unstructured data\n",
      "Experience with advanced analytics, including unsupervised and supervised learning techniques, such as regression, forecasting, clustering, and outlier detection\n",
      "Ability to obtain a security clearance\n",
      "HS diploma or GED\n",
      ", \n",
      "Experience with using APIs to integrate data from multiple systems\n",
      "Experience with using Python scripting for data extraction and manipulation\n",
      "Experience with using Splunk as a data analysis environment\n",
      "Experience with multiple data visualization tools\n",
      "Knowledge of nation-state, targeted, and financially motivated threats\n",
      "Knowledge of Cybersecurity infrastructure and log sources\n",
      "Possession of excellent oral and written communication skills\n",
      "Possession of excellent collaboration skills\n",
      "Secret clearance\n",
      "BA or BS degree\n",
      "]\"\n",
      "\"[\n",
      "Establish and adhere to best practices in reporting and analysis: data integrity, test design, analysis, validation to ensure team is providing exceptional quality work and is continuously gaining everyone's trust.\n",
      "entry --- Splunk\n",
      "substring --- \"[\n",
      "\n",
      "Analyze traditional, social and digital media data using qualitative and quantitative research methods\n",
      "\n",
      "Leverage data to develop new insights with the goal of improving planning, deliverables, growth and efficiency\n",
      "\n",
      "Identify trends and insights from data to generate actionable insights\n",
      "\n",
      "Help develop internal processes and lead the analytic group in the management of projects and resources\n",
      "\n",
      "Jointly develop business cases with account leads that clearly show impact of campaigns and initiatives on business objectives as well as ROI\n",
      "\n",
      "Manage, organize, and clean data effectively and efficiently while reducing manual reporting and data redundancy\n",
      "\n",
      "Use data visualization skills and tools to analyze, package and communicate reports to key stakeholders, both internally and to external clients, \n",
      "\n",
      "Ability to translate data into insights that help clients understand audience needs and behavioral drivers\n",
      "\n",
      "Highly versed in analytic methodologies and modeling\n",
      "\n",
      "Excellent oral and written communication skills, specifically the ability to convey research findings in a concise and effective manner\n",
      "\n",
      "Ability to work individually and in a team setting\n",
      "\n",
      "Ability to remain organized, driven, and focused on multiple projects at a time\n",
      "\n",
      "Ability to meet deadlines and adapt quickly to new projects\n",
      "\n",
      "Project/time/client management skills\n",
      "\n",
      "Strong presentation and data visualization skills\n",
      "\n",
      "Enthusiastic, eager, and curious]\"\n",
      "[Overall 8+ Years of experience in IT industryAtleast 4 years experience in SplunkVery good knowledge and working experience in Big Data Hadoop / No SQL3+ years' experience with Splunk in developing text mining use casesIntegrating Splunk with Big Data Hadoop for log storageIntegration with variety of external data sourcesThe ability to design Splunk reports and dashboards using complex data elementsFamiliarity of a Web Based application environmentLinux shell scripting/Regex experience would be highly preferableSplunk certifications is a plus.]\n",
      "entry --- Splunk\n",
      "substring --- [Overall 8+ Years of experience in IT industryAtleast 4 years experience in SplunkVery good knowledge and working experience in Big Data Hadoop / No SQL3+ years' experience with Splunk in developing text mining use casesIntegrating Splunk with Big Data Hadoop for log storageIntegration with variety of external data sourcesThe ability to design Splunk reports and dashboards using complex data elementsFamiliarity of a Web Based application environmentLinux shell scripting/Regex experience would be highly preferableSplunk certifications is a plus.]\n",
      "entry --- Splunk\n",
      "substring --- At Splunk, we‚Äôre committed to our work, customers, having fun, and most meaningfully to each other‚Äôs success.\n",
      "entry --- Splunk\n",
      "substring --- We continue to be on a tear while enjoying incredible growth year over year., \n",
      "\n",
      "As a Senior Business Data Analyst at Splunk, you will help drive projects by enabling data and analytics to improve the company's Enterprise Data processes and the applications it builds and uses.\n",
      "entry --- Splunk\n",
      "substring --- Splunk offers the chance to work with cutting-edge technology in a collaborative, exciting, and fast-paced environment., \n",
      "\n",
      "Responsibilities: I want to and can do that!, \n",
      "\n",
      "Partner with Splunk‚Äôs product managers and internal teams to address complex business data questions and provide insightful analysis and strategic recommendations to both technical and non-technical colleagues.\n",
      "entry --- Splunk\n",
      "substring --- Experience with data instrumentation, interpretation and visualization tools (ETL Tools, Splunk, Tableau).\n",
      "entry --- Splunk\n",
      "substring --- At Splunk, we‚Äôre committed to our work, customers, having fun, and most meaningfully to each other‚Äôs success.\n",
      "entry --- Splunk\n",
      "substring --- We continue to be on a tear while enjoying incredible growth year over year., \n",
      "\n",
      "As a Senior Business Data Analyst at Splunk, you will help drive projects by enabling data and analytics to improve the company's Enterprise Data processes and the applications it builds and uses.\n",
      "entry --- Splunk\n",
      "substring --- Splunk offers the chance to work with cutting-edge technology in a collaborative, exciting, and fast-paced environment., \n",
      "\n",
      "Responsibilities: I want to and can do that!, \n",
      "\n",
      "Partner with Splunk‚Äôs product managers and internal teams to address complex business data questions and provide insightful analysis and strategic recommendations to both technical and non-technical colleagues.\n",
      "entry --- Splunk\n",
      "substring --- Experience with data instrumentation, interpretation and visualization tools (ETL Tools, Splunk, Tableau).\n",
      "entry --- Splunk\n",
      "substring --- Informatica DQ), 1+ years of experience working with Agile development methodologies]\"\n",
      "\"[Guide business and technical stakeholders in the collection and analysis of key data related Cyber Security metrics\n",
      "\n",
      "Collaborate with a wide range of stakeholders to establish qualitative analysis on metrics depicting key trends and messages to communicate to targeted audiences\n",
      "\n",
      "Build and maintain dashboards for executive & senior leadership reporting, providing critical Cyber Security metrics trending and forecasting information, summarized as appropriate for executive and senior levels consumption\n",
      "\n",
      "Produce ad-hoc Security metrics reporting in a concise and consistent manner\n",
      "\n",
      "Create data platforms and manage Cyber Security metrics tools\n",
      "\n",
      "Proactively identify opportunities for optimization in the data collection\n",
      "\n",
      "Partner with stakeholders to turn analyses into opportunities to detect and mitigate future security risk\n",
      "\n",
      "Coordinate the GS budget activities including tracking and coordination with IT PMO to drive appropriate sourcing and investments decisions, Education:\n",
      "\n",
      "A university degree\n",
      "\n",
      "Certifications such as CISM, CISSP, ISO27001 or trainings in the domain of Information Security are considered as a plus, \n",
      "\n",
      "A university degree\n",
      "\n",
      "Certifications such as CISM, CISSP, ISO27001 or trainings in the domain of Information Security are considered as a plus, \n",
      "\n",
      "Experience:\n",
      "\n",
      "Minimum of 3+ years managing, analyzing and reporting on large datasets\n",
      "\n",
      "Exposure to Cyber Security metrics, key performance indicators (KPIs) and key risk indicators (KRIs)\n",
      "\n",
      "Very good understanding of Information Security management reporting processes\n",
      "\n",
      "Previous experience in a corporate security organization is highly preferred\n",
      "\n",
      "Good knowledge of Information Security processes, procedures and controls\n",
      "\n",
      "Proven track record in managing multiple projects\n",
      "\n",
      "Experience in interfacing with multiple levels of management\n",
      "\n",
      "Knowledge of Splunk and ServiceNow is a plus, \n",
      "\n",
      "Minimum of 3+ years managing, analyzing and reporting on large datasets\n",
      "\n",
      "Exposure to Cyber Security metrics, key performance indicators (KPIs) and key risk indicators (KRIs)\n",
      "\n",
      "Very good understanding of Information Security management reporting processes\n",
      "\n",
      "Previous experience in a corporate security organization is highly preferred\n",
      "\n",
      "Good knowledge of Information Security processes, procedures and controls\n",
      "\n",
      "Proven track record in managing multiple projects\n",
      "\n",
      "Experience in interfacing with multiple levels of management\n",
      "\n",
      "Knowledge of Splunk and ServiceNow is a plus, \n",
      "\n",
      " Other skills:\n",
      "\n",
      "Excellent analytical & organizational skills\n",
      "\n",
      "Proactive, consultative and business-minded\n",
      "\n",
      "Ability to work independently\n",
      "\n",
      "Strong communication skills\n",
      "\n",
      "Very good interpersonal skills\n",
      "\n",
      "Ability to deliver data-driven conclusions effectively\n",
      "\n",
      "Critical mindset ‚Äì challenges status quo, \n",
      "\n",
      "Excellent analytical & organizational skills\n",
      "\n",
      "Proactive, consultative and business-minded\n",
      "\n",
      "Ability to work independently\n",
      "\n",
      "Strong communication skills\n",
      "\n",
      "Very good interpersonal skills\n",
      "\n",
      "Ability to deliver data-driven conclusions effectively\n",
      "\n",
      "Critical mindset ‚Äì challenges status quo]\"\n",
      "\n",
      "\"[About Bill.com, \n",
      "\n",
      "Bill.com is the leading business payments network, with 3 million members paying and getting paid over $52 billion per year.\n",
      "entry --- Splunk\n",
      "substring --- Experience working with Journey, Voice of the Customer and operational data sources such as Splunk is preferred\n",
      "Experience working with Web and native Mobile app data\n",
      "\n",
      "Experience applying aggregations, segmentation, statistics, clustering, to complex business problems.\n",
      "entry --- Splunk\n",
      "substring --- Experience working with Journey, Voice of the Customer and operational data sources such as Splunk is preferred\n",
      "Experience working with Web and native Mobile app data\n",
      "\n",
      "Experience applying aggregations, segmentation, statistics, clustering, to complex business problems.\n",
      "entry --- Splunk\n",
      "substring --- Mentor others in using analytics tools\n",
      "\n",
      "Evaluate and enhance existing reports and dashboards\n",
      "\n",
      "Define and document business requirements for new metrics and reports\n",
      "\n",
      "Ensure accuracy and integrity of data and reporting applications through detailed analysis, efficient coding, writing clear documentation processes, identifying and resolving problems as they arise\n",
      "\n",
      "Review and write complex SQL queries and develop stored procedures and functions in SQL\n",
      "\n",
      "Perform ongoing monitoring and refinement of reports and BI solutions\n",
      "\n",
      "Ability to work effectively within competing deadlines with minimal guidance\n",
      "\n",
      "Interact professionally and collaborate with a diverse group including executives, managers, and subject matter experts, 4 or more years of quality experience using SQL Server, SSRS, SSAS, Azure, and SSIS\n",
      "\n",
      "Strong knowledge of relational and multi-dimensional database architecture\n",
      "\n",
      "Experience creating and maintaining documentation following standard creation and change control processes\n",
      "\n",
      "Proficient oral and written communication skills\n",
      "\n",
      "Ability to lead a meeting and present to small audiences\n",
      "\n",
      "Experience integrating Power BI into web applications]\"\n",
      "\"[\n",
      "\n",
      "Assist with data collection and optimization of storage approaches\n",
      "\n",
      "Provide support for scalable batch or real-time data processing for discovery and model creation\n",
      "\n",
      "Implement scalable APIs for utilizing analytics results (e.g., utilizing models produced)\n",
      "\n",
      "Collaborate with data scientists and help them evaluate the computation/data requirements for discovery and the deployed solution\n",
      "\n",
      "Design, build, operationalize, and scale some of the largest data pipelines in the world\n",
      "\n",
      "Advise on and manage big data infrastructure\n",
      "\n",
      "Architect and develop data ingestion pipelines\n",
      "\n",
      "Develop proofs of concept with emerging technologies\n",
      "\n",
      "Assist with data preparation, \n",
      "\n",
      "Bachelor's degree in Computer Science or a related technical field\n",
      "\n",
      "3 years of experience as a Software Engineer or closely related position\n",
      "\n",
      "3 years of of experience with the following:\n",
      "\n",
      "Designing, integrating, and optimizing distributed data-processing pipelines\n",
      "\n",
      "Utilizing database technologies, including: SQL and No-SQL (e.g., Hadoop, Splunk, Spark, Samza, MySQL, Postgres, MongoDB, Sqlite, Neo4j, Apache Giraph), within a cloud environment\n",
      "\n",
      "Writing data processing code in Go, Java, Python, Scala, or other high-performance languages\n",
      "\n",
      "Using distributed and fault-tolerant computing and map/reduce processing techniques\n",
      "\n",
      "Utilizing Linux/UNIX systems\n",
      "\n",
      "Systems-level debugging\n",
      "\n",
      "Building REST APIs for analytics services\n",
      "\n",
      "Working with or in support of multiple open source communities\n",
      "\n",
      "Optimizing critical components in applications for efficiency using C or C++\n",
      "\n",
      "Utilizing cloud deployment and virtualization and containerization technologies (e.g, Docker, Ansible, Terraform and Vagrant)\n",
      "\n",
      "1 year of experience with the following:\n",
      "\n",
      "Machine learning libraries, such as Google CloudML, DataFlow, DataLab, TensorFlow, SciKit Learn, Mahout, and MLib\n",
      "\n",
      "Optimizing advanced SQL queries\n",
      "\n",
      "Working in an agile environment with SCRUM and PODS]\"\n",
      "\"[\n",
      "Design, develop, automate, monitor and maintain Extract Transform Load (ETL) data movement applications using our preferred ETL tools and techniques.\n",
      "entry --- Splunk\n",
      "substring --- to ensure data is quickly and reliably available in all contexts\n",
      "\n",
      "Prepare technical documentation to include as-built design, requirements, and Standard Operating Procedures\n",
      "\n",
      "Interface with the broader Forcepoint data science team about analytic opportunities and accomplishments in the field to drive the evolution of the Forcepoint UEBA platform\n",
      "\n",
      "Provide technical briefings to customer leadership and Forcepoint corporate leadership as required\n",
      "\n",
      "Coordinate tasks and activities with various groups within Forcepoint, the government or partners\n",
      "\n",
      ", Required Skills & Experience:\n",
      "\n",
      ", Minimum of bachelors in computer engineering, computer science, information security, or equivalent with 5 years of technical work experience\n",
      "\n",
      "Experience writing modular and reusable code in Python\n",
      "\n",
      "Facility in scripting and troubleshooting application errors in Linux/Unix environments\n",
      "\n",
      "Experience with the ETL: cleaning, transforming, and ingesting large datasets\n",
      "\n",
      "Experience with full Software Development Life Cycle (SLDC) from requirements through to testing and deployment\n",
      "\n",
      "Possess strong analytical, verbal, and technical written communication skills\n",
      "\n",
      "Must be able to coordinate collaboratively across traditional engineering disciplines and effectively engage with customers\n",
      "\n",
      "Must be eligible to work in the U.S.\n",
      "\n",
      ", Nice to have:\n",
      "\n",
      ", Prior technical experience in large enterprises\n",
      "\n",
      "Experience with Apache NiFi and high volume ETL tasks\n",
      "\n",
      "Integration experience with data stores such as Elasticsearch, PostgreSQL, Splunk, ArcSight, Cloudera, etc.\n",
      "entry --- Splunk\n",
      "substring --- Hadoop, Spark, Kafka, Clickhouse, NiFi)\n",
      "\n",
      "Experience with crafting and managing data pipelines\n",
      "\n",
      "DevOps mindset with experience on agile team\n",
      "\n",
      "Strong technical writing and communication skills\n",
      "\n",
      "Excellent problem solving and decision-making skills, \n",
      "\n",
      "Experience with containerization (specifically Docker & Kubernetes)\n",
      "\n",
      "Experience with SQL and Linux\n",
      "\n",
      "Security experience\n",
      "\n",
      "Splunk dashboards, reports, and alerting, \n",
      "\n",
      "At Cisco, each person brings their unique talents to work as a team and make a difference.\n",
      "entry --- Splunk\n",
      "substring --- Experience with integration, and analysis of data from multiple sources using tools like: Hive, Impala, Rstudio, Splunk, etc.\n",
      "entry --- Splunk\n",
      "substring --- This role requires someone excited to advance a team through the transition from traditional data solutions to emerging data patterns., \n",
      "\n",
      "What you‚Äôll do:, \n",
      "Work with business product owners to understand business requirements and use cases\n",
      "Create technical and business solutions architectures (logical and physical)\n",
      "Resolve questions during design and implementation of architecture\n",
      "Evaluate tools for use case fit, perform vendor/tool comparisons and present recommendations\n",
      "Contribute to the capability roadmaps for data platforms\n",
      "Review schemas, data models and data architecture for Hadoop and Teradata environments\n",
      "Prototype solutions for specific use cases\n",
      "Advise peers and business partners on fit-for-use and technical complexities\n",
      "Partner with other technical leaders for solution alignment with strategy and standards\n",
      ", What you have:, \n",
      "Hands-on experience with Hadoop, Teradata (or other MPP RDBMS), MapReduce, Hive, Sqoop, Splunk, STORM, SPARK, Kafka and HBASE (At least 2 years)\n",
      "Experience with end-to-end solution architecture for data capabilities including:\n",
      "Experience with ELT/ETL development, patterns and tooling (Informatica, Talend)\n",
      "Experience with BI tools (BusinessObjects, Tableau) and other visualization (D3)\n",
      "Experience with Advanced Analytics (SAS, R)\n",
      "Experience with Graph and In-memory databases\n",
      "Experience with Machine Learning techniques and practices\n",
      "Experience with Test Driven Code Development and SCM tools\n",
      "Fluent understanding of best practices for building Data Lake and analytical architectures on Hadoop\n",
      "Strong scripting / programming background (Unix, Python preferred)\n",
      "Strong SQL experience with the ability to develop, tune and debug complex SQL applications\n",
      "Expertise in schema design, developing data models and proven ability to work with complex data is required\n",
      "Experience in real time and batch data ingestion\n",
      "Proven experience in working in large environments such as RDBMS, EDW, NoSQL, etc.\n",
      "entry --- Splunk\n",
      "substring --- AWS Kinesis/Lambda, GC Pub/Sub)\n",
      "Cloud infrastructure devops to support deployment and data management\n",
      "Excellent communication skills both written and verbal\n",
      ", Python, Javascript, Node.js, MongoDB, BigQuery\n",
      "Infrastructure management on Amazon Web Services and Google Cloud Platform\n",
      "Docker container deployment on Kubernetes\n",
      "RESTful Web Service API development\n",
      "Mobile development in Android and iOS\n",
      "Experience in games or fast paced company such as growth phase startup\n",
      "Git, GitHub, Perforce, Jenkins, Splunk]\"\n",
      "\"[\n",
      "Work with computational and research scientists to understand common analysis use cases and data access needs.\n",
      "entry --- Splunk\n",
      "substring --- You are smart, quick, and creative: an engineer who will dig into the system and find various ways to improve it., \n",
      "\n",
      "Set the direction and be the primary executor with the goal of making Animoto‚Äôs data easily consumable, highly actionable, and available to the widest number of internal users\n",
      "\n",
      "Architect, design, and develop Animoto.com‚Äôs data infrastructure to support the wide variety of application and analytical needs\n",
      "\n",
      "Design and implement dimensional data models and systems that scale\n",
      "\n",
      "Partner with product, engineering, and data analysts to explore structured and unstructured data to leverage business insights, \n",
      "\n",
      "Bachelors degree in CS or equivalent work experience\n",
      "\n",
      "Solid experience in languages like Ruby or Python\n",
      "\n",
      "Strong experience with SQL\n",
      "\n",
      "Experience with Splunk or other Elasticsearch tools\n",
      "\n",
      "Familiarity with ETL and BI concepts, \n",
      "\n",
      "Comfortable with AWS (Redshift, Athena, etc)\n",
      "\n",
      "Comfortable working in application code when needed\n",
      "\n",
      "Familiarity with Looker, \n",
      "\n",
      "Be a part of a thriving engineering team that includes opportunities to collaborate with teams across the organization including, product, design, and marketing.\n",
      "entry --- Splunk\n",
      "substring --- \"[Required:, \n",
      "\n",
      "Experience in AWS technologies such as EC2, Cloud formation, EMR Cluster, AWS S3, Splunk, and AWS Analytics.\n",
      "entry --- Splunk\n",
      "substring --- to ensure data is quickly and reliably available in all contexts\n",
      "\n",
      "Prepare technical documentation to include as-built design, requirements, and Standard Operating Procedures\n",
      "\n",
      "Interface with the broader Forcepoint data science team about analytic opportunities and accomplishments in the field to drive the evolution of the Forcepoint UEBA platform\n",
      "\n",
      "Provide technical briefings to customer leadership and Forcepoint corporate leadership as required\n",
      "\n",
      "Coordinate tasks and activities with various groups within Forcepoint, the government or partners\n",
      "\n",
      ", Required Skills & Experience:\n",
      "\n",
      ", Experience writing modular and reusable code in Python\n",
      "\n",
      "Facility in scripting and troubleshooting application errors in Linux/Unix environments\n",
      "\n",
      "Experience with the ETL: cleaning, transforming, and ingesting large datasets\n",
      "\n",
      "Experience with full Software Development Life Cycle (SLDC) from requirements through to testing and deployment\n",
      "\n",
      "Possess strong analytical, verbal, and technical written communication skills\n",
      "\n",
      "Must be able to coordinate collaboratively across traditional engineering disciplines and effectively engage with customers\n",
      "\n",
      "Must be eligible to work in the US\n",
      "\n",
      ", Desired Skills:\n",
      "\n",
      ", Prior technical experience in finance and/or information security organisations\n",
      "\n",
      "Experience with Apache NiFi and high volume ETL tasks\n",
      "\n",
      "Integration experience with data stores such as Elasticsearch, PostgreSQL, Splunk, ArcSight, Cloudera, etc.\n",
      "entry --- Splunk\n",
      "substring --- Identify opportunities to use data to drive enhanced business decision making and promote a data-driven culture\n",
      ", \n",
      "Hands-on experience with Hadoop, Teradata (or other MPP RDBMS), MapReduce, Hive, Sqoop, Splunk, STORM, SPARK, Kafka and HBASE\n",
      "Experience with end-to-end solution architecture for data capabilities including:\n",
      "Experience with ELT/ETL development, patterns and tooling\n",
      "Experience with BI tools - Periscope Data or equivalent tool (Tableau, etc.)\n",
      "entry --- Splunk\n",
      "substring --- Splunk, PagerDuty, DataDog or Graphite)\n",
      "\n",
      "Data Architecture & Governance, Experience with:, \n",
      "\n",
      "Other AWS technologies (e.g.\n",
      "entry --- Splunk\n",
      "substring --- Splunk, PagerDuty, DataDog or Graphite), \n",
      "\n",
      "Other AWS technologies (e.g.\n",
      "entry --- Splunk\n",
      "substring --- Splunk, PagerDuty, DataDog or Graphite), \n",
      "\n",
      "Data Architecture & Governance, Zillow Group is owned, fueled and grown by innovators who help people make better, smarter decisions around all things home.\n",
      "entry --- Splunk\n",
      "substring --- Our fast paced environment will require you to rise to the challenge and strive to exceed expectations\n",
      " Enforce standards and best practices across all aspects of the platform/product\n",
      ", You'll need to have:, BA, BS, MS, PhD in Computer Science, Engineering or related technology field\n",
      " 3+ years of relevant post-grad industry experience\n",
      " Deep understanding of large scale distributed systems/databases\n",
      " Solid understanding of different types of data models (relational, columnar, document based, key/value)\n",
      " Experience/strong knowledge in Hadoop, Spark, and Large scale data processing\n",
      " Experience building data pipelines and services and scaling them\n",
      " Knowledge/Experience with web services, API design, OLAP/Business Intelligence, in-memory computing\n",
      " Relentless focus on the quality and reliability needed for an infrastructure team]\"\n",
      "[Hands on experience in implementing Data Lake and AWS Cloud DATA and Enterprise Data Warehouse SolutionsProviding Solutions for Big Data Platform infrastructure for across AWS VPCUnderstand GDPR lawsArchitect and standardize the way data is ingested, processed and exportedExpertise working with AWS and Other Cloud infrastructure:, Strong Database knowledge in Cloud based Database like RedShift, Snowflake etcMonitoring (CloudWatch, and ideally commercial solutions like DataDog, Splunk, PagerDuty)Identity Management & Security (e.g.\n",
      "entry --- Splunk\n",
      "substring --- [Hands on experience in implementing Data Lake and AWS Cloud DATA and Enterprise Data Warehouse Solutions, Providing Solutions for Big Data Platform infrastructure for across AWS VPC, Understand GDPR laws, Architect and standardize the way data is ingested, processed and exported, Expertise working with AWS and Other Cloud infrastructure:, Strong Database knowledge in Cloud based Database like RedShift, Snowflake etc, Monitoring (CloudWatch, and ideally commercial solutions like DataDog, Splunk, PagerDuty), Identity Management & Security (e.g.\n",
      "entry --- Splunk\n",
      "substring --- [Hands on experience in implementing Data Lake and AWS Cloud DATA and Enterprise Data Warehouse Solutions, Providing Solutions for Big Data Platform infrastructure for across AWS VPC, Understand GDPR laws, Architect and standardize the way data is ingested, processed and exported, Expertise working with AWS and Other Cloud infrastructure:, Strong Database knowledge in Cloud based Database like RedShift, Snowflake etc, Monitoring (CloudWatch, and ideally commercial solutions like DataDog, Splunk, PagerDuty), Identity Management & Security (e.g.\n",
      "entry --- Splunk\n",
      "substring --- , \n",
      "\n",
      "Responsibilities, \n",
      "\n",
      "You will design and develop Data life cycle management such as Ingestion, pipeline development, data at rest strategy, Archive and Migration solution\n",
      "\n",
      "Work with the Chief Architect and other engineering groups to align with company product design paradigm\n",
      "\n",
      "Provide design mentorship and review the work of other specialists\n",
      "\n",
      "Able to work with Nutanix Global (mainly India and USA) engineering and multi-functional team, \n",
      "\n",
      "Qualifications and Experience, \n",
      "\n",
      "BS/MS degree in Computer science or equivalent (PhD degree a plus)\n",
      "\n",
      "8+ years of product platform development with 4+ years of data life cycle management\n",
      "\n",
      "Experience with building a data pipeline development framework\n",
      "\n",
      "Hands-on development in at least one of the programming languages: Java, Python/Golang and C++\n",
      "\n",
      "Knowledge of storage/file system and its meta data\n",
      "\n",
      "Strong development experience in Linux/Unix OS platform\n",
      "\n",
      "Hands-on experience working with version control / DevOps tools ‚Äì Git, Gerrit and Jenkins, \n",
      "\n",
      "Pluses, \n",
      "\n",
      "Understanding of any of the cloud computing technology ‚Äì AWS / Google Cloud / Azure / VMWare\n",
      "\n",
      "Knowledge in any of the area such as - Splunk, Spark, Kafka, Elasticsearch and its component, Apache/Tomcat server, Flask framework is a plus\n",
      "\n",
      "Experience in Message Bus (RabbitMQ, Kafka), Elastic Search, Cassandra and Zookeeper.\n",
      "entry --- Coyote Logistics\n",
      "substring --- The Supply Chain Research group at Coyote Logistics is responsible for designing, selling, and implementing Coyote‚Äôs emerging portfolio of non-transactional supply chain services.\n",
      "entry --- Twitter\n",
      "substring --- \"[What You‚Äôll Do:, You will work with our team of experts in machine learning and software engineering to build powerful and scalable models and surface the most relevant content on Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Come help us make Twitter the best place for finding what the world is saying, live!\n",
      "entry --- Twitter\n",
      "substring --- You like a fast-paced & fun environment, believe in Twitter‚Äôs mission in the world and want to be a core actor in pushing it forward.\n",
      "entry --- Twitter\n",
      "substring --- \"[Who We Are:, \n",
      "\n",
      "Machine learning is advancing products at Twitter (e.g., Timeline ranking, On-boarding) and Cortex is advancing Machine learning at Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Cortex is the central ML/AI team with the goal to build an ML platform and provide deep ML expertise to support our internal customers, while advancing ML inside & outside Twitter., \n",
      "\n",
      "In particular, the ML Extended Environment team (MLX) in Cortex is focused on unifying & advancing recommendation systems.\n",
      "entry --- Twitter\n",
      "substring --- From timeline ranking to ads ranking to new user on-boarding, recommendation systems are prevalent at Twitter.\n",
      "entry --- Twitter\n",
      "substring --- We are building shared components to unify & advance recommendation systems, e.g., embeddings and approximate nearest neighbor solutions., \n",
      "\n",
      "MLX team has a unique mix of ML engineers & scientists who work together to explore & build new prototypes and scale them to augment Twitter‚Äôs ML capability.\n",
      "entry --- Twitter\n",
      "substring --- You like a fast-paced & fun environment, believe in Twitter‚Äôs mission in the world and want to be a core actor in pushing it forward., \n",
      "\n",
      "What You‚Äôll Do:, \n",
      "\n",
      "You will work with our team of experts in machine learning and software engineering to build powerful and scalable models and surface the most relevant content on Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Come help us make Twitter the best place for finding what the world is saying, live!, \n",
      "\n",
      "Requirements:, \n",
      "\n",
      "Expertise in Deep Learning and NLP\n",
      "\n",
      "Experience with software engineering best practices\n",
      "\n",
      "MS or PhD in machine learning or equivalent work experience, Desired:, \n",
      "\n",
      "Experience using big data platforms such as Spark or Hadoop]\"\n",
      "\"[\n",
      "Proven experience in computer vision and deep learning.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- You can also follow us on LinkedIn, Instagram, Twitter and Facebook., Data is more than stats to our Business Development and Strategic Planning team‚Äîit‚Äôs a story waiting to be told.\n",
      "entry --- Twitter\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Twitter\n",
      "substring --- For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.\n",
      "entry --- Twitter\n",
      "substring --- Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- , \n",
      "\n",
      "Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- For more information, visit www.weatherford.com and connect with Weatherford on LinkedIn, Twitter, YouTube and Facebook., \n",
      "\n",
      "Weatherford delivers innovative technologies and services designed to meet the world‚Äôs current and future energy needs in a safe, ethical, and sustainable manner.\n",
      "entry --- Twitter\n",
      "substring --- To learn more about Hill's and Colgate, please visit http://www.hillspet.com and http://www.colgatepalmolive.com, or find us on LinkedIn, Facebook, Twitter and YouTube., \n",
      "\n",
      "Location: Topeka, Kansas, United States\n",
      "\n",
      "Relocation Assistance Offered Within Country\n",
      "\n",
      "# 62547, \n",
      "\n",
      "The focus of the Data Scientist role is to analyze large amounts of complex raw and processed information to find patterns that will improve our understanding of the relationship between nutrition and health/wellbeing.\n",
      "entry --- Twitter\n",
      "substring --- Work with cross-functional partners across the business\n",
      "\n",
      ", QUALIFICATIONS\n",
      "\n",
      ", Advanced degree in Computer Science, Statistics, Mathematics, Economics, or related field\n",
      "\n",
      "3+ years of work experience in data science and/or predictive analytics functions in business environment (preferably internal or external consulting)\n",
      "\n",
      "Programming experience in one or more of Python and R, or other open-source programming languages\n",
      "\n",
      "Experience with big data technology (such as Hadoop, Hive, Data Lake), either cloud or on-premise platforms\n",
      "\n",
      "Knowledge of statistics and experience using statistical packages for analyzing datasets\n",
      "\n",
      "Strong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\n",
      "\n",
      "Ability to write queries, generate reports, and present findings\n",
      "\n",
      "Strong communication and facilitation skills\n",
      "\n",
      "Excellent planning and organizing skills\n",
      "\n",
      "Strong ability to continuously learn and upgrade technical skills\n",
      "\n",
      ", EOE/Disabled/Veterans]\"\n",
      "\"[Key Responsibilities:\n",
      "\n",
      ", Drive end to end analytical process: from formulation of requirements, data acquisition, identification of analytical methods, creation/validation of models to business-friendly summarization of results\n",
      "\n",
      "Interact with stakeholders to identify critical questions that need to be answered in order for the Analytics team to provide effective KPIs - actionable insights rather than just reports\n",
      "\n",
      "Conduct analysis and data modeling to draw insights that drive critical decision making and to uncover social media patterns, fan engagement, behavior and feedback\n",
      "\n",
      "Analyze data to identify outliers, missing, incomplete, and/or invalid data\n",
      "\n",
      "Create models, KPIs, and dashboards to operationalize outcomes of analytics\n",
      "\n",
      "Create, automate, and maintain reports and visualizations (e.g., social media mentions, competitive engagement, talent impact mapping)\n",
      "\n",
      "Work in complex data environment comprising several heterogeneous internal and third party data sources, manipulate large data sets and navigate a variety of servers, data types, and data structures to complete statistical and other analyses\n",
      "\n",
      "Design and build dashboards and automated reports with embedded visualizations\n",
      "\n",
      ", Qualifications:\n",
      "\n",
      ", Proven track record of identifying and highlighting key insights, signals, and trends deep within data\n",
      "\n",
      "Well-rounded individual with the ability to write code to query and transform both unstructured and structured data\n",
      "\n",
      "Openness to an environment of active developmental feedback and coaching from peers and managers, with desire to learn and grow rapidly\n",
      "\n",
      "Experience publishing reports using visualization and presentation tools\n",
      "\n",
      "Strong planning and organizational skills\n",
      "\n",
      "Should enjoy generating actionable insights by mining data and be passionate about answering challenging questions and telling stories with data and visualizations\n",
      "\n",
      "Self-motivated, attentive to detail, and driven to continuously improve analytics skill set\n",
      "\n",
      "Bachelor‚Äôs degree in Statistics/Mathematics, Econometrics/Economics, Engineering/Computer Science, Business/Finance, or related quantitative field\n",
      "\n",
      "Working knowledge of at least two technologies: SQL, SAS, Python, Big Query, Google Analytics, Excel, and Tableau\n",
      "\n",
      "SPSS and/or R\n",
      "\n",
      "Knowledge of social media platforms including but not limited to Facebook, Twitter, Instagram, Snapchat, YouTube\n",
      "\n",
      ", _]\"\n",
      "\"[Position Description, Work closely with merchants to define objectives and design appropriate analytics solutionsApply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand consumersDevelop analytical models to drive analytics insightsLead small and participate in large data analytics project teamsParticipate in the continuous improvement of data science and analyticsPresent data insights and recommendations to key stakeholdersProvide and support the implementation of business solutionsModel compliance with company policies and support company mission, values, and standards of ethics and integrity, \n",
      "\n",
      "Minimum Qualifications, \n",
      "\n",
      "Bachelor of Science and 5 years data science experience OR Master of Science and 3 years data science experience., \n",
      "\n",
      "Additional Preferred Qualifications, 5 years‚Äô experience in predictive modeling and large data analysis5 years‚Äô experience with statistical programming languages (for example, R, SAS)5 years‚Äô experience with SQL and relational databases (for example, DB2, Oracle, SQL Server)Expert in any scripting language (Python, PHP, Perl, etc.\n",
      "entry --- Twitter\n",
      "substring --- Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- , \n",
      "\n",
      "Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- Visit www.guycarpenter.com for more information and follow us on LinkedIn and Twitter @GuyCarpenter, \n",
      "\n",
      "Guy Carpenter & Company, LLC and its separately incorporated operating entities around the world are part of Marsh & McLennan Companies, a publicly held company (ticker symbol: MMC)., \n",
      "\n",
      "Marsh & McLennan Companies offers competitive salaries and comprehensive benefits and programs including: health and welfare, tuition assistance, pension, employee assistance program, domestic partnership benefits, career mobility, employee network groups, volunteer opportunities, and other programs.\n",
      "entry --- Twitter\n",
      "substring --- Learn more at sensus.com and follow @SensusGlobal on Facebook, LinkedIn and Twitter., \n",
      "\n",
      "The Role: Sensus, a Xylem brand seeks to hire a Data Scientist with a desire to join a team delivering Big Data applications in the Cloud.\n",
      "entry --- Twitter\n",
      "substring --- Follow Hawaiian‚Äôs Twitter updates (@HawaiianAir), become a fan on Facebook (Hawaiian Airlines), and follow us on Instagram (hawaiianairlines).\n",
      "entry --- Twitter\n",
      "substring --- For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.\n",
      "entry --- Twitter\n",
      "substring --- Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- , \n",
      "\n",
      "Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- \"[Data Scientist, Self Serve Ads, \n",
      "\n",
      "Who we are:, \n",
      "\n",
      "The SSA team is responsible for driving global initiatives for Twitter's self serve advertisers.\n",
      "entry --- Twitter\n",
      "substring --- Through analyzing large volume of data both from Twitter users and Twitter advertisers, you‚Äôll help Twitter grow revenue globally and in scale., \n",
      "\n",
      "You are able to:, \n",
      "\n",
      "Become an expert on the data sources and systems at Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Knowledge of digital ad space or social media data preferred., We are committed to an inclusive and diverse Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Twitter is an equal opportunity employer.\n",
      "entry --- Twitter\n",
      "substring --- For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Twitter\n",
      "substring --- We are looking for candidates who are ambitious, self-assured, possess strong can-do attitude, and want to be a part of a world-class team\n",
      "\n",
      ", Why you‚Äôll want to come work here:\n",
      "\n",
      ", Competitive salary (commission/bonus based on type of role), 4 weeks paid time off, great benefits (medical, dental, vision, FSA), 401K match\n",
      "\n",
      "Gift matching, volunteer for vacation program, and endless community involvement opportunities\n",
      "\n",
      "Named to Forbes‚Äô Fast Tech 25 and Fortune‚Äôs Change the World List; we are growing and offer incredible opportunity for advancement\n",
      "\n",
      "Tremendous company culture and office perks as well as a new cutting-edge new headquarters completed in 2018\n",
      "\n",
      ", Stay up to date on everything Blackbaud, follow us on Linkedin , Twitter and Facebook .\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- If you said yes, we‚Äôd love to talk to you about joining our award-winning team., \n",
      "\n",
      "Learn more at zscaler.com or follow us on Twitter @zscaler.\n",
      "entry --- Twitter\n",
      "substring --- We can‚Äôt wait to meet you., Arity.com Instagram Twitter LinkedIn, Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- \"[The team is responsible for placing each and every ad that Twitter serves.\n",
      "entry --- Twitter\n",
      "substring --- While placing those ads we decide how best to balance user experience, advertiser results, and Twitter revenue.\n",
      "entry --- Twitter\n",
      "substring --- We routinely deliver significant improvements to our revenue, and work in a close sync with our executive staff (including our COO & CFO) due to our direct impact on Twitter‚Äôs business., We‚Äôre looking for a key individual contributor to drive our advertising products forward.\n",
      "entry --- Twitter\n",
      "substring --- We work on every high-priority ads project at Twitter., You‚Äôre a data scientist with a track record of delivering results.\n",
      "entry --- Twitter\n",
      "substring --- You‚Äôre looking to join a strong, high-performing team., We build new ways for advertisers to buy ads on Twitter, such as paying up front for guaranteed results\n",
      "\n",
      "We design incrementality studies to measure the lift in brand awareness that our advertising campaigns drive\n",
      "\n",
      "We dive into individual products (e.g.\n",
      "entry --- Twitter\n",
      "substring --- video ads) to improve results for our most critical business priorities\n",
      "\n",
      "We evaluate the impact of ads on new Twitter users, determining how to show them ads in order to maximize their long-term usage of the product\n",
      "\n",
      "We are responsible for measuring the results of all experiments on Twitter ads, Experience using data intelligently to optimize product performance\n",
      "\n",
      "Experience performing analysis on raw event data in modern data warehouse systems\n",
      "\n",
      "Deep understanding of data platforms in which you‚Äôve previously worked\n",
      "\n",
      "Good understanding of how to grow and shape data tools and datasets to improve data-driven decision making\n",
      "\n",
      "Ability to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact\n",
      "\n",
      "Good understanding of (one or more of the following): Python or R, \n",
      ", Past experience in adtech\n",
      "\n",
      "PhD or MS in computer science, machine learning, or statistics\n",
      "\n",
      "Good understanding of (one or more of the following): Java, Scala, or C++\n",
      "\n",
      "Interesting side projects or Kaggle competition results, \n",
      ", We are committed to an inclusive and diverse Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Twitter is an equal opportunity employer.\n",
      "entry --- Twitter\n",
      "substring --- For additional information on BlackRock, please visit www.blackrock.com | Twitter: @blackrock | Blog: www.blackrockblog.com | LinkedIn: www.linkedin.com/company/blackrock., Job Description:, Data Science at BlackRock:, \n",
      "\n",
      "In February 2018, BlackRock announced the creation of a new central Data Science team in order to accelerate innovation and technology in artificial intelligence, and to have firm-wide impact using data science to solve strategic problems.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Twitter Analytics, Facebook Insights, Instagram Insights, Hootsuite, Shareablee)\n",
      "\n",
      "Experience with BI tools (ex.\n",
      "entry --- Twitter\n",
      "substring --- For more information about Toole Design, visit our website (www.tooledesign.com), follow us on Twitter (@tooledesign), or like us on Facebook (www.facebook.com/TooleDesignGroup).]\"\n",
      "entry --- Twitter\n",
      "substring --- For more information about Toole Design, visit our website (www.tooledesign.com), follow us on Twitter (@tooledesign), or like us on Facebook (www.facebook.com/TooleDesignGroup).]\"\n",
      "entry --- Twitter\n",
      "substring --- For more information about Toole Design, visit our website (www.tooledesign.com), follow us on Twitter (@tooledesign), or like us on Facebook (www.facebook.com/TooleDesignGroup).]\"\n",
      "entry --- Twitter\n",
      "substring --- For more information about Toole Design, visit our website (www.tooledesign.com), follow us on Twitter (@tooledesign), or like us on Facebook (www.facebook.com/TooleDesignGroup).]\"\n",
      "entry --- Twitter\n",
      "substring --- And check us out at ipsy.com, @ipsyofficial on Snapchat, and @ipsy on Facebook, Instagram, YouTube, and Twitter.]\"\n",
      "entry --- Twitter\n",
      "substring --- You‚Äôll work on exciting brand and acquisition campaigns, perform site optimizations, monitor and run reporting, contribute to an online testing strategy and more., \n",
      "\n",
      "Day-to-day, your role includes:\n",
      "\n",
      ", Keeping a pulse on day-to-day performance data, including display media, site, search, email, and/or social campaigns\n",
      "\n",
      "Working in a variety of reporting systems and databases for the creation of recurring reports and dashboards\n",
      "\n",
      "Identifying nuances in data to optimize our clients‚Äô business\n",
      "\n",
      "Supporting marketing initiatives across project and campaign lifecycles, including measurement plans, primary and secondary research, and performance reporting\n",
      "\n",
      "Expanding industry knowledge and relevant skillsets through internal training, \n",
      "\n",
      "We‚Äôre looking for strong, impactful work experience, which typically includes:, \n",
      "\n",
      "A four-year college degree\n",
      "\n",
      "1-3 years of work experience in the social analytics space\n",
      "\n",
      "Passion for digital marketing, eagerness to learn in a constantly-changing space, and a natural curiosity\n",
      "\n",
      "Experience with Analytics across social channels and tactics (i.e., Facebook, Instagram, Twitter, Pinterest, Social Retargeting)\n",
      "\n",
      "Solid experience with display ad-serving, 1st party onboarding/targeting, brand study measurement partners, and Site Analytics\n",
      "\n",
      "Experience building real-time reporting/dashboarding, knowledge of quantitative and qualitative side of analytics\n",
      "\n",
      "Exposure and experience with Social Listening tools (i.e., Netbase, Brandwatch, Affinio, Crimson Hexagon)\n",
      "\n",
      "Extensive knowledge in data management, data mining, data integration\n",
      "\n",
      "Experience compiling measurement plans and identifying KPIs and optimization metrics\n",
      "\n",
      "Well-versed in Microsoft Office suite ‚Äì Excel, Word, PPT\n",
      "\n",
      "Someone who can work quickly and manage multiple tasks to completion\n",
      "\n",
      "The ability to quickly \"\"switch gears\"\" while remaining organized across multiple projects\n",
      "\n",
      "Strong oral/written communication skills\n",
      "\n",
      "Retail and/or beauty experience is a plus, Facebook\n",
      "\n",
      "Instagram\n",
      "\n",
      "Twitter\n",
      "\n",
      "Pinterest\n",
      "\n",
      "Google Analytics\n",
      "\n",
      "Adobe Omniture\n",
      "\n",
      "Netbase\n",
      "\n",
      "Brandwatch\n",
      "\n",
      "Affinio\n",
      "\n",
      "Crimson Hexagon\n",
      "\n",
      "DCM (DoubleClick), \n",
      "\n",
      "Got what it takes?\n",
      "entry --- Twitter\n",
      "substring --- Attempts through analysis to generate new, innovative ideas that optimize service delivery\n",
      "\n",
      "Manages customer expectations throughout implementation process\n",
      "\n",
      ", Desired Qualifications\n",
      "\n",
      ", 2+ years of experience in field\n",
      "\n",
      "Experience with SQL coding and data analysis required\n",
      "\n",
      "Excellent written and verbal communication\n",
      "\n",
      "Strong customer service and interpersonal skills\n",
      "\n",
      "Detail oriented\n",
      "\n",
      "Ability to manage time and multiple tasks/projects efficiently\n",
      "\n",
      "Basic problem solving and conflict resolution\n",
      "\n",
      "Positive attitude centered on achieving high client satisfaction, both internal and external\n",
      "\n",
      "Experience with Blackbaud‚Äôs RE7/RENXT product is nice to have\n",
      "\n",
      ", Why you‚Äôll want to come work here:\n",
      "\n",
      ", Competitive salary (commission/bonus based on type of role), 4 weeks paid time off, great benefits (medical, dental, vision, FSA), 401K match\n",
      "\n",
      "Gift matching, volunteer for vacation program, and endless community involvement opportunities\n",
      "\n",
      "Named to Forbes‚Äô Fast Tech 25 and Fortune‚Äôs Change the World List; we are growing and offer incredible opportunity for advancement\n",
      "\n",
      "Tremendous company culture and office perks as well as a new cutting-edge new headquarters completed in 2018\n",
      "\n",
      ", Stay up to date on everything Blackbaud, follow us on Linkedin , Twitter and Facebook .\n",
      "entry --- Twitter\n",
      "substring --- Connect with NRG Energy on Facebook and follow us on Twitter @nrgenergy., \n",
      "\n",
      "Job Summary, \n",
      "\n",
      "NRG is seeking an Analyst, Data Analytics with excellent analytical and interpersonal skills to join our Asset Integration team in NRG‚Äôs Asset-Backed Demand Response (ABDR) business.\n",
      "entry --- Twitter\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Twitter\n",
      "substring --- Follow us on LinkedIn, Youtube and Twitter.]\"\n",
      "entry --- Twitter\n",
      "substring --- Please submit any online presence you may have (Twitter, Facebook, Fan pages made because of you), and if you are a DIY enthusiast, whether you think you are a good one or not, that means a lot to us, and we would love to hear about it when you send us your information!]\"\n",
      "entry --- Twitter\n",
      "substring --- And check us out at ipsy.com, @ipsyofficial on Snapchat, and @ipsy on Facebook, Instagram, YouTube, and Twitter.]\"\n",
      "entry --- Twitter\n",
      "substring --- Learn more at www.hasbro.com, and follow us on Twitter (@Hasbro & @HasbroNews) and Instagram (@Hasbro).]\"\n",
      "entry --- Twitter\n",
      "substring --- Find us on Facebook at www.facebook.com/gettyimages and Twitter at https://twitter.com/GettyImages., \n",
      "\n",
      "Getty Images is an equal opportunity employer and strongly supports diversity in the workplace.]\"\n",
      "entry --- Twitter\n",
      "substring --- Successful candidate shall analyze data in the BI tool, consolidate data, and present findings., \n",
      "\n",
      "Responsibilities include, but are not limited to:, \n",
      "Develops pre and post-campaign analyses for digital marketing and loyalty campaigns to measure effectiveness\n",
      "Analyzes overall customer data trends to create and present actionable insights that help drive decision making in support of the Subway Digital marketing initiatives\n",
      "Supports Loyalty Strategy by analyzing loyalty customer trends and program performance overall and within campaigns\n",
      "Designs and manages the reporting and dashboards using for customer insights and campaign performance\n",
      "Supports the offer management and analysis of offers for the marketing campaigns\n",
      "Liaises with the Analytics, Reporting and Experience Optimization teams\n",
      ", Skills and Abilities Required:, \n",
      "5+ years experience\n",
      "Strong analytics skills and structured problem solving skills\n",
      "Strong financial analysis background\n",
      "Strong understanding of Excel, PowerPoint, and data visualizations\n",
      "Experience in using BI tools to query and analyze data\n",
      "Familiar with campaign data, digital/web analytics, digital display advertising, and customer analysis\n",
      "Capable of telling the big picture story and making recommendations based on trends founds in the data\n",
      "Excellent communications skills and deep knowledge of marketing trends\n",
      "Able to mentor a junior analyst, once he/she is on-boarded\n",
      "Experience in the QSR space or related industry]\"\n",
      "\"[\n",
      "Identifying and assessing sources of crypto data\n",
      "Analyzing assets and exchanges\n",
      "Data collection and automation\n",
      "Daily monitoring of news and publications, websites, Twitter feeds, etc.\n",
      "entry --- Twitter\n",
      "substring --- For more information, visit www.weatherford.com and connect with Weatherford on LinkedIn, Twitter, YouTube and Facebook., \n",
      "\n",
      "Weatherford delivers innovative technologies and services designed to meet the world‚Äôs current and future energy needs in a safe, ethical, and sustainable manner.\n",
      "entry --- Twitter\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Twitter\n",
      "substring --- Connect with NRG Energy on Facebook and follow us on Twitter @nrgenergy., \n",
      "\n",
      "Job Summary:, \n",
      "\n",
      "At NRG, we apply advanced analytics and modeling to address challenging business problems.\n",
      "entry --- Twitter\n",
      "substring --- For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.\n",
      "entry --- Twitter\n",
      "substring --- While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \n",
      "\n",
      "Facebook\n",
      "\n",
      "Twitter\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "Google\n",
      "\n",
      "More]\"\n",
      "\"[Title: Data Analyst\n",
      "Reports to: Research Director\n",
      "Classification: Exempt\n",
      "Location: New York\n",
      "Start Date: Immediately, \n",
      "\n",
      "Summary:\n",
      "\n",
      "The Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \n",
      "\n",
      "The Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets.\n",
      "entry --- Twitter\n",
      "substring --- While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \n",
      "\n",
      "Facebook\n",
      "\n",
      "Twitter\n",
      "\n",
      "LinkedIn\n",
      "\n",
      "Google\n",
      "\n",
      "More]\"\n",
      "\"[The Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \n",
      "\n",
      "The Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets.\n",
      "entry --- Twitter\n",
      "substring --- www.precima.com, Alliance Data participates in E-Verify., Check us out ‚Äì LoyaltyOne on Stack Overflow | LinkedIn | Glassdoor | Facebook |Twitter | Blog | Instagram]\"\n",
      "[ Be an expert in business analysis, used to researching across business functions, subsidiaries and partners, complex and integrated business systems.\n",
      "entry --- Twitter\n",
      "substring --- Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- , \n",
      "\n",
      "Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Check out the Times Open blog , which is written by engineers and other technical team members, and follow @nytdevs on Twitter to see what we‚Äôre up to.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- We can‚Äôt wait to meet you., Arity.com Instagram Twitter LinkedIn, Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- We can‚Äôt wait to meet you., Arity.com Instagram Twitter LinkedIn, Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- We can‚Äôt wait to meet you., Arity.com Instagram Twitter LinkedIn, Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- For more information visit our website and follow GoodData on Twitter and LinkedIn., \n",
      "\n",
      "\n",
      "JOB DESCRIPTION, \n",
      "\n",
      "As a key member of our Consulting team within Professional Services, The Solutions Engineer will be the data engineer that helps guide our customers through their data product implementation.\n",
      "entry --- Twitter\n",
      "substring --- This role is key to activating our innovative solutions and the role requires an individual who can work with other analysts and business users to create solutions which integrate with our marketing technology stack., \n",
      "\n",
      "In this role, the Marketing Data Engineer will:, \n",
      "\n",
      "Integrate data from various third-party and first-party data sources, including but not limited to Google Analytics 360, YouTube, LinkedIn, Facebook, Twitter, SFDC and Hubspot\n",
      "Collaborate with our team of in-house RPA engineers to automate API integrations and tedious process around marketing data collectionResponsible for all extract, transform and load (ETL) processes and the creation of applications that can connect to remote APIs.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- This role is key to activating our innovative solutions and the role requires an individual who can work with other analysts and business users to create solutions which integrate with our marketing technology stack., \n",
      "\n",
      "In this role, the Marketing Data Engineer will:, \n",
      "\n",
      "Integrate data from various third-party and first-party data sources, including but not limited to Google Analytics 360, YouTube, LinkedIn, Facebook, Twitter, SFDC and Hubspot\n",
      "Collaborate with our team of in-house RPA engineers to automate API integrations and tedious process around marketing data collectionResponsible for all extract, transform and load (ETL) processes and the creation of applications that can connect to remote APIs.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Twitter\n",
      "substring --- , Key Responsibilities:\n",
      "\n",
      ", Build and validate large-scale batch and real-time data pipelines with Big Data Technologies such as Talend Real-Time Big Data Platform, Python, Spark, Hadoop, Hive, Pig, Redshift, Snowflake, NoSQL DB on AWS/Google Cloud\n",
      "\n",
      "Evaluate, configure and implement new technologies, methodologies and architecture design patterns to build data processing ETL pipeline\n",
      "\n",
      "Design and Develop processes for data discovery, modeling, mining and archival\n",
      "\n",
      "Collaborate with data analytics team to ensure the integrity and availability of the data necessary for the business analytics & reporting\n",
      "\n",
      "Think strategically & bring new ideas to build the ETL pipeline architecture and how to scale it with the business as it grows\n",
      "\n",
      "Build reusable components and framework to speed up the data pipeline development\n",
      "\n",
      "Provide guidance/ directions to the data engineers team and implement best practices as well as standards across all the data pipelines\n",
      "\n",
      ", Education & Technical Experience Requirements:\n",
      "\n",
      ", Bachelor‚Äôs in computer science, science, or similar field of study\n",
      "\n",
      "8+ years of Data Warehousing, OLAP, SQL Queries, ETL/ELT design and development experience\n",
      "\n",
      "3+ years of experience with AWS services including S3, Redshift, EMR, Lambda and RDS\n",
      "\n",
      "3+ years of solid experience in developing and performance tuning the data pipeline with Hadoop, Hive, Spark, Talend Big Data Platform\n",
      "\n",
      "3+ years of experience in programming languages such as Python, Scala, R, Java or C#\n",
      "\n",
      "2+ years of experience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka\n",
      "\n",
      "2+ years of experience in columnar databases such as RedShift, Snowflake as well as NoSQL databases such as MongoDB, DynamoDB\n",
      "\n",
      "Self-starter and highly motivated to add value to the team and platform using innovations around data and data solutions\n",
      "\n",
      "Experience in dealing with the structured, semi-structured and unstructured datasets\n",
      "\n",
      "Excellent communication skills to collaborate with the data engineering, analytics and science teams\n",
      "\n",
      "Experience in Social Media Datasets such as Twitter, YouTube, Facebook, Instagram is a plus\n",
      "\n",
      "Experience in Google Clickstream, DFP, or Adobe Analytics datasets is a plus\n",
      "\n",
      "Experience in dealing with the Media content subscription-based datasets is a plus\n",
      "\n",
      "Experience in creating restful API‚Äôs is a plus\n",
      "\n",
      "Experience in AI, machine learning and statistics is a plus\n",
      "\n",
      "Experience in Media and Entertainment Industry is a plus\n",
      "\n",
      ", _]\"\n",
      "\"[\n",
      "3 years of experience with Big Data, systems, including Hadoop, Hive, and Pig\n",
      "Experience with ETL tools, including NiFi and StreamSets\n",
      "Experience with Java\n",
      "Experience with using Cloud services, including Amazon Web Services (AWS), Azure, or Google Cloud\n",
      "Top Secret clearance\n",
      "BA or BS degree\n",
      ", \n",
      "Experience with Agile software development\n",
      "Possession of excellent oral and written communication skills\n",
      "BS degree in CS, Computer Information Systems, Information Systems, or a related field\n",
      "]\"\n",
      "\n",
      "\"[Are passionate about working on cutting edge, high profile projects and are motivated by delivering solutions on an aggressive schedule\n",
      "Aren‚Äôt satisfied with status quo, insatiably curious, and regularly look for creative ways to solve problems and help your team meet commitments\n",
      "Love learning new technologies and sharing them with your team\n",
      "Have a keen interest in using any and all appropriate tools, especially Cloud-based and Open Sourced, to solve the problem at hand\n",
      "Have strong verbal and written communication skills, and enjoy participating in dynamic, face-paced collaborations with customers, vendors, and other engineering teams to solve complex business problems together\n",
      "Use your experience and leadership skills to motive your teammates to deliver high quality results in a fast-paced work environment\n",
      ", Work within a team of like-minded professionals to design, build and deploy critical business and mission data-centric applications in a production environment\n",
      "Design and implement appropriate data extraction, transform, and load (ETL) processes to properly prepare data, ensuring data quality and accuracy, for consumption by business and mission applications\n",
      "Identify, retrieve, manipulate, relate and/or exploit multiple structured data sets from various sources\n",
      "Design and implement data storage, sharing, and dissemination environment, ensuring support for all relevant agency and community policies\n",
      "Engineer suitable data management and governance procedures and provide production support when required\n",
      "Design and develop automation workflows, perform unit tests and conduct reviews to make sure your work is rigorously designed, elegantly coded, and effectively tuned for platform performance, and assess the overall quality of all delivered components\n",
      ", Master's Degree preferred, or a Bachelor‚Äôs degree and 4 years‚Äô experience, or 10 years of specialized experience\n",
      "Minimum 4 years‚Äô experience working on complex data/database projects as a data analyst, data architect, or database engineer\n",
      "TS Clearance with ability to obtain an SCI and CI poly\n",
      ", Certified Data Management Professional (CDMP), Microsoft Certified Solutions Associate (Business Intelligence) or equivalent certification(s) strongly desired\n",
      "Experience building n-tier web-based applications using SQL and non-SQL back-ends\n",
      "Experience with large-scale data processing tools, such as Spark, NiFi, Hadoop, Kafka, etc.\n",
      "entry --- Twitter\n",
      "substring --- We engage and develop people to their greatest potential., \n",
      "\n",
      "Work Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \n",
      "\n",
      "Achieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \n",
      "\n",
      "For more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \n",
      "\n",
      "MassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.\n",
      "entry --- Twitter\n",
      "substring --- \"[Who We Are:, \n",
      "\n",
      "As data engineers, on the Revenue Data Platform, our mission is to build real-time and offline solutions to make data accessible and reliable while leveraging the largest-scale data processing technologies in the world at the Petabytes scale - and then apply them to the Revenue‚Äôs most critical and fundamental data problems., \n",
      "\n",
      "What You‚Äôll Do:, \n",
      "\n",
      "As a member of the DataEng team, you will build and own mission-critical data pipelines that are ‚Äòsource of truth‚Äô for Twitter‚Äôs fundamental revenue data., \n",
      "\n",
      "You will be a part of an early stage team and have a significant stake in defining its future with a considerable potential to impact all of Twitter‚Äôs revenue and hundreds of millions of users., \n",
      "\n",
      "You will be among the earliest adopters of bleeding-edge data technologies, working directly with the Pipelines Infrastructure team to integrate your services at scale., \n",
      "\n",
      "Your efforts will reveal invaluable business and user insights, leveraging vast amounts of Twitter revenue data to fuel numerous Revenue teams including Ads Analytics, Ads Experience, Data Science, Marketplace, Targeting, Prediction, and many others., \n",
      "\n",
      "Who You Are:, \n",
      "\n",
      "You have a deep expertise in distributed systems, database internals, and performance analysis; you are also experienced with Hadoop, Spark, Hive, Scalding, Parquet, or other similar technologies.\n",
      "entry --- Twitter\n",
      "substring --- You are driven and excited to face the challenges of building a robust and scalable data platform, \n",
      "\n",
      "Requirements:, \n",
      "\n",
      "Strong programming and algorithmic skills\n",
      "\n",
      "Backend development experience with a solid foundation in data pipelines, distributed systems, and large-scale data processing\n",
      "\n",
      "Extensive experience with Hadoop Hive, Spark, Presto, Pig, Parquet or similar technologies\n",
      "\n",
      "Proficiency with Java or Scala\n",
      "\n",
      "Proficiency with SQL (Relational, AWS Redshift, Hive, Presto etc)\n",
      "\n",
      "Experience with schema design and dimensional data modeling\n",
      "\n",
      "Experience in a custom or structured ETL, implementation and maintenance\n",
      "\n",
      "Ability in managing and communicating data warehouse project plans to internal clients, \n",
      ", We are committed to an inclusive and diverse Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Twitter is an equal opportunity employer.\n",
      "entry --- Twitter\n",
      "substring --- For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- Twitter\n",
      "substring --- Find iStock on Facebook, Twitter, Instagram and LinkedIn, or download the iStock app where you can easily search, save and share superior images to create standout visual communications.\n",
      "entry --- Twitter\n",
      "substring --- The team‚Äôs most important roles are to enable fast, rigorous product experimentation and to provide automated tools to generate insights and understanding of our users., \n",
      "\n",
      "Responsible for experimentation (A/B testing) methodology and implementation\n",
      "\n",
      "Understanding user behavior with great visualization and analysis tools, \n",
      ", Twitter has a very data-driven culture and experimentation is at the center of product decisions.\n",
      "entry --- Twitter\n",
      "substring --- PIE engineers regularly participate in discussions with the most senior leaders at Twitter to understand how experimentation can further increase the rate of innovation.\n",
      "entry --- Twitter\n",
      "substring --- We want to maintain and increase our diversity so whoever you are and wherever you come from, if you are a great engineer we would be honored if you applied., \n",
      "\n",
      "We are committed to an inclusive and diverse Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Twitter is an equal opportunity employer.\n",
      "entry --- Twitter\n",
      "substring --- For additional information on BlackRock, please visit www.blackrock.com | Twitter: @blackrock | Blog: www.blackrockblog.com | LinkedIn: www.linkedin.com/company/blackrock., Job Description:, The Digital Wealth Platform and Sales Technology team's mission is to dramatically transform BlackRock‚Äôs current retail distribution strategy and performance around the globe, by enabling the sales team to deepen and expand their relationships with Financial Advisors & Home Offices by leveraging data to provide thoughtful analytics and by delivering cutting edge technology tools & applications to the sales force.\n",
      "entry --- Twitter\n",
      "substring --- Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]\n",
      "\"[Twitter users generate many terabytes of data every day; Twitter engineers run hundreds of experiments; Twitter Data Engineers build data pipelines and data processes that calculate metrics and scale increasingly sophisticated models of users and content., \n",
      "\n",
      "The Data Science team at Twitter is at the intersection of all this data and strives to make it actionable to all business units around Twitter.\n",
      "entry --- Twitter\n",
      "substring --- We also implement metrics to track the impact of new product experiments and more generally find ways to make very large scale data approachable to guide our decisions., Twitter has very large and complex datasets.\n",
      "entry --- Twitter\n",
      "substring --- As a Twitter Data Engineer you will build datasets and make them accessible to our partner teams by writing great production code to simplify the complexity.\n",
      "entry --- Twitter\n",
      "substring --- In every decision that you influence, you will see the product improve and be more valuable to Twitter users., \n",
      "\n",
      "We are trying to improve Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Make Twitter-scale data more discoverable and easy to use for Data Scientists and Analysts across the company.\n",
      "entry --- Twitter\n",
      "substring --- in Computer Science or a related technical field, or equivalent experience\n",
      "\n",
      "2+ years of experience in either data infrastructure or backend systems\n",
      "\n",
      "Strong understanding of SQL\n",
      "\n",
      "Broad knowledge of the data infrastructure ecosystem\n",
      "\n",
      "Experience with Hadoop or other MapReduce-based architectures\n",
      "\n",
      "Experience working with large data volumes\n",
      "\n",
      "Good understanding of one or more of the following: Scala, C++, or Java, \n",
      ", Scalding\n",
      "\n",
      "Full Stack Development\n",
      "\n",
      "Presto or Hive\n",
      "\n",
      "Spark, \n",
      ", Applicants will be considered for this role at all levels from SWE I to Senior SWE depending on qualifications., \n",
      "\n",
      "ÔªøWe are committed to an inclusive and diverse Twitter.\n",
      "entry --- Twitter\n",
      "substring --- Twitter is an equal opportunity employer.\n",
      "entry --- Twitter\n",
      "substring --- Our Data Management Platform (DMP) is now ingesting thousands of GB's of data from our online marketing sources:\n",
      ", \n",
      "\n",
      "Display Advertising\n",
      "\n",
      "Social Advertising\n",
      "\n",
      "Email marketing\n",
      "\n",
      "Online Job Postings\n",
      "\n",
      "Career Web Sites\n",
      ", Display Advertising, Social Advertising, Email marketing, Online Job Postings, Career Web Sites, Amongst many other things, Symphony Talent will be using this data to produce the following:, \n",
      "\n",
      "Multi source attribution analytics\n",
      "\n",
      "Predictive Analytics\n",
      "\n",
      "Client facing Analytics - via our SaaS portal\n",
      "\n",
      "Integration with external vendors and clients (Google, Facebook, Twitter, Indeed etc)\n",
      ", Multi source attribution analytics, Predictive Analytics, Client facing Analytics - via our SaaS portal, Integration with external vendors and clients (Google, Facebook, Twitter, Indeed etc), About the Role:\n",
      "\n",
      "\n",
      "We are looking for a \"\"generalist\"\" engineer, that will primarily be responsible for collecting, storing, processing, and analyzing huge sets of data.\n",
      "entry --- Twitter\n",
      "substring --- Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \n",
      "\n",
      "Effective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.\n",
      "entry --- iD Tech\n",
      "substring --- Requirements:, Expertise in Deep Learning and NLP\n",
      "\n",
      "Experience with software engineering best practices\n",
      "\n",
      "MS or PhD in machine learning or equivalent work experience, Desired:, Experience using big data platforms such as Spark or Hadoop, Experience using big data platforms such as Spark or Hadoop]\"\n",
      "\"[Description, The Position, \n",
      "\n",
      "iD Tech is looking for a Temporary Machine Learning Content Developer to produce the educational content and classroom tools to be used by our machine learning summer instructors across the nation with Python and TensorFlow.\n",
      "entry --- iD Tech\n",
      "substring --- , A few reasons why this is the #BestJobEver, \n",
      "iD Tech has been voted a Top Workplace by the Bay Area News Group 8 times!\n",
      "entry --- iD Tech\n",
      "substring --- We are highly profitable and expanding quickly\n",
      "iD Tech is a national leader in youth, STEM education\n",
      ", Our Company.\n",
      "entry --- iD Tech\n",
      "substring --- Over 50,000 students attended our programs last year, and that number continues to grow rapidly!, \n",
      "\n",
      "iD Tech is committed to fostering a diverse work environment and proud to be an equal opportunity employer.\n",
      "entry --- OpenAI\n",
      "substring --- Experience with Starcraft II and PySC2, and OpenAI Gym a plus.\n",
      "entry --- IBM\n",
      "substring --- , QUALIFICATIONS:\n",
      "\n",
      ", Advanced Degree (Ph.D. preferred) with a focus on Analytics, Statistical Sciences, Operations Research, Economics, Finance or a related Business quantitative discipline\n",
      "\n",
      "5+ years of real world analytical solution building experience\n",
      "\n",
      "Data mining technical knowledge and skills including: decision trees, multivariate analysis, segmentation modeling, factor analysis, regression analysis, forecasting, and machine learning\n",
      "\n",
      "Expertise in R, SAS Enterprise Miner, or IBM SPSS Modeler or other analytical software\n",
      "\n",
      "Intellectual curiosity and commitment to teaching data analytics concepts to others\n",
      "\n",
      "Experience in leading and developing data science teams a plus\n",
      "\n",
      ", Qualifications:\n",
      "\n",
      ", Company Overview:\n",
      "\n",
      ", Our success comes from strategically placing you in the most suitable role.\n",
      "entry --- IBM\n",
      "substring --- Hadoop, Cloudera, Horton Works, IBM Insights, MongoDB, Spark, Storm, HDFS, HBase, Accumulo, HIVE, PIG, SQL, Cassandra, Kafka and equivalents.\n",
      "entry --- IBM\n",
      "substring --- , How you will impact WestRock:\n",
      "\n",
      ", Works with stakeholders throughout WestRock to identify opportunities for leveraging data to drive business solutions\n",
      "\n",
      "Analyzes large data sets and use programming languages such as Python, R, IBM SPSS Modeler to develop statistical and optimization models to drive business solutions.\n",
      "entry --- IBM\n",
      "substring --- , How you will impact WestRock:\n",
      "\n",
      ", Works with stakeholders throughout WestRock to identify opportunities for leveraging data to drive business solutions\n",
      "\n",
      "Analyzes large data sets and use programming languages such as Python, R, IBM SPSS Modeler to develop statistical and optimization models to drive business solutions.\n",
      "entry --- IBM\n",
      "substring --- Working knowledge in the following technologies: Python, SQL, R, Alteryx, Microsoft Azure, IBM Watson, Tableau, etc.\n",
      "entry --- IBM\n",
      "substring --- If you're as passionate about your future as we are, join our team., \n",
      "\n",
      "KPMG is currently seeking a Sr Associate, Data Science to join our Ignition practice., \n",
      "\n",
      "Responsibilities:, \n",
      "\n",
      "Work closely with various KPMG's Tax functional teams and clients to incorporate cognitive and NLP models and algorithms into both KPMG and client solutions\n",
      "\n",
      "Define and develop new Tax solutions leveraging approaches such as Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, image recognition, deep learning, Machine Learning, cognitive science and analytics\n",
      "\n",
      "Design and implement cognitive computing/AI applications using some combination of the following commercial and open source platforms and libraries such as Microsoft AI, Google AI, AWS AI, IBM Watson, Tensor flow, Keras, Spark, Mahout, Torch, Caffe, ScIkit-learn, and NLTK, \n",
      "\n",
      "Qualifications:, \n",
      "\n",
      "Minimum of five years of IT industry experience with at least three years of experience in one of the following domains of interest - Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, Image Recognition, Deep Learning, Machine Learning, Cognitive Science and Data Analytics\n",
      "\n",
      "MS or BS in Computer Science, Applied Statistics, Engineering, Science or other quantitative discipline with specialization and experience in Artificial Intelligence, Machine Learning, Natural Language Processing, Cognitive Science or other related areas\n",
      "\n",
      "Experience working with leading cognitive computing commercial and open source platforms and libraries such as IBM Watson, Google AI, Microsoft AI, AWS AI, or Apache Mahout\n",
      "\n",
      "Demonstrated expertise with analytics and cognitive engagements across design and implementation\n",
      "\n",
      "Excellent verbal and written communication skills with the ability to work with diverse teams in a highly matrixed environment, \n",
      "\n",
      "KPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\n",
      "entry --- IBM\n",
      "substring --- SAP HANA, IBM SPSS, DSX.\n",
      "entry --- IBM\n",
      "substring --- Experience with Anaconda, IBM Blue, Oracle Big Data) to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations.\n",
      "entry --- IBM\n",
      "substring --- , 6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\n",
      "\n",
      "2+ years of design, implementation and governance experience with Artificial Intelligence, Natural Language Processing or Machine Learning architecture\n",
      "\n",
      "2 + years of experience using quantitative machine learning techniques\n",
      "\n",
      "2 + years of text analytics experience\n",
      "\n",
      "2+ years of Python experience, Extensive knowledge and understanding of research and analysis\n",
      "\n",
      "Strong analytical skills with high attention to detail and accuracy\n",
      "\n",
      "Excellent verbal, written, and interpersonal communication skills\n",
      "\n",
      "2+ years of experience with H2O software or Keras with TensorFlow\n",
      "\n",
      "2+ years of statistical modeling experience\n",
      "\n",
      "Experience with Spark, Hive and Kafka\n",
      "\n",
      "Cloud computing experience, Knowledge and/or experience with the following:\n",
      "Common NLP techniques, such as, \n",
      "\n",
      "o Pre-processing (tokenization, part-of-speech tagging, parsing, stemming)\n",
      "\n",
      "o Semantic analysis (named entity recognition, sentiment analysis)\n",
      "\n",
      "o Modeling and word representations (RNN / ConvNets, TF-IDF, LDA, Word2Vec), \n",
      "Working with data science workbench solutions (Dataiku, IBM DSX, Domino), \n",
      "\n",
      "All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check.\n",
      "entry --- IBM\n",
      "substring --- , 6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\n",
      "\n",
      "2+ years of design, implementation and governance experience with Artificial Intelligence, Natural Language Processing or Machine Learning architecture\n",
      "\n",
      "2 + years of experience using quantitative machine learning techniques\n",
      "\n",
      "2 + years of text analytics experience\n",
      "\n",
      "2+ years of Python experience, Extensive knowledge and understanding of research and analysis\n",
      "\n",
      "Strong analytical skills with high attention to detail and accuracy\n",
      "\n",
      "Excellent verbal, written, and interpersonal communication skills\n",
      "\n",
      "2+ years of experience with H2O software or Keras with TensorFlow\n",
      "\n",
      "2+ years of statistical modeling experience\n",
      "\n",
      "Experience with Spark, Hive and Kafka\n",
      "\n",
      "Cloud computing experience, Knowledge and/or experience with the following:\n",
      "Common NLP techniques, such as, \n",
      "\n",
      "o Pre-processing (tokenization, part-of-speech tagging, parsing, stemming)\n",
      "\n",
      "o Semantic analysis (named entity recognition, sentiment analysis)\n",
      "\n",
      "o Modeling and word representations (RNN / ConvNets, TF-IDF, LDA, Word2Vec), \n",
      "Working with data science workbench solutions (Dataiku, IBM DSX, Domino), \n",
      "\n",
      "All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check.\n",
      "entry --- IBM\n",
      "substring --- Experience with Anaconda, IBM Blue, Oracle Big Data) to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations.\n",
      "entry --- IBM\n",
      "substring --- Includes agency management, budget allocation, SME curation, publishing assets into the campaign and the appropriate IBM tracking systems.\n",
      "entry --- IBM\n",
      "substring --- , 5+ years of hands-on experience with R, Microsoft Machine Learning, IBM I2, STATA, SPSS, S+, SAS Enterprise Miner or similar tools.\n",
      "entry --- IBM\n",
      "substring --- Research mindset with bias towards action - able to structure a project from idea to experimentation to prototype to implementation\n",
      "\n",
      "Independence, great communication, and amazing follow-through - you aggressively tackle your work and love the responsibility of being individually empowered, \n",
      "\n",
      "Background in Machine Learning, Statistics, Operations Research, Operations Management, Econometrics, or similar\n",
      "\n",
      "Experience in software engineering]\"\n",
      "\"[At least 5 years of related experience\n",
      "\n",
      "Strong expertise in software development using Java, Node JS, Python and Bash\n",
      "\n",
      "Experience in the use of R\n",
      "\n",
      "Experience working with front end languages/document formats like JavaScript, HTML/CSS, XML/XSL\n",
      "\n",
      "Experience with relational (SQL) and non-relational databases (Mongo DB, Couch DB and others)\n",
      "\n",
      "Strong IT background including Windows and Linux\n",
      "\n",
      "Experience in building Cloud Applications using APIs and Services\n",
      "\n",
      "Experience in building solutions leveraging artificial intelligence systems and services such as IBM Watson\n",
      "\n",
      "Knowledge in software engineering practices including agile techniques\n",
      "\n",
      "Knowledge in system building/debugging/testing\n",
      "\n",
      "Experience with GitHub Enterprise based source control systems\n",
      "\n",
      "Project management skills, Developer skills in web technologies such as apache wicket, IBM Websphere, Django, Docker but also C coding\n",
      "\n",
      "Experience IT infrastructure architecture]\"\n",
      "\n",
      "\"[Leverage analytics to enhance existing products and deliver new impactful products.\n",
      "entry --- IBM\n",
      "substring --- PREFERRED EXPERIENCE:, PREFERRED EXPERIENCE:, \n",
      "\n",
      "Technical Expertise ‚Äì Experience with modeling tools & platforms (like MiniTab, R, Python, IBM SPSS, SAS or other), data management/data mining skills, visualization techniques and descriptive statistics to solve complex problems required.\n",
      "entry --- IBM\n",
      "substring --- Supporting the Analytic‚Äôs automated batch processes running on a combination of Cloudera Data Science Workbench (CDSW) and IBM SPSS Modeler in a Linux environment.\n",
      "entry --- IBM\n",
      "substring --- , Knowledge and Experience:\n",
      "\n",
      ", Advanced degree or equivalent work experience in a quantitative discipline such as statistics, computer science, actuarial, applied mathematics, or engineering\n",
      "\n",
      "Expertise in SQL query development\n",
      "\n",
      "Big Data expertise in Hadoop, including: Hue, HDFS, Hive, Python, Spark, GitHub, and data visualization\n",
      "\n",
      "2+ years of Experience with Cloudera Data Science Workbench (CDSW)\n",
      "\n",
      "Share and Document Best Practices for CDSW including project collaboration, production code migrations, and automation\n",
      "\n",
      "Knowledge of, or a desire to learn, IBM SPSS Modeler\n",
      "\n",
      "Some on-call support may be required.\n",
      "entry --- IBM\n",
      "substring --- Fluent in multiple technologies such as with Python, Azure ML, IBM SPSS Modeler, R or comparable technologies required.\n",
      "entry --- IBM\n",
      "substring --- Experience with AI tools such as TensorFlow, IBM's OpenFlow, Dialogflow.\n",
      "entry --- IBM\n",
      "substring --- Implement new, highly scalable platform components and tools leveraging machine learning and deep learning models to solve real-world problems in areas such as Speech Recognition, Natural Language Processing and Time Series predictions\n",
      "\n",
      "Demonstrating self-reliance to achieve goals collaboratively, \n",
      "\n",
      "BENEFITS, ibm.com/employment/us/benefits/\n",
      "\n",
      "ibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\n",
      "\n",
      "Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\n",
      "\n",
      "Diversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\n",
      "\n",
      "ibm.com/ibm/responsibility/corporateservicecorps, Strong programming skills and data structures, with proficiency in Python, R, Java or similar with related machine learning packages\n",
      "\n",
      "Proficient in SQL\n",
      "\n",
      "Experience using Unix/Linux & the corresponding standard command line tools preferred\n",
      "\n",
      "Deep understanding of machine learning techniques for classification, & regression is preferred\n",
      "\n",
      "Ability to design or evaluate intrinsic & extrinsic metrics of your model‚Äôs performance which are aligned with business goals\n",
      "\n",
      "Using NLP & ML techniques to extract structure from unstructured data\n",
      "\n",
      "Ability to come up with solutions to loosely defined business problems by leveraging pattern detection over large datasets\n",
      "\n",
      "Demonstrated ability to investigate & debug difficult problems\n",
      "\n",
      "Strong written and verbal communication skills.\n",
      "entry --- IBM\n",
      "substring --- Experience connecting and analyzing data from multiple business applications(SAP, SFDC, IBM Cognos)\n",
      "\n",
      "Systems engineer or reliability engineering experience.\n",
      "entry --- IBM\n",
      "substring --- 4+ years of experience applying IBM analytics software to business problems: SPSS Statistics, SPSS Modeler and SPSS Collaboration and Deployment Services\n",
      "\n",
      "Masters Degree or PhD in statistics, mathematics or closely related field]\"\n",
      "\"[\n",
      "\n",
      "Work closely with the Embedded Data Scientists/Analysts to set up, maintain and optimize performance analysis of our various in-market experiments\n",
      "\n",
      "Provide test requesters with testing methodology and frameworks to create and monitor tests over time\n",
      "\n",
      "Work with experimentation tools team to improve & enhance tool capabilities\n",
      "\n",
      "Develop traffic forecasts and size opportunities based on constraints and interpretation of data findings\n",
      "\n",
      "Define, implement and standardize metrics, reports and dashboards leveraging Tableau or other data visualization tools\n",
      "\n",
      "Deliver key metrics, reports, dashboards and ad-hoc analyses with interpretation, contributing to the development of hypotheses and actions\n",
      "\n",
      "Work with Marketing and Product Managers to develop learning plans with recommendations of analytics approaches to address questions or validate hypotheses\n",
      "\n",
      "Generate follow-up questions with stakeholders, refine data findings and interpret results to drive data-based insights\n",
      "\n",
      "Collaborate with internal and external partners to assist with data collection and reporting, \n",
      "\n",
      "7-10 years of experience in decision support and site optimization for an online/e-commerce business\n",
      "\n",
      "Deep knowledge of testing and web analytics\n",
      "\n",
      "Confident applying appropriate analysis methods of causal inference in both experimental and non-experimental situations\n",
      "\n",
      "Subject matter expertise with clickstream data, SQL & Hive is a must\n",
      "\n",
      "Understanding of complex web ecosystems, best practices and ability to put this knowledge into action\n",
      "\n",
      "Ability to tell stories with data, educate effectively, and instill confidence, motivating stakeholders to act on recommendations\n",
      "\n",
      "Excellent problem solving skills and end to end quantitative thinking\n",
      "\n",
      "Outstanding communications skills with both technical and non-technical colleagues.\n",
      "entry --- IBM\n",
      "substring --- \"[Responsible for following the defined agile development processes including attending the required meetings with contribution towards the successful completion of the sprints..Collaborates with product management and customer delivery teams to ensure product requirements are clear on what customers expect and what the delivery teams should set as the right expectations with the customers.Communicate rigorously within the squad on goals, ongoing progress, milestones, and any issues.Support and follow the overall product architects, delivery architects, to drive and establish the architecture decisions and designs for the product.Leverage the DevOps team to ensure product can be automatically built, deployed, and tested using a CI/CD pipelines across all of the release cycles from dev to production.Mentor and develop required skills of other junior product developers., Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.Experience applying machine learning and predictive analytic techniques to large, complex data sets specializing in event data processingExperience with Machine Learning frameworksExpert in coding hands on in Python and RExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processingProven ability to develop resilient code (best practice error handling) that performs and scales for large enterprise needsDeep expertise in developing REST-based API's (json/yaml), Micro-services with RDBMS and NoSQLBachelor's degree in Computer Science or equivalent with specialization Machine Learning, Understanding of Public and Private Cloud Provider services, usage and delivery paradigmsWorking knowledge of cloud technologies and architectures, including Virtualization, APIs, Micro-services and Containers.5+ years experience delivering enterprise-class cognitive applications2+ years experience developing in Python and modern web-based languagesExcellent verbal and written communication abilities: must effectively communicate with technical and non-technical teamsHigh attention to detail and proven track record in taking ownership, driving results and moving with speed to implement ideas in a fast-paced online environmentWillingness to roll up your sleeves and do whatever is necessaryAbility to process and manage multiple priorities, Ph.D or Masters in Computer Science/Artificial Intelligence with specialization in Machine Learning.Knowledge of IT Service Management and IT Operations Management processes, tools and technologiesKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment modelsExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storageExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.,  Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.\n",
      "entry --- IBM\n",
      "substring --- Knowledge of IT Service Management and IT Operations Management processes, tools and technologies\n",
      "\n",
      "Knowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment models\n",
      "\n",
      "Experience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storage\n",
      "\n",
      "Experience with Big Data architectures including Spark/Hadoop, HDFS, analytical processing\n",
      "\n",
      "Experienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.]\"\n",
      "entry --- IBM\n",
      "substring --- \"[\n",
      "3+ years of experience as a data scientist\n",
      "Experience with building statistical models and developing machine learning algorithms\n",
      "Experience with data visualization\n",
      "Experience with managing data scientist team\n",
      "Experience with programming languages, including Python, R, Scala, or Java\n",
      "Experience with Big Data technologies, including HDFS, Hadoop, or Spark\n",
      "Experience with manipulating data and ETL in parallel processing and distributed compute environments\n",
      "Experience with designing and executing machine learning models and applications\n",
      "TS/SCI clearance\n",
      "MA or MS degree\n",
      ", \n",
      "2+ years of experience as a developer in Java, Python, R, or similar high-level languages\n",
      "2+ years of experience with designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results\n",
      "2+ years of experience in managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications\n",
      "Experience in working with Big Data storage, processing, and computation, including one or more of the following: Accumulo, Spark, Storm, Kafka, or MapReduce\n",
      "Ability to both manage and manipulate large data sets, develop data science approaches, and manage data science tasks\n",
      "Ability to leverage a wide variety of data science capabilities and languages\n",
      "Ability to exhibit flexibility, initiative, and innovation when dealing with ambiguous and fast-paced situations\n",
      "]\"\n",
      "\"[Responsible for following the defined agile development processes including attending the required meetings with contribution towards the successful completion of the sprints..Collaborates with product management and customer delivery teams to ensure product requirements are clear on what customers expect and what the delivery teams should set as the right expectations with the customers.Communicate rigorously within the squad on goals, ongoing progress, milestones, and any issues.Support and follow the overall product architects, delivery architects, to drive and establish the architecture decisions and designs for the product.Leverage the DevOps team to ensure product can be automatically built, deployed, and tested using a CI/CD pipelines across all of the release cycles from dev to production.Mentor and develop required skills of other junior product developers., Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.Experience applying machine learning and predictive analytic techniques to large, complex data sets specializing in even data processingExperience with Machine Learning frameworksExpert in coding hands on in Python and RExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processingProven ability to develop resilient code (best practice error handling) that performs and scales for large enterprise needsDeep expertise in developing REST-based API's (json/yaml), Micro-services with RDBMS and NoSQLBachelor's degree in Computer Science or equivalent with specialization Machine Learning, Understanding of Public and Private Cloud Provider services, usage and delivery paradigmsWorking knowledge of cloud technologies and architectures, including Virtualization, APIs, Micro-services and Containers.5+ years experience delivering enterprise-class cognitive applications2+ years experience developing in Python and modern web-based languagesExcellent verbal and written communication abilities: must effectively communicate with technical and non-technical teamsHigh attention to detail and proven track record in taking ownership, driving results and moving with speed to implement ideas in a fast-paced online environmentWillingness to roll up your sleeves and do whatever is necessaryAbility to process and manage multiple priorities, Ph.D or Masters in Computer Science/Artificial Intelligence with specialization in Machine Learning.Knowledge of IT Service Management and IT Operations Management processes, tools and technologiesKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment modelsExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storageExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.,  Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.\n",
      "entry --- IBM\n",
      "substring --- Knowledge of IT Service Management and IT Operations Management processes, tools and technologies\n",
      "\n",
      "Knowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment models\n",
      "\n",
      "Experience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storage\n",
      "\n",
      "Experience with Big Data architectures including Spark/Hadoop, HDFS, analytical processing\n",
      "\n",
      "Experienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.]\"\n",
      "entry --- IBM\n",
      "substring --- , 6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\n",
      "\n",
      "2+ years of design, implementation and governance experience with Artificial Intelligence, Natural Language Processing or Machine Learning architecture\n",
      "\n",
      "2 + years of experience using quantitative machine learning techniques\n",
      "\n",
      "2 + years of text analytics experience\n",
      "\n",
      "2+ years of Python experience, Extensive knowledge and understanding of research and analysis\n",
      "\n",
      "Strong analytical skills with high attention to detail and accuracy\n",
      "\n",
      "Excellent verbal, written, and interpersonal communication skills\n",
      "\n",
      "2+ years of experience with H2O software or Keras with TensorFlow\n",
      "\n",
      "2+ years of statistical modeling experience\n",
      "\n",
      "Experience with Spark, Hive and Kafka\n",
      "\n",
      "Cloud computing experience, Knowledge and/or experience with the following:\n",
      "Common NLP techniques, such as, \n",
      "\n",
      "o Pre-processing (tokenization, part-of-speech tagging, parsing, stemming)\n",
      "\n",
      "o Semantic analysis (named entity recognition, sentiment analysis)\n",
      "\n",
      "o Modeling and word representations (RNN / ConvNets, TF-IDF, LDA, Word2Vec), \n",
      "Working with data science workbench solutions (Dataiku, IBM DSX, Domino), \n",
      "\n",
      "All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check.\n",
      "entry --- IBM\n",
      "substring --- , 6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\n",
      "\n",
      "2+ years of design, implementation and governance experience with Artificial Intelligence, Natural Language Processing or Machine Learning architecture\n",
      "\n",
      "2 + years of experience using quantitative machine learning techniques\n",
      "\n",
      "2 + years of text analytics experience\n",
      "\n",
      "2+ years of Python experience, Extensive knowledge and understanding of research and analysis\n",
      "\n",
      "Strong analytical skills with high attention to detail and accuracy\n",
      "\n",
      "Excellent verbal, written, and interpersonal communication skills\n",
      "\n",
      "2+ years of experience with H2O software or Keras with TensorFlow\n",
      "\n",
      "2+ years of statistical modeling experience\n",
      "\n",
      "Experience with Spark, Hive and Kafka\n",
      "\n",
      "Cloud computing experience, Knowledge and/or experience with the following:\n",
      "Common NLP techniques, such as, \n",
      "\n",
      "o Pre-processing (tokenization, part-of-speech tagging, parsing, stemming)\n",
      "\n",
      "o Semantic analysis (named entity recognition, sentiment analysis)\n",
      "\n",
      "o Modeling and word representations (RNN / ConvNets, TF-IDF, LDA, Word2Vec), \n",
      "Working with data science workbench solutions (Dataiku, IBM DSX, Domino), \n",
      "\n",
      "All offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check.\n",
      "entry --- IBM\n",
      "substring --- \"[Bachelor's degree in computer science or engineering\n",
      "\n",
      "Master's degree in computer science or engineering, or MBA preferred\n",
      "\n",
      "Eight (8) years or more of relevant IT experience with a variety of DW/BI technologies supporting the full software development life cycle\n",
      "\n",
      "Five (5) years or more of experience as a Data Integration Lead, managing large and complex environment, ideally in a multibillion dollar organization\n",
      "\n",
      "Experience managing production incident/change request backlog, performing initial triage of issues and resource allocation\n",
      "\n",
      "Excellent project management skills\n",
      "\n",
      "Strong verbal communication, interpersonal and listening skills\n",
      "\n",
      "Strong technical aptitude\n",
      "\n",
      "A team player, with a positive attitude and willingness to help and mentor others\n",
      "\n",
      "Expertise in Informatica & Microsoft Data Integration platform, IBM Netezza Analytical appliance, Oracle Golden Gate replication and SQL Server transactional database (expert level)\n",
      "\n",
      "Knowledge of data modeling tools preferred (intermediate level) preferred, \n",
      "\n",
      "Bring collections and/or elements of legacy and new data together as part of a BI&A data integration architecture that adds value to the business\n",
      "\n",
      "Collaborate with BIA development teams, enterprise architecture and other IT application teams to define current and strategic future state data integration architectures\n",
      "\n",
      "Contribute to the creation and implementation of new design patterns and standards for the data integration domain\n",
      "\n",
      "Provide leadership in the logical and physical design of analytical and reporting application systems, and ensure design is consistent and well integrated with existing conceptual, logical, and physical application architectures\n",
      "\n",
      "Manage a team of data integration developers to guide the creation of ETL processes and support existing production jobs\n",
      "\n",
      "Maintain a depth of expertise with database security, data virtualization and replication as well as other complex technical tools and solutions, data access, transformation, design, modeling, metadata structures, data integrity, archiving/recovery, etc.\n",
      "entry --- IBM\n",
      "substring --- This means we offer these great perks to help keep our team healthy, productive and happy:, Health, dental and vision coverage\n",
      "Life insurance, short-term, and long-term disability paid for by the company\n",
      "401(k) plan offered with employer match\n",
      "High-end hardware to work with\n",
      "Learning and career growth prospects\n",
      "Paid Holiday and Time Off\n",
      "Referral bonus program\n",
      "Opportunities for profit sharing, bonuses and ownership\n",
      "Ability to working with bleeding edge technology right here in AZ\n",
      "Fast paced Startup Culture]\"\n",
      "\"[IBM Global Business Services (GBS) is hiring a Data Scientist for our Cognitive & Analytics Consulting Practice.\n",
      "entry --- IBM\n",
      "substring --- Responsibilities:\n",
      "\n",
      "\n",
      ", Lead strategy discussions and help to design and develop a solution that meets clients goals and outcomes\n",
      "\n",
      "Conduct data analysis and predictive analysis to meet client needs\n",
      "\n",
      "Reverse-engineer implemented solutions to understand the client problem and resolve client challenges\n",
      "\n",
      "Create predictive models, train and leverage machine learning APIs, build machine learning pipelines, build Chatbots for the enterprise, embed intelligence in a variety of industry or domain-specific use-cases, and more, BENEFITS, ibm.com/employment/us/benefits/\n",
      "\n",
      "ibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\n",
      "\n",
      "Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\n",
      "\n",
      "Diversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\n",
      "\n",
      "ibm.com/ibm/responsibility/corporateservicecorps/, At least 2 years of experience working on predictive analytics and data mining projects\n",
      "\n",
      "At least 2 years of hands-on experience using complex machine learning methods and algorithms such neural net, deep learning and collaborative filtering\n",
      "\n",
      "At least 2 years of experience working with one or more data mining tools such as R, Python, SAS and SPSS\n",
      "\n",
      "Hands-on experience writing complex SQL queries and working with relational databases such as Oracle DB2 and SQL Server\n",
      "\n",
      "Hands-on experience constructing and manipulating JSON and XML documents and working with NoSQL databases such as MangoDB and CouchDB.\n",
      "entry --- IBM\n",
      "substring --- ), Caffe/TensorFlow/Keras/etc, Hadoop, Spark, Pig, Experience providing direct support to analysts, Experience building models and tools to help analysts understand data and answer intelligence questions, Experience using Data Science libraries in Python or R: tidyverse, NumPy, SciPy, Pandas, Familiarity with commercial and open source data science software: IBM SPSS Modeler, SAS, KNIME, RapidMiner, Statistica, Familiarity with software development (Scala, C#, Java, JavaScript, etc.\n",
      "entry --- IBM\n",
      "substring --- Data-oriented personality]\"\n",
      "\"[\n",
      "8+ years of experience with data science or Cybersecurity\n",
      "Experience with Python\n",
      "Experience with SQL\n",
      "Knowledge of data science and machine learning techniques\n",
      "Knowledge of Cybersecurity concepts and trends\n",
      "Ability to build presentations and present to large groups\n",
      "TS/SCI clearance\n",
      "BA or BS degree in CS, Mathematics, Engineering, Science, or Technology\n",
      ", \n",
      "Experience with Apache Spark\n",
      "Experience with Hadoop, YARN, HDFS, Kafka, and Ambari\n",
      "Experience with Elasticsearch, Logstash, and Kibana (ELK) stack\n",
      "Experience with IBM Netezza, Tableau, and bash scripting\n",
      "Experience with JIRA and working in an Agile environment\n",
      "DHS Suitability clearance\n",
      "Apache Spark Developer Certification\n",
      "CISSP, Security+, or other Cybersecurity Certification\n",
      "]\"\n",
      "\"[\n",
      "\n",
      "Collaborating with other developers (both data scientists and engineers) to design, research, integrate, and implement solutions, \n",
      "\n",
      "Collaborating with other analysts, product and client-facing stakeholders to determine the feasibility of specific client requests given our data and capability, \n",
      "\n",
      "Communicating with team members, project management and business stakeholders to understand requirements and strategically implement robust software and machine learning design, \n",
      "\n",
      "Identifying opportunities for improvement within existing software applications and frameworks, \n",
      "\n",
      "Mandatory Qualifications:]\"\n",
      "\"[At American Family Insurance, we‚Äôre driven by our customers and employees.\n",
      "entry --- IBM\n",
      "substring --- Need to be close to a major airport\n",
      "Salary: Entirely depends on skill-level and location (wide range), \n",
      "\n",
      "Everyday Responsibilites:, \n",
      "Work with clients‚Äô software architects and engineers to provide technical solutions w/ company‚Äôs technologies\n",
      "Consult with clients on how to integrate a new technology stack\n",
      "Develop software in Scala, Kafka, Akka, Spark, and other reactive platforms\n",
      "Involvement in the pre-sales process\n",
      "Develop training curriculum for clients\n",
      ", Required Qualifications:, \n",
      "4+ years of JVM-based languages/systems\n",
      "Expert-level development experience in Java & Scala\n",
      "Experience working with at least one of the following technologies (Spark, Kafka, Akka)\n",
      "Experience in and knowledge of big data batch streaming architectures\n",
      "Experience working with Distributed Architecture technologies\n",
      "Strong interest in adopting new technologies and evangelizing them\n",
      "Ability to be client facing (strong written and oral communication skills)\n",
      "Experience leading/advising software development teams\n",
      ", **US Citizen or Green Card Holder only**]\"\n",
      "\n",
      "\"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.\n",
      "entry --- IBM\n",
      "substring --- We establish new, flexible and iterative approaches that only IBM can offer through our unique combination of skills, experience and capabilities, leveraging the proven roadmaps and frameworks we have developed across our 17 industries.\n",
      "entry --- IBM\n",
      "substring --- Additionally, we apply IBM‚Äôs global expertise and local capabilities through our unique global delivery network combined with our teams in over 170 countries to provide our clients with an integrated approach to business design and execution, and turning strategies into actions.\n",
      "entry --- IBM\n",
      "substring --- Responsibilities:\n",
      "\n",
      "\n",
      ", Work with clients across many levels: C-Level, Vice-President, IT, Analytics and Business Users\n",
      "\n",
      "Leverage experience to apply elements of the Cross-Industry Standard Process for Data Mining (CRISP-DM)\n",
      "\n",
      "Define key business problems from starter conversations, gather and analyze relevant data, conduct advanced transformations and integrations, identify suitable algorithmic approaches, conduct proper evaluations and stage outputs for operational deployments\n",
      "\n",
      "Translate complex technical findings, conclusions and recommendations in compelling written and oral delivery formats, often to non data science personas\n",
      "\n",
      ", BENEFITS, ibm.com/employment/us/benefits/\n",
      "\n",
      "ibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\n",
      "\n",
      "Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\n",
      "\n",
      "Diversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\n",
      "\n",
      "ibm.com/ibm/responsibility/corporateservicecorps/, At least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\n",
      "\n",
      "At least 5 years of experience in project management for external consulting engagements\n",
      "\n",
      "At least 5 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\n",
      "\n",
      "At least 5 years of experience data management and coding such as DB2, SQL, Hadoop\n",
      "\n",
      "At least 3 years of experience in visualization such as d3, Javascript, HTML, CSS, Advanced degree in a technical field\n",
      "\n",
      "At least 7 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\n",
      "\n",
      "At least 7 years of experience in project management for external consulting engagements\n",
      "\n",
      "At least 7 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\n",
      "\n",
      "At least 4 years of experience in visualization such as d3, Javascript, HTML, CSS]\"\n",
      "\n",
      "\"[Must possess an active TS/SCI clearance with a CI polygraph.\n",
      "entry --- IBM\n",
      "substring --- Differentiate the offering and the people working on it through the depth and breadth of expert skills\n",
      "\n",
      "Manage and coordinate teams to deploy data analytics projects using innovative solutions and to provide analytics-driven insights\n",
      "\n",
      "Educate and coach both clients and team members on machine learning knowledge, practical mathematical modeling, simulation and optimization in multiple analytics platform\n",
      "\n",
      ", \n",
      "\n",
      "Leverage IBM offerings, assets, and capabilities to create and deliver differentiated service offerings to our clients.\n",
      "entry --- IBM\n",
      "substring --- Implement new, highly scalable platform components and tools leveraging machine learning and deep learning models to solve real-world problems in areas such as Speech Recognition, Natural Language Processing and Time Series predictions\n",
      "\n",
      "Demonstrating self-reliance to achieve goals collaboratively, \n",
      "\n",
      "BENEFITS, ibm.com/employment/us/benefits/\n",
      "\n",
      "ibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\n",
      "\n",
      "Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\n",
      "\n",
      "Diversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\n",
      "\n",
      "ibm.com/ibm/responsibility/corporateservicecorps, Bachelor‚Äôs Degree in Statistics, Mathematics, Engineering or related STEM fields\n",
      "\n",
      "At least 5 years of progressive experience with a broad set of technical stacks, hands-on Machine Learning and Big Data\n",
      "\n",
      "Deep expertise in building scalable with Machine Learning powered applications\n",
      "\n",
      "Expertise across a variety of data integration tools streamlining data across several big data solutions\n",
      "\n",
      "Experience in creating and managing capabilities and solutions for any one of the following:\n",
      "\n",
      "Risk, Legal, Fraud, Compliance Management\n",
      "\n",
      "Retail, Wealth and Private Banking\n",
      "\n",
      "Marketing Analytics\n",
      "\n",
      "Quantitative Financial Analytics\n",
      "\n",
      "Digital Customer Experience, Customer Care and Customer Journey Optimization, \n",
      "\n",
      "Risk, Legal, Fraud, Compliance Management\n",
      "\n",
      "Retail, Wealth and Private Banking\n",
      "\n",
      "Marketing Analytics\n",
      "\n",
      "Quantitative Financial Analytics\n",
      "\n",
      "Digital Customer Experience, Customer Care and Customer Journey Optimization, Master‚Äôs Degree in Statistics, Mathematics, Engineering or related STEM fields\n",
      "\n",
      "At least 7 years of progressive experience with a broad set of technical stacks, hands-on Machine Learning and Big Data\n",
      "\n",
      "Sales and or Pre-Sales experience]\"\n",
      "\"[Senior Data Scientist, \n",
      "\n",
      "Santa Clara, \n",
      "\n",
      "A compelling opportunity has arisen to join a leading analytics business based in the South Bay, as a Senior Data Scientist with a core focus on Natural Language Processing and Linguistics., \n",
      "\n",
      "The business was recently awarded the highest possible scores for corporate strategy, analysis, consulting and product roadmaps by a leading market research organization., \n",
      "\n",
      "Reporting directly to the Director of Data Science, you will be joining an organization on a strong growth path, working with one of the most interesting and complex data sets available., \n",
      "\n",
      "YOUR ROLE AS SENIOR DATA SCIENTIST:, \n",
      "\n",
      "Document classification - genre recognition - ads, spam, natural speech\n",
      "\n",
      "Sentiment Analysis of linguistic data\n",
      "\n",
      "Extending insight extraction functions\n",
      "\n",
      "Understanding trends and theories in linguistic classification, \n",
      "\n",
      "SKILLS AND EXPERIENCE:\n",
      ", Expert hands-on Python programming experience\n",
      "\n",
      "Hands on experience with JavaScript & MySQL\n",
      "\n",
      "Extensive experience with NLP and Linguistics\n",
      "\n",
      "Exceptional communication skills, \n",
      "\n",
      "Desirable Requirements:, \n",
      "\n",
      "Hands-on experience with Hadoop, Cassandra, Spark\n",
      "\n",
      "Statistics or Data Visualization experience\n",
      "\n",
      "Cross functional project management experience\n",
      "\n",
      "Prior experience working with overseas teams.\n",
      "entry --- IBM\n",
      "substring --- Minimum of 5+ years experience working in a quantitative analysis/data analytics, managing and/or coaching one or more analysts\n",
      "\n",
      "Experience working with relational databases, such as SQL\n",
      "\n",
      "Strong communication skills to be able to work with clients and present to C-level executives\n",
      "\n",
      "Solid project management methodology background, including schedule, scope, issue and risk management experience, change management, strategic planning and analysis\n",
      "\n",
      "Present experience or proficiency with data related projects\n",
      "\n",
      "Proficient analytical, problem solving and quality delivery experience\n",
      "\n",
      "Proven expertise with advanced analytics and data mining tools and programming languages such as SAS, IBM/SPSS, R, Python, and SQL\n",
      "\n",
      "Familiarity with BI/data visualization tools such as Tableau and Qlikview\n",
      "\n",
      "Hands-on experience with multivariate analytic techniques such as linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and neural nets\n",
      "\n",
      "NoSQL (preferred): HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.\n",
      "entry --- IBM\n",
      "substring --- The team‚Äôs goal is to continuously improve the company‚Äôs marketplace and shopping efficiencies., \n",
      "\n",
      "Some of the teams‚Äô projects include:, \n",
      "Design experiments to help with cutting edge technology such as augmented reality or indoor GPS\n",
      "Design and rigorously test new features in our app that improve quality of service for our customers\n",
      "Identify the optimal product strategy for different marketplaces\n",
      "Define and measure metrics that quantify the tradeoffs between different fulfillment models\n",
      "Distill complex datasets into actionable KPIs; build and automate reporting to empower data driven decision making across the company\n",
      ", Qualifications:\n",
      "\n",
      "3+ years of experience or equivalent in conducting quantitative research, analysis and modeling, preferably at a start-up, \n",
      "\n",
      "Experience supporting Data Scientists in model validation and algorithm / model optimization, \n",
      "\n",
      "Expertise in wrangling large datasets (SQL, Hive, or Spark), \n",
      "\n",
      "Effective data visualization skills (Tableau, Looker, or D3.js), \n",
      "\n",
      "Solid programming skills for statistical analysis (Python or R), \n",
      "\n",
      "A passion for leveraging data for business impact, \n",
      "\n",
      "A high sense of urgency and ownership, \n",
      "\n",
      "Growth mindset; the ability to thrive in a dynamic and collaborative environment, \n",
      "\n",
      "Prior experience in logistics and marketplace systems preferred]\"\n",
      "\"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.\n",
      "entry --- IBM\n",
      "substring --- We establish new, flexible and iterative approaches that only IBM can offer through our unique combination of skills, experience and capabilities, leveraging the proven roadmaps and frameworks we have developed across our 17 industries.\n",
      "entry --- IBM\n",
      "substring --- Additionally, we apply IBM‚Äôs global expertise and local capabilities through our unique global delivery network combined with our teams in over 170 countries to provide our clients with an integrated approach to business design and execution, and turning strategies into actions.\n",
      "entry --- IBM\n",
      "substring --- Responsibilities:\n",
      "\n",
      "\n",
      ", Work with clients across many levels: C-Level, Vice-President, IT, Analytics and Business Users\n",
      "\n",
      "Leverage experience to apply elements of the Cross-Industry Standard Process for Data Mining (CRISP-DM)\n",
      "\n",
      "Define key business problems from starter conversations, gather and analyze relevant data, conduct advanced transformations and integrations, identify suitable algorithmic approaches, conduct proper evaluations and stage outputs for operational deployments\n",
      "\n",
      "Translate complex technical findings, conclusions and recommendations in compelling written and oral delivery formats, often to non data science personas\n",
      "\n",
      ", BENEFITS, ibm.com/employment/us/benefits/\n",
      "\n",
      "ibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\n",
      "\n",
      "Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\n",
      "\n",
      "Diversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\n",
      "\n",
      "ibm.com/ibm/responsibility/corporateservicecorps/, At least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\n",
      "\n",
      "At least 5 years of experience in project management for external consulting engagements\n",
      "\n",
      "At least 5 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\n",
      "\n",
      "At least 5 years of experience data management and coding such as DB2, SQL, Hadoop\n",
      "\n",
      "At least 3 years of experience in visualization such as d3, Javascript, HTML, CSS, Advanced degree in a technical field\n",
      "\n",
      "At least 7 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\n",
      "\n",
      "At least 7 years of experience in project management for external consulting engagements\n",
      "\n",
      "At least 7 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\n",
      "\n",
      "At least 4 years of experience in visualization such as d3, Javascript, HTML, CSS]\"\n",
      "\"[As a Data scientist/Machine learning engineer, You will be part of a very fast growing engineering team and one of the first engineers in our machine learning team.\n",
      "entry --- IBM\n",
      "substring --- ), Caffe/TensorFlow/Keras/etc, Hadoop, Spark, PigExperience providing direct support to analystsExperience building models and tools to help analysts understand data and answer intelligence questionsExperience using Data Science libraries in Python or R: tidyverse, NumPy, SciPy, PandasFamiliarity with commercial and open source data science software: IBM SPSS Modeler, SAS, KNIME, RapidMiner, StatisticaFamiliarity with software development (Scala, C#, Java, JavaScript, etc.\n",
      "entry --- IBM\n",
      "substring --- One of:\n",
      "\n",
      "Experience or interest in controlling physical systems using Machine Learning\n",
      "\n",
      "Computational Neuroscience modeling experiences\n",
      "\n",
      "Interest and ability to make fundamental advances in ML\n",
      "\n",
      "Interest at the intersection of computer vision and language\n",
      "\n",
      "Strong understanding of classical ML techniques, \n",
      "\n",
      "#LI-post]\"\n",
      "\"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.\n",
      "entry --- IBM\n",
      "substring --- We establish new, flexible and iterative approaches that only IBM can offer through our unique combination of skills, experience and capabilities, leveraging the proven roadmaps and frameworks we have developed across our 17 industries.\n",
      "entry --- IBM\n",
      "substring --- Additionally, we apply IBM‚Äôs global expertise and local capabilities through our unique global delivery network combined with our teams in over 170 countries to provide our clients with an integrated approach to business design and execution, and turning strategies into actions.\n",
      "entry --- IBM\n",
      "substring --- thought leadership, articles, talks, competitions, certifications)\n",
      "\n",
      "Educate and coach both clients and team members on machine learning knowledge, practical mathematical modeling, simulation and optimization in multiple analytics platform, BENEFITS, ibm.com/employment/us/benefits/\n",
      "\n",
      "ibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\n",
      "\n",
      "Finding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\n",
      "\n",
      "Diversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\n",
      "\n",
      "ibm.com/ibm/responsibility/corporateservicecorps/, Master's Degree in Statistics, Mathematics, Engineering or related STEM fields\n",
      "\n",
      "At least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\n",
      "\n",
      "At least 5 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\n",
      "\n",
      "At least 5 years of experience in data management and coding such as DB2, SQL, Hadoop, PhD in Statistics, Mathematics, Engineering or related STEM fields\n",
      "\n",
      "Applied knowledge on simulation and optimization\n",
      "\n",
      "Experience in visualization such as d3, Javascript, HTML, CSS]\"\n",
      "\"[\n",
      "\n",
      "Deliver lectures and tutorials on scientific Python, SQL, probability, statistics (Bayesian and frequentist), machine learning, and data engineering.\n",
      "entry --- IBM\n",
      "substring --- Prior familiarity with programs involving Chatbots, Machine Learning, API.AI, and IBM Watson is REQUIRED\n",
      "\n",
      "Ability to lead digital transformation in a traditional Business Process.\n",
      "entry --- IBM\n",
      "substring --- Develops responses to legislative requests including fiscal notes., \n",
      "Develops queries in TRS' IBM Cognos database to extract data for use in spreadsheets, models, dashboards, and summaries that support decision-making.\n",
      "entry --- IBM\n",
      "substring --- Strong knowledge of randomForest, nnet, svm, PMML and glmnet packages., \n",
      "\n",
      "#LI-MC1, \n",
      "\n",
      "Company Summary, \n",
      "\n",
      "Zeta is a data-driven marketing technology innovator whose SaaS-based marketing cloud helps 500+ Fortune 1000 and Middle Market brands acquire, retain and grow customer relationships through actionable data, advanced analytics and machine learning., \n",
      "\n",
      "Founded by David A. Steinberg and John Sculley (former CEO of Apple and Pepsi-Cola) in 2007, the company's highly-rated ZetaHub technology platform has been recognized in Gartner's Magic Quadrant for Digital Marketing Hubs (February 2017) and in its Magic Quadrant for Multichannel Campaign Management (April 2017), competing with offerings from Oracle, IBM, Salesforce and Adobe., \n",
      "\n",
      "Operating on four continents with 1,300+ employees, the company is headquartered in New York City, with Centers of Excellence in Silicon Valley, Boston, London, and Hyderabad, India.\n",
      "entry --- IBM\n",
      "substring --- , Other Credentials Required: Driver's License, Vehicle Liability Insurance]\"\n",
      "\"[Serves as site coordinator for one or more of the following database tools:\n",
      "\n",
      "Truven/IBM-Watson Care Discovery Advantage Solution\n",
      "\n",
      "3M Encompass/360 MD analytics\n",
      "Clinovations HCC/HHS Program\n",
      "\n",
      "PEPPERreports\n",
      "Executive Health Resources Exchange/OptumInsights\n",
      "Vizient HIIN\n",
      "\n",
      "Epic electronic health record database\n",
      "Collects and reports data for organizational clinical performance improvement initiatives\n",
      "Obtains listing of patients for clinical analysis, reviews charts, and reports data trends and analysis\n",
      "Performs download of reports and site-specific outcomes\n",
      "Coordinates with other organizational analysts and CPSL Programs Managers to insure consistency between database tools, to the extent that definition and exclusion variations allow\n",
      "Prepares and distributes reports as directed utilizing various software presentation tools\n",
      "Educates physicians and other staff on current and updated database definitions\n",
      "Serves as a resource person in the development, maintenance, and troubleshooting of assigned database initiatives\n",
      "Performs data collection, analysis, and presentation, as directed, on various performance improvement activities within the CPSL\n",
      "Performs analysis of ‚Äúoutliers‚Äù as directed\n",
      "Attends clinical meetings as directed\n",
      "Participates in regular phone/webex conferences to keep up-to-date on issues\n",
      "Updates CPSL dashboard for assigned database functions\n",
      "Supports respective managers for designated program development accreditation responsibilities\n",
      ", Truven/IBM-Watson Care Discovery Advantage Solution\n",
      "\n",
      "3M Encompass/360 MD analytics\n",
      "Clinovations HCC/HHS Program\n",
      "\n",
      "PEPPERreports\n",
      "Executive Health Resources Exchange/OptumInsights\n",
      "Vizient HIIN\n",
      "\n",
      "Epic electronic health record database\n",
      "]\"\n",
      "\n",
      "\"[M inimum Requirements:\n",
      "]\"\n",
      "\"[Position Purpose:, \n",
      "\n",
      "The Data Analyst is responsible for the collection, analysis and reporting of client/customer data using complex analysis of datasets in areas of research, development, product enhancement or other targeted business objectives.\n",
      "entry --- IBM\n",
      "substring --- We desire someone with diverse experience and skills in data analysis, litigation support, statistical software, analytic programming languages (Python, R, Java, SAS), visualization software, and database management., \n",
      "\n",
      "RESPONSIBILITIES:, \n",
      "\n",
      "Work with client case teams to identify their needs and jointly develop solutions through leveraging all available analytic and visualization options\n",
      "\n",
      "Conduct regular consultations with clients\n",
      "\n",
      "Provides regular status updates regarding assigned tasks\n",
      "\n",
      "Ensures successful completion of work, timeliness of deliverables, and quality control\n",
      "\n",
      "Build experience in all available analysis and visualization software, Qualifications, \n",
      "\n",
      "EDUCATION & EXPERIENCE, \n",
      "\n",
      "Bachelor‚Äôs degree or equivalent; 2+ years of experience using analytics tools, methods, and visualization software\n",
      "\n",
      "Significant experience in one or more of the following tools is required:\n",
      "\n",
      "Tableau Software\n",
      "\n",
      "IBM I2/EIA\n",
      "\n",
      "IBM Analyst Notebook\n",
      "\n",
      "Database (SQL Server, Oracle, PostgreSQL, MySQL)\n",
      "\n",
      "Programming and/or scripting (Python, R, Java)\n",
      "\n",
      "Natural Language Processing\n",
      "\n",
      "Neo4j or other graph databases\n",
      "\n",
      "Palantir Gotham\n",
      "\n",
      "Nexidia\n",
      "\n",
      "Other analytic and visualization tools, \n",
      "\n",
      "Tableau Software\n",
      "\n",
      "IBM I2/EIA\n",
      "\n",
      "IBM Analyst Notebook\n",
      "\n",
      "Database (SQL Server, Oracle, PostgreSQL, MySQL)\n",
      "\n",
      "Programming and/or scripting (Python, R, Java)\n",
      "\n",
      "Natural Language Processing\n",
      "\n",
      "Neo4j or other graph databases\n",
      "\n",
      "Palantir Gotham\n",
      "\n",
      "Nexidia\n",
      "\n",
      "Other analytic and visualization tools, Background in Law Enforcement, Data Science, Investigations, Data Analysis, Computer Information Systems, or Statistics\n",
      "\n",
      "Industry analytics/business intelligence knowledge including current industry trends, challenges, and data quality approaches\n",
      "\n",
      "Deep understanding of database, ETL, and analytics tools and concepts\n",
      "\n",
      "Must be able to work independently and prioritize work effectively, as well as to function as an effective team member in a local and virtual team development environment\n",
      "\n",
      "Strong analytical and problem solving skills with an unsurpassed attention to detail\n",
      "\n",
      "Excellent communication (written and verbal) skills\n",
      "\n",
      "Experience supporting federal agencies\n",
      "\n",
      "SQL experience is required, We‚Äôve been named a Best Place to Work by the Washington Post., Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives., We offer competitive benefits and learning and development opportunities., We are mission-oriented and ever vigilant in aligning our solutions with the nation‚Äôs highest priorities., For over 55 years, the principles of CACI‚Äôs unique, character-based culture have been the driving force behind our success., \n",
      "\n",
      "Job Location, \n",
      "\n",
      "US-Washington-DC-WASHINGTON DC, \n",
      "\n",
      "CACI employs a diverse range of talent to create an environment that fuels innovation and fosters continuous improvement and success.\n",
      "entry --- IBM\n",
      "substring --- Strong knowledge of randomForest, nnet, svm, PMML and glmnet packages., \n",
      "\n",
      "#LI-MC1, \n",
      "\n",
      "Company Summary, \n",
      "\n",
      "Zeta is a data-driven marketing technology innovator whose SaaS-based marketing cloud helps 500+ Fortune 1000 and Middle Market brands acquire, retain and grow customer relationships through actionable data, advanced analytics and machine learning., \n",
      "\n",
      "Founded by David A. Steinberg and John Sculley (former CEO of Apple and Pepsi-Cola) in 2007, the company's highly-rated ZetaHub technology platform has been recognized in Gartner's Magic Quadrant for Digital Marketing Hubs (February 2017) and in its Magic Quadrant for Multichannel Campaign Management (April 2017), competing with offerings from Oracle, IBM, Salesforce and Adobe., \n",
      "\n",
      "Operating on four continents with 1,300+ employees, the company is headquartered in New York City, with Centers of Excellence in Silicon Valley, Boston, London, and Hyderabad, India.\n",
      "entry --- IBM\n",
      "substring --- Strong knowledge of randomForest, nnet, svm, PMML and glmnet packages., \n",
      "\n",
      "#LI-MC1, \n",
      "\n",
      "Company Summary, \n",
      "\n",
      "Zeta is a data-driven marketing technology innovator whose SaaS-based marketing cloud helps 500+ Fortune 1000 and Middle Market brands acquire, retain and grow customer relationships through actionable data, advanced analytics and machine learning., \n",
      "\n",
      "Founded by David A. Steinberg and John Sculley (former CEO of Apple and Pepsi-Cola) in 2007, the company's highly-rated ZetaHub technology platform has been recognized in Gartner's Magic Quadrant for Digital Marketing Hubs (February 2017) and in its Magic Quadrant for Multichannel Campaign Management (April 2017), competing with offerings from Oracle, IBM, Salesforce and Adobe., \n",
      "\n",
      "Operating on four continents with 1,300+ employees, the company is headquartered in New York City, with Centers of Excellence in Silicon Valley, Boston, London, and Hyderabad, India.\n",
      "entry --- IBM\n",
      "substring --- Oracle\n",
      "\n",
      "Background in Statistics\n",
      "\n",
      "Data quality experience and familiarity with commercial data quality software\n",
      "\n",
      "Experience with Informatica or IBM Infosphere data quality tools\n",
      "\n",
      "Familiarity with IBM Initiate, Workbench and/or Identity Management\n",
      "\n",
      "Knowledgeable of or experience with data warehouse, graphical presentation of large dataset\n",
      "\n",
      ", # of Openings:\n",
      "\n",
      ", Scheduled Weekly Hours:\n",
      "\n",
      ", T elecommuting Options:\n",
      "\n",
      ", Work Location:\n",
      "\n",
      ", Additional Work Locations:\n",
      "\n",
      ", CSRA is committed to creating a diverse environment and is an equal opportunity employer.\n",
      "entry --- IBM\n",
      "substring --- Expert in Oracle\n",
      "\n",
      "Background in Statistics\n",
      "\n",
      "Data quality experience and familiarity with commercial data quality software\n",
      "\n",
      "Experience with Informatica or IBM MDM Infosphere data quality tools\n",
      "\n",
      "Familiarity with IBM MDM InfoSphere 11.5 (or initiate), Workbench and/or Identity Management\n",
      "\n",
      "Knowledgeable of or experience with data warehouse, graphical presentation of large dataset\n",
      "\n",
      ", # of Openings:\n",
      "\n",
      ", Scheduled Weekly Hours:\n",
      "\n",
      ", T elecommuting Options:\n",
      "\n",
      ", Work Location:\n",
      "\n",
      ", Additional Work Locations:\n",
      "\n",
      ", CSRA is committed to creating a diverse environment and is an equal opportunity employer.\n",
      "entry --- IBM\n",
      "substring --- Master's degree in Engineering, Mathematics, Computer Science, Supply Chain or related field., \n",
      "\n",
      "Company Summary, Position Summary]\"\n",
      "\"[\n",
      "\n",
      "Gather, document, and communicate requirements effectively to ensure appropriate implementation of solutions and processes\n",
      "\n",
      "Develop effective problem statements and drive to resolution, \n",
      "\n",
      "Perform as-is and to-be analysis, \n",
      "\n",
      "Serves as a data steward, ensuring accurate and timely data capture, \n",
      "\n",
      "Plan and manage projects; anticipate and mitigate risk, document decisions, manage change, \n",
      "\n",
      "Compose effective cross-team and inter-departmental communications, \n",
      "\n",
      "Ensure continuous improvement in quality of data and deliverables, \n",
      "\n",
      "Collaborate with cross-functional teams to enable and promote Enterprise adoption of Master Data Platforms, \n",
      "\n",
      "5 years of data analyst experience\n",
      "\n",
      "Bachelor of Science degree in STEM (Science, Technology, Engineering or Math)\n",
      "\n",
      "Project Management experience\n",
      "\n",
      "Experience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\n",
      "\n",
      "Experience manipulating and analyzing large datasets, \n",
      "\n",
      "Experience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\n",
      "\n",
      "Experience manipulating and analyzing large datasets, \n",
      "\n",
      "Concentration in Computer Science, Computer Engineering, or related field strongly preferred\n",
      "\n",
      "Understands NI's products and how NI engages customers is strongly preferred\n",
      "\n",
      "Self-Starter, high level of ownership, proactive nature, problem-solving skills\n",
      "\n",
      "Keen eye for detail and precision\n",
      "\n",
      "Strong technical skills, comfortable working with technical teams (Excel, PIM IBM, Datawarehousing, SQL Queries)\n",
      "\n",
      "Solution driven - strong analytical skills to identify, analyze and solve problems given ambiguous information\n",
      "\n",
      "Strong personal organizational and project planning and management skills\n",
      "\n",
      "Teamwork skills essential; sense of humor required\n",
      "\n",
      "Excellent English communication skills - verbal and written]\"\n",
      "\"[Qualys is seeking a Data Analyst with experience in financial systems and data management and interest in helping automate reporting and financial analysis.\n",
      "entry --- IBM\n",
      "substring --- Must like to laugh.Exceptional skills with: Word, Excel, PowerPoint, and other analytics tools as well as, Tableau, SQL, Slack, Zoom, Box and Architect., Develop, manage and create content for the Analyst Relations department.The content you generate educates IBM executives, the most influential technical analysts, hybrid analysts, bloggers, marketers, etc., who work with existing or prospective IBM customers, key global media and financial markets.Work closely with and for Vice President, department colleagues and BU‚Äôs to influence strategy while improving analyst/influencer perceptions and relationships.Collaborate with colleagues in Analyst Relations, Marketing, Sales, Product Management, Communications, Finance and BU leadership to ensure that IBM is receiving the best representation with the analyst/influencer community.Develop and broaden Analyst Relations key performance metrics to elevate efforts to key BU leadership and stakeholders.Analyze analyst inputs, such as social media, blogs, reports, and other forms of influence.\n",
      "entry --- IBM\n",
      "substring --- Leverage data to guide Analyst Relations leads to maximize amplification of IBM messages.Develop a keen understanding of how to build credible and impactful relationships with key influencers and leading industry analysts.\n",
      "entry --- IBM\n",
      "substring --- Honesty, tenacity and consistency.Grow a deep technical interest in the spaces that IBM plays in.Be a person who thinks about bettering the world through your work in the technology sector., Bachelor‚Äôs Degree in Data Analytics, Data Science, Applied Math, EconomicsProven proficiency in analysis and visualization tools such as SQL, Tableau, and Excel.Expertise in writing and creating compelling data-based content and graphics, and presenting them in Word and PowerPoint.Experience with collaboration software tools such as Box, Zoom, Slack and Architect.Experience in social media analysis.Experience working in the tech sector and/or a passion for technology.Polish and presence to work with senior management.Excellent verbal and written communication skills.Unwavering attention to detail and excellence.Compassion and respect for fellow colleagues and clients.Entrepreneurial mindset, being able to operate in a highly visible and accountable role., Advanced Degree in the Engineering/Sciences, Math, Computer Science and/or MBA Strategy or JD.5+ years of work technology flavored experience in: Data Analytics, Market Research, Performance Marketing, Management Consulting, Strategy, Product Management, Communications, PR, or Graphic Design.Existing relationships with leading industry analysts/influencers in emerging technologies space.]\n",
      "entry --- IBM\n",
      "substring --- \"[\n",
      "\n",
      "Gather, document, and communicate requirements effectively to ensure appropriate implementation of solutions and processes\n",
      "\n",
      "Develop effective problem statements and drive to resolution, \n",
      "\n",
      "Perform as-is and to-be analysis, \n",
      "\n",
      "Serves as a data steward, ensuring accurate and timely data capture, \n",
      "\n",
      "Plan and manage projects; anticipate and mitigate risk, document decisions, manage change, \n",
      "\n",
      "Compose effective cross-team and inter-departmental communications, \n",
      "\n",
      "Ensure continuous improvement in quality of data and deliverables, \n",
      "\n",
      "Collaborate with cross-functional teams to enable and promote Enterprise adoption of Master Data Platforms, \n",
      "\n",
      "5 years of data analyst experience\n",
      "\n",
      "Bachelor of Science degree in STEM (Science, Technology, Engineering or Math)\n",
      "\n",
      "Project Management experience\n",
      "\n",
      "Experience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\n",
      "\n",
      "Experience manipulating and analyzing large datasets, \n",
      "\n",
      "Experience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\n",
      "\n",
      "Experience manipulating and analyzing large datasets, \n",
      "\n",
      "Concentration in Computer Science, Computer Engineering, or related field strongly preferred\n",
      "\n",
      "Understands NI's products and how NI engages customers is strongly preferred\n",
      "\n",
      "Self-Starter, high level of ownership, proactive nature, problem-solving skills\n",
      "\n",
      "Keen eye for detail and precision\n",
      "\n",
      "Strong technical skills, comfortable working with technical teams (Excel, PIM IBM, Datawarehousing, SQL Queries)\n",
      "\n",
      "Solution driven - strong analytical skills to identify, analyze and solve problems given ambiguous information\n",
      "\n",
      "Strong personal organizational and project planning and management skills\n",
      "\n",
      "Teamwork skills essential; sense of humor required\n",
      "\n",
      "Excellent English communication skills - verbal and written]\"\n",
      "\"[Los Alamos Technical Associates, Inc. (LATA) is a premier employee-owned engineering services company with over three decades of success.\n",
      "entry --- IBM\n",
      "substring --- \"[5-10 years‚Äô experience with Application/ System support, development and design\n",
      "\n",
      "Experience with IBM database management systems\n",
      "\n",
      "Technical skills with DB2, QMF and SQL\n",
      "\n",
      "Demonstrated project management and communication skills\n",
      "\n",
      "Strong analytic skills, focus on problem determination and solving\n",
      "\n",
      "Ability to write technical and operational management documentation, 5-10 years‚Äô experience with Application/ System support, development and design\n",
      "\n",
      "Experience with IBM database management systems\n",
      "\n",
      "Technical skills with DB2, QMF and SQL\n",
      "\n",
      "Demonstrated project management and communication skills\n",
      ", Strong analytic skills, focus on problem determination and solving\n",
      "\n",
      "Ability to write technical and operational management documentation]\"\n",
      "\n",
      "\"[First San Francisco Partners is a business advisory and enterprise information management (EIM) consultancy dedicated to helping companies leverage their data to improve strategic decision-making, reduce risk, create operational efficiencies and fuel unprecedented business success.\n",
      "entry --- IBM\n",
      "substring --- Prior experience with IBM Guardium tool.\n",
      "entry --- IBM\n",
      "substring --- Prior experience with IBM Guardium Big Data Intelligence/SongarG tooling., \n",
      "\n",
      "\n",
      "Incumbency:\n",
      "\n",
      "\n",
      "This position will have an 18-month incumbency period, beginning on the effective date of the position, which must be met before the employee can post for any other lateral State Farm position.\n",
      "entry --- IBM\n",
      "substring --- Have experience in extracting data and building complex data transformation using SQL on MS SQL Server, IBM DB2, Sybase, XML, and other popular data structures.\n",
      "entry --- IBM\n",
      "substring --- \"[Define database physical structure and functional capabilities, security, back-up, and recovery specifications.Install database systems by developing flowcharts; applying optimum access techniques; coordinating installation actions; document actions.Map data elements from client systems to target application for ingestion and processingMaintain database performance by identifying and resolving production and application development problems; calculating optimum values for parameters; evaluating, integrating, and installing new releases; completing maintenance; answering user questions., Bachelors degree and 5 years total relevant experience or equivalentAt least 3 years‚Äô experience as Data Analyst.As per TO2 of the contract, one of the discriminating factors for selecting the deployment architecture alternative shall be:Data acquisition, data processing and data lifecycle managementThe contractor should be able understand the selected alternative for data architecture, and help in mapping data from SSA systems to the IBM Counter Fraud Management Solution (ICFM) in the pre-production and production environments.Good communication skills, and problem solving abilities., Do you have what it takes to be mission critical?, \n",
      "\n",
      "We are always looking for team members that have what it takes to be mission critical.\n",
      "entry --- IBM\n",
      "substring --- \"[Bachelor's degree preferably in Computer Science, Statistics, or Mathematics or equivalent experience\n",
      "\n",
      "5-8 years experiences in data analysis required\n",
      "5 or more years hand on experience writing complex SQL\n",
      "General knowledge of Netezza and/or Oracle databases\n",
      "\n",
      "Working experience with Informatica Analyst and IBM Information Governance Catalog\n",
      "Strong analytical and problem-solving skills, Performs data analysis, gap and impact analysis for medium to large sized assignment (with med/large number of data elements, one-to-multiple sources, business impact, and visibility).\n",
      "entry --- IBM\n",
      "substring --- Work with Business SMEs and Analysts to understand functional requirements and interact with other cross-functional teams to support their work to architect, design, develop, and test the solution., Ability to work seamlessly with complex data models and data relationships\n",
      "\n",
      "Very strong SQL query language skills is a must have\n",
      "\n",
      "Experience profiling data within relational data model structures is required\n",
      "\n",
      "Must have significant experience creating logical source to target maps for complex data warehouses\n",
      "\n",
      "Ability to design and implement data model tables, with experience using Erwin or IBM Data Architect data modeling tools required\n",
      "\n",
      "Must have at least 7 years experience working mapping and analyzing data within a Data Warehousing or Data Lake environment, with 5 years experience working with clinical Healthcare data.\n",
      "entry --- IBM\n",
      "substring --- )Demonstrate knowledge of networking concepts and devices (Firewalls, Routers, Switches, and Load Balancers)Demonstrate an understanding of network and web related protocols (such as, TCP/IP, UDP, IPSEC, HTTP, HTTPS, routing protocols)Experience developing and improving KPIs, metrics, and trending for vulnerability management functionsUnderstanding of how applications, networking, operating systems, and databases work, Interested candidate must submit a resume/CV through www.nbcunicareers.com to be consideredMust be willing to work at one of the following locations: New York, NY, Desired Characteristics, Intellectual capability and curiosity to learn complex processes.Highly collaborative; personally, and professionally self-aware; able to and interested in interacting with employees at all levels; embody integrity; and represent and inspire the highest ethical standards.Strong sense of urgency and commitment, as well as sound business sense with a strategic, conceptual and operational orientationExperience advising on technical related issuesPassion for and interest in media and entertainment industry highly desiredFlexible, organized, and passionate about advanced cyber securityGreat interpersonal skills and love for a team environment, Sub-Business, Career Level, City, State/Province, Country, About Us, Notices]\"\n",
      "\"[Job Description, \n",
      "\n",
      "\n",
      "What You‚Äôll Get to Do:, \n",
      "\n",
      "JOB DESCRIPTION:\n",
      "\n",
      ", The Business Intelligence Data Analyst is a software data analysis/engineering position for BIG Data Analytics, using SAS/IBM COGNOS Solutions to help business clients.\n",
      "entry --- IBM\n",
      "substring --- The Business Intelligence Data Analyst is responsible to support all CMS Marketplace users, who consume MIDAS Data and ensures the highest levels of customer satisfaction and provides thought leadership focusing on value-based design through the implementation and adoption of SAS solutions to empower analytics., \n",
      "\n",
      "More About the Role:\n",
      "\n",
      "\n",
      "Chantilly, VA, \n",
      "\n",
      "The Business Intelligence Data Analyst will perform the following duties:, \n",
      "\n",
      "Creates data modules in SAS and IBM COGNOS to fuse together many sources of data including relational databases, Hadoop-based technologies, Microsoft Excel, Flat files and so on and refine data by creating calculations, defining filters, and updating metadata for detail analysis of data.\n",
      "entry --- IBM\n",
      "substring --- Maintain the latest knowledge in software and hardware products or services, trends, and identify best solutions to meet business requirements., \n",
      "\n",
      "\n",
      "You‚Äôll Bring These Qualifications:, \n",
      "\n",
      "Master's degree in Computer Science, Computer Engineering, Information Technology or Engineering Management or related or equivalent., \n",
      "\n",
      "Experience/Skills: 2 years of experience in data analysis using SAS platform tools such as SAS Programming, EBI, Enterprise Guide, Enterprise Miner, SAS Visual Analytics and SQL; 2 years of development experience with IBM COGNOS Business Intelligence Platform; 2 years of experience to support users for development issues and provide guidelines to address the issues; experience analyzing big data using SAS and big data products such as Hive, Impala, HDFS, Spark, Hue and HBase; data analysis experience, with a combination of business and technical skills; experience in building BI Reports to meet customer requirements using IBM COGNOS & SAS Tools; experience automating operational processes using scripting languages such as Shell/Ruby/Python; experience working with Data warehouse., We‚Äôve been named a Best Place to Work by the Washington Post., Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives., We offer competitive benefits and learning and development opportunities., We are mission-oriented and ever vigilant in aligning our solutions with the nation‚Äôs highest priorities., For over 55 years, the principles of CACI‚Äôs unique, character-based culture have been the driving force behind our success., \n",
      "\n",
      "Job Location, \n",
      "\n",
      "US-Chantilly-VA-VIRGINIA SUBURBAN, \n",
      "\n",
      "CACI employs a diverse range of talent to create an environment that fuels innovation and fosters continuous improvement and success.\n",
      "entry --- IBM\n",
      "substring --- Experience building re-usable data integration frameworks and patterns\n",
      "Working knowledge of Informatica, Hadoop/AWS, IBM Infosphere products and other Big Data tools.\n",
      "entry --- IBM\n",
      "substring --- \"[Experience - Consulting experience and client interaction on challenging projects\n",
      "\n",
      "Education & Training - Ongoing learning and development opportunities\n",
      "\n",
      "Networking & Professional Development - IBM leadership and peer networking opportunities\n",
      "\n",
      "Supportive and dynamic team work environment\n",
      "\n",
      "Compensation ‚Äì our employees enjoy a competitive compensation package, Natural language processing by helping to understand the complexities of unstructured data\n",
      "\n",
      "Hypothesis generation and evaluation by applying advanced analytics to weigh and evaluate a panel of responses based on only relevant evidence\n",
      "\n",
      "Dynamic learning by helping to improve learning based on outcomes to get smarter with each iteration and interaction.\n",
      "entry --- IBM\n",
      "substring --- Experience with Informatica, Talend and other data management systems\n",
      "Experience operating in traditional and agile project models\n",
      "Experience in developing and setup of MDM organization structures\n",
      "Technical expertise to include: Talend ESB, IBM IIB, IBM Informatica tools, J2EE, Exari, Drupal, Oracle, Microsoft SQL Server, MySQL, Subversion, Agile, DevOps and Java Based Workflow/BPM, and Office 365 including SharePoint\n",
      ", About Octo Consulting Group, Inc., \n",
      "\n",
      "Octo Consulting Group (Octo) is an industry-leading, award-winning provider of digital services for the federal government.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Advanced oral and written communication skills; must be a self-starter.\n",
      "entry --- IBM\n",
      "substring --- Knowledge of machine learning platforms such as Amazon, IBM Watson, Azure, Google Predict, BigML\n",
      "Strong trouble-shooting skills.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Advanced oral and written communication skills; must be a self-starter.\n",
      "entry --- IBM\n",
      "substring --- At IBM and The Weather Company, we're strongly committed to the advancement of open Internet standards and applications.\n",
      "entry --- IBM\n",
      "substring --- The Weather Company (an IBM Business) is seeking a Data Engineer to utilize skills in DevOps and data management/engineering to work with architects, developers and other team members to design, build, and operationalize solutions for strategic enterprise data processing in geospatial data.\n",
      "entry --- IBM\n",
      "substring --- Experience in Geospatial analytics is preferred\n",
      "\n",
      "Preferred Tech and Prof Experience\n",
      "\n",
      "\n",
      "DevOps & automation: Kubernetes, Git, Github, Jenkins, Terraform,Chef,Docker\n",
      "\n",
      "\n",
      "Experience in designing, running and troubleshooting Hadoop/SPARK clusters\n",
      "\n",
      "BIGDATA: HBase, spark, hive, elastic search\n",
      "\n",
      "\n",
      "Cloud: IBM Cloud, AWS, S3, Swagger\n",
      "\n",
      "\n",
      "Strong understanding of Linux OS core principles, performance and tuning\n",
      "\n",
      "\n",
      "Strong programming skills in the following languages: Python, Scala, SQL, Java, bash, c++\n",
      "\n",
      "\n",
      "Experience with Analytics : SPARK, python, scala, Jupyter notebooks\n",
      "\n",
      "\n",
      "Strong knowledge of RDBMS management and application development: Postgres, MySQL, DB2\n",
      "\n",
      "EO Statement\n",
      "\n",
      "IBM is committed to creating a diverse environment and is proud to be an equal opportunity employer.\n",
      "entry --- IBM\n",
      "substring --- IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.]\"\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Advanced oral and written communication skills; must be a self-starter.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Advanced oral and written communication skills; must be a self-starter.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Advanced oral and written communication skills; must be a self-starter.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Must be a self-starter and have excellent oral and communication skills\n",
      ", The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Must be a self-starter and have excellent oral and communication skills\n",
      ", The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "2+ years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Must be a self-starter with excellent oral and communication skills.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "2+ years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Must be a self-starter with excellent oral and communication skills.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "2+ years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Must be a self-starter with excellent oral and communication skills.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Advanced oral and written communication skills; must be a self-starter.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Advanced oral and written communication skills; must be a self-starter.\n",
      "entry --- IBM\n",
      "substring --- Identify impact and opportunities to reuse data structures through services oriented architecture (Data as a Service ‚Äì Daas)\n",
      "\n",
      "Leading data engineering teams for large BI, Cloud and / or ERP projects, \n",
      "\n",
      "Preferred Skills:, \n",
      "\n",
      "Focus in Oil & Gas with Hadoop technology stack\n",
      "\n",
      "AWS, MS Azure and other Cloud RDBMS experience is a PLUS\n",
      "\n",
      "Experience with Enterprise Architecture Tools (Mega, Troux, IBM, Opentext etc)\n",
      "\n",
      "Data Archiving, Disaster Recovery and DBA, \n",
      "\n",
      "Professional Skills:, \n",
      "\n",
      "Eagerness to contribute in a team-oriented environment\n",
      "\n",
      "Ability to work creatively and analytically in a problem-solving environment\n",
      "\n",
      "Desire to work in an information systems environment\n",
      "\n",
      "Excellent leadership, communication (written and oral) and interpersonal skills]\"\n",
      "\"[Data Engineer Consultant, \n",
      "\n",
      "As a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.\n",
      "entry --- IBM\n",
      "substring --- Experience with a RDBMS (IBM DB2, Netezza, MySQL a plus).\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Must be a self-starter and have excellent oral and communication skills\n",
      ", The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.\n",
      "entry --- IBM\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Must be a self-starter and have excellent oral and communication skills\n",
      ", The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Must be a self-starter and have excellent oral and communication skills\n",
      ", The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Must be a self-starter and have excellent oral and communication skills\n",
      ", The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.\n",
      "entry --- IBM\n",
      "substring --- \"[Build, design and implement high impact data analytics and machine learning solutionsBring new ideas in machine learning software developmentLeverage industry knowledge and stay close to technology developments in the open-source communitiesCollaborate with cross-functional teamsAssist and drive the team by providing oversight., Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms\n",
      "Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions\n",
      "Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements, Solid foundation in SQL, data structures, algorithms, design patterns and strong analytical and problem-solving skillsExperience working with predictive modeling in SAS, Python, R or other2+ years of experience leading workstreams with significant experience leading components of data engagements and team sizes ranging from 3 to 10 resources.A strategic thinker who is proactive in providing valuable insights and strong leadership skillsExcellent communications and interpersonal skills, Experience in data management consulting or industry experience (master data, metadata, data architecture, data governance, data quality, data modeling) with experience including the following tools: Informatica, IBM, Oracle and Cloud MDM, Reltio, PIM, SAP BODS, etc.Experience with other visualization tools is a major plus, such as TableauAbility to work independently; lead small teams focused on specific work streams of larger projects.Strong oral and written communication skills, including presentation skills (MS Visio, MS PowerPoint).Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.Eagerness to mentor junior staffBachelor‚Äôs Degree or 4+ years of equivalent professional experience, As used in this posting, ‚ÄúDeloitte‚Äù means Deloitte Consulting LLP, a subsidiary of Deloitte LLP.\n",
      "entry --- IBM\n",
      "substring --- Deep experience or knowledge in foundational information management arenas, such as Master Data Management, Data Governance, Modern Data Architecture, and Data Integration\n",
      "Experience in Data Architecture/Modeling, ETL, Data Quality and MDM tools, including IBM Infosphere and Microsoft SQL Server Integration Services, Data Quality Services, and Master Data Services\n",
      "Experience in architecting and implementing emerging technologies/tools, such as AWS, Hadoop, Cloudera, and/or Hortonworks, to address predictive analytics and unstructured data use cases\n",
      "Experience in designing and implementing Next Generation Architecture solutions incorporating Big Data, NoSQL, Cloud-Based Analytics, and Real-Time Analytics\n",
      "Experience in working with large volumes of data from disparate data sources across complex business processes and functions\n",
      "Must have strong leadership and interpersonal skills to resolve problems in a professional manner, lead working groups, negotiate, and create consensus\n",
      "Must be able to astutely operate in and navigate through client organizations\n",
      "Must have strong written/oral communication and presentation skills\n",
      "Must be highly self-motivated, entrepreneurial, humble, and curious\n",
      ", Location, \n",
      "Work remotely from home, your favorite coffee shop, or HatchWorks.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "2+ years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Working knowledge of Tableau ‚Äì a plus\n",
      "Must be a self-starter with excellent oral and communication skills.\n",
      "entry --- IBM\n",
      "substring --- Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\n",
      "At least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\n",
      "Experience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\n",
      "Experience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\n",
      "Must be a self-starter and have excellent oral and communication skills\n",
      ", The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.\n",
      "entry --- IBM\n",
      "substring --- Knowledge of distributed systems as it pertains to data storage and computing\n",
      "Strong problem-solving skills and capability to understand and set direction for complex technology integration\n",
      "Experience and/or interest in designing and building Artificial intelligence solutions using third party API‚Äôs such as Microsoft Azure, Amazon Machine Learning, Google ML, IBM Watson etc\n",
      "Experience and/or interest in working with open source eco-system components such as Tensorflow, Scikit learn, Hadoop, Apache Spark, Apache Flume and Apache Kafka.\n",
      "entry --- IBM\n",
      "substring --- Experience in API Gateways (IBM Datapower, Apigee)\n",
      "\n",
      "Experience with microservice and event driven architectures\n",
      "\n",
      "Familiarity with Lambda and Kappa architectures for data intensive applications\n",
      "\n",
      "Shows passion for hands-on work in the data engineering and data management space with a focus to bring them together to control at scale while improving data provisioning and consumption velocity\n",
      "\n",
      "Excellent organizational, communication, influence and execution skills]\"\n",
      "\"[At Capital One, we‚Äôre building a leading information-based technology company.\n",
      "entry --- T-Mobile\n",
      "substring --- Represents T-Mobile at professional meetings, in professional societies and universities.\n",
      "entry --- T-Mobile\n",
      "substring --- Represents T-Mobile at professional meetings, in professional societies and universities.\n",
      "entry --- T-Mobile\n",
      "substring --- Direct technically, and/or manage, within the broad mission of the group, activities of other research staff members and technical support persons., \n",
      "\n",
      "Democratize AI by deploying AI Solutions easily for common business scenarios\n",
      "\n",
      "Leverage Powerful prebuilt AI models exposed as API services\n",
      "\n",
      "Simple REST APIs with .NET, Java, Python, Node SDKs\n",
      "\n",
      "Train in the cloud and deploy anywhere model\n",
      "\n",
      "Text Analytics and NLP services to the broader T-Mobile functional areas\n",
      "\n",
      "Innovation: Contributes designs to implement new ideas improving existing or new system/process/service directly supporting Business value drivers.\n",
      "entry --- T-Mobile\n",
      "substring --- \"[T-Mobile Home and Entertainment is seeking a proactive and driven Marketing Data Analyst with a passion for numbers and solving big data problems with actionable solutions.\n",
      "entry --- Argonne National Laboratory\n",
      "substring --- As a multidisciplinary national laboratory, Argonne offers an exciting campus atmosphere in which to collaborate on interdisciplinary projects developing solutions to complex scientific and engineering problems on the world‚Äôs largest parallel supercomputers., Position Requirements\n",
      "\n",
      "\n",
      ", Minimum bachelor‚Äôs degree in Bioinformatics, CS, or Biology\n",
      "\n",
      "Fluency in scientific programming languages\n",
      "\n",
      "Experience with bioinformatics analysis techniques and tools\n",
      "\n",
      "Familiarity working in a Unix environment\n",
      "\n",
      "Experience on high performance computing platforms and newer GPU systems\n",
      "\n",
      "Experience processing NGS sequence data, familiarity with bacterial genomics, or demonstrated work in microbiology\n",
      "\n",
      "Knowledge of artificial intelligence across machine learning, deep learning and statistics\n",
      "\n",
      "Strong analytical and problem-solving skills\n",
      "\n",
      "Understanding of computational algorithms to support DNA sequence alignment, small nucleotide polymorphism detection, gene expression quantification and/or small molecule (drug) structure\n",
      "\n",
      "Experience working on protected health information including electronic health records\n",
      "\n",
      "Familiarity with regulatory policies and procedures surrounding electronic protected health information required\n",
      "\n",
      "Ability to write research publications\n",
      "\n",
      "Considerable collaborative skills, including the ability to interact well with external and internal collaborators\n",
      "\n",
      "United States citizenship is a requirement on some projects\n",
      "\n",
      "Ability to think independently and innovatively to develop exceptional technical solutions required, As an equal employment opportunity and affirmative action employer, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation.\n",
      "entry --- Elder Research Inc\n",
      "substring --- Citizenship\n",
      "TS/SCI clearance with CI polygraph\n",
      "Bachelor‚Äôs degree in math, statistics, or computer science\n",
      "Must have a minimum of 5 years‚Äô experience with large-scale data manipulation, analytic tools, and data visualization\n",
      "Demonstrated expertise in constructing and performing complex database search queries of various databases\n",
      "Ability to simultaneously understand computer science concepts, data context, and mission objectives while completing projects\n",
      "Experience producing both tactical and strategic analytic products and briefing senior level managers\n",
      "Excellent critical thinking, communication, and collaboration skills, including the ability to communicate technical findings to non-technical audiences\n",
      "Expertise in statistical packages such as SPSS, SAS, or R\n",
      ", Experience with all-source analysis in the U.S. Intelligence Community\n",
      "Programming experience in Python or Perl\n",
      "Background in statistics]\"\n",
      "\"[Data Scientist - Defense & Intelligence, \n",
      "\n",
      "Elder Research Inc. is a recognized leader in predictive analytics and data science.\n",
      "entry --- Dell\n",
      "substring --- , Responsibilities Include:, \n",
      "\n",
      "Provide creative solutions to marketplace problems using data driven approach, both in short and long term\n",
      "\n",
      "Deliver robust and scalable solutions to improve Users' and advertisers' experience on Bing\n",
      "\n",
      "Work closely with various feature teams, evaluating the feature impact on Bing marketplace\n",
      "\n",
      "Be a ‚ÄòGo-To‚Äô person for any data analytical needs ranging from data extraction/manipulations, long term trend analysis, statistical analysis and Machine learning models\n",
      "\n",
      "Use hypothesis driven approach to answer analytical questions, provide recommendations to the leadership teams, \n",
      "\n",
      "Share standard methodologies and documentation across teams, \n",
      "\n",
      "Basic Qualifications:,  Bachelor‚Äôs degree or above in a Computer science, STEM, related engineering or Business-related field with strong emphasis on data analytics 2+ years of experience in Data mining and qualitative analytics Curious mind and willing to tackle complex business problems Understanding of Machine learning & statistical analytical tools, \n",
      "\n",
      "Preferred skills:,  Be Skillful at C/C++/C#, SQL programming, python, R Have a strong interest in online advertising products business models and system architectures Experience in online Ad space is a plus]\"\n",
      "\"[Dell provides the technology that transforms the way we all work and live.\n",
      "entry --- Dell\n",
      "substring --- Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.\n",
      "entry --- Dell\n",
      "substring --- All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\n",
      "entry --- Dell\n",
      "substring --- Dell will not tolerate discrimination or harassment based on any of these characteristics.\n",
      "entry --- Dell\n",
      "substring --- Learn more about Diversity and Inclusion at Dell here.]\"\n",
      "entry --- Dell\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "substring --- Our vibrant and diverse international community of nearly 250 publishing brands and imprints include Ballantine Bantam Dell, Berkley, Clarkson Potter, Crown, DK, Doubleday, Dutton, Grosset & Dunlap, Little Golden Books, Knopf, Modern Library, Pantheon, Penguin Books, Penguin Press, Penguin Random House Audio, Penguin Young Readers, Portfolio, Puffin, Putnam, Random House, Random House Children‚Äôs Books, Riverhead, Ten Speed Press, Viking, and Vintage, among others.\n",
      "entry --- Dell\n",
      "substring --- If you have what it takes to bring innovative new products and services to life in collaboration with world-class experts, this is your opportunity to develop with Dell.\n",
      "entry --- Dell\n",
      "substring --- Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.\n",
      "entry --- Dell\n",
      "substring --- All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\n",
      "entry --- Dell\n",
      "substring --- Dell will not tolerate discrimination or harassment based on any of these characteristics.\n",
      "entry --- Dell\n",
      "substring --- Learn more about Diversity and Inclusion at Dell here.]\"\n",
      "entry --- Dell\n",
      "substring --- Passion about machine learning and a desire to constantly learn as the field evolves., \n",
      "\n",
      "BA/BS degree in Computer Science, Machine Learning, or related technical field., \n",
      "\n",
      "2-5 years of relevant work experience with machine learning or data science., \n",
      "\n",
      "Proficiency in R, Python, and/or Scala., \n",
      "\n",
      "Experience with problems and projects that depart from your average academic or Kaggle project and address real-world issues like severe class imbalance., \n",
      "\n",
      "Understanding of machine learning techniques in high-dimensional spaces including kernels, ensembles, regularization, dimensionality reduction, and clustering., \n",
      "\n",
      "Superior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts., \n",
      "\n",
      "Passion about machine learning and a desire to constantly learn as the field evolves., \n",
      "\n",
      "Secureworks (A Dell Technologies Company) is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.\n",
      "entry --- Dell\n",
      "substring --- Experience with statistical software or scientific computation software (e.g.,R, Matlab) is preferred\n",
      "\n",
      "Hadoop or other comparable MapReduce experience is preferred\n",
      "\n",
      "Experience with hands-on coding from scratch is preferred\n",
      "\n",
      "Exposure to Internet measurement data is a plus\n",
      "\n",
      "Online advertising industry experience is a plus, LI-BM1\n",
      ", MSJA]\"\n",
      "\"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \n",
      "\n",
      "Predictive Science is looking for a Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world.]\"\n",
      "entry --- Dell\n",
      "substring --- U.S. Citizen with a TS/SCI clearance]\"\n",
      "\"[Dell provides the technology that transforms the way we all work and live.\n",
      "entry --- Dell\n",
      "substring --- If you share our passion for data and you‚Äôre keen to play a key role in driving progress, this is your opportunity to develop with Dell., \n",
      "\n",
      "Closing date: January 2019., \n",
      "\n",
      "Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.\n",
      "entry --- Dell\n",
      "substring --- All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\n",
      "entry --- Dell\n",
      "substring --- Dell will not tolerate discrimination or harassment based on any of these characteristics.\n",
      "entry --- Dell\n",
      "substring --- Learn more about Diversity and Inclusion at Dell here.]\"\n",
      "entry --- Dell\n",
      "substring --- Experience extracting data from both conventional databases (via SQL) and Hadoop data clusters (via Hive or similar language)]\"\n",
      "\"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \n",
      "\n",
      "Predictive Science is looking for a Chief Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them stand-up, manage, or take their data science practice to a whole new level.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world.]\"\n",
      "entry --- Dell\n",
      "substring --- \"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \n",
      "\n",
      "Predictive Science is looking for a Senior Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world.]\"\n",
      "entry --- Dell\n",
      "substring --- www.levyrestaurants.com]\"\n",
      "\"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \n",
      "\n",
      "Predictive Science is looking for a Data Analyst who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results.\n",
      "entry --- Dell\n",
      "substring --- Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world.]\"\n",
      "entry --- Dell\n",
      "substring --- The Transformation team helps the CSG leadership to define the near- and long-term strategy for Dell‚Äôs worldwide PC business., \n",
      "\n",
      "Role Responsibilities, \n",
      "\n",
      "Data mining using state-of-the-art methods\n",
      "\n",
      "Developing and enhancing data models to deliver predictive insights\n",
      "\n",
      "Creating automated anomaly detection systems and constant tracking of its performance\n",
      "\n",
      "Developing data visualizations to help guide decision making\n",
      "\n",
      "Conducting ad hoc deep dives to understand root cause of issues\n",
      "\n",
      "Collaborating with internal and external consulting teams on transformation projects\n",
      "\n",
      "Collaborating with LOB/function strategy, sales, marketing, and product teams to address issues identified, Requirements, \n",
      "\n",
      "Excellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.\n",
      "entry --- Dell\n",
      "substring --- Experience in using statistical analysis and data science to drive corporate decision making\n",
      "\n",
      "5+ years of experience preferred\n",
      "\n",
      "Bachelor‚Äôs degree in business, data science or other quantitative discipline; Masters degree preferred, Dell offers:, \n",
      "\n",
      "Opportunity to work with a strong brand at one of the world's largest IT solutions providers\n",
      "\n",
      "Dynamic, challenging, international work environment\n",
      "\n",
      "A team with a high level of energy, integrity and motivation to win\n",
      "\n",
      "Exciting internal career opportunities\n",
      "\n",
      "A commitment to diversity and inclusion\n",
      "\n",
      "Competitive compensation including bonus plans & a great benefit package\n",
      "\n",
      "An individual professional development plan, Company Description, \n",
      "\n",
      "With more than 100,000 team members globally, we promote an environment that is rooted in the entrepreneurial spirit in which the company was founded.\n",
      "entry --- Dell\n",
      "substring --- Dell‚Äôs team members are committed to serving our communities, regularly volunteering for over 1,500 non-profit organizations.\n",
      "entry --- Dell\n",
      "substring --- Our team members follow an open approach to technology innovation and believe that technology is essential for human success., \n",
      "\n",
      "Why work with us?, Life at Dell means collaborating with dedicated professionals with a passion for technologyWhen we see something that could be improved, we get to work inventing the solutionOur people demonstrate our winning culture through positive and meaningful relationshipsWe invest in our people and offer a series of programs that enables them to pursue a career that fulfills their potentialOur team members‚Äô health and wellness is our priority as well as rewarding them for their hard work, \n",
      "\n",
      "Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.\n",
      "entry --- Dell\n",
      "substring --- All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.\n",
      "entry --- Dell\n",
      "substring --- Dell will not tolerate discrimination or harassment based on any of these characteristics.\n",
      "entry --- Dell\n",
      "substring --- Learn more about Diversity and Inclusion at Dell here., \n",
      "\n",
      "Come join us!\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark is a company rooted in connecting people.\n",
      "entry --- Hallmark\n",
      "substring --- A career at Hallmark means you get to make a big impact and create something that can make a genuine difference.\n",
      "entry --- Hallmark\n",
      "substring --- , The Retail Marketing Analytics team develops and drives the advancement of the marketing data and analytics strategy for Hallmark Retail.\n",
      "entry --- Hallmark\n",
      "substring --- Collaborates with the team in order to improve the effectiveness of business decisions through the use of data and machine learning/predictive modeling\n",
      "Communicates findings to data science team and small cross-functional teams to ensure models are well understood and incorporated into business processes\n",
      "Works with various business customers and leaders to ensure the projects will meet their business needs\n",
      "Takes leadership in Hallmark Analytics community by educating and training other analytics and non-analytics staff on various analytics and data science techniques.\n",
      "entry --- Hallmark\n",
      "substring --- Accepted file types are Microsoft Word (DOC or DOCX), PDF, HTML, or TXT., In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark does not generally provide sponsorship for employment.\n",
      "entry --- Hallmark\n",
      "substring --- Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, Bachelors or Master‚Äôs degree in Statistics, Physics, Math, Engineering, Economics, Finance, Data Science, Computer Science, Operations Research OR a quantitative field\n",
      "1+ year of entry-level experience or academic training in data science, advanced analytics, and/or statistical modeling (regression, ANOVA, validation techniques, etc.)\n",
      "entry --- Hallmark\n",
      "substring --- Able to provide a GitHub or coding portfolio of prior data science, computer programming and statistical work and projects\n",
      "Strong desire to explore various data sources to uncover hidden trends and opportunities for the organization\n",
      "Self-directed, detail & team oriented with highly developed problem solving and analytical skills\n",
      "Excellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\n",
      ", Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\n",
      "entry --- Hallmark\n",
      "substring --- Save for your future: Through profit sharing, you share in the success of Hallmark.\n",
      "entry --- Hallmark\n",
      "substring --- , Hallmark is an equal opportunity employer.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark is a company rooted in connecting people.\n",
      "entry --- Hallmark\n",
      "substring --- A career at Hallmark means you get to make a big impact and create something that can make a genuine difference.\n",
      "entry --- Hallmark\n",
      "substring --- This means that Hallmark was a big data company before big data was even a ‚Äúthing.‚Äù We have data on millions of consumers and their purchases across tens-of-thousands of products across thousands of points of distribution.\n",
      "entry --- Hallmark\n",
      "substring --- You will have the opportunity to analyze large datasets in a collaborative team work environment providing daily challenges and ongoing learning., Hallmark‚Äôs Data Scientist perform data analyses to derive insight, patterns and correlations from Hallmark's big data that includes vast amounts of consumer data, store data, product sales data, and other relevant data.\n",
      "entry --- Hallmark\n",
      "substring --- You will work in a team environment alongside a group of expert mathematicians, statisticians and data scientists., The perfect candidate‚Ä¶:, is an analytic leader who can mentor and teach to help enhance, build, and grow Hallmark‚Äôs analytic capabilities.\n",
      "entry --- Hallmark\n",
      "substring --- can hit the ground running and bring new analytical approaches not currently practiced by Hallmark.\n",
      "entry --- Hallmark\n",
      "substring --- Individual file size attachment limit is 10 MB., In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark does not generally provide sponsorship for employment.\n",
      "entry --- Hallmark\n",
      "substring --- Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, 3+ years of mathematical predictive algorithm development utilizing large-scale multivariate datasets in a business environment\n",
      "3+ years‚Äô business experience in application of advanced analytics and data mining including predictive algorithms\n",
      ", PREFERRED QUALIFICATIONS, Business experience working with large-scale consumer analytics datasets\n",
      "6+ years‚Äô business experience of mathematical predictive algorithm development utilizing large-scale multivariate datasets\n",
      "6+ years‚Äô experience in business application of advanced analytics and data mining including predictive algorithms in a professional environment\n",
      "Experience in building big data based IT processes, understanding data science workflows and building pipelines\n",
      "Strong communication skills: written, verbal, and presentation\n",
      "PhD or MS in quantitative discipline - Statistics, Physics, Math, Engineering, Economics, Econometrics, Data Science, Computer Science, Operations Research ‚Äì highly preferred\n",
      "Experience with SAS, R, Python, Tableau, SQL, Hadoop, Spark\n",
      "Proficiency in either R or Python\n",
      "Experience deriving insight from structured and unstructured data\n",
      "Experience with a consumer packaged goods (CPG) company or retailer\n",
      "Demonstrated ability to derive explanatory variables from high-dimensionality collections of data: social, click-stream, SKU-level sales, digital marketing, weather, economic\n",
      "Experience working with Big Data\n",
      "Inherently Curious, Self-starter, Proactive, Comfort with Ambiguity, Passion for Problem-solving, Creative, Collaborative, Team-oriented\n",
      "Demonstrated ability to coach and teach others\n",
      ", Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\n",
      "entry --- Hallmark\n",
      "substring --- Save for your future: Through profit sharing, you share in the success of Hallmark.\n",
      "entry --- Hallmark\n",
      "substring --- , Hallmark is an equal opportunity employer.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark is looking for someone like you., People rely on us to help them connect and express their emotions through products and services that enrich lives every day.\n",
      "entry --- Hallmark\n",
      "substring --- It is an exciting time to be in the Greetings business at Hallmark!, WE ARE LOOKING FOR:, Hallmark is in the midst of a data analytics revolution and we need a talented senior-level Data Analytics Lead to join our Customer Analytics team.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark‚Äôs mission is to inspire people everywhere ‚Äúto live a caring, connected life full of meaningful moments‚Äù.\n",
      "entry --- Hallmark\n",
      "substring --- People who are passionate about driving analytical thought within our customer teams and throughout the Hallmark Analytics community.\n",
      "entry --- Hallmark\n",
      "substring --- Accepted file types are Microsoft Word (DOC or DOCX), PDF, HTML, or TXT., In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark does not generally provide sponsorship for employment.\n",
      "entry --- Hallmark\n",
      "substring --- Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, The following is required to be considered for this role:, Bachelor‚Äôs degree in Business or quantitative field (Data Science, Statistics, Analytics, Economics, Mathematics, Computer Science).\n",
      "entry --- Hallmark\n",
      "substring --- Strong desire to combine rich business acumen and explore various data sources to uncover hidden trends and opportunities for the organization\n",
      "Able to provide a GitHub or coding portfolio of prior advanced analytics, data science, computer programming and statistical work and projects\n",
      "Self-directed, detail & team oriented with highly developed problem solving and analytical skills\n",
      "Excellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\n",
      ", Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\n",
      "entry --- Hallmark\n",
      "substring --- Save for your future: Through profit sharing, you share in the success of Hallmark.\n",
      "entry --- Hallmark\n",
      "substring --- , Hallmark is an equal opportunity employer.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark is looking for someone like you., People rely on us to help them connect and express their emotions through products and services that enrich lives every day.\n",
      "entry --- Hallmark\n",
      "substring --- It is an exciting time to be in the Greetings business at Hallmark!, WE ARE LOOKING FOR:, Hallmark is in the midst of a data revolution and we need a talented data engineer to join our team.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark‚Äôs mission is to inspire people everywhere ‚Äúto live a caring, connected life full of meaningful moments‚Äù.\n",
      "entry --- Hallmark\n",
      "substring --- We can only do that by understanding how people connect with those who mean the most to them., We are seeking innovative individuals who are energized by solving data mysteries; people who see the thought of bringing unknown or unexploited data to the Hallmark environment is a career high.\n",
      "entry --- Hallmark\n",
      "substring --- We‚Äôre looking for people who bring an inquisitive mind to solve complex data issues and have all the necessary tools to take it to the next level., WHO WE ARE:, The Data Engineering and Reporting team under Category Solutions provides data enablement solutions across Hallmark Greetings.\n",
      "entry --- Hallmark\n",
      "substring --- This team manages the automation of reporting and processes, creation of data pipelines and database management, development of powerful technical solutions to empower staff and other robust data engineering solutions at Hallmark.\n",
      "entry --- Hallmark\n",
      "substring --- We are building a team to develop the technical framework to drive performance and success at Hallmark., IN THIS ROLE YOU WILL:, Automate analytics and data science solutions\n",
      "Develop robust data pipelines while ensuring data integrity\n",
      "Connect staff to big data from various internal and external sources\n",
      "Create technical solutions to simplify the processes at Hallmark Greetings\n",
      "Have a proven track record in big data and cloud environments\n",
      ", APPLICATION INSTRUCTIONS:, You must show how you meet the basic qualifications (listed below) in a resume or document you upload, or by completing the work experience and education application fields.\n",
      "entry --- Hallmark\n",
      "substring --- Accepted file types are Microsoft Word (DOC or DOCX), PDF, HTML, or TXT., In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States.\n",
      "entry --- Hallmark\n",
      "substring --- Hallmark does not generally provide sponsorship for employment.\n",
      "entry --- Hallmark\n",
      "substring --- Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, The following is required to be considered for this role:, Bachelors degree in Computer Science, Engineering, Data Science, Mathematics, OR a degree with technology, analytics, or quantitative focused curriculum\n",
      "5+ years of experience with database management and programming languages (SQL, Python, Java, .NET, C++, Java Script, Scala, Perl, or Ruby, etc)\n",
      "3+ years of experience in numerous databases (Oracle, Teradata, MySQL, etc), Big Data platforms (Hadoop, Hive, Spark, etc) and/or Cloud-based platforms and ERPs (AWS, Azure, Google Cloud, SAP S4 Hanna, etc)\n",
      "1+ years of experience with software/web development (including automation), data science and/or advanced statistical modeling, including predictive analysis, forecasting, regression, experimentation (multivariate is a plus), data mining, sequential/time-series, supervised and unsupervised models, etc\n",
      ", PREFERRED QUALIFICATIONS, Your resume will stand out if you have:, Master‚Äôs or PhD in the above fields\n",
      "Expertise with data visualization tools (including Tableau, Dash, RShiny, D3.js, Microstrategy, etc) and creating automated interactive dashboards and reports for business customers that are robust in knowledge and simplistic in usage\n",
      "Ability to develop data models and data pipelines to enable analysts and data scientists access to a vast array of data sources from numerous locations\n",
      "Expertise in computer programming, APIs, macro/function design and automation (Chron Jobs) in order to streamline statistical models and business processes for the organization\n",
      "Expertise in software development, notably developing GUIs for non-technical staff members we have little to no experience with data and analytics, in order to collect data, conduct analysis, run simulations and other activities\n",
      "Strong ability to communicate with analytics staff across the organization and develop innovative solutions to simplify their work processes and increase productivity\n",
      "Strong ability to work with Senior Leadership across an organization to design and drive optimal data strategy across the company\n",
      "Experience leading teams of data engineers, developers, data scientists, data analysts and/or others to develop robust technical solutions and software to optimize a business\n",
      "Able to provide a GitHub or coding portfolio of prior data engineering, data science, computer programming and statistical work and projects\n",
      "Strong desire to explore various data sources to uncover hidden opportunities for the organization\n",
      "Self-directed, detail & team oriented with highly developed problem solving and analytical skills\n",
      "Excellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\n",
      ", Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.\n",
      "entry --- Hallmark\n",
      "substring --- Save for your future: Through profit sharing, you share in the success of Hallmark.\n",
      "entry --- Hallmark\n",
      "substring --- , Hallmark is an equal opportunity employer.\n",
      "['Learn more about Splunk careers and how you can become a part of our journey!, \\n\\nThe Data Scientist role involves working on all the stages of the data science pipeline, from acquiring and understanding the data, modeling various algorithms, performing evaluation of the performance of algorithms but also implementing these solutions in a commercial product either as standalone code or in existing ML frameworks like Spark/MLib.', 'Experience with Google Cloud Platform (Dataflow, Beam, BigQuery, Tensorflow) and other big data technologies a plus.', 'Proficiency with SQL like relational database technology\\n\\nExperience using one or more advanced analytic software: numpy, scipy, pandas, R, SPARK\\n\\nExperience with one or more data storage and manipulation technology:Hadoop, Azure Data Lake\\n\\nDemonstrates the ability to transform ambiguous business problem to a technical problem and communicate the technical result to non-technical audience\\n\\nSelf-driven and demonstrates the ability to drive project across multi-discipline teams, \\n\\nData engineering experience is highly desirable\\n\\nExperience with a general-purpose programming language (C++, C#, Java, javascript) is a plus\\n\\nIndustry Experience with one or more of the deep learning frameworks (CNTK, MXNet, TensorFlow, Caffe/Caffe2, PyTorch) is a plus\\n\\nExperience with the following is a plus: Splunk, Azure Kusto, Azure Machine Learning Studio and TLC, Jupyter]\"\\n\"[Partners with our Marketing Engagement, In-Product Discovery, and Machine Learning Teams to drive cross-sell, upsell and retention outcomes\\n\\nCreates and deploys advanced statistical models and analyses from relational data sources to power initiatives and programs\\n\\nPresents technical findings in a summarized form to non-technical audiences; translates complex quantitative data into succinct actionable insights\\n\\nDesigns, implements and measures results for A/B and multivariate tests; drives end to end test process from launch, to readout, to recommendation, to retest\\n\\nMeasures and reports on actual performance vs target; performs analysis to identify root cause drivers of variances\\n\\nDevelops and maintains reports and dashboards to track performance\\n\\nConducts research projects, including surveys, to produce actionable customer insights\\n\\nWorks with members of multiple departments to understand processes, data and reporting requirements, At least 2 years of experience in an analytical role in a business environment.', 'Helping build a storage and caching system that facilitates both a deep archive of data that can explored and fast-moving real-time data that is accessible to thousands of users\\n, \\nStrong experience with scientific Python, particularly NumPy and Pandas\\nBuilt systems on Linux and cloud platforms, preferably Google Cloud Platform (GCP) or Amazon Web Services (AWS)\\nWorked with both relational databases (preferably Postgres/PostGIS) and some sort of Non-SQL database (preferably MongoDB)\\nFamiliarity with automated deployments and continuous integration\\nKnowledge of service-oriented and/or microservice architectures\\nExperience building services that interface via message queues, RPC, or REST interfaces\\nA passion for automated testing\\nExperience with parallel processing systems (joblib, Dask, Ray, Spark, Hadoop)\\n, \\nBachelor‚Äôs degree in Computer Science, Computer Engineering, or similar, or equivalent experience\\n4+ years of relevant experience\\n, \\nExperience with geospatial data, especially gridded data (GRIB, GeoTIFF, NetCDF, BUFR)\\nExperience with other scientific Python libraries or frameworks (SciPy, sklearn, skimage, xarray, Numba, etc.)', 'This role includes heavy technical knowledge in implementing Google Tag Manager, gathering insights from Google Analytics and other analytics platforms as well as knowledge of the marketing life cycle and common marketing channels., General Responsibilities, Responsibilities are applicable based on the position focus/channel, Helps to identify, analyze/execute new and potential product/services, markets, and advertising opportunities.', 'Experience writing production ready code is a plus\\nExperience with GCP or other cloud platforms is a plus\\n, If you are a true data enthusiast who wants to elevate yourself and your company to the next level then please send your Word resume to afagin@daleyaa.com for consideration., #LI-AF1]\"\\n\"[\\nEstablish Life Science Analytics prototype platform ‚Äì Guiding the effort to produce a first prototype of the life sciences Analytics platform, in collaboration with other members of the team (biostatisticians and clinical data analysts) developing and embedding the first data science packages leveraging HealthCatalyst data for Life Science Analytics into a more generalizable framework that can be re-utilized and re-deployed to solve other similar problems, leveraging Google Datalab platform/Jupyter Notebooks.', 'You have a deep industry understanding of the digital advertising industry, Google‚Äôs ad product suite, and a passion for using data in storytelling., Google‚Äôs Global Partnerships team works with a wide range of partners to bring the best of Google to power their business.', 'Experience developing scalable and automated data pipelines\\nMachine learning experience in Python and/or R\\nExperience with one or more cloud environments (AWS, Google Cloud Platform, Azure or other platforms)\\nPractical knowledge applying analytical techniques such as time series regression, decision trees, segmentation, clustering, response modeling and factor analysis to real-world data.', 'Strong autonomy and team player, \\n\\nPreferred Qualifications, \\n\\nExperience with Google Cloud Platform (such as BigQuery, Compute Engine, Data Flow, ..)\\n\\nExperience with relational (SQL) and NoSQL Databases\\n\\nExperience with developing products deployed to production\\n\\nExperience in developing Search, Recommendation, Visual and/or Language applications, 50%-Design and develop algorithms and models to use against large datasets to create business insights\\n\\n20%-Establish scalable, efficient processes for large scale data analyses, model development and model implementation\\n\\n20%-Present analysis and resulting recommendations to senior management; Leverage data to present a compelling business case to optimize investments and operations\\n\\n10%-Communicate and educate technical and non-technical employees on analytics and data-driven decision making, This position reports to Director of Data Science, or Sr.', 'Research mindset with bias towards action - able to structure a project from idea to experimentation to prototype to implementation\\n\\nIndependence, great communication, and amazing follow-through - you aggressively tackle your work and love the responsibility of being individually empowered, \\n\\nBackground in Machine Learning, Statistics, Operations Research, Operations Management, Econometrics, or similar\\n\\nExperience in software engineering]\"\\n\"[At least 5 years of related experience\\n\\nStrong expertise in software development using Java, Node JS, Python and Bash\\n\\nExperience in the use of R\\n\\nExperience working with front end languages/document formats like JavaScript, HTML/CSS, XML/XSL\\n\\nExperience with relational (SQL) and non-relational databases (Mongo DB, Couch DB and others)\\n\\nStrong IT background including Windows and Linux\\n\\nExperience in building Cloud Applications using APIs and Services\\n\\nExperience in building solutions leveraging artificial intelligence systems and services such as IBM Watson\\n\\nKnowledge in software engineering practices including agile techniques\\n\\nKnowledge in system building/debugging/testing\\n\\nExperience with GitHub Enterprise based source control systems\\n\\nProject management skills, Developer skills in web technologies such as apache wicket, IBM Websphere, Django, Docker but also C coding\\n\\nExperience IT infrastructure architecture]\"\\n\\n\"[Leverage analytics to enhance existing products and deliver new impactful products.', 'The ideal candidate should be highly analytical and have a strong technical skill-set, with solid experience in a data extraction language (such as SQL) and experience working in the Salesforce environment., \\n\\nResponsibilities:, \\n\\nWork cross-functionally with west region executives, marketing, member experience, real estate, sales ops and finance to analyze data, identify trends, implement optimization\\n\\nLeverage predictive analytics to support demand pipeline forecast, by segment, product and territory/market, to support 80% occupancy rate for new building openings\\n\\nEstablish regional KPIs and benchmarks for growth acquisition and across multiple channels, including paid search/social, display, mobile, email marketing, and OOH campaigns\\n\\nEstablish measurement framework for pilot programs on member experience, via both qualitative studies and quantitative approach, including using analytics to measure the impact of member interactions and satisfaction\\n\\nExecute accurate test design and evaluation ‚Äì including sampling techniques and determining statistical significance\\n\\nOwn the reporting and dashboards of west region, with rigorous quality control and timely delivery\\n\\nImplement standard processes, data infrastructure, operational best practices for west region\\n\\nDevelop recommendations for changes to investment and marketing strategy, optimize the efficacy of marketing spend based on quantitative analyses\\n\\nExecute on data strategy and implement technology to support hyper-segmentation, account-based marketing, and multi-touch attribution\\n\\nLead the training processes on a range of marketing analytics and BI tools, and foster the data-driven culture across teams, Qualifications:, \\n\\nStrong quantitative, analytical, and problem solving skills\\n\\n4+ years experience within business/marketing/data analytics\\n\\nFlexibility and ability to adapt to evolving business objectives\\n\\nExpertise in a query language such as SQL or equivalent\\n\\nExperience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics\\n\\nOrganized with strong problem solving skills, attention to detail, communication skills, and time management abilities\\n\\nAbility to manage multiple projects and deliver against aggressive deadlines\\n\\nMasters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable]\"\\n\"[Partner with Business Developer team to maximize our marketplace health and performance through data-driven insights\\n\\nPresent as appropriate to individuals throughout the organization and to Criteo clients externally (i.e.', \"Research and develop analysis, forecasting and optimization methods to improve the quality of Google's user facing products; example application areas include ads quality, search quality, end-user behavioral modeling, and live experiments.\", 'Minimum 4 years full-time, analytics-relevant work experience (experience in the digital industry is preferred, SQL proficiency is required)\\n\\nKeen intellectual curiosity and ability to structure & solve difficult problems with minimal supervision\\n\\nPassion for translating ‚Äòdata-speak‚Äô into relevant, compelling stories\\n\\nBackground in any of the following preferred: Tableau, Vertica, Hive/Hadoop, R, Python, Pentaho, Kettle\\n\\nExceptional attention to detail coupled with an ability to see the big picture\\n\\nThorough conceptual and practical understanding of relational databases, data architecture/governance, and real-world application of statistical concepts (particularly in a testing context)\\n\\nEffective presentation and public speaking skills with the ability to present and defend complex analysis both internally and externally to both technical and non-technical audiences ‚Äì and a passion for making the\\n\\nMust have the combination of technical skills, passion for learning, and the soft skills to work with all personality types in a dynamic environment]\"\\n\"[\\n3+ years of experience with developing and deploying scalable machine learning or artificial intelligence algorithms\\nExperience with data mining techniques for large-scale datasets, including both structured and unstructured data\\nExperience with advanced analytics, including unsupervised and supervised learning techniques, such as regression, forecasting, clustering, and outlier detection\\nAbility to obtain a security clearance\\nHS diploma or GED\\n, \\nExperience with using APIs to integrate data from multiple systems\\nExperience with using Python scripting for data extraction and manipulation\\nExperience with using Splunk as a data analysis environment\\nExperience with multiple data visualization tools\\nKnowledge of nation-state, targeted, and financially motivated threats\\nKnowledge of Cybersecurity infrastructure and log sources\\nPossession of excellent oral and written communication skills\\nPossession of excellent collaboration skills\\nSecret clearance\\nBA or BS degree\\n]\"\\n\"[\\nEstablish and adhere to best practices in reporting and analysis: data integrity, test design, analysis, validation to ensure team is providing exceptional quality work and is continuously gaining everyone\\'s trust.', 'While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \\n\\nFacebook\\n\\nTwitter\\n\\nLinkedIn\\n\\nGoogle\\n\\nMore]\"\\n\"[Title: Data Analyst\\nReports to: Research Director\\nClassification: Exempt\\nLocation: New York\\nStart Date: Immediately, \\n\\nSummary:\\n\\nThe Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \\n\\nThe Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets.', 'Our customers include some of the nation‚Äôs largest hospitals including Stanford, UCSF, NewYork-Presbyterian, the University of Texas MD Anderson Cancer Center, and more\\nOur team includes veteran executives and the brightest minds from Google, McKinsey, Stanford, MIT, Duke, Berkeley, UIUC, and more.', ', \\n\\nBachelor‚Äôs degree in related field or 8 to 11 years of experience., \\n\\nABOUT THE DEPARTMENT, \\n\\nABOUT EXPRESS SCRIPTS, \\n\\nAdvance your career with the company that makes it easier for people to choose better health., \\n\\nExpress Scripts is a leading healthcare company serving tens of millions of consumers.', 'You can find us in 27 cities across the U.S., U.K., and Canada., \\n\\nJob Title, \\n\\nData Engineer, \\n\\nAs a Data Engineer, you‚Äôll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core cloud data warehouse tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.', 'Hadoop, Spark, Kafka, Clickhouse, NiFi)\\n\\nExperience with crafting and managing data pipelines\\n\\nDevOps mindset with experience on agile team\\n\\nStrong technical writing and communication skills\\n\\nExcellent problem solving and decision-making skills, \\n\\nExperience with containerization (specifically Docker & Kubernetes)\\n\\nExperience with SQL and Linux\\n\\nSecurity experience\\n\\nSplunk dashboards, reports, and alerting, \\n\\nAt Cisco, each person brings their unique talents to work as a team and make a difference.', 'Experience with front-end analytics tools, Google Analytics a plus.', 'Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.', 'Google Analytics, etc.)', 'Experience with Anaconda, IBM Blue, Oracle Big Data) to analyze large data sets and develop automated analytics in making sense of data affecting DoD operations.', 'Whether battling large system processes or leveraging our homegrown suite of Google products for Googlers themselves, you help Googlers work faster and more efficiently., As part of the Google Technology Solution (GTS) Data and Business Intelligence team, you will help build out a data platform that will support our users in Google Cloud business and the needs of executives for data and insights.', \"Expert in python\\n\\nExpert working with cloud platforms (AWS, Google Cloud, etc)\\n\\nExperience with Airflow or other workflow management software\\n\\nAbility to define data model and data storage strategies, including knowledge of distributed data systems\\n\\nAbility to manage multiple/competing priorities and make the right tradeoffs and timely delivery of features\\n\\nExperience or familiarity with geography, geometry and GIS systems\\n\\nExperience working with satellite/remote imagery\\n\\nRelevant education (Coding Bootcamp, and/or Bachelors in Computer Science) or equivalent experience, \\n\\nWHAT‚ÄôS YOUR STYLE, \\n\\nA developer who loves the speed of a start-up and won‚Äôt quit until the job is done with quality, whatever it takes\\n\\nA team-player with a good sense of humor and the ability to work on multiple projects under a tight schedule\\n\\nSomeone with strong communication skills, excellent ability to analyze and diagnose, good planning and work management skills, and great attention to detail, WHAT'S IN IT FOR YOU, \\n\\nThe opportunity to join a fast growing startup that is out to disrupt the insurance and real estate markets\\n\\nCompetitive salary\\n\\nGenerous early stage equity\\n\\nThe coolest office space in Jack London\\n\\nBenefits\\n\\nOur culture is awesome!\", 'You‚Äôre looking to join a strong, high-performing team., We build new ways for advertisers to buy ads on Twitter, such as paying up front for guaranteed results\\n\\nWe design incrementality studies to measure the lift in brand awareness that our advertising campaigns drive\\n\\nWe dive into individual products (e.g.', 'Geo helps merchants get their businesses on Google, and more than a million developers use the power of Google Maps to enhance their apps and websites.', 'Visit www.guycarpenter.com for more information and follow us on LinkedIn and Twitter @GuyCarpenter, \\n\\nGuy Carpenter & Company, LLC and its separately incorporated operating entities around the world are part of Marsh & McLennan Companies, a publicly held company (ticker symbol: MMC)., \\n\\nMarsh & McLennan Companies offers competitive salaries and comprehensive benefits and programs including: health and welfare, tuition assistance, pension, employee assistance program, domestic partnership benefits, career mobility, employee network groups, volunteer opportunities, and other programs.', 'You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.You will have access to distinctive analytics assets that we use to accelerate delivering value to our clients including more than 550 analytics assets underpinned by a strong information management and BI technology foundation.', 'Work closely with engineers to identify opportunities, design and assess improvements to Google products.', 'Experience connecting and analyzing data from multiple business applications(SAP, SFDC, IBM Cognos)\\n\\nSystems engineer or reliability engineering experience.', 'Desired skills: MATLAB, Python, or C++ programming experience is strongly desired., \\n\\nMIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.', 'Successful candidate shall analyze data in the BI tool, consolidate data, and present findings., \\n\\nResponsibilities include, but are not limited to:, \\nDevelops pre and post-campaign analyses for digital marketing and loyalty campaigns to measure effectiveness\\nAnalyzes overall customer data trends to create and present actionable insights that help drive decision making in support of the Subway Digital marketing initiatives\\nSupports Loyalty Strategy by analyzing loyalty customer trends and program performance overall and within campaigns\\nDesigns and manages the reporting and dashboards using for customer insights and campaign performance\\nSupports the offer management and analysis of offers for the marketing campaigns\\nLiaises with the Analytics, Reporting and Experience Optimization teams\\n, Skills and Abilities Required:, \\n5+ years experience\\nStrong analytics skills and structured problem solving skills\\nStrong financial analysis background\\nStrong understanding of Excel, PowerPoint, and data visualizations\\nExperience in using BI tools to query and analyze data\\nFamiliar with campaign data, digital/web analytics, digital display advertising, and customer analysis\\nCapable of telling the big picture story and making recommendations based on trends founds in the data\\nExcellent communications skills and deep knowledge of marketing trends\\nAble to mentor a junior analyst, once he/she is on-boarded\\nExperience in the QSR space or related industry]\"\\n\"[\\nIdentifying and assessing sources of crypto data\\nAnalyzing assets and exchanges\\nData collection and automation\\nDaily monitoring of news and publications, websites, Twitter feeds, etc.', 'Proficient in querying, segmenting and modeling data from large datasets located in Google BigQuery and CRM databases.', 'If you have what it takes to bring innovative new products and services to life in collaboration with world-class experts, this is your opportunity to develop with Dell.', 'Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\\nAt least 1-2 years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\\nExperience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\\nExperience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\\nMust be a self-starter and have excellent oral and communication skills\\n, The candidate(s) offered this position will be required to submit to a background investigation, which includes a drug screen., Good Work.', 'Expertise with the AWS platform is a plus!, \\n\\nResponsibilities, \\n\\nBuild design, develop, test, deploy, maintain and enhance full-stack software solutions\\n\\nProvide technical leadership to the Data Warehouse organization, as well as the Shutterfly teams who use Shutterfly‚Äôs Enterprise Data Warehouse\\n\\nWith your technical expertise own and manage project priorities, deadlines and deliverables\\n\\nAlways with a customer focus, evangelize the benefits of existing solutions and new technologies to drive the use and push the technology of the Data Warehouse forward\\n\\nWork closely with Data Operations to improve CI/CD pipelines, as well as continually improving the operation and performance of the Data Warehouse\\n\\nWork across multiple teams in high visibility roles and own solutions end-to-end, \\n\\nQualifications, \\n\\nExpert knowledge of one of the following languages: Python, Java\\n\\n10+ years of hands on experience in software development, including design, implementation, debugging, support, and building scalable system software and/or Services\\n\\nDeep understanding of distributed, message driven systems\\n\\nStrong at applying data structures, algorithms, and object oriented design, to solve challenging problems\\n\\nExperience working with REST and RPC service patterns and other client/server interaction models\\n\\nExperience working in the AWS Services Ecosystem or relevant Cloud Infrastructures such as Google Cloud or Azure\\n\\nBachelor‚Äôs degree in Computer Science or equivalent]\"\\n\"[Extensive experience building RESTful APIs, preferably in Java 8/J2EE., Expertise with micro services design and development, including API and cloud based platforms and technologies such as containers a plus., Write code and set coding standards / best practices within the team.', 'It is an exciting time to be in the Greetings business at Hallmark!, WE ARE LOOKING FOR:, Hallmark is in the midst of a data analytics revolution and we need a talented senior-level Data Analytics Lead to join our Customer Analytics team.', 'Learn more at www.hasbro.com, and follow us on Twitter (@Hasbro & @HasbroNews) and Instagram (@Hasbro).]\"', 'Advanced Degree preferred but not required., 10+ years of professional level experience in a related role\\nRelevant professional experience with an emphasis on Retail or Digital Commerce Business\\n\\nExperience leading a team and driving results, Demonstrated track record leading high performing and engaged teams\\n\\nPassion for business analytics and working with large amounts of data with demonstrated ability to use data to influence decision making\\nExcellent communication and presentation skills to senior leadership\\nStrong project management capabilities to manage multiple project streams with a focus on prioritization, resourcing and timely business impact\\nProven experience building positive working relationships and working successfully in cross-functional teams, including demonstrated success in managing and influencing without direct authority\\nA strong understanding of advanced analytic techniques, particularly related to measuring consumer & business outcomes in a digital commerce setting\\nFluency in SQL\\nExperience with clickstream tools including Adobe Analytics / Omniture, Google Analytics or Optimizely\\nExperience with Business Intelligence, Analytics and Data Visualization tools, e.g.', '\"[\\n\\nCollaborate with Data Analysts, Product Managers, and Engineers to design a high-quality PostgreSQL Data Warehouse schema and solution\\n\\nWork within the company‚Äôs Agile process and systems to prioritize projects into sprints\\n\\nImplement Amazon Cloud (AWS) services for data connectors, ELT, data cleansing, data summarization, and automated data QA\\n\\nUpdate and create scripts in Python, Node.js, and similar languages\\n\\nImport data from sources including PostgreSQL, Mixpanel, Google Analytics, Amazon Kinesis, and Zendesk\\n\\nCreate, monitor, and maintain a job scheduling system\\n\\nBuild automated tests to ensure data quality\\n\\nEstablish best practices and standards for data definitions and quality\\n\\nPublish and maintain a Data Dictionary, \\n\\nBachelor‚Äôs degree in computer science, mathematics, engineering or related discipline\\n\\n5+ years of relevant Data Warehouse work experience\\n\\nTrack record of building Data Warehouses that enable accurate and easy analyses\\n\\nExceptional database and schema design skills including Star and Snowflake schema design\\n\\nMaster of DDL, DML, and query SQL\\n\\nAbility to scale systems and performance tune\\n\\nPostgreSQL and Mixpanel experience is preferred]\"\\n\"[Passion: The Kinsa team is driven towards a goal that is bigger than themselves, they have a real passion in working toward a solution for a widespread social issue.', 'Come join a friendly, seasoned team and a great company as we change the world., \\n\\nWhat you‚Äôll do, \\n\\nBuild ETL code to populate our Google BigQuery data warehouse with Apache Airflow scheduled batch updates from our Sansar Virtual Reality platform\\n\\nDevelop real-time ETL apps using Google DataFlow (Java or Python) to provide critical insights into the business\\n\\nMaintain, improve, troubleshoot, and evaluate real-time data processing systems such as PubSub, Kafka, and Stackdriver\\n\\nWork closely with our Data Architect, Product Managers, and Analysts to design and model new tables to meet constantly-evolving analytics needs\\n\\nLiaise with our systems engineers, Google support, and our consulting partners to quickly assess the impact of production system changes to existing data warehouse processes\\n\\nOther duties may be assigned, \\n\\nWhat you need, \\n\\nExtensive Real Time Data Engineering experience - we are not looking for a Data Analyst or Scientist.', 'Relevant certifications considered but not required., \\n\\nTechnical Requirements, \\nExperience with distributed computing technologies including Hadoop, HBase, Cassandra, Elasticsearch and Apache Spark\\nDevelopment experience with Java, C++, Scala, Groovy, Python, and/or shell scripting\\nExperience with data warehousing tools and technologies\\nAbility to work within UNIX/Linux operating systems\\nAWS experience a plus\\n, Company Benefits, \\n6 weeks PTO\\n\\nPaid Overtime\\nAnnual Bonuses\\n10% Employer 401k Contribution\\nHealth/Vision/Dental/Disability/Life Insurance\\nAnnual Training and Tuition Budgets\\nTechnology/Fitness/Communications Reimbursement\\nCharity Matching Program\\n, EOE/M/F/Vet/Disabled]\"\\n\"[The Curbside Engineering team is looking for highly motivated engineers to help build the next generation mobile commerce platform., \\n\\nAs part of a dynamic team environment you will:, Architect and develop processing pipelines that convert data to useful information consumed by internal and external processesDevelop web services that make data available in real-time for in-product applicationsBuild monitoring and debugging tools to analyze the data pipelinesDesign data schemas and manage operational scalability of data modelsCollaborate with product to build new features and infrastructureMentor junior engineers and provide technical leadership within the development teamParticipate in code reviews and write unit, integration and load tests as necessary, \\n\\nRequirements, Demonstrated proficiency in Python, Clojure, Java or GoHands-on experience with Big Data technologies (e.g Hadoop, Hive, HBase, Spark, Kafka, Storm, Cassandra, Columnar Databases or Graph Databases)Track record working with data from multiple sources ‚Äì willingness to dig-in and understand the data and to leverage creative thinking to deliver resultsStrong database fundamentals including SQL, performance and schema designExperience with cloud computing platforms like AWS, Google Cloud or Microsoft AzureKnowledge of the tooling for deployment, monitoring and site reliabilityAbility to work well in a team environment and be able to effectively drive cross-team solutions that have complex dependencies and requirementsExcellent communication and problem solving skills, MS or BS in Computer Science or related technical field or equivalent practical experience5+ years of industry experience working on building scalable ETL pipelines, data warehousing and schema modeling, \\n\\nPreferred Qualifications, Functional programming experience, All your information will be kept confidential according to EEO guidelines.]\"', \"The types of things you‚Äôll do:\\n, Work with Apache Beam, Airflow, Google Dataflow, BigTable, and BigQuery to build the next generation of the Censys data processing pipeline\\n\\nDesign automated solutions for building, testing, monitoring, and deploying ETL pipelines in a continuous integration environment\\n\\nWork with application engineers to develop internal APIs and data solutions to power Censys product offerings\\n\\nCoordinate with backend engineering team to analyze data in order to improve the quality and consistency of our data\\n, \\nDesired Qualifications\\n, Bachelor's degree in Computer Science or related field, or equivalent experience\\n\\n3+ years of full-time, industry experience\\n\\nDeep understanding of relational as well as NoSQL data stores (e.g., Snowflake, Redshift, BigTable, Spark) and approaches\\n\\nHands-on experience building data processing pipelines (e.g, in Storm, Beam)\\n\\nProficiency with object-oriented and/or functional languages (e.g.\", 'Connect with NRG Energy on Facebook and follow us on Twitter @nrgenergy., \\n\\nJob Summary:, \\n\\nAt NRG, we apply advanced analytics and modeling to address challenging business problems.', 'Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, Bachelors or Master‚Äôs degree in Statistics, Physics, Math, Engineering, Economics, Finance, Data Science, Computer Science, Operations Research OR a quantitative field\\n1+ year of entry-level experience or academic training in data science, advanced analytics, and/or statistical modeling (regression, ANOVA, validation techniques, etc.)', '\"[\\nPartner with Customer Strategy Manager to understand the messaging requirements for upcoming initiatives\\nProvide reliable estimates for lead time necessary to develop and execute against functional requirements\\nTranslate functional requirements into SQL and execute to pull lists for messaging campaigns\\nWork collaboritavely to establish a stable, repeatable process for working within a cross-functional team to deliver manual user lists and actionable insights\\nAct as a backup to Analytics partners to perform more complex data pulls based on ad-hoc requests as necessary\\nWorks closely with cross-functional teams: Content Strategy, Legal, Marketing (CRM), Product, and financial planning to deliver ad-hoc analysis\\nServe as POC to partner with Ops & CS teams to review service issues and customer make good programs\\nOpportunity to expand responsibilities as internal capabilities develop to help define advertising segments, and to provide input on automated tools for trigger messaging\\n, \\n2-3 years experience\\nBachelor\\'s degree required\\nExperience in the MVPD or vMVPD space, or within TV | Studio | Entertainment Industry preferred\\nExpert in SQL and Excel required\\nProficiency in Adobe Omniture, Conviva, Microstrategy, and other analytics tools preferred\\nAbility to translate complex requirements for the delineation of distinct customer groups into executable SQL which can return lists of users to send tailored messaging\\nOwner mentality and an entrepreneurial drive; proven ability to think big and influence others\\nSelf-starter with a bias for action; can make things happen in a fast-paced, dynamic environment\\nStrong verbal and written communication skills across all levels of the organization\\nHigh attention to detail and ability to manage multiple, competing priorities simultaneously\\nEnjoy getting your hands dirty in day-to-day tasks and working in ambiguous environments\\nWorks on site at Vue offices in Los Angeles, CA\\nOccasional travel to other office locations may be necessary\\n]\"\\n\"[\\nPartner with marketing, product and engineering team to understand our customers and ultimately create a better shopping experience\\nDesign dashboards and reports to communicate business trends and opportunities\\nWork closely with data engineering to validate data and ensure we have data points needed for analysis\\nEnable self service analytics through BI enhancements\\n, \\n2+ years of related work experience in analytics\\nStrong SQL skills\\nExperience with at least one analytics & visualization tool such as Looker, Tableau, Mode\\nHighly analytical and quantitative, with strong attention to detail\\nAbility to communicate complex ideas effectively\\nBachelor\\'s degree in Mathematics, Statistics, Economics, Business or quantitative focused study\\nProficiency with website analytics tools like Heap, Mixpanel or Google Analytics a plus\\n, \\nComprehensive health benefits\\nEquity\\n401k plan\\nSubsidized lunches and fully stocked kitchen\\nWellness benefits including in-office massage visits\\nQuarterly product allotment -- a package of the world\\'s best bras every 3 months!', '\"[Who We Are:, \\n\\nMachine learning is advancing products at Twitter (e.g., Timeline ranking, On-boarding) and Cortex is advancing Machine learning at Twitter.', \"We partner with companies to push the boundaries of what‚Äôs possible‚Äîtogether., \\n\\nJob Title: Data Engineer, \\n\\nAs a Data Engineer for Slalom Consulting, you'll work in small teams to deliver innovative solutions on Amazon Web Services, Azure and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other big data related technologies.\", '), Caffe/TensorFlow/Keras/etc, Hadoop, Spark, Pig, Experience providing direct support to analysts, Experience building models and tools to help analysts understand data and answer intelligence questions, Experience using Data Science libraries in Python or R: tidyverse, NumPy, SciPy, Pandas, Familiarity with commercial and open source data science software: IBM SPSS Modeler, SAS, KNIME, RapidMiner, Statistica, Familiarity with software development (Scala, C#, Java, JavaScript, etc.', 'If you share our passion for data and you‚Äôre keen to play a key role in driving progress, this is your opportunity to develop with Dell., \\n\\nClosing date: January 2019., \\n\\nDell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.', 'There will be extended periods of sitting and using a computer\\nTravel, predominantly domestic, approximately 10-15%., \\nA relevant university degree in a quantitative field such as Mathematics, Statistics, Business or Economics., \\n2+ years of marketing and/or finance]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; New York, NY, USA, \\n\\nBusinesses that partner with Google come in all shapes, sizes and market caps, and no one Google advertising solution works for all.', 'The goal of the residency is to help residents become productive and successful AI researchers., As part of this program, Residents collaborate with distinguished scientists from various Google AI teams working on machine learning applications and problems.', \"If you're as passionate about your future as we are, join our team., \\n\\nKPMG is currently seeking a Sr Associate, Data Science to join our Ignition practice., \\n\\nResponsibilities:, \\n\\nWork closely with various KPMG's Tax functional teams and clients to incorporate cognitive and NLP models and algorithms into both KPMG and client solutions\\n\\nDefine and develop new Tax solutions leveraging approaches such as Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, image recognition, deep learning, Machine Learning, cognitive science and analytics\\n\\nDesign and implement cognitive computing/AI applications using some combination of the following commercial and open source platforms and libraries such as Microsoft AI, Google AI, AWS AI, IBM Watson, Tensor flow, Keras, Spark, Mahout, Torch, Caffe, ScIkit-learn, and NLTK, \\n\\nQualifications:, \\n\\nMinimum of five years of IT industry experience with at least three years of experience in one of the following domains of interest - Natural Language Processing (NLP), Linguistics, Advanced Semantic Design, Visualization, Information Extraction, Information Retrieval, Probabilistic Decision Making, Image Recognition, Deep Learning, Machine Learning, Cognitive Science and Data Analytics\\n\\nMS or BS in Computer Science, Applied Statistics, Engineering, Science or other quantitative discipline with specialization and experience in Artificial Intelligence, Machine Learning, Natural Language Processing, Cognitive Science or other related areas\\n\\nExperience working with leading cognitive computing commercial and open source platforms and libraries such as IBM Watson, Google AI, Microsoft AI, AWS AI, or Apache Mahout\\n\\nDemonstrated expertise with analytics and cognitive engagements across design and implementation\\n\\nExcellent verbal and written communication skills with the ability to work with diverse teams in a highly matrixed environment, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\", 'Dell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.', \"As a cross-functional and global team, it's our job to help keep the lights on and the ads relevant., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.\", 'Degree(s) should be in a technical discipline such as Computer Science, Engineering, Statistics, Physics, Math, quantitative social science\\n\\nWork experience as an engineer highly desired\\n\\nExperience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\\n\\nRequired: SQL, Python, R, linux shell scripting\\n\\nDesired: Scala, Java, or Ruby\\n\\nExperience with machine learning and computational statistics packages (sci-kit learn, nltk, statsmodels, networkx, gephi, arules, glmnet, bigrf, caret, igraph, MLLib, GraphX, MADlib, Weka, etc)\\n\\nExperience with visualization tools (seaborn, d3, plotly, bokeh, ggplot2, rCharts, networkD3, Shiny, Tableau, CartoDB, etc)\\n\\nFrequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\\n\\nBonus Points for: experience with web application frameworks (Shiny, Flask, Tkinter, Ruby on Rails, Pyramid, Django, etc)\\n\\nDouble Bonus Points: previous work on medical applications and/or with claims data]\"\\n\"[Data Scientist - Marketing Analytics, \\n\\nSan Francisco, CA, \\n\\n$130,000-$150,000, \\n\\nTHE COMPANY, \\n\\nThis emerging Direct to Consumer eCommerce brand is looking to add a Data Scientist (Marketing Analytics focused) to the team.', 'Experience using Google Analytics, Google Tag Manager, and implementing scripts\\n\\n\\nExperience with utilizing and working with various data visualization tools\\n\\n\\nExperience with various media api platforms such as Google Analytics/Adwords, Facebook, Linkedin etc\\n\\n\\nExperience with design and development of reporting tools and\\n\\n\\nExperience developing various forecasting and analytical models utilizing tools such as Excel\\n\\n\\nExperience managing out-sourced vendors\\n, 4-year degree from an accredited institution in Marketing or equivalent discipline OR appropriate combination of experience and education, \\n\\nMinimum of 3 years‚Äô experience serving in a data analyst capacity in marketing, finance, mathematics etc., \\n\\nExperience using Google Analytics, Google Tag Manager, and implementing scripts, \\n\\nExperience with utilizing and working with various data visualization tools, \\n\\nExperience with various media api platforms such as Google Analytics/Adwords, Facebook, Linkedin etc, \\n\\nExperience with design and development of reporting tools and, \\n\\nExperience developing various forecasting and analytical models utilizing tools such as Excel, \\n\\nExperience managing out-sourced vendors, Supervisory Responsibilities, None., Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.', 'Hadoop, Cloudera, Horton Works, IBM Insights, MongoDB, Spark, Storm, HDFS, HBase, Accumulo, HIVE, PIG, SQL, Cassandra, Kafka and equivalents.', 'Knowledge of server-less infrastructure beneficial\\n\\nAbility to scope a project based on a technical brief and work with the DevOps and QA teams to provide a detailed project plan including:, \\n\\nData Flow Diagrams for process flow\\n\\nDatabase Schemas & Normalisation\\n\\nRecommended software / plugins / architecture\\n\\nScalable environment architecture suggestions\\n\\nHosting, storage, load balancing and caching suggestions\\n\\nPerformance considerations\\n\\nSecurity considerations\\n\\nAssumptions & Exclusions\\n\\nA complete and accurate estimate for the project, \\n\\nAbility to assess new business and respond with a full list of targeted questions to ensure accurate estimates are created\\n\\nAbility to research solutions to technical problems\\n\\nExperience scheduling/automating scripts\\n\\nExperience with streaming data beneficial\\n\\nExperience on Linux command line and Bash scripting\\n\\nExperience with Git/GitHub\\n\\nExperience with Amazon/Google Cloud services.', 'Requirements:, Expertise in Deep Learning and NLP\\n\\nExperience with software engineering best practices\\n\\nMS or PhD in machine learning or equivalent work experience, Desired:, Experience using big data platforms such as Spark or Hadoop, Experience using big data platforms such as Spark or Hadoop]\"\\n\"[Description, The Position, \\n\\niD Tech is looking for a Temporary Machine Learning Content Developer to produce the educational content and classroom tools to be used by our machine learning summer instructors across the nation with Python and TensorFlow.', ', As an Application Data Engineer, you will develop solutions to high visibility data challenges in one of the fastest growing businesses within Google., Behind everything our users see online is the architecture built by the Technical Infrastructure team to keep it running.', 'We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status]\"\\n\"[gTech‚Äôs Product and Tools Operations team (gPTO) leverages deep user, operational, and technical insights to innovate Google\\'s Ads products into customer experiences that are so intuitive (or automated) that they require no support at all.', 'Google Analytics), data visualization tools (i.e.', 'PostgreSQL, MongoDB)\\n\\nAptitude for problem solving\\n\\nStrong quantitative analysis skills\\n\\nExcellent written and spoken communication skills\\n\\nGood presentation skills\\n\\nTrack record of learning new skills and putting them to use immediately\\n\\nHunger for continued learning\\n\\nSense of ownership and pride in your performance and that of the company\\n\\n, Things That Will Impress Us\\n\\n, Experience with eCommerce, Magento Commerce, and/or Magento BI\\n\\nKnowledge of Google Analytics\\n\\nExperience with data analysis\\n\\nCustomer-facing experience\\n\\n, At Adobe, you will be immersed in an exceptional work environment that is recognized throughout the world on Best Companies lists .', 'Deep product knowledge and understanding of Microsoft Azure, AWS, Google Cloud.', ', \\nGreat team: Founded by successful veterans of Yahoo, Zynga, and eBay\\nHuge market: Disrupting a massive, growing $35+ billion market for CRMs\\nFunding: Raised $53M for our Series C from top-tier investors like Norwest Venture Partners\\nOur CRM has been awarded: G2Crowd #1 in Customer Satisfaction Summer Rankings, Google Best New Tech Partner of the Year\\nImpact: A fun, transparent, and exciting start-up culture that empowers its people to make a huge impact.', 'You are a communicative person that values building strong relationships with colleagues and multiple stakeholders, and have the ability to explain complex topics in simple terms., Coding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\\nData visualization (such as Tableau, Qlik, D3, ggplot)\\nExperience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google‚Äôs Cloud Platform\\nExperience training and tuning statistical and machine learning models with libraries/frameworks such as sci-kit learn, tensorflow, pytorch or similar\\nFamiliarity with experimentation and A/B testing\\n]\"\\n\"[This is your opportunity to join AXIS Capital ‚Äì a trusted global provider of specialty lines insurance and reinsurance.', 'Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \\n\\nPredictive Science is looking for a Senior Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results.', \", The CX Lab conducts scaled research on Google's advertisers.\", ', We do research differently here at Google.', ', Knowledge and Experience:\\n\\n, Advanced degree or equivalent work experience in a quantitative discipline such as statistics, computer science, actuarial, applied mathematics, or engineering\\n\\nExpertise in SQL query development\\n\\nBig Data expertise in Hadoop, including: Hue, HDFS, Hive, Python, Spark, GitHub, and data visualization\\n\\n2+ years of Experience with Cloudera Data Science Workbench (CDSW)\\n\\nShare and Document Best Practices for CDSW including project collaboration, production code migrations, and automation\\n\\nKnowledge of, or a desire to learn, IBM SPSS Modeler\\n\\nSome on-call support may be required.', 'Learn how to use and navigate our various databases and write scripts using our data for various analyses\\n\\nLearn about our existing code-base and best practices\\n\\nCollaborate with other data scientists to help build our patient-physician matching products, Integrate into long-term multi-data-scientist ventures and deliver on one or several short-term individual projects\\n\\nPerform analyses that help us better understand patients and/or physicians, while helping you get familiarized with our data\\n\\nSpend time with Staff Physicians and other medical domain experts to learn about the world of healthcare\\n\\nDevelop an understanding of both immediate business objectives as well as longer term company aspirations to develop intuition around prioritization and trade-offs between short-term deliverables and longer term R&D efforts, \\n\\nDevelop creative solutions to diverse problems including engineering challenges, unstructured data messes, ontology development, and machine learning applications\\n\\nLead and develop major projects from end-to-end encompassing planning, design, technical implementation, debugging, roll-out to Product & Engineering, testing, and iteration\\n\\nOperate at level of sophistication in statistics, machine learning, or computer science that is publication-worthy\\n\\nRegularly monitor pull requests, perform code reviews, and produce excellent peer reviews on projects prior to shipping to Product & Engineering\\n\\nEvaluate and experiment with new technologies and tools prior to wider adoption by the team\\n\\nWork closely with analysts, data scientists, product managers, and engineers, \\n\\nMinimum 2 years of industry production experience as a Data Scientist or Engineer\\n\\nExcellent verbal communications, including the ability to clearly and concisely articulate complex concepts to both technical and non-technical collaborators\\n\\nDegree(s) should be in a technical discipline such as Computer Science, Computational Biology, Engineering, Statistics, Physics, Math, quantitative social science\\n\\nExperience with SQL relational databases as well as big data: the Hadoop ecosystem, Hive, Spark, Presto, Vertica, Greenplum, etc\\n\\nRequired: SQL, Python, R, linux shell scripting\\n\\nDesired: Scala, Java, or Ruby\\n\\nExperience with machine learning and computational statistics packages\\n\\nExperience with visualization tools\\n\\nFrequent user of cloud computing platforms such as Amazon Web Services, Microsoft Azure, or Google Cloud Platform\\n\\nBonus Points: previous work on medical applications and/or with claims data]\"\\n\"[At Yapstone, we approach payments with the same startup mentality that we had when we launched our first payment solution in 1999.', 'IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.]\"', '\"[Required:, \\n\\nExperience in AWS technologies such as EC2, Cloud formation, EMR Cluster, AWS S3, Splunk, and AWS Analytics.', 'Maintain internal Alloy logic to automate the interpretation of data across channels through the unified Alloy data model, \\n\\nStrong knowledge of Python and SQL, especially in data wrangling and ETL applications\\n\\nFamiliarity with Java is a plus\\n\\nExperience in interpreting and manipulating supply chain-related datasets (Point-of-sale, logistics/EDI, product master)\\n\\nWorking knowledge of Selenium and other web-scraping tools, \\n\\nGoogle Cloud Platform\\n\\nPostgres, Redis\\n\\nPython, modern Java, React]\"\\n\"[In this role, the candidate will be responsible for performing data engineering duties such as planning, developing, Testing, maintaining and monitoring systems.', 'S/he is experienced with Google Analytics, and works closely with the Marketing team to evaluate careers site data and prepares reports of findings relevant to audience, behavior, and acquisition.', ')Demonstrate knowledge of networking concepts and devices (Firewalls, Routers, Switches, and Load Balancers)Demonstrate an understanding of network and web related protocols (such as, TCP/IP, UDP, IPSEC, HTTP, HTTPS, routing protocols)Experience developing and improving KPIs, metrics, and trending for vulnerability management functionsUnderstanding of how applications, networking, operating systems, and databases work, Interested candidate must submit a resume/CV through www.nbcunicareers.com to be consideredMust be willing to work at one of the following locations: New York, NY, Desired Characteristics, Intellectual capability and curiosity to learn complex processes.Highly collaborative; personally, and professionally self-aware; able to and interested in interacting with employees at all levels; embody integrity; and represent and inspire the highest ethical standards.Strong sense of urgency and commitment, as well as sound business sense with a strategic, conceptual and operational orientationExperience advising on technical related issuesPassion for and interest in media and entertainment industry highly desiredFlexible, organized, and passionate about advanced cyber securityGreat interpersonal skills and love for a team environment, Sub-Business, Career Level, City, State/Province, Country, About Us, Notices]\"\\n\"[Job Description, \\n\\n\\nWhat You‚Äôll Get to Do:, \\n\\nJOB DESCRIPTION:\\n\\n, The Business Intelligence Data Analyst is a software data analysis/engineering position for BIG Data Analytics, using SAS/IBM COGNOS Solutions to help business clients.', 'Lucktastic is consistently ranked in the top 3 on Google Play Store‚Äôs lifestyle category (beating brands like Tinder, Zillow, and Starbucks) and are regularly in the Apple Store‚Äôs top 10.\\n\\n, Jump Ramp‚Äôs team of nearly 40 employees works out of an airy 11th-floor loft in Midtown Manhattan‚Äôs Fashion District, and includes action-figure collecting developers, tattooed fixed-bike-riding artists, Classic Rock-singing CSR reps, globe-trotting marketing and sales people, and two founders who keep their shirts untucked and their office door open.', ', \\n\\nFollow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.', ', Hallmark is an equal opportunity employer.', '[Hands on experience in implementing Data Lake and AWS Cloud DATA and Enterprise Data Warehouse Solutions, Providing Solutions for Big Data Platform infrastructure for across AWS VPC, Understand GDPR laws, Architect and standardize the way data is ingested, processed and exported, Expertise working with AWS and Other Cloud infrastructure:, Strong Database knowledge in Cloud based Database like RedShift, Snowflake etc, Monitoring (CloudWatch, and ideally commercial solutions like DataDog, Splunk, PagerDuty), Identity Management & Security (e.g.', 'Experience with analytics tools such as Adobe Analytics or Google Analytics.', 'Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]\\n\"[Twitter users generate many terabytes of data every day; Twitter engineers run hundreds of experiments; Twitter Data Engineers build data pipelines and data processes that calculate metrics and scale increasingly sophisticated models of users and content., \\n\\nThe Data Science team at Twitter is at the intersection of all this data and strives to make it actionable to all business units around Twitter.', 'Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, 3+ years of mathematical predictive algorithm development utilizing large-scale multivariate datasets in a business environment\\n3+ years‚Äô business experience in application of advanced analytics and data mining including predictive algorithms\\n, PREFERRED QUALIFICATIONS, Business experience working with large-scale consumer analytics datasets\\n6+ years‚Äô business experience of mathematical predictive algorithm development utilizing large-scale multivariate datasets\\n6+ years‚Äô experience in business application of advanced analytics and data mining including predictive algorithms in a professional environment\\nExperience in building big data based IT processes, understanding data science workflows and building pipelines\\nStrong communication skills: written, verbal, and presentation\\nPhD or MS in quantitative discipline - Statistics, Physics, Math, Engineering, Economics, Econometrics, Data Science, Computer Science, Operations Research ‚Äì highly preferred\\nExperience with SAS, R, Python, Tableau, SQL, Hadoop, Spark\\nProficiency in either R or Python\\nExperience deriving insight from structured and unstructured data\\nExperience with a consumer packaged goods (CPG) company or retailer\\nDemonstrated ability to derive explanatory variables from high-dimensionality collections of data: social, click-stream, SKU-level sales, digital marketing, weather, economic\\nExperience working with Big Data\\nInherently Curious, Self-starter, Proactive, Comfort with Ambiguity, Passion for Problem-solving, Creative, Collaborative, Team-oriented\\nDemonstrated ability to coach and teach others\\n, Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.', '\"[\\n2+ years of experience with advanced analytical functions\\nExperience with at least one statistical analytical programming language, including Python or R\\nExperience with source control and dependency management software, including Git or Maven\\nExperience with using relational databases, including MySQL\\nExperience with identifying analytic insight in data, developing visualizations, and presenting findings to stakeholders\\nKnowledge of object-oriented programming, including Java, C++, and various machine learning algorithms, their design, capabilities, and limitations\\nKnowledge of statistical analysis technique\\nAbility to build complex extraction, transformation, and loading (ETL) pipelines to clean and fuse data together\\nAbility to obtain a security clearance\\nBA or BS degree required\\n, \\nExperience with designing and implementing custom machine learning algorithms\\nExperience with graph algorithms and semantic Web\\nExperience with designing and setting up relational databases\\nExperience with Big Data computing environments, including Hadoop\\nExperience with Navy mission systems\\nMA or MS degree in Mathematics, CS, or quantitative fields\\n]\"\\n\"[Google\\'s projects, like our users, span the globe and require managers to keep the big picture in focus while being able to dive into the unique engineering challenges we face daily.', 'Continuous Monitoring of A/B Tests, \\n\\nCODE @ MIT 2016: A/B Testing in a Changing World, \\n\\nINFORMS 2015: Can I Take a Peek?', \"You are a fast-learner and self-driven performer, who feels comfortable in a start-up environment, where everything needs to be built up from scratch., \\n\\nGoogle's mission is to organize the world's information and make it universally accessible and useful.\", 'Mentor others in using analytics tools\\n\\nEvaluate and enhance existing reports and dashboards\\n\\nDefine and document business requirements for new metrics and reports\\n\\nEnsure accuracy and integrity of data and reporting applications through detailed analysis, efficient coding, writing clear documentation processes, identifying and resolving problems as they arise\\n\\nReview and write complex SQL queries and develop stored procedures and functions in SQL\\n\\nPerform ongoing monitoring and refinement of reports and BI solutions\\n\\nAbility to work effectively within competing deadlines with minimal guidance\\n\\nInteract professionally and collaborate with a diverse group including executives, managers, and subject matter experts, 4 or more years of quality experience using SQL Server, SSRS, SSAS, Azure, and SSIS\\n\\nStrong knowledge of relational and multi-dimensional database architecture\\n\\nExperience creating and maintaining documentation following standard creation and change control processes\\n\\nProficient oral and written communication skills\\n\\nAbility to lead a meeting and present to small audiences\\n\\nExperience integrating Power BI into web applications]\"\\n\"[\\n\\nAssist with data collection and optimization of storage approaches\\n\\nProvide support for scalable batch or real-time data processing for discovery and model creation\\n\\nImplement scalable APIs for utilizing analytics results (e.g., utilizing models produced)\\n\\nCollaborate with data scientists and help them evaluate the computation/data requirements for discovery and the deployed solution\\n\\nDesign, build, operationalize, and scale some of the largest data pipelines in the world\\n\\nAdvise on and manage big data infrastructure\\n\\nArchitect and develop data ingestion pipelines\\n\\nDevelop proofs of concept with emerging technologies\\n\\nAssist with data preparation, \\n\\nBachelor\\'s degree in Computer Science or a related technical field\\n\\n3 years of experience as a Software Engineer or closely related position\\n\\n3 years of of experience with the following:\\n\\nDesigning, integrating, and optimizing distributed data-processing pipelines\\n\\nUtilizing database technologies, including: SQL and No-SQL (e.g., Hadoop, Splunk, Spark, Samza, MySQL, Postgres, MongoDB, Sqlite, Neo4j, Apache Giraph), within a cloud environment\\n\\nWriting data processing code in Go, Java, Python, Scala, or other high-performance languages\\n\\nUsing distributed and fault-tolerant computing and map/reduce processing techniques\\n\\nUtilizing Linux/UNIX systems\\n\\nSystems-level debugging\\n\\nBuilding REST APIs for analytics services\\n\\nWorking with or in support of multiple open source communities\\n\\nOptimizing critical components in applications for efficiency using C or C++\\n\\nUtilizing cloud deployment and virtualization and containerization technologies (e.g, Docker, Ansible, Terraform and Vagrant)\\n\\n1 year of experience with the following:\\n\\nMachine learning libraries, such as Google CloudML, DataFlow, DataLab, TensorFlow, SciKit Learn, Mahout, and MLib\\n\\nOptimizing advanced SQL queries\\n\\nWorking in an agile environment with SCRUM and PODS]\"\\n\"[\\nDesign, develop, automate, monitor and maintain Extract Transform Load (ETL) data movement applications using our preferred ETL tools and techniques.', 'You will also be able to tap into the continuous innovation of our Accenture Technology Labs and Innovation Centers, as well as top universities such as MIT through our academic alliance program.', 'a huge plus., Career Path, We hire Data Engineers at our Associate to Director career stages., Available locations, Arlington; Atlanta; Chicago; Newport Beach, CA; San Luis Obispo, CA; Sydney; Toronto]\"\\n\"[You yearn to be part of cutting edge, high profile projects and are motivated by delivering world-class solutions on an aggressive scheduleYou are not intimidated by challenges, thrive under pressure, passionate about your craft, and focused on delivering exceptional resultsYou love to learn new technologies and mentor junior analysts to raise the bar on your teamPassionate about intuitive and engaging user interfaces, as well as new/emerging concepts and techniques, Develop sustainable data driven solutions with new data technologies to meet the needs of our organization and business customersBuild robust end-to-end systems with an eye on the long term maintenance and support of the applicationLeverage reusable code modules to solve problems across the team and organizationHandle multiple functions / roles for the projects / Agile teamsWork with established standards across the team and organizationUnderstand complex multi-tier, multi-platform systemsContribute to building a framework of a significant complexityWork with internal team of data engineers (both full-time associates and/or third party resources), At least 5 years coding, or at least 5 years experience in data warehousing or at least 5 years in unstructured data environmentsAt least 2 years experience in Azure cloud technologies AzureAt least 2 years experience in big data technologies (Cassandra, , HBase, Spark, Hadoop, HDFS, AVRO, MongoDB, Zookeeper, or similar)2+ years of experience with Agile engineering practices\\n, 1+ years experience in Azure cloud technologies AWS, MapR, Cloudera, Google Cloud5+ years experience with NoSQL implementation (Mongo, Cassandra, etc.', 'The Google AI Residency Program will have 3 start dates over the course of 5 months, from June to October 2019.', 'Ability to accurately forecast volume and/or track and complete the specific project to meaningful deadlines\\n, Web analytics tool (Adobe Site Catalyst or Google 360 Premium),\\nCRM platform\\nLoyalty platform\\nA/B testing platform\\nEmail marketing platform (SalesForce Marketing Cloud is preferable)\\n, CAREER DEVELOPMENT\\n\\n, The role can advance depending on the individual‚Äôs passions and interests.', 'Atos operates under the brands Atos, Atos Consulting, Atos Worldgrid, Bull, Canopy, Unify and Worldline., \\n\\nPlease follow this link, Atos.net page, to learn more about the new Global Partnership with Google Cloud and Atos!', ', Responsibilities Include:, \\n\\nProvide creative solutions to marketplace problems using data driven approach, both in short and long term\\n\\nDeliver robust and scalable solutions to improve Users\\' and advertisers\\' experience on Bing\\n\\nWork closely with various feature teams, evaluating the feature impact on Bing marketplace\\n\\nBe a ‚ÄòGo-To‚Äô person for any data analytical needs ranging from data extraction/manipulations, long term trend analysis, statistical analysis and Machine learning models\\n\\nUse hypothesis driven approach to answer analytical questions, provide recommendations to the leadership teams, \\n\\nShare standard methodologies and documentation across teams, \\n\\nBasic Qualifications:,  Bachelor‚Äôs degree or above in a Computer science, STEM, related engineering or Business-related field with strong emphasis on data analytics 2+ years of experience in Data mining and qualitative analytics Curious mind and willing to tackle complex business problems Understanding of Machine learning & statistical analytical tools, \\n\\nPreferred skills:,  Be Skillful at C/C++/C#, SQL programming, python, R Have a strong interest in online advertising products business models and system architectures Experience in online Ad space is a plus]\"\\n\"[Dell provides the technology that transforms the way we all work and live.', 'Preferably including DoubleClick, Google Analytics, AdWords and Google Tag-Manager and stream data into environments such as BigQuery\\n\\nResponsible for the management of multiple processes and applications, performance reporting and error checking\\n\\nResponsible for the management of all data created within client applications, the structure of data held and the views of data created\\n\\nResponsible for recommending the correct technologies to be used and in the most cost effective manner\\n\\nResponsible for the design and creation of data led strategies which provide clients with opportunities to leverage their data for greater insight or performance\\n\\nProvide thought leadership with regards to best practice and use of the google cloud platform, \\n\\nBS Degree\\n\\nData Engineering/ BI Development/ Data Warehousing experience.', '\"[\\n\\nIdentify opportunities to operate the marketplace more efficiently, working closely with business, product, and engineering leaders\\n\\nBuild multivariate models to arrive at inferences or predict future behavior\\n\\nDevelop algorithms that match owners with providers or solve other customer needs\\n\\nDesign and analyze A/B user tests and marketplace experiments, often in partnership with product managers\\n\\nDeploy machine learning models at scale, writing production code in collaboration with machine learning platform engineers, \\n\\nSQL\\n\\nPython\\n\\nProbably at least one additional programming language / computational programming environment; e.g., R, Matlab, C++, etc\\n\\nGoogle Analytics or similar user funnel analytics tools\\n\\nTableau, Looker, or similar data visualization tools\\n\\nData-informed decision making with rigorous split testing.', 'How will Google Cloud and Atos‚Äô global partnership work together to deliver secure hybrid Cloud, machine learning, and collaboration solutions to the enterprise?', 'You will be working with internal customers in all departments (marketing, finance, operations and customer service) to dig into data insights and develop operation and business metrics using a wide range of tools (Redshift, Looker, Tableau, etc)., \\n\\nResponsibilities, \\n\\nOwn business intelligence and reporting of overall company KPIs and performance metrics by product, \\n\\nBuild and utilize tools and processes that will scale our reporting and analytics capabilities and help shape the data roadmap\\n\\nPerform diagnostics and data-driven recommendations to improve overall performance\\n\\nOwn business forecasts ‚Äì overall and by product\\n\\nWork with marketing, finance, operations, support teams to help shape and track business objectives with a data-driven approach\\n\\nSupport all cross-functional teams by prioritizing and responding to ad hoc analytics needs, \\n\\nQualifications, \\n\\nBachelor‚Äôs degree in Computer Science, Engineering, Statistics or equivalent\\n\\n3 years in a previous position as a data analyst, ideally for a web or mobile-based business\\n\\nProficient knowledge in SQL and relational databases\\n\\nProficient knowledge in MS Excel or Google Sheets including formats, charts, tables, functions\\n\\nExperience in data visualization tools such as Tableau or Looker\\n\\nDemonstrated experience showing strong critical thinking and problem solving skills paired with a desire to take initiative\\n\\nDemonstrated experience working under pressure, both individually and collaboratively in a team environment\\n\\nDemonstrated organizational skills and customer focus]\"\\n\"[\\n\\nFor the 28th year, MSK has been named a top hospital for cancer by U.S. News & World Report.', '\"[\\n\\nArchitect and implement high performance data pipelines for distributed systems and data analytics for deep learning teams\\n\\nUse infrastructure as code to build, deploy, operate, and maintain big data analytics infrastructure\\n\\nOrchestrate large PB sized data storage and compute clusters across bare-metal and cloud\\n\\nDeploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform\\n\\nCreate and maintain optimal data and model dataOps pipeline architecture\\n\\nAssemble large, complex data sets that meet functional / non-functional business requirements\\n\\nIdentify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.', 'Experience building re-usable data integration frameworks and patterns\\nWorking knowledge of Informatica, Hadoop/AWS, IBM Infosphere products and other Big Data tools.', 'This individual will dig into raw and processed data (backend DBs, Google Analytics, and event/message data), transform information into visualizations using Tableau, R, Excel, etc., and effectively articulate the story behind the data.', 'Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\\n2+ years of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\\nExperience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\\nExperience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\\nWorking knowledge of Tableau ‚Äì a plus\\nMust be a self-starter with excellent oral and communication skills.', 'The team‚Äôs goal is to continuously improve the company‚Äôs marketplace and shopping efficiencies., \\n\\nSome of the teams‚Äô projects include:, \\nDesign experiments to help with cutting edge technology such as augmented reality or indoor GPS\\nDesign and rigorously test new features in our app that improve quality of service for our customers\\nIdentify the optimal product strategy for different marketplaces\\nDefine and measure metrics that quantify the tradeoffs between different fulfillment models\\nDistill complex datasets into actionable KPIs; build and automate reporting to empower data driven decision making across the company\\n, Qualifications:\\n\\n3+ years of experience or equivalent in conducting quantitative research, analysis and modeling, preferably at a start-up, \\n\\nExperience supporting Data Scientists in model validation and algorithm / model optimization, \\n\\nExpertise in wrangling large datasets (SQL, Hive, or Spark), \\n\\nEffective data visualization skills (Tableau, Looker, or D3.js), \\n\\nSolid programming skills for statistical analysis (Python or R), \\n\\nA passion for leveraging data for business impact, \\n\\nA high sense of urgency and ownership, \\n\\nGrowth mindset; the ability to thrive in a dynamic and collaborative environment, \\n\\nPrior experience in logistics and marketplace systems preferred]\"\\n\"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.', 'Cortex is the central ML/AI team with the goal to build an ML platform and provide deep ML expertise to support our internal customers, while advancing ML inside & outside Twitter., \\n\\nIn particular, the ML Extended Environment team (MLX) in Cortex is focused on unifying & advancing recommendation systems.', 'Work effectively with clients to align Google Marketing Platform attribution and analytic solutions with key organizational challenges and develop value-based roadmaps to solve client business issues on a continuous and repeatable basis.', 'We are looking for sharp, disciplined, and self-motivated individuals who have a passion for utilizing the cloud solutions from Amazon Web Services, Microsoft Azure, and Google Cloud Platform to solve real business problems for our customers., \\n\\nResponsibilities:, \\n\\nWork as part of a team, to design and develop cloud data solutions.', '[Raytheon is an Equal Opportunity/Affirmative Action employer.', ', QUALIFICATIONS:\\n\\n, Advanced Degree (Ph.D. preferred) with a focus on Analytics, Statistical Sciences, Operations Research, Economics, Finance or a related Business quantitative discipline\\n\\n5+ years of real world analytical solution building experience\\n\\nData mining technical knowledge and skills including: decision trees, multivariate analysis, segmentation modeling, factor analysis, regression analysis, forecasting, and machine learning\\n\\nExpertise in R, SAS Enterprise Miner, or IBM SPSS Modeler or other analytical software\\n\\nIntellectual curiosity and commitment to teaching data analytics concepts to others\\n\\nExperience in leading and developing data science teams a plus\\n\\n, Qualifications:\\n\\n, Company Overview:\\n\\n, Our success comes from strategically placing you in the most suitable role.', 'Familiarity with Big Data tools such as Splunk, Hadoop, Spark, etc.', \"[Overall 8+ Years of experience in IT industryAtleast 4 years experience in SplunkVery good knowledge and working experience in Big Data Hadoop / No SQL3+ years' experience with Splunk in developing text mining use casesIntegrating Splunk with Big Data Hadoop for log storageIntegration with variety of external data sourcesThe ability to design Splunk reports and dashboards using complex data elementsFamiliarity of a Web Based application environmentLinux shell scripting/Regex experience would be highly preferableSplunk certifications is a plus.]\", \"Improve the data stack using the latest and greatest innovations in Google's internal and external Google Cloud Platform stack.\", 'Experience writing and executing complex SQL queries\\n\\nExperience managing and optimizing SQL databases\\n\\nExperience with development in one or more of the following Python, R, Scala, SQL\\n\\nExperience with data processing frameworks and data warehouses such as Hadoop, Spark, Redshift\\n\\n\\nBonus points for:\\n\\nExperience working with healthcare data\\n\\nExperience with Looker, Tableau and other BI tools\\n\\nExperience with DataBricks analysis platform\\n\\nExperience with building and operating data pipelines\\n\\nExperience with machine learning]\"\\n\"[Providing actionable reporting on how our users are engaging with our productsBringing data thinking to our projects by attaching metrics to our processesMaintaining, improving, and scaling our internal processes and learnings around data thinking, collecting and, reporting, Measurement Strategy: Define problems and solutions and attach metrics (KPIs) or other views of data that reflect how those problems can be being solvedSpecifications: Designing the specification for event tags (Segment.io, Mixpanel, Google Analytics) fired from the front end/back end, or queries that can enable those metrics or views of data to be calculatedReporting: Design and build a dashboard that displays those metrics and continues to iterate through ad-hoc reporting and meetings with stakeholders, Consume and report on external data sets, primarily logs (i.e., Sumo Logic)Consult and build business intelligence dashboards that are part of our products shipped to customers (Birst or Infor Business Intelligence), and work with the team to build a corporate-wide design system for these dashboardsAssist in non-quant researchContribute to storytelling, UX and product strategy, \\n\\nWe are looking for an engineer or data wizard first, a data analyst second, and designer as a value-add., Bachelor‚Äôs degree in Engineering or computer scienceAbility to rapidly execute against building data models and dashboards.', 'Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc...\\n, Lead the design, implementation, and operation of a state-of-the-art ‚Äúbig data‚Äù analytics approach which is scalable and innovative in the way it extracts, manages and analyzes data\\nRoughly 65% thought leadership and management and 35% hands-on working with data\\nAssemble the right team, ask the right questions, and avoid mistakes that could derail a data science project.', 'Follow us on LinkedIn, Youtube and Twitter.]\"', 'Work with Business SMEs and Analysts to understand functional requirements and interact with other cross-functional teams to support their work to architect, design, develop, and test the solution., Ability to work seamlessly with complex data models and data relationships\\n\\nVery strong SQL query language skills is a must have\\n\\nExperience profiling data within relational data model structures is required\\n\\nMust have significant experience creating logical source to target maps for complex data warehouses\\n\\nAbility to design and implement data model tables, with experience using Erwin or IBM Data Architect data modeling tools required\\n\\nMust have at least 7 years experience working mapping and analyzing data within a Data Warehousing or Data Lake environment, with 5 years experience working with clinical Healthcare data.', 'We offer a highly competitive base salary and a comprehensive benefits program, including medical, prescription drug, dental, vision, 401(k) with company match, life insurance, paid time off, tuition assistance and an employee stock purchase plan., \\n\\nExpress Scripts is committed to hiring and retaining a diverse workforce.', ')Link analysis and related topicsAnalytic software development in Python, Perl, R, Java, or other languages]\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \\n\\nAs a Solutions Architect with a core focus on Machine Learning (ML), you\\'ll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.', 'You can find us in 27 cities across the U.S., U.K., and Canada., \\n\\nJob Title, \\n\\nSolution Principal ‚Äì Machine Learning, \\n\\nAs a Solution Principal, you‚Äôll design and deliver innovative Machine Learning solutions on Amazon Web Services, Azure and Google Cloud using core cloud data science tools and other big data related technologies.', 'Master‚Äôs preferredProven experience with data mining, cleansing and manipulations, variable transformations, linear and non-linear multi-variable regression analysis, K-mean and hierarchical cluster analysis, discrete and continuous probability distributions, systems of equations and numerical analysisProven exp using the cloud to do large computationsProven exp joining large data sets from various repositoriesProven experience with 1 or more statistical programming languages: R, Python, Matlab, SAS.Experience with queries to extract and transform data from multiple data sources, including Oracle, Teradata, and SQL ServerExperience utilizing Excel, PowerPoint, and other MS Office softwareExperience with 1 or more statistical analysis software: Minitab, Stata, SPSS, APTKnowledgeable about digital, E-commerce, marketing a plus]\\n\"[With demand sensing, OM Partners is breaking through some boundaries of classical demand forecasting.', 'and multithreading\\n\\n, Cloud-based services (Google Cloud, Amazon Web Services)\\n\\n, Relational SQL and NoSQL databases, graphical database (e.g.', '\"[\\n\\nExperience working for Facebook, Amazon, LinkedIn or Google required\\n\\nProblem solver with a track record of addressing root-cause issues\\n\\nBig picture thinking combined with an exacting attention to detail\\n\\nSelf-motivated and directed fast learner\\n\\nAbility to partner with business and technical groups in a cross-functional capacity, \\n\\nUsing available data to address business questions or concerns.', 'Prior experience with IBM Guardium tool.', 'SAP HANA, IBM SPSS, DSX.', 'Create pipelines: and know what‚Äôs the right infrastructure, both in terms of storage and in terms of computing at massive scale, that can run scoring or predictions on new data., 5-8 years of related professional experience\\n\\nBachelor‚Äôs Degree in related field and Masters or higher a plus\\n\\nStrong analyst background; generated insights and business recommendations\\n\\nStrong project consultative background; creating project requirements\\n\\nStrong experience creating ETLs and pipelines (streaming vs. batch; low vs. high frequency pipelines), using tools such as AirFlow, ApacheNiFi, Kafka\\n\\nStrong experience wrangling, exploring and cleaning structured and unstructured data\\n\\nStrong data visualization skills using Tableau or open-source tools\\n\\nAbility to code from Python/R to Java/Scala/Spark\\n\\nExperience with collaboration tools such as Bitbucket, GitHub, Teams, or Jira\\n\\nExperience with various data sources (on-premises vs. cloud; database vs. files)\\n\\nExperience with various data environments (on-premises vs. cloud; database vs. data lake; small vs. medium vs. big data), such as Google, AWS, Oracle, or Hadoop\\n\\nFriendly, fun, conscientious, curious and out-of-the box mindset\\n\\nAbility to ask questions and figure out what‚Äôs the right data and data science solution, in a collaborative team environment that follows an agile data science process\\n\\nA subject matter expert leading hands-on with technical know-how, determining methods and procedures on new projects, and providing leadership to other engineers\\n\\nStrong written and verbal communication skills with internal and external clients]\"\\n[Job Summary, External Role / Title: Big Data Engineer - AWS & Hadoop, Internal Role / Title: Technology Architect, Job ID: 32890BR, Work Locations: Across cities in USA., Wanted: Global Innovators to Help Us Build Tomorrow‚Äôs Enterprise, As a Technology Architect, you will provide top-notch solution design and implementations; assist in defining scope and sizing of work; develop Proof of Concepts, innovate in solution development, solve problems and support Infosys brand., Locations for this position can be most cities in US.', 'Experience in Python, Scala, Java, C, C++ or R is required\\nKnowledge of statistics, linear algebra, multiple variable calculus, Fourier analysis or machine learning\\nExperience using one or more of the following software packages: scikit-learn, numpy, pandas, jupyter, matplotlib, scipy, nltk, spacy, keras, tensorflow\\nExperience solving problems using one or more of the following techniques: Regression, Support Vector Machines, Decision trees, random forest, Boosting, PCA, KMeans\\nExperience in using SQL/No SQL databases is an advantage\\nExperience working in Linux and in a High Performance Computing environment is an advantage\\n, Alternate Location: United States : Baytown, Texas || United States : Clinton, New Jersey || United States : Hugoton, Kansas, ExxonMobil is an Equal Opportunity Employer.', 'The Transformation team helps the CSG leadership to define the near- and long-term strategy for Dell‚Äôs worldwide PC business., \\n\\nRole Responsibilities, \\n\\nData mining using state-of-the-art methods\\n\\nDeveloping and enhancing data models to deliver predictive insights\\n\\nCreating automated anomaly detection systems and constant tracking of its performance\\n\\nDeveloping data visualizations to help guide decision making\\n\\nConducting ad hoc deep dives to understand root cause of issues\\n\\nCollaborating with internal and external consulting teams on transformation projects\\n\\nCollaborating with LOB/function strategy, sales, marketing, and product teams to address issues identified, Requirements, \\n\\nExcellent understanding of machine learning techniques and algorithms, such as k-NN, Naive Bayes, SVM, Decision Forests, etc.', 'Learn more about Diversity and Inclusion at Dell here., \\n\\nCome join us!', 'Able to provide a GitHub or coding portfolio of prior data science, computer programming and statistical work and projects\\nStrong desire to explore various data sources to uncover hidden trends and opportunities for the organization\\nSelf-directed, detail & team oriented with highly developed problem solving and analytical skills\\nExcellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\\n, Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.', 'Lab employees and external candidates may be considered for these positions., About Us, \\n\\nLawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE).', '[Engages with Google fellows, local Goodwill¬Æ team members, GII colleagues and other subject matter experts to coordinate implementation of the Google-supported Goodwill Impact Data Collaboration (IDC).Facilitates work on mission impact systems from implementation and enhancement.Prepares effective oral and written communications and materials to support alignment, collaboration and learning.Provides technical training to internal project team members and Goodwill member users.]', 'degree in Computer Science, Electrical/Chemical/Mechanical Engineering, Applied Mathematics, Statistics or other related scientific discipline\\nStrong theoretical and applied background in machine learning, statistics, data-mining and optimization\\nStrong communication skills with an ability to interact with a variety of researchers and business partners in different disciplines\\nDemonstrate personal accountability for quality of work\\nUse a measured risk approach in business decisions\\n, ExxonMobil is an Equal Opportunity Employer.', 'Maintenance and improvement of created platforms and/or models\\nWriting client-facing reports and contributing to proposal work\\nWork related travel as needed (2-3 times per quarter)\\n, 3-5 years of data science/software development experience\\nStrong background in Machine Learning and AI\\nSolid training in probability and statistics\\nExperience with managing big datasets\\nExcellent communication and writing skills\\nProficiency in Python, R, Java, Tableau or similar\\n, Experience with QA/NLP\\nExperience with AWS, Google Cloud, etc.', \"Most importantly, you‚Äôll work and collaborate with a nimble, autonomous, cross-functional team of makers, breakers, doers, and disruptors who love to solve real problems and meet real customer needs., \\n\\nThe person we're looking for:, \\n\\nhas a sense of intellectual curiosity and a burning desire to learn\\n\\nis self-driven, actively looks for ways to contribute, and knows how to get things done\\n\\nis deliriously customer-focused\\n\\nvalues data and truth over ego\\n\\nhas a strong sense of engineering craftsmanship, takes pride in the code they write\\n\\nbelieves that good software development includes good testing, good documentation, and good collaboration\\n\\nhas great communication and reasoning skills, including the ability to make a strong case for technology choices, Basic Qualifications:, Bachelor‚Äôs degree or Military ExperienceAt least 1+ years‚Äô experience with leading big data technologies such as Spark, Cassandra, Hadoop, HDFS, PostgreSQL, Redshift, and MongoDBAt least 2 years of professional experience with data engineering concepts, \\n\\nPreferred Qualifications:, 2+ years experience with AWS cloud2+ years of experience in Java, Scala, or Python2+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python2+ years of experience building data pipelinesAt least 1 year of Cloud (AWS, Azure, Google) development experienceExperience with Streaming and/or NoSQL implementation (Mongo, Cassandra, etc.)\", 'Be versed in Amazon Web Services, Google Cloud Platform and/or Microsoft Azure cloud solutions, architecture, related technologies and their interdependencies.', 'To achieve this, we‚Äôre working on projects that utilize the latest techniques in Machine Learning (including Deep Learning approaches like Google Brain) and Natural Language Understanding., We‚Äôve already been joined by some of the best minds, and we‚Äôre looking for talented Research Scientists that have applied experience in the fields of Machine Learning, Natural Language Processing and Machine Intelligence to join our team.', 'Hadoop, Spark or Vertica) is required\\n\\nMinimum of 1-2 years implementing solutions in a cloud environment (AWS, Azure or Google)Prior experience leading technical teams of data scientists/engineers at various levels where you were responsible for providing project estimates for your work stream and assigning tasks to other team members\\n\\nExcellent written and oral communication skills; must be capable of effectively articulating technical concepts to executive level and business audiences\\n\\nMust have an undergraduate (BS) or postgraduate (MS/Ph.D.)', 'Fluent in multiple technologies such as with Python, Azure ML, IBM SPSS Modeler, R or comparable technologies required.', 'Our vibrant and diverse international community of nearly 250 publishing brands and imprints include Ballantine Bantam Dell, Berkley, Clarkson Potter, Crown, DK, Doubleday, Dutton, Grosset & Dunlap, Little Golden Books, Knopf, Modern Library, Pantheon, Penguin Books, Penguin Press, Penguin Random House Audio, Penguin Young Readers, Portfolio, Puffin, Putnam, Random House, Random House Children‚Äôs Books, Riverhead, Ten Speed Press, Viking, and Vintage, among others.', 'Work with data and analytics experts to strive for greater functionality in our data systems., \\n\\nKnowledge of Meta and Master Data Management\\n\\nFamiliar with Google Cloud Platform Service cloud services like: Cloud Sql, BigQuery, DataFlow, DataPrep, AppEngine\\n\\nKnowledge of stream-processing systems: i.e.', 'You‚Äôll work on exciting brand and acquisition campaigns, perform site optimizations, monitor and run reporting, contribute to an online testing strategy and more., \\n\\nDay-to-day, your role includes:\\n\\n, Keeping a pulse on day-to-day performance data, including display media, site, search, email, and/or social campaigns\\n\\nWorking in a variety of reporting systems and databases for the creation of recurring reports and dashboards\\n\\nIdentifying nuances in data to optimize our clients‚Äô business\\n\\nSupporting marketing initiatives across project and campaign lifecycles, including measurement plans, primary and secondary research, and performance reporting\\n\\nExpanding industry knowledge and relevant skillsets through internal training, \\n\\nWe‚Äôre looking for strong, impactful work experience, which typically includes:, \\n\\nA four-year college degree\\n\\n1-3 years of work experience in the social analytics space\\n\\nPassion for digital marketing, eagerness to learn in a constantly-changing space, and a natural curiosity\\n\\nExperience with Analytics across social channels and tactics (i.e., Facebook, Instagram, Twitter, Pinterest, Social Retargeting)\\n\\nSolid experience with display ad-serving, 1st party onboarding/targeting, brand study measurement partners, and Site Analytics\\n\\nExperience building real-time reporting/dashboarding, knowledge of quantitative and qualitative side of analytics\\n\\nExposure and experience with Social Listening tools (i.e., Netbase, Brandwatch, Affinio, Crimson Hexagon)\\n\\nExtensive knowledge in data management, data mining, data integration\\n\\nExperience compiling measurement plans and identifying KPIs and optimization metrics\\n\\nWell-versed in Microsoft Office suite ‚Äì Excel, Word, PPT\\n\\nSomeone who can work quickly and manage multiple tasks to completion\\n\\nThe ability to quickly \"\"switch gears\"\" while remaining organized across multiple projects\\n\\nStrong oral/written communication skills\\n\\nRetail and/or beauty experience is a plus, Facebook\\n\\nInstagram\\n\\nTwitter\\n\\nPinterest\\n\\nGoogle Analytics\\n\\nAdobe Omniture\\n\\nNetbase\\n\\nBrandwatch\\n\\nAffinio\\n\\nCrimson Hexagon\\n\\nDCM (DoubleClick), \\n\\nGot what it takes?', 'Javascript coding skills: you need to be able to write snippets for custom event tracking for different softwares & tools we use, like Google Analytics or Active Campaign.', 'Ability to manage multiple projects and deliver against aggressive deadlines\\n\\nMasters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable\\n\\nStrong work ethic and intellectual curiosity, with laser focus on execution, \\n\\nStrong quantitative, analytical, and problem solving skills, \\n\\n4+ years experience within business/marketing/data analytics, \\n\\nExperience working in the Salesforce environment, understanding business products, journey flow and terminology\\n\\n, Expertise in a query language such as SQL or equivalent, \\n\\nExperience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics, \\n\\nExperience in reporting on customer insights and LTV analysis, \\n\\nWorking knowledge in Google Tag Manager, \\n\\nWorking knowledge of ad trafficking/ad serving platforms including but not limited to Doubleclick etc., \\n\\nAbility to manage multiple projects and deliver against aggressive deadlines, \\n\\nMasters Degree in Statistics, Marketing Analytics, or other Quantitative fields is highly preferable, \\n\\nStrong work ethic and intellectual curiosity, with laser focus on execution]\"\\n\"[\\n\\nCollaborating with BU Partners & exercising expertise in selecting methods & techniques to design, develop, implement, modify & support software products involving data movement of very large data sets and integration processes in preparation for analysis, data warehousing & operational data stores\\n\\nDevelop ETL process on big data platforms & ensuring the data is available per the SLA\\n\\nDevelop APIs to provide access to in-house and third-party data and enable analysis\\n\\nCollect, process, and interpret large data sets, identify and analyze features of interest such as key performance metrics for channel marketing strategies, what if scenarios, aggregations, filtering, statistical modeling\\n\\nWork on problems of complex scope requiring the synthesis of various inputs, analyzing large quantities of data & related products/services\\n\\nAssist in data model documentation, data dictionary, data flow, and data mapping for analysts\\n\\nCreate new metrics and develop tools for monitoring and reporting\\n\\nParticipate in complete end-to-end data warehousing & analytics work, including design, reviews, development, unit tests, and deployment\\n\\nResearching & POC of the latest tools & technologies required for software & data engineering tasks, \\n\\n4+ years of experience with data warehouse & software engineering background\\n\\nUsing Data integration (ETL) Tools such as Informatica, Pentaho, ODI & SQLSERVER Technologies such as SSIS, SSAS & SSRS or equivalent\\n\\nExperience using scheduling & orchestration tools such as Tidal, Oozie or Control-M\\n\\nRDBMS expertise on Oracle, SQL Server, etc and MPP systems such as Netezza & Vertica\\n\\nSecure handling of sensitive information using Safenet, HSM, SSL, Access Control Lists (ACLs), encryption & key management\\n\\nProficient in SQL, Unix and Perl\\n\\nImplementing big data analytical solutions using Hadoop, Hive and Pig\\n\\nUsing Cloud based technologies such as Amazon s3, Redshift, EMR, DynamoDB, or RDS\\n\\nProgramming & Automation skills in Python, Scala, Java or R using bigdata\\n\\nMaintaining centralized data cataloging/quality using technologies such as Informatica Data Quality (IDQ) or Alation\\n\\nDesign and development of analytical reports and dashboards using Business Objects, QlikView, Tableau or similar visualization technologies is preferred\\n\\nExperience working with SaaS-based subscription metrics including conversion, retention and product usage is preferred]\"\\n\"[Our client, One of the biggest Software Companies, is actively looking for a Data Analyst to join their growing team in San Jose, CA!, The Service Management Analyst will be responsible for analyzing macro trends across a Cloud Technology and Digital Media service landscape which includes a rich ecosystem of services supporting customers, businesses, and employees., A background in Incident, Problem, Change, and Release Management will provide the context necessary to analyze the datasets., Preferred Qualifications:, Analytical mindset and critical thinking ability\\nAbility to use data to derive actionable insights (including skills in designing data models, collecting data, data preparation, data augmentation, data mining)\\nFamiliarity with Service Management and ITIL Framework (Incident Management, Problem Management, Change Management, Release Management)\\nAbility to work with relational datasets and excel spreadsheets\\nAbility to build partnerships with cross functional teams in order to achieve objectives and results\\nAbility to work through failed attempts and look at it as a learning experience on the road to success\\nEffectively communicate with leadership and technical personnel by ‚Äútranslating‚Äù and conveying ideas and insights between the two\\n, Experience:, 3-5 years experience working with data models and conducting data analysis and applying insights learned from the data into working processes to achieve desired results\\nSQL, Excel, Python, or Tableau Experience\\n, The Offer:, Up to $65/hr DOE\\nHSA Health Savings plan\\n, Benefits:, Medical insurance\\n401k\\nTransportation benefits\\nPaid Sick Time\\n, Benefits & Perks, A competitive benefits package is offered complete with: health, transportation benefits, accrued sick-time off, and a 401k option.]\"', 'Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and Google Cloud Platform ‚Äòbig data‚Äô technologies.', 'Your relationships with customers are crucial in helping Google grow its Google Cloud business and in bringing our product portfolio into companies around the world., Our Analytics and Data Science team is responsible for the data needs of the Google Suite support services, a large global support team for customers around the globe.', \"Responsibilities:\\n\\n\\n, Lead strategy discussions and help to design and develop a solution that meets clients goals and outcomes\\n\\nConduct data analysis and predictive analysis to meet client needs\\n\\nReverse-engineer implemented solutions to understand the client problem and resolve client challenges\\n\\nCreate predictive models, train and leverage machine learning APIs, build machine learning pipelines, build Chatbots for the enterprise, embed intelligence in a variety of industry or domain-specific use-cases, and more, BENEFITS, ibm.com/employment/us/benefits/\\n\\nibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\\n\\nFinding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\\n\\nDiversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\\n\\nibm.com/ibm/responsibility/corporateservicecorps/, At least 2 years of experience working on predictive analytics and data mining projects\\n\\nAt least 2 years of hands-on experience using complex machine learning methods and algorithms such neural net, deep learning and collaborative filtering\\n\\nAt least 2 years of experience working with one or more data mining tools such as R, Python, SAS and SPSS\\n\\nHands-on experience writing complex SQL queries and working with relational databases such as Oracle DB2 and SQL Server\\n\\nHands-on experience constructing and manipulating JSON and XML documents and working with NoSQL databases such as MangoDB and CouchDB.\", 'Have experience in extracting data and building complex data transformation using SQL on MS SQL Server, IBM DB2, Sybase, XML, and other popular data structures.', 'At Raytheon, we work together as one global team creating trusted, innovative solutions to make the world a safer place.', 'You‚Äôll have the opportunity to collaborate with the best AI talents in the company, both inside cloud as well as Google Research, DeepMind and other organizations.', 'Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]\\n\"[Design, construct, install, test and maintain highly scalable data management systems\\nBring structure to large, disparate sources of data ranging from highly structured market data through to fully unstructured text\\nBuild high-performance algorithms, prototypes, predictive models and proof of concepts\\nDesign and structure a research environment flexible enough for creative research whilst stable enough to generate investment ideas\\nIntegrate new data management technologies and software engineering tools into existing structures\\nRecommend ways to improve data reliability, efficiency and quality\\nCollaborate with data analysts and modelers on project goals, Python\\nDatabase architectures and storage structures (Parquet)\\nHadoop-based technologies (Spark, HDFS)\\nAnalytics workbenches (Jupyter, AWS Sagemaker, Domino Data Lab)\\nData mining, statistical analysis and machine learning (Pandas, Keras)\\nDocker containers\\nAWS and Google Cloud, Creative Problem-Solving: Approaching data organization challenges with a clear eye on what is important; employing the right approach/methods to make the maximum use of time and human resources.', 'Experience with using web analytics tools such as Google Analytics.', 'While our clients are financial service providers, our mission is to engage consumers ‚Äì women who are marginalized by financial systems., \\n\\nFacebook\\n\\nTwitter\\n\\nLinkedIn\\n\\nGoogle\\n\\nMore]\"\\n\"[The Data Analyst will work directly with internal and external stakeholders as well as data providers, leveraging advanced statistical techniques to drive strategic thought and effective decision making in addition to collect and analyzing data an information about customers, markets and the business environment in countries in Africa, Asia, and Latin America., \\n\\nThe Analyst also supports all aspects of analytic initiatives from conception to completion, through the development of clear and well-structured analytical plans, and ability to analyze large and complex data-sets.', ', Excellent oral and written communication skills required for presenting to and collaborating with groups of diverse backgrounds., \\n\\nAbility to explain complex research concepts to individuals without a research background., \\n\\nExtensive knowledge of Microsoft Office and Google Suite applications (Docs, Sheets, Slides, Excel, and Powerpoint), \\n\\nDesired Qualification:, \\n\\nMBA/MS or higher in a statistical, mathematical or technical field.', '), \\n\\nE- Strong verbal, presentation, and written skills, \\n\\nE- Strong critical thinking and creative problem solving skills, \\n\\nE- Strong planning and organizational skills, \\n\\nE- Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets, \\n\\nE- Proficiency in MS Office suite (Excel, Access, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail), \\n\\nE- Knowledge of statistical tests and procedures such as ANOVA, Chi-squared, Correlation, Regression, Student t-test, and Time Series, \\n\\nP- Familiarity with Tableau , BI, Spotfire, or other data visualization software and techniques, \\n\\nP- Proficiency with the SAS language and toolset (Enterprise Guide, Forecast Studio, etc.', 'Provide expertise in building for scale, including potentially migrating data warehouse operations to a cloud service such as Google Compute Engine, Snowflake, and/or other platforms\\n\\nAdvise and train members of the team to maximize overall productivity and effectiveness of the team\\n\\nIdentify skills gaps and silos on the team and advocate for resolution\\n\\nParticipate in and contribute to scrum meetings i.e.', 'Minimum of 3 years of experience with cloud architectures, e.g., AWS (preferred), Azure, Google Cloud.', 'As a Technical Program Manager at Google, you lead complex, multi-disciplinary engineering projects using your engineering expertise.', 'Experience in visualizing data to stakeholders in a simple and concise manner through visualization software such as ggplot, D3,Tableau Qlinkview, Periscope, Business Objects, or other similar software.Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc...\\nSelf-starter who can multi-task, prioritize, and manage a multitude of conflicting priorities against competing deadlines without breaking a sweat.', 'We also manage the industry-leading services that help make Google a great place to work - from how we design healthy and collaborative workspaces, create energizing food experiences, provide convenient transportation and fitness options, to delivering inclusive environments where Google and our employees can thrive., Work closely with REWS management and their teams to understand their business problems and processes and how data can be applied to those problems and processes, and create appropriate analyses and tools to address them.', 'We are seeking an entrepreneurial Senior Data Scientist capable of working across functional and business areas with minimal supervision in order to support the application of data science methods and statistical techniques to data for internal use at Raytheon.', 'Dell will not tolerate discrimination or harassment based on any of these characteristics.', 'Agile: Experience participating in Scrum based projects, \\n\\nExperience working with ML & AI technology platforms such as Google.AI, AWS, and or Azure a plus.', 'Our products inspire outdoor exploration, exercise, and meaningful social interaction., \\n\\nOriginally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.', '\"[T-Mobile Home and Entertainment is seeking a proactive and driven Marketing Data Analyst with a passion for numbers and solving big data problems with actionable solutions.', 'Develop comprehensive understanding of Google data structures and metrics, advocating for changes where needed for both products development and sales activity.', 'Knowledge of Google BigQuery is a plus.', 'Responsibilities:\\n\\n\\n, Work with clients across many levels: C-Level, Vice-President, IT, Analytics and Business Users\\n\\nLeverage experience to apply elements of the Cross-Industry Standard Process for Data Mining (CRISP-DM)\\n\\nDefine key business problems from starter conversations, gather and analyze relevant data, conduct advanced transformations and integrations, identify suitable algorithmic approaches, conduct proper evaluations and stage outputs for operational deployments\\n\\nTranslate complex technical findings, conclusions and recommendations in compelling written and oral delivery formats, often to non data science personas\\n\\n, BENEFITS, ibm.com/employment/us/benefits/\\n\\nibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\\n\\nFinding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee\\'s strength and career aspirations\\n\\nDiversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\\n\\nibm.com/ibm/responsibility/corporateservicecorps/, At least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\\n\\nAt least 5 years of experience in project management for external consulting engagements\\n\\nAt least 5 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\\n\\nAt least 5 years of experience data management and coding such as DB2, SQL, Hadoop\\n\\nAt least 3 years of experience in visualization such as d3, Javascript, HTML, CSS, Advanced degree in a technical field\\n\\nAt least 7 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\\n\\nAt least 7 years of experience in project management for external consulting engagements\\n\\nAt least 7 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\\n\\nAt least 4 years of experience in visualization such as d3, Javascript, HTML, CSS]\"\\n\"[As a Data scientist/Machine learning engineer, You will be part of a very fast growing engineering team and one of the first engineers in our machine learning team.', 'Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\\n\\nExposure to Google Machine Learning is a plus]\"\\n\\n\"[\\n\\nLead a small team of data scientists to build products and services to delight our partners and customers.', '\"[\\nExperience with designing and implementing machine learning, data mining, statistics, or graph algorithms in an academic or professional work environment\\nExperience with Splunk\\nExperience with Tableau\\nAbility to program in an object-oriented language, including Java or C++ and Python\\nAbility to obtain a security clearance\\nBA or BS degree in Statistics, Mathematics, CS, or EE\\n, \\nExperience with the development of Hadoop, MapReduce, or HDFS\\nMA or MS degree a plus\\n]\"\\n\"[Position Description, \\n\\nA Staff Data Scientist is responsible for analyzing large data sets to develop multiple custom models and algorithms to drive innovative business solutions.', ', Responsibilities:\\n\\n, Maintain ongoing reporting that paints a picture of the ‚Äúpulse‚Äù of our business\\n\\nProactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance\\n\\nAbility to understand the business operations as a whole and translate questions into effective analysis based on the goals behind the specific asks\\n\\nCommunicate findings effectively and translate them into recommended actions appropriate for each area of the business\\n\\nDesign and build automated reporting dashboards on our BI platform\\n\\n, Maintain ongoing reporting that paints a picture of the ‚Äúpulse‚Äù of our business\\n\\n, Proactively analyze data to answer key questions from stakeholders or out of self-initiated curiosity with an eye for what drives business performance\\n\\n, Ability to understand the business operations as a whole and translate questions into effective analysis based on the goals behind the specific asks\\n\\n, Communicate findings effectively and translate them into recommended actions appropriate for each area of the business\\n\\n, Design and build automated reporting dashboards on our BI platform\\n\\n, Qualifications:\\n\\n, Excellent verbal and written communication skills\\n\\nComfortable deconstructing complex and open-ended problems which may not yield a clear cut solution\\n\\nAbility to work independently and to carry out assignments to completion based on the original goals with minimal supervision\\n\\n4-year degree in statistics or related field\\n\\n3+ years of experience in a data analyst role at an affiliate marketing, e-commerce company, or online publisher\\n\\n3+ years of experience using SQL is required\\n\\n1+ year of experience designing and building automated reporting dashboards with a data visualization tool such as Tableau or similar\\n\\nProficient with statistical analysis tools such as R or similar\\n\\nGoogle Analytics certification or equivalent experience\\n\\nDemonstrated ability to work collaboratively in a multi-disciplinary team\\n\\nStrong interest in Wirecutter‚Äôs mission\\n\\n, Excellent verbal and written communication skills\\n\\n, Comfortable deconstructing complex and open-ended problems which may not yield a clear cut solution\\n\\n, Ability to work independently and to carry out assignments to completion based on the original goals with minimal supervision\\n\\n, 4-year degree in statistics or related field\\n\\n, 3+ years of experience in a data analyst role at an affiliate marketing, e-commerce company, or online publisher\\n\\n, 3+ years of experience using SQL is required\\n\\n, 1+ year of experience designing and building automated reporting dashboards with a data visualization tool such as Tableau or similar\\n\\n, Proficient with statistical analysis tools such as R or similar\\n\\n, Google Analytics certification or equivalent experience\\n\\n, Demonstrated ability to work collaboratively in a multi-disciplinary team\\n\\n, Strong interest in Wirecutter‚Äôs mission\\n\\n, Culture and benefits at The New York Times Company and Wirecutter:\\n\\n, Though Wirecutter has physical locations in both NYC and LA, the company promotes and encourages a remote workforce, so that our employees can work in flexible and comfortable ways.', 'Extensive knowledge of Microsoft Office and Google Suite applications (Docs, Sheets, Slides, Excel, and Powerpoint), \\n\\nBA/BS degree in statistics or mathematics., \\n\\nStrong quantitative analysis skills using statistical software such as Python or R., \\n\\nWorking knowledge of Structured Query Language.', 'We work on every high-priority ads project at Twitter., You‚Äôre a data scientist with a track record of delivering results.', 'Orchestrate large PB sized data storage and compute clusters across bare-metal and cloud\\nDeploy and manage infrastructures based on Docker, Kubernetes, or OpenStack, and public Clouds such as Azure, AWS or Google Cloud Platform.', 'Analytical/problem-solving skills.Strong communication and interpersonal skills to communicate effectively with all levels of staff; both verbally and in writing.Strong skills in analyzing and synthesizing large amounts of data for preparing sound and relevant proposals.Ability to multi-task with demanding time-frames.Ability to use discretion and maintain all confidentiality., Bachelors degree in related area and/or equivalent experience/training]\\n\"[Fossil Group is seeking a passionate Data Analyst to join our Omni-Channel Marketing team., \\n\\nThe ideal candidate will demonstrate:, \\n\\n- A strong understanding of the scientific method and its role in developing business insights and decision making process, \\n\\n- An aptitude communicating complex quantitative analysis in a clear, compelling, and actionable manner, \\n\\n- Ability to interpret the results of analyses and communicate findings to internal stakeholders and leadership by utilizing data discovery, visualization, and statistical techniques, \\n\\n- A natural curiosity to solve complex problems and a desire to learn new skills, \\n\\nResponsibilities:, \\n\\n- Work closely with cross-functional team that includes CRM, eComm, marketing, brand teams and IT to improve overall digital investment efficiency through insights and analytics, \\n\\n- Collaborate with Global Partners to accommodate analytical needs, \\n\\n- Define campaign targeting/selection criteria, design A/B test and learn, multivariate testing, and perform related marketing effectiveness and incrementality assessments to inform future decisions, \\n\\n- Define and design analytical methodologies that result in weekly, monthly, and quarterly reporting that offers actionable recommendations based on data, \\n\\n- Conduct ad-hoc analyses that include basic ROI reports and in-depth conversion funnel insights, \\n\\n- Work with manager to identify opportunities to improve campaign analysis and reporting efficiencies, Your Skills, Required Skills and Experience:, \\n\\n- Demonstrated record of 1-3 years in customer data, analytics, and reporting function with emphasis on marketing, business intelligence, and data mining, \\n\\n- Experience with database marketing, CRM platforms, reporting and analysis design, measurement reporting based on relevant business metrics, \\n\\n- Academic degree in quantitative field, Advanced degree is a plus, \\n\\n- Familiarity with web analytics platforms such as Adobe Analytics, Google Analytics, etc., \\n\\n- Experience using SQL to manipulate data, \\n\\n- Experience using Python programming language, \\n\\n- Experience using data visualization tool, Tableau preferred]\"\\n\"[Hub Data Analyst\\n\\n\\n\\nThe Fund for Public Health in New York City, (FPHNYC) is a 501(c)3 non-profit organization that is dedicated to\\n\\nthe advancement of the health and well-being of all New Yorkers.', '\"[Degree in Analytics, IT, Economics or related field (Advanced Technical or Business Degree a plus)\\n\\n5+ years of data management and marketing experience, with 2+ years direct experience with data management in a cloud environment either in an eCommerce environment or for a Database Management/Customer Insights firm\\n\\nStrong data analytics expertise, including experience translating customer KPIs into actionable marketing strategies that drive growth\\n\\nExperience with data analytics tools and technologies across data (Google Analytics, Omniture, SQL, R, SAS, Python), visualization (Tableau, QlikView, or PowerBI))\\n\\nExperience with data warehouses, Big Data and Data Lakes a plus\\n\\nExperience with Lean Startup, Design Thinking, and Agile Methodologies preferred, Collaborate to build an end-to-end, extendable customer data solution from defining requirements to data migration and creation of dashboards, ensuring data integrity, accuracy and compliance.', 'At Google, engineers not only revolutionize search, they routinely work on massive scalability and storage solutions, large-scale applications and entirely new platforms for developers around the world.', 'Gracenote, a Nielsen Company is the leading provider of entertainment metadata and media recognition technology that powers discovery features and discover the music, TV shows, movies and sports they love across the world‚Äôs most popular entertainment platforms and devices, from Amazon, Apple, Facebook, Google, Time Warner Cable, Tesla and others.', 'Depending on your experience - hence level of autonomy - it will be required to work from the head office., OM Partners is a software and consulting company focused on Supply Chain Planning.', 'Deliver data and data analysis on an ad-hoc basis using whatever tools are necessary for the task, \\n\\nMust Haves, \\n\\nExperience with Google Analytics or other Web Analytics tool, and A/B testing concepts Demonstrated capacity to clearly define product and business KPIs in support of company goals and strategies\\n\\nExcellent communication skills\\n\\nDeep understanding and empathy for users\\n\\nWillingness to get your hands dirty conducting data analysis, building dashboards, and supporting internal and external data requests\\n\\nBasic knowledge of SQL: its concepts and basic syntax, \\n\\nNice to Haves, \\n\\nExperience with E-commerce concepts, things like Conversion rate, Customer Acquisition Costs, Attribution, etc.', 'All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status., \\nNearest Major Market: New Jersey\\n\\n\\nJob Segment: Analytics, Database, Engineer, Electrical, Computer Science, Management, Technology, Engineering]\"\\n\"[Working at MIT offers opportunities, an environment, a culture ‚Äì and benefits ‚Äì that just aren‚Äôt found together anywhere else.', 'You have a passion for Data products from cloud providers like Amazon Web Services (AWS), Google Cloud or Azure you might want to leverage to make a difference to our Analytics stack.', ', In this role, you will use your knowledge of data processing, technical systems, and project management to enhance our existing data and machine learning platforms for internal and customer facing use cases., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.', ', Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\\n, Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\\n, Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\\nProficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\\nAbility to digest and explain complex ideas to a diverse group of stakeholders\\nMust be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\\nExperience with digital media measurement and reporting platforms preferred as well as programming languages\\nExperienced in effective dashboard designing with a focus on customizing to client needs\\nAbility to work under pressure and manage multiple priorities\\nStrong communication and presentation skills equally capable of interacting with peers and senior leaders\\nMust be a team player but also have the ability to work independently]\"\\n\"[\\n2+ years of experience with supporting or executing data building, data queries, modeling, or programming of complex analytical methods to support military applications\\n2+ years of experience with analytical technologies used in enterprise reporting, including Tableau, Qlik, Looker, OBIEE, or equivalent\\n1+ years of experience in working with data infrastructure approaches, including open data architectures, Cloud infrastructure, and Infrastructure as a Service, Platform as a Service, or Data as a Service\\n1+ years of experience in working with Microsoft Excel to perform data analysis and data cleansing\\nActive Secret clearance\\nBS degree in Science, Technology, IT, Data Science, Engineering, Command and Control Research, or Mathematics or 6+ years of experience with operational research or assessment\\n, \\nExperience with leveraging varying data methods to inform qualitative and quantitative analyses, including SAS, SPSS, STATA, Python, and R\\nKnowledge of basic concepts in computer science and data science, including machine learning and artificial intelligence a plus\\nTS/SCI clearance\\n]\"\\n\"[Responsible for collaborating with the business analyst to develop business requirements and translating requirements into a technical solution\\n\\nAnalyze and defines tasks, data flows, and dependencies\\n\\nDevelop and maintain advanced reporting, analytics, dashboards and other BI solutions using Tableau and/or Alteryx\\n\\nResponsible for identifying and communicating design and scope issues to the stakeholders\\n\\nConduct design reviews and oversee QA functions for the information delivery applications, including ensuring that system and integration test plans are developed and executed\\n\\nCreate other technical deliverable artifacts needed for project implementation\\n\\nDevelop and delivers knowledge transfer to the client, \\n\\n2+ years of background developing Data Visualization solutions using Tableau, PowerBI and/or Alteryx\\n\\nExcellent client interaction, problem solving & communication skills\\n\\nUnderstanding of data modeling techniques\\n\\nExperience working with relational databases (Oracle, SQL Server, Netezza, Teradata) is required\\n\\nExperience using Tableau, PowerBI and/or Alteryx for the creation of dashboards, standard reports and ad-hoc reports\\n\\nExperience working with multiple disparate data sources in Tableau and/or Alteryx\\n\\nExperience with advanced Tableau, PowerBI and Alteryx topics such as complex calculations, table calculations, parameters, geographic mapping, and performance optimization\\n\\nFamiliar with Data Visualization best practices\\n\\nTravel to the client on a weekly basis is required.', '\"[\\n\\nGather, document, and communicate requirements effectively to ensure appropriate implementation of solutions and processes\\n\\nDevelop effective problem statements and drive to resolution, \\n\\nPerform as-is and to-be analysis, \\n\\nServes as a data steward, ensuring accurate and timely data capture, \\n\\nPlan and manage projects; anticipate and mitigate risk, document decisions, manage change, \\n\\nCompose effective cross-team and inter-departmental communications, \\n\\nEnsure continuous improvement in quality of data and deliverables, \\n\\nCollaborate with cross-functional teams to enable and promote Enterprise adoption of Master Data Platforms, \\n\\n5 years of data analyst experience\\n\\nBachelor of Science degree in STEM (Science, Technology, Engineering or Math)\\n\\nProject Management experience\\n\\nExperience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\\n\\nExperience manipulating and analyzing large datasets, \\n\\nExperience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\\n\\nExperience manipulating and analyzing large datasets, \\n\\nConcentration in Computer Science, Computer Engineering, or related field strongly preferred\\n\\nUnderstands NI\\'s products and how NI engages customers is strongly preferred\\n\\nSelf-Starter, high level of ownership, proactive nature, problem-solving skills\\n\\nKeen eye for detail and precision\\n\\nStrong technical skills, comfortable working with technical teams (Excel, PIM IBM, Datawarehousing, SQL Queries)\\n\\nSolution driven - strong analytical skills to identify, analyze and solve problems given ambiguous information\\n\\nStrong personal organizational and project planning and management skills\\n\\nTeamwork skills essential; sense of humor required\\n\\nExcellent English communication skills - verbal and written]\"\\n\"[Los Alamos Technical Associates, Inc. (LATA) is a premier employee-owned engineering services company with over three decades of success.', 'Experience with BI / Big-data solutions (Hadoop, Google Cloud, Amazon Web Services Microsoft Azure)\\n\\nExperience with Microservice development is a plus\\n\\nCapable of guiding and inspiring team members, peers and stakeholders to drive the best possible practices\\n\\nAbility to think out-of-the-box and give pleasant surprises to end users over the data, Competencies, \\n\\nExcellent thought leadership in bioinformatics technology\\n\\nStrong customer and quality-focus is a must.', 'We are building shared components to unify & advance recommendation systems, e.g., embeddings and approximate nearest neighbor solutions., \\n\\nMLX team has a unique mix of ML engineers & scientists who work together to explore & build new prototypes and scale them to augment Twitter‚Äôs ML capability.', \", As a Project and Data Analyst, you'll deliver innovative solutions that help our entire team keep pace with Google‚Äôs rapidly changing landscape.\", 'Experience using streaming data processing techniques is a plus\\n\\nBachelor\\'s degree from four-year college or university; four years related experience; or equivalent combination of education and experience\\n\\nExperience with Agile]\"\\n\"[At Google, data drives all of our decision-making.', '[Work with resort marketing teams to ensure Google Tag Management is properly applied on their websites and Ecommerce engines ensuring accurate tracking, Help develop and manage acquisition funnels for all resorts ‚Äì on datarama, Work with Marketing teams to take advantage of guest data in our sequel azure database, Once in SQL, develop queries that provide insights to marketing teams as well as responding, Expertise in Google Tag Manager and utilizing tracking toolsExpertise in SQL and ability to write queriesExpertise in Microsoft Office applicationsGood listening and communication skills]\\n\\n\"[Clarivate Analytics clients are the trailblazers and risk takers who come up with life-changing ideas.', '[Bachelor‚Äôs degree in a related field of study3+ years of experience with digital analytics or web analyticsStrong analytic and critical thinking skillsImpeccable attention to detailsProficiency with Google Analytics or OmnitureDemonstrates understanding of digital tracking and tagging QASQL, Python, R, or any coding experience a plusTableau or Microsoft PowerBI experience a plusComfortable and effective working in a dynamic and past-paced environment, with the ability to be flexibleMust have legal right to work in the United States]\\n\"[Piper Companies is currently looking for a Customer Quality Data Analyst in West Chester, PA to work for one of the largest medical device companies globally focused on orthopaedic and neuro products and services., The consultant will be responsible for data ETL, database management and visualization/ analysis of data to support complaint excursion/ signal detection, management reporting (metrics)/ process monitoring, audit requests, and special projects associated with Customer Quality and business data., Responsibilities for the Customer Quality Data Analyst:, Perform data extraction and transformation to deliver operational reporting and predictive outcomes analysis\\nMethodically documents assumptions, methods and results through code commentary and preparation of verification/ validation reports\\nWorks with internal customers to define required data sets/ views, assists in prioritization and planning including appropriate scheduling of tasks, properly contextualizing materials as appropriate (ex.', ', Strong Candidates will also have:, \\nZapier, Slack API, Netsuite ERP/SOAP API, Google API.', 'Highly proficient with Microsoft Excel and Google Apps.', 'You are a strong team player who will interact with a global team, gather business requirements, and bring order to chaos by becoming and expert in the operation‚Äôs nuances, and creating and maintaining state-of-the-art data solutions, on Google dashboards for Tableau.', 'Guide and help other teams in using our ads data, \\n\\nWe are the fastest growing health information site on the planet, and the 2nd largest health site in the US (per comScore)!', 'Extensive experience manipulating and analyzing complex data with SQL, Python and/or R. Knowledge of Google BigQuery and Java/Scala is a plus.', 'Hallmark is a company rooted in connecting people.', 'Experience with at least 2 of the following data ecosystem elements such as Hbase, MongoDB, Cassandra, and/or CouchDB; graph databases such as Neo4j; Hadoop, MapReduce, and/or Spark; AWS, Google Cloud, and/or Azure\\nMinimum of 3 years of fluency in a JVM language such as Java or Scala, or demonstrated mastery of another language\\nExcellent data management and software development practice\\nThe ability and desire to coach and learn from other excellent practitioners\\nExceptional verbal and written communication, interpersonal and problem-solving skills such as required to negotiate scope and resources, manage projects, and synchronize activities with team members, stakeholders, and management, \\nExperience with Platform-as-a-Service software such as Cloud Foundry or Kubernetes; demonstrated experience building cloud native applications\\nKnowledge of data science practices, to better steer our efforts to support them through the infrastructure we create\\nPublic contributions to conference presentations, community forums (e.g.', 'SQL or other querying languages\\n\\nDashboard and visualization software (Tableau, D3, Mixpanel, Flurry, Google Analytics, etc.', 'to ensure data is quickly and reliably available in all contexts\\n\\nPrepare technical documentation to include as-built design, requirements, and Standard Operating Procedures\\n\\nInterface with the broader Forcepoint data science team about analytic opportunities and accomplishments in the field to drive the evolution of the Forcepoint UEBA platform\\n\\nProvide technical briefings to customer leadership and Forcepoint corporate leadership as required\\n\\nCoordinate tasks and activities with various groups within Forcepoint, the government or partners\\n\\n, Required Skills & Experience:\\n\\n, Experience writing modular and reusable code in Python\\n\\nFacility in scripting and troubleshooting application errors in Linux/Unix environments\\n\\nExperience with the ETL: cleaning, transforming, and ingesting large datasets\\n\\nExperience with full Software Development Life Cycle (SLDC) from requirements through to testing and deployment\\n\\nPossess strong analytical, verbal, and technical written communication skills\\n\\nMust be able to coordinate collaboratively across traditional engineering disciplines and effectively engage with customers\\n\\nMust be eligible to work in the US\\n\\n, Desired Skills:\\n\\n, Prior technical experience in finance and/or information security organisations\\n\\nExperience with Apache NiFi and high volume ETL tasks\\n\\nIntegration experience with data stores such as Elasticsearch, PostgreSQL, Splunk, ArcSight, Cloudera, etc.', \"Experience with Google Analytics API and Facebook Business Manager API is a plus., \\n\\nReady to Grow: The BI team is the engine driving Sun Basket's stupendous growth, and you are eager and ready for this job to get bigger over time.\", '[Adept at researching, testing, and analyzing.Review existing analytics to make informed data-driven recommendations for SEO improvements.Collaborate with internal teams to recommend and implement SEO improvements to a wide variety of sites.Keep current with trends and advancements in technology, SEO, UI/UX, Google algorithm updates, etc.Ability to manage several projects simultaneously in a fast-paced environment.Help prioritize projects for maximum impact in as short a time as possible.Assist SEO team with site audits through crawling tools and personal direct assessment to maintain best practices as well as diagnosis potential issues., A strong analytical mind, with demonstrated experience with SEO.A great communicator, boiling complex concepts down into clear, actionable instructions.A true collaborator, working with multiple stakeholders across teams to educate, influence, and execute.Willingness to dive in and research a problem from multiple points-of-view, provide supported conclusions, and lay out a clear go forward game plan.]', 'And that‚Äôs where you come in‚Ä¶, \\n\\nYour background includes:, \\n3+ years of industry data analysis experience, with solid knowledge of statistical methods\\nBachelor‚Äôs Degree, preferably in a STEM discipline\\nExpert SQL skills and experience querying very large data sets\\nProven ability to thrive using multiple mixed, varied, and inconsistent data sources\\nFundamental knowledge of project management methodologies\\nComfort presenting complicated material to diverse audiences\\n, To take things a level up, it would be nice to have:, \\nExperience with Google BigQuery, Tableau, JIRA and/or other project management software\\nExperience working for a social or mobile game developer\\nExperience working in the performance ad space\\nUnderstanding of game design concepts and principles\\nMaster‚Äôs Degree\\n, Joining a team of highly-motivated individuals inquisitive spirits who are always searching for the answers to hard questions.', 'In this role, you will be working across industry sectors such as retail, finance, healthcare and high-tech and you\\'ll get an opportunity to solve some of the most challenging business problems., \\n\\nQualifications:, \\n\\n5+ years of demonstrated data engineering experience\\n\\n3+ years of experience with Big Data Technologies like Hadoop or Hive\\n\\n 2+ years of experience scripting using Perl, Python, Ruby, or other programming languages\\n\\nAdvanced knowledge and expertise with Data modelling skills, Advanced SQL with Oracle, MySQL, and Columnar Databases\\n\\n3+ years‚Äô experience in custom ETL design, implementation and maintenance\\n\\nPreferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure\\n\\nBachelor‚Äôs degree in CS or related discipline preferred]\"\\n\"[(NYSE: WRK) partners with our customers to provide differentiated paper and packaging solutions that help them win in the marketplace.', 'Must be willing and able to pass a counterintelligence (CI) polygraph examination\\n, Python\\nLinux\\nElasticsearch, NoSQL, Hadoop ecosystem, or similar big data technology\\n, Interest In:\\n\\nBuilding data services and APIs\\nLeveraging event-driven architecture concepts\\nScaling systems on AWS\\nPair programming\\nExperience with:\\n\\nWorking on a cross functional team\\nGoogle\\'s Protobuf data format\\nAmazon Web Services - EMR, DynamoDB, SQS, SNS\\nDevOps best practices - Jenkins\\nComfortable with:\\n\\nAgile development\\nHands on system engineering tasks\\nModule development\\n, Building data services and APIs\\nLeveraging event-driven architecture concepts\\nScaling systems on AWS\\nPair programming\\n, Working on a cross functional team\\nGoogle\\'s Protobuf data format\\nAmazon Web Services - EMR, DynamoDB, SQS, SNS\\nDevOps best practices - Jenkins\\n, Agile development\\nHands on system engineering tasks\\nModule development\\n]\"\\n\"[At Capital One, we‚Äôre building a leading information-based technology company.', 'Basic understanding of marketing analytics\\nStrong understanding of relational databases required with strong SQL skills\\nExperience with Google Analytics and BigQuery preferred\\nProficiency in at least one programming language (Matlab, Python, R, Julia, etc.)', 'AWS, Azure, Google Cloud etc.', \"10% travel required., \\n\\nTravel: 10% travel required., \\n\\nInternal use only: reference code lhrs4262, \\n\\nSAP'S DIVERSITY COMMITMENT\\n\\n\\nTo harness the power of innovation, SAP invests in the development of its diverse employees.\", ', Other Credentials Required: Driver\\'s License, Vehicle Liability Insurance]\"\\n\"[Serves as site coordinator for one or more of the following database tools:\\n\\nTruven/IBM-Watson Care Discovery Advantage Solution\\n\\n3M Encompass/360 MD analytics\\nClinovations HCC/HHS Program\\n\\nPEPPERreports\\nExecutive Health Resources Exchange/OptumInsights\\nVizient HIIN\\n\\nEpic electronic health record database\\nCollects and reports data for organizational clinical performance improvement initiatives\\nObtains listing of patients for clinical analysis, reviews charts, and reports data trends and analysis\\nPerforms download of reports and site-specific outcomes\\nCoordinates with other organizational analysts and CPSL Programs Managers to insure consistency between database tools, to the extent that definition and exclusion variations allow\\nPrepares and distributes reports as directed utilizing various software presentation tools\\nEducates physicians and other staff on current and updated database definitions\\nServes as a resource person in the development, maintenance, and troubleshooting of assigned database initiatives\\nPerforms data collection, analysis, and presentation, as directed, on various performance improvement activities within the CPSL\\nPerforms analysis of ‚Äúoutliers‚Äù as directed\\nAttends clinical meetings as directed\\nParticipates in regular phone/webex conferences to keep up-to-date on issues\\nUpdates CPSL dashboard for assigned database functions\\nSupports respective managers for designated program development accreditation responsibilities\\n, Truven/IBM-Watson Care Discovery Advantage Solution\\n\\n3M Encompass/360 MD analytics\\nClinovations HCC/HHS Program\\n\\nPEPPERreports\\nExecutive Health Resources Exchange/OptumInsights\\nVizient HIIN\\n\\nEpic electronic health record database\\n]\"\\n\\n\"[M inimum Requirements:\\n]\"\\n\"[Position Purpose:, \\n\\nThe Data Analyst is responsible for the collection, analysis and reporting of client/customer data using complex analysis of datasets in areas of research, development, product enhancement or other targeted business objectives.', 'While we invest in our live games, we are also proud to be one of the first gaming companies innovating on emerging platforms such as Facebook Messenger and Google Play Instant., \\n\\nCome join us, thrive, take risks and dream big to shape the future of fastest growing gaming platform ‚Äì mobile., \\n\\nThe Role, \\n\\nThe Central Technology team at Zynga provides products and services that are foundational for building games across mobile and emerging platforms.', 'Must like to laugh.Exceptional skills with: Word, Excel, PowerPoint, and other analytics tools as well as, Tableau, SQL, Slack, Zoom, Box and Architect., Develop, manage and create content for the Analyst Relations department.The content you generate educates IBM executives, the most influential technical analysts, hybrid analysts, bloggers, marketers, etc., who work with existing or prospective IBM customers, key global media and financial markets.Work closely with and for Vice President, department colleagues and BU‚Äôs to influence strategy while improving analyst/influencer perceptions and relationships.Collaborate with colleagues in Analyst Relations, Marketing, Sales, Product Management, Communications, Finance and BU leadership to ensure that IBM is receiving the best representation with the analyst/influencer community.Develop and broaden Analyst Relations key performance metrics to elevate efforts to key BU leadership and stakeholders.Analyze analyst inputs, such as social media, blogs, reports, and other forms of influence.', 'The role serves as a key Marketing Analytics team member in measuring performance of marketing initiatives and making proactive recommendations that deliver the key performance goals of the agency‚Äôs clientele., Create custom reports and dashboards, audit performance on an on-going basis, and build automated reports where relevant\\n\\nBuild and distribute repeatable reports and performance metrics/insights on client marketing campaigns\\n\\nCollect, maintain, manage, interpret and analyze data received from internal and external data sources\\n\\nProficient with Excel when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\\n\\nExperience with data visualization and analytic dashboard development in Tableau\\n\\nReport requirements collection/analysis, writing SQL, extracting structured data sets, building reports\\n\\nPerform ad hoc analysis and data investigation/ discovery to identify and/or explain business and marketing trends or anomalies\\n\\nAnalyze marketing channel and website performance data for assigned projects and develop recommendations on ways to further optimize for performance\\n\\nWork cross-functionally to help inform the agency and clients on key learnings from data analysis, Able to perform in a highly analytical role delivering actionable marketing campaign insights\\n\\nAbility to deep dive into performance data on a daily basis, drawing conclusions and making optimization recommendations\\n\\nHighly analytical, focused on informing performance optimization based on gathering and examining data from multiple sources\\n\\nExcel guru when it comes to creating charts, pivot tables, and presentations on multi-channel campaign performance\\n\\nDeep knowledge of web analytics tools (Adobe Analytics, Google Analytics, Optimizely, etc.)', '(Google Data Studio, Birst, and other tooling)Data analyst with the innate curiosity to uncover interesting/differentiating insights for a projectExcellent communication skillsExcellent attention to detailAbility to manage multiple projects concurrently and prioritize workload to meet deadlinesExperience with/understanding of the requirements for designing enterprise software/mobile applications, Data visualization and storytelling (i.e., Nate Silver, Zach Lowe, Hans Rosling or Kirk Goldsberry)Ability to execute on mixed method projects combining quant and qualThe North Star: Scale our data practice as an independent service to Infor, backed by the power of designExperience running regressions, or using Python to mung, transform and analyze dataSelf-motivated and monitoringEager to contribute, 2-3+ years of related job experience, General office environmentNo special physical demandsSome stress may occur at timesAbility to work across multiple time zones (requires some meetings before/after regular business hours to accommodate), \\n\\nHook & Loop designs and builds products that scale user experience into the enterprise.', 'Familiarity with cloud infrastructure such as Amazon AWS, Google Cloud Platform, Microsoft Azure (AWS preferred)\\n\\nExperience designing and building APIs, especially using Swagger (Open API)\\n\\nBS in Computer Science or equivalent technical domain\\n\\n4+ years experience in software development or IT organizations\\n\\n, Working with wicked smart, super cool people in a campus-like atmosphere\\n\\nWorking on leading edge technologies in cloud micro-services, big data, and IoT\\n\\nCompetitive salary, benefits, and retirement plan\\n\\nEasy commute right off Mass Pike\\n\\nA culture of excellence, respect, opportunity and passion for innovation\\n\\n]\"\\n\"[Design, implement and deploy custom applications using real-time data streams and/or big data platforms\\n\\nCollect, create, and structure data sets from disparate sources to be able to leverage them for machine learning applications\\n\\nBuild data pipelines to ingest, transform, and analyze data in artificial intelligence and analytics systems\\n\\nDesign data architectures that address specific client needs, using combinations of relational databases, No-SQL databases, and unstructured file stores in both cloud and on-premise settings\\n\\nDevelop solutions and iterate rapidly\\n\\nEnsure code and design quality through the execution of test plans and assist in development of standards, methodology and repeatable processes, working closely with internal and external design, business, and technical counterparts., Minimum 2 years of hands-on technical experience implementing or supporting big data or real-time analytics solutions\\n\\nHigh level of competence in SQL, Python and/or scripting languagesBachelor‚Äôs Degree or Associate‚Äôs Degree with 6 years of work experience or equivalent work experience of 12 years, Ability to travel about 10% of the time, Experience with delivering Big Data Solutions in the cloud with AWS, Azure or Google CloudAbility to configure and support API and OpenSource integrationsExperience administering Hadoop or other Data Science and Analytics platforms using the technologies aboveExperience working with DevOpsDesigning ingestion, low latency, visualization clusters to sustain data loads, Experience developing solutions utilizing any of the following:]\"\\n[Job Summary, Join Accenture Digital and leave your digital mark on the world, enhancing millions of lives through digital transformation.', 'Use tools such as Google Sheet, Tableau and many internal tools to work efficiently at scal, \\n\\nBS/MS in Engineering, Computer Science, Math, Economics, Statistics, or equivalent experience.', 'Citizenship\\nTS/SCI clearance with CI polygraph\\nBachelor‚Äôs degree in math, statistics, or computer science\\nMust have a minimum of 5 years‚Äô experience with large-scale data manipulation, analytic tools, and data visualization\\nDemonstrated expertise in constructing and performing complex database search queries of various databases\\nAbility to simultaneously understand computer science concepts, data context, and mission objectives while completing projects\\nExperience producing both tactical and strategic analytic products and briefing senior level managers\\nExcellent critical thinking, communication, and collaboration skills, including the ability to communicate technical findings to non-technical audiences\\nExpertise in statistical packages such as SPSS, SAS, or R\\n, Experience with all-source analysis in the U.S. Intelligence Community\\nProgramming experience in Python or Perl\\nBackground in statistics]\"\\n\"[Data Scientist - Defense & Intelligence, \\n\\nElder Research Inc. is a recognized leader in predictive analytics and data science.', 'with Flask\\n\\nExperience in test automation and ensuring data quality across multiple datasets used for analytical purposes\\n\\nExperience with Lambda Architecture or other Big Data architectural best practices\\n\\nA graduate degree in Computer Science or similar discipline\\n\\nCommit code to open source projects\\n\\nExperience with test automation and continuous delivery, \\n\\nExperience with Tableau\\n\\nExperience with Machine Learning\\n\\nHave worked with Data Scientists]\"\\n\"[\\n3 years of experience with Big Data, systems, including Hadoop, Hive and Pig\\nExperience with ETL tools including NiFi and StreamSets\\nExperience with Java\\nExperience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services\\nSecret clearance\\nBA or BS degree\\n, \\nExperience with Agile software development\\nPossession of excellent oral and written communication skills\\nBS degree in CS, Computer Information Systems, Information Systems, or a related field\\n]\"\\n\"[Born and built 100% in the cloud, Zscaler operates a massive, global cloud security architecture, delivering the entire gateway security stack as a service.', '2+ years of experience in data ingestion and storage systems for big data environment using at least one of the COTS integration tools, like - Snap Logic, webMethods, TIBCO, Talend, Informatica, and/or custom scripting in Python/Java\\n2+ years of MUST have experience in using Apache Beam / Google Dataflow / Apache Spark in creating end-to-end data pipelines\\n2+ years of data engineering experience with big data environments and writing map-reduce jobs using Java/ Scala or Python.', \"We continue to be on a tear while enjoying incredible growth year over year., \\n\\nAs a Senior Business Data Analyst at Splunk, you will help drive projects by enabling data and analytics to improve the company's Enterprise Data processes and the applications it builds and uses.\", 'As a key member of the team, you work with engineers to analyze and interpret data, develop metrics to measure results and integrate new methodologies into existing systems., Google is and always will be an engineering company.', 'Associate level3+ year(s) of managing parts of the client engagement, including: leading conversations to understand business context, building relationships with the client, identifying key business issues, structuring analysis, and managing the development and delivery of recommendations3+ year(s) of people management experienceExperience participating in the firm\\'s recruiting activities, \\n\\nSkill Set, \\n\\nRequired, Ability to structure analysis to solve complex business problemsAbility to package findings/recommendations from analysis in a coherent, impactful wayStrong presentation and communications skillsProficiency in analysis and business modeling using ExcelBasic understanding of statistics and A/B testing, \\n\\nNot required but nice to have, Experience working on engagements focused on online businessesExperience working on engagements focused on subscription businessesBasic to mid-level proficiency in data extraction using SQLWeb analytics tools like Google Analytics, OmniturePredictive modeling, regression analysis using R or Python]\"\\n\"[Bachelor‚Äôs degree\\n\\nMinimum of 5 years of relevant Natural Resources industry experience\\n\\nMinimum of 5 years working in advanced analytics and business transformation\\n\\nMinimum of 5 years in strategy or management consulting\\n\\nMeet travel requirements, up to 80%, \\nBachelor‚Äôs degree in quantitative discipline (Engineering, Economics, Statistics, Operations Research, Computer Science)\\n\\nMasters or MBA\\n\\nPhD in Analytics, Statistic or other quantitative disciplines\\n\\nExceptional presentation skills ‚Äì ability to convey technology and business value propositions\\n\\nAbility to understand and apply statistical methods and outputs to create client value in a business context\\n\\nExperience with evolving approaches and technologies such as Big Data, Artificial Intelligence, Machine Learning, Cognitive Systems, and Robotics\\n\\nData management skills\\n\\nData visualization skills\\n\\nValue based constructs, Proven ability to build, manage and foster a team-oriented environment\\n\\nProven ability to work creatively and analytically in a problem-solving environment\\n\\nDesire to work in an information systems environment\\n\\nExcellent communication (written and oral) and interpersonal skills\\n\\nExcellent leadership and management skills, \\nYour entrepreneurial spirit and vision will be rewarded, and your success will fuel opportunities for career advancement.', 'This role is key to activating our innovative solutions and the role requires an individual who can work with other analysts and business users to create solutions which integrate with our marketing technology stack., \\n\\nIn this role, the Marketing Data Engineer will:, \\n\\nIntegrate data from various third-party and first-party data sources, including but not limited to Google Analytics 360, YouTube, LinkedIn, Facebook, Twitter, SFDC and Hubspot\\nCollaborate with our team of in-house RPA engineers to automate API integrations and tedious process around marketing data collectionResponsible for all extract, transform and load (ETL) processes and the creation of applications that can connect to remote APIs.', 'Experience working with cloud platforms such as AWS, and Google Cloud Platform and distributed computing technologies such as Apache Spark.]\"', 'If you said yes, we‚Äôd love to talk to you about joining our award-winning team., \\n\\nLearn more at zscaler.com or follow us on Twitter @zscaler.', 'Differentiate the offering and the people working on it through the depth and breadth of expert skills\\n\\nManage and coordinate teams to deploy data analytics projects using innovative solutions and to provide analytics-driven insights\\n\\nEducate and coach both clients and team members on machine learning knowledge, practical mathematical modeling, simulation and optimization in multiple analytics platform\\n\\n, \\n\\nLeverage IBM offerings, assets, and capabilities to create and deliver differentiated service offerings to our clients.', \"As a Data Analyst with Geo Operations, you design and implement methodologies, dashboards and presentations, all while partnering with stakeholders across multiple functions and locations., Google's Consumer Hardware is looking for a Data Analyst to join its rapidly growing Reverse Logistics team.\", 'Develop visualization based on user needs on Google dashboards or Tableau.', 'Data Analytics packages such as Pandas, Scikit-learn, Numpy or R.\\n\\nCloud Technology Stacks from providers such as AWS and Google Cloud.', 'iO is an innovation lab within Ochsner Health System, Louisiana‚Äôs largest not-for-profit health system.', \"Publish research in refereed scientific and technical journals\\n\\nProvide publicly available software for use by the scientific community\\n\\nSupport the public use of available software\\n\\nAssist in the organization of computational astrophysics workshops and conferences\\n\\nAssist in the organization of weekly group seminars\\n\\nPresent papers at scientific conferences\\n\\nSupervise research conducted by Flatiron research fellows and graduate and undergraduate students from neighboring institutions\\n\\nMentor summer students and assist in the organization of summer programs\\n\\nPerform any other duties or tasks as assigned or required\\n\\n, MINIMUM QUALIFICATIONS\\n\\n, Education\\n\\n, Ph.D. in a related field\\n\\n, Experience\\n\\n, 4 - 10 years of graduate and postgraduate research experience in computer science, machine learning and statistics\\n\\nA record of excellence in scientific publication\\n\\n, Required Application Materials\\n\\n, CV\\n\\nResearch statement outlining both past research accomplishments and a vision for scientific research at the Flatiron Institute\\n\\nThree (3) letters of recommendation submitted confidentially by the letter writers to astro@simonsfoundation.org\\n\\n, Deadline\\n\\n, All applications must be submitted no later than November 15, 2017.\\n\\n, THE SIMONS FOUNDATION'S DIVERSITY COMMITMENT\\n\\n, Many of the greatest ideas and discoveries come from a diverse mix of minds, backgrounds and experiences, and we are committed to cultivating an inclusive work environment.\", 'Coding experience in Python is added bonus.Tagging/labeling/parsing/indexing unstructured text data.Processing text data indexed for Bibliometric Analysis Tool (BAT)Supervised and unsupervised clustering of text data; experience with Natural Language Processing, Coding experience in R is required; Coding experience in Python is added bonus.Graph Theory / Image Processing / Neural Networks, Experience with Big Data (parallel processing power and options for handling analysis of)Ability to understand retrieval processes in Microsoft SQL or experience working in SQL]\\n\"[\\nExperience in building machine learning infrastructure on AWS, Google Cloud, or Azure.', 'Follow Baker Hughes, a GE company on Twitter @BHGECo, or visit us at BHGE.com.', '\"[Splunk‚Äôs Guild of Data Science has been tasked with helping Splunk build smarter software and make data-driven decisions.', \"The team partners with Publishers and App Developers of all sizes to promote their ad inventory, working with Google's broad range of partner solutions including AdSense, AdMob and Google Ad Manager, across mobile, display, and video formats, helping our partners and their audiences get the most out of the web.\", 'Learn more at sensus.com and follow @SensusGlobal on Facebook, LinkedIn and Twitter., \\n\\nThe Role: Sensus, a Xylem brand seeks to hire a Data Scientist with a desire to join a team delivering Big Data applications in the Cloud.', 'Learn more about Diversity and Inclusion at Dell here.]\"', 'Above all, your work will impact the way the world experiences art., Build large-scale batch and real-time data pipelines with data processing frameworks like Scio, Storm or Spark and the Google Cloud Platform.', 'Python or shell scripting)\\n\\nPreferred experience working with either a Map Reduce or an MPP system\\n\\nPreferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure\\n\\nExperience to analyze data to identify deliverables, gaps, and inconsistencies]\"\\n\"[\\nDeliver end-to-end analytics projects, including data ingest, data transformation, data science, and data visualization\\nDesign and deploy databases and data pipelines to support analytics projects\\nClearly document datasets, solutions, findings and recommendations to be shared internally & externally\\nLearn and apply tools and technologies proficiently, including:\\nLanguages: SQL (standard and DB-specific), Python, R, Spark/Scala, Bash\\nFrameworks: Hadoop, Spark, AWS\\nTools/Products: Data Science Studio, Alteryx, Jupyter, RStudio, Tableau, PowerBI\\nBuild compelling visualizations and dashboards that address the analytic needs of the end-user/customer\\nPerformance optimization for queries and dashboards\\nDevelop and deliver clear, compelling briefings to internal and external stakeholders on findings, recommendations, and solutions\\nAnalyze client data & systems to determine whether requirements can be met\\nTest and validate data pipelines, transformations, datasets, reports, and dashboards built by team\\nDevelop and communicate solutions architectures and present solutions to both business and technical stakeholders\\nProvide end user support to other data engineers and analysts\\n, \\nExpertise in SQL and Python.', 'Significant scientific background with prior experience in clinical research\\nPhD in relevant domain highly preferred (Data Science, Machine Learning ideally applied to health-related insight generation)\\nAbility to derive robust insights from complex RWD datasets\\nMust have experience in performing data analysis utilizing statistical frameworks (R, SciPy) and ideally experienced already in using environments such as Jupyter Notebooks/Google Datalab\\nSome data engineering experience (ETL, SQL) desirable\\nMust be comfortable working in rapid prototyping environment, using agile approaches to guiding teams and projects\\nSome understanding of drug development process and use of biomedical data for drug development and clinical trials design preferred\\nStrong communication skills; ability to guide small projects, interacting with clients and internal management.', 'We are building a team to develop the technical framework to drive performance and success at Hallmark., IN THIS ROLE YOU WILL:, Automate analytics and data science solutions\\nDevelop robust data pipelines while ensuring data integrity\\nConnect staff to big data from various internal and external sources\\nCreate technical solutions to simplify the processes at Hallmark Greetings\\nHave a proven track record in big data and cloud environments\\n, APPLICATION INSTRUCTIONS:, You must show how you meet the basic qualifications (listed below) in a resume or document you upload, or by completing the work experience and education application fields.', 'Check out the Times Open blog , which is written by engineers and other technical team members, and follow @nytdevs on Twitter to see what we‚Äôre up to.', 'Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\\n\\nExposure to Google Machine Learning is a plus, \\n\\nWe are an Equal Opportunity Employer M/F/Disability/Vet and maintain a drug-free and smoke-free workplace.]\"', 'You will be a trusted partner in the team tackling the toughest and most impactful analytical problems while making the data accessible to the broader organization., \\n\\nResponsibilities include:\\n\\nIdentify key questions, problems, and KPIs using your sharp business acumen and judgment, \\n\\nConduct quantitative research and analysis requiring complex data retrieval that results in actionable insights and recommendations, \\n\\nDesign and analyze rigorous a/b experiments, \\n\\nAnalyze and share the results of product features and find opportunities to improve them, \\n\\nWork daily with product managers, engineers, and designers to discover and guide the most impactful product investments, \\n\\nProvide access to data through dashboards to empower your team, and look for opportunity to automate insights through alerting and anomaly detection, \\n\\nQualifications:\\n\\nPassion for, and track record of leveraging data for business impact, preferably in a consumer facing digital environment, \\n\\nAbility to write complex and performant queries in your dialect of SQL to extract data from our Redshift cluster, \\n\\nExperience building tools and automated processes to extract, clean, and distill data in a procedural language of your choice such as Python, Julia or R, \\n\\nUnderstanding of A/B testing and other forms of statistical analysis using statistical packages similar to R, SAS, or Pandas, \\n\\nExcellent communication skills with the ability to distill complex problems into digestible insights, \\n\\nEffective data visualization skills with analytical tools such as Tableau, Looker, D3.js or other tools, \\n\\nGrowth mindset; the ability to thrive in a dynamic and collaborative environment]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \\n\\nAs a Solutions Architect with a core focus on Machine Learning (ML), you\\'ll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.', 'You\\'ll be a trusted partner in the team tackling the toughest and most impactful analytical problems., Responsibilities, Quantitative research and data analysis of partnerships, Complex data retrieval using SQL, Actionable insights and recommendations on relationships with existing partners and acquisition of new partners\\n\\n\\nAnalyze and present results of partner campaigns and make improvements, Build effective and scalable data models, Build and maintain production data within a data warehouse, Work with product managers, data and machine learning engineers to discover and guide the most impactful product investments, Design and analyze rigorous A/B experiments, Build dashboards and other analytical tools, Automate insights alerting anomaly detection, Requirements, Data leveraging for impact, preferably in customer facing retail or CPG space, SQL, and Python or R or SAS or Pandas, A/B testing, statistical analysis, Tableau, Looker, D3.js or similar tools, Data modeling, ETL and data pipeline development, Advanced degree in statistics or other quantitative field]\"\\n[Responsibilities and Capabilities:, Coordinate the communication between the data science team and the development teams., Analyze data and study the system to provide meaningful insights on the product performance and the ways to improve it., Build predictive models to improve the advertising campaigns performances., Cross-collaborate with engineers on building statistical models, applying machine learning techniques for targeted solutions and effectively communicating the analysis and findings through interactive visualizations, documents and presentations., Cross-collaborate with the account management and sales teams to conduct dedicated studies for some of our big customers or demonstrate in client meetings, Some of the capabilities should include:, Strong interpersonal, oral and written communication and presentation skills, ability to communicate complex findings in a simple manner., Ability to communicate with Developers or Data-Analysts to describe complex algorithms in a simple manner., Enjoy discovering and solving problems; proactively seeking clarification of requirements and direction; being a self-starter who takes responsibility when required., Ability to explore different directions based on data and be able to quickly change direction based on the analysis., Minimum requirements:, 2+ years of work experience in a Data-Science team., Proven ability and experience in using data science, statistical computing, and modeling to improve business KPIs., Experience with statistical, predictive modeling, machine learning with big-data using tools like R, Hadoop, Spark, Strong mathematical skills., Solid communication skills,  Preferred Qualifications:, MS/ PhD in fields like computer science, mathematics, statistics, machine learning, operations research, data mining, AI., Understanding of public cloud design patterns and considerations in the areas of distributed systems, distributed storage systems, big-data, data mining, cluster computing., Basic understanding of the distributed concepts behind Hadoop and Spark Data-Analysis frameworks., Strong ability to learn new concepts quickly., PostgreSQL, Hadoop, Cassandra, Aerospike, Redis, LevelDB, Golang; Java; JavaScript; Python; C; C#, AWS; Google Cloud; OpenStack, NSQ, Kafka, Flume, GCP Pub/Sub, Consistently trying out new possibilities]\\n\"[Principal Data Scientist, \\n\\nSouth Bay, \\n\\nHarnham are currently partnering with a well funded Series A start up based in the South Bay in their search for a Principal Data Scientist, \\n\\nWith a high degree of flexibility and ownership, you will be working with a high performing, mission driven team, that is disrupting the way we understand, diagnose and treat numerous illnesses.', 'Programming / Scripting (Python, Java, C/C++, Scala, Bash, Korn Shell)\\n\\nLinux / Windows (Command line)\\n\\nBig Data (Hadoop, Flume, HBase, Hive, Map-Reduce, Oozie, Sqoop, Spark)\\n\\nCloud Platforms (AWS, Azure, Google Cloud Platform)\\n\\nData Concepts (ETL, near-/real-time streaming, data structures, metadata and workflow management)\\n\\nData Integration Tools (Ab Initio, DataStage, Informatica, SSIS, Talend)\\n\\nDatabases (DB2, HANA, Netezza, Oracle, Redshift, Teradata, Vertica)\\n\\nMarkup Languages (JSON, XML, YAML)\\n\\nCode Management Tools (Git/GitHub, SVN, TFS)\\n\\nDevOps Tools (Chef, Docker, Puppet, Bamboo, Jenkins)\\n\\nTesting / Data Quality (TDD, unit, regression, automation)\\n\\nSolving complex data and technology problems\\n\\nLeading technical teams of 2+ consultants\\n\\nAbility to design components of a larger implementation\\n\\nExcellent communication to narrate data driven insights and technical approach\\n]\"\\n\"[Senior Data Engineer- E-commerce Start-Up, \\n\\nSan Francisco, Bay Area, \\n\\n$1650,000-$185,000 (cap varies by expertise) + equity, \\n\\nWill support Visa transfer, \\n\\nHarnham has partnered with a dominant San Francisco based start-up that has been taking over a trillion dollar U.S. market by storm.', '\"[What You‚Äôll Do:, You will work with our team of experts in machine learning and software engineering to build powerful and scalable models and surface the most relevant content on Twitter.', 'You will work in a team environment alongside a group of expert mathematicians, statisticians and data scientists., The perfect candidate‚Ä¶:, is an analytic leader who can mentor and teach to help enhance, build, and grow Hallmark‚Äôs analytic capabilities.', \"You believe that great just isn't good enough, and constantly seek out opportunities to improve Google‚Äôs security services, by leveraging data.\", 'Your passion for technology, learning, and solving problems, along with your enthusiasm for working with customers will empower a diverse audience of decision makers to embrace the Google Cloud to build what‚Äôs next for their businesses., \\n\\nAs a member of this dynamic, exciting team, you will use your expertise in cloud technology to communicate directly with businesses of all types to help them seamlessly adopt Google products and solutions wherever they are on their cloud journey.', 'The team‚Äôs most important roles are to enable fast, rigorous product experimentation and to provide automated tools to generate insights and understanding of our users., \\n\\nResponsible for experimentation (A/B testing) methodology and implementation\\n\\nUnderstanding user behavior with great visualization and analysis tools, \\n, Twitter has a very data-driven culture and experimentation is at the center of product decisions.', 'Other duties as assigned., Minimum Qualifications:\\n\\n, Master\\'s degree in Analytics, Mathematics, Physics, Computer and Information Science, or Engineering\\n\\n5 - 10 years in Data Analytics\\n\\n5 - 7 years utilizing Statistical Software\\n\\n5 - 7 years in Large Datasets\\n\\n5 - 7 years in Data Visualization\\n\\n3 - 5 years in Predictive Modeling\\n\\n1 - 3 years in a Business Analyst role\\n\\n1 - 3 years in Consulting\\n\\n1 - 3 years in Research and Development, Preferred Qualifications:\\n\\n, Doctorate degree in Analytics, Mathematics, Physics, Computer and Information Science, or Engineering\\n\\n3 - 5 years in the Healthcare Industry\\n\\n3-5 years of experience leading Human Subjects Research projects\\n\\nMultiple peer-reviewed publications in high impact factor journals, Knowledge, Skills & Abilities:, \\n\\nAnalysis of business problems/needs\\n\\nAnalytical and Logical Reasoning/Thinking\\n\\nCollaborative Problem Solving\\n\\nStatistical Analysis\\n\\nWritten & Oral Presentation Skills\\n\\nSAS, R, Python, SPSS or related, Referral Bonus Level: 3]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: Seattle, WA, USA; New York, NY, USA; Mountain View, CA, USA; Pittsburgh, PA, USA, \\n\\nResearch in machine intelligence has already impacted user-facing services across Google including Search, Maps and Google Now.', 'Experience with cloud platforms such as Amazon Web Services (AWS) and/or Google Cloud Platform (GCP)\\n\\nExperience with power engineering and power-related data.', 'Work with cross-functional partners across the business\\n\\n, QUALIFICATIONS\\n\\n, Advanced degree in Computer Science, Statistics, Mathematics, Economics, or related field\\n\\n3+ years of work experience in data science and/or predictive analytics functions in business environment (preferably internal or external consulting)\\n\\nProgramming experience in one or more of Python and R, or other open-source programming languages\\n\\nExperience with big data technology (such as Hadoop, Hive, Data Lake), either cloud or on-premise platforms\\n\\nKnowledge of statistics and experience using statistical packages for analyzing datasets\\n\\nStrong analytical skills with the ability to collect, organize, analyze, and disseminate significant amounts of information with attention to detail and accuracy\\n\\nAbility to write queries, generate reports, and present findings\\n\\nStrong communication and facilitation skills\\n\\nExcellent planning and organizing skills\\n\\nStrong ability to continuously learn and upgrade technical skills\\n\\n, EOE/Disabled/Veterans]\"\\n\"[Key Responsibilities:\\n\\n, Drive end to end analytical process: from formulation of requirements, data acquisition, identification of analytical methods, creation/validation of models to business-friendly summarization of results\\n\\nInteract with stakeholders to identify critical questions that need to be answered in order for the Analytics team to provide effective KPIs - actionable insights rather than just reports\\n\\nConduct analysis and data modeling to draw insights that drive critical decision making and to uncover social media patterns, fan engagement, behavior and feedback\\n\\nAnalyze data to identify outliers, missing, incomplete, and/or invalid data\\n\\nCreate models, KPIs, and dashboards to operationalize outcomes of analytics\\n\\nCreate, automate, and maintain reports and visualizations (e.g., social media mentions, competitive engagement, talent impact mapping)\\n\\nWork in complex data environment comprising several heterogeneous internal and third party data sources, manipulate large data sets and navigate a variety of servers, data types, and data structures to complete statistical and other analyses\\n\\nDesign and build dashboards and automated reports with embedded visualizations\\n\\n, Qualifications:\\n\\n, Proven track record of identifying and highlighting key insights, signals, and trends deep within data\\n\\nWell-rounded individual with the ability to write code to query and transform both unstructured and structured data\\n\\nOpenness to an environment of active developmental feedback and coaching from peers and managers, with desire to learn and grow rapidly\\n\\nExperience publishing reports using visualization and presentation tools\\n\\nStrong planning and organizational skills\\n\\nShould enjoy generating actionable insights by mining data and be passionate about answering challenging questions and telling stories with data and visualizations\\n\\nSelf-motivated, attentive to detail, and driven to continuously improve analytics skill set\\n\\nBachelor‚Äôs degree in Statistics/Mathematics, Econometrics/Economics, Engineering/Computer Science, Business/Finance, or related quantitative field\\n\\nWorking knowledge of at least two technologies: SQL, SAS, Python, Big Query, Google Analytics, Excel, and Tableau\\n\\nSPSS and/or R\\n\\nKnowledge of social media platforms including but not limited to Facebook, Twitter, Instagram, Snapchat, YouTube\\n\\n, _]\"\\n\"[Position Description, Work closely with merchants to define objectives and design appropriate analytics solutionsApply your expertise in quantitative analysis, data mining, and the presentation of data to see beyond the numbers and understand consumersDevelop analytical models to drive analytics insightsLead small and participate in large data analytics project teamsParticipate in the continuous improvement of data science and analyticsPresent data insights and recommendations to key stakeholdersProvide and support the implementation of business solutionsModel compliance with company policies and support company mission, values, and standards of ethics and integrity, \\n\\nMinimum Qualifications, \\n\\nBachelor of Science and 5 years data science experience OR Master of Science and 3 years data science experience., \\n\\nAdditional Preferred Qualifications, 5 years‚Äô experience in predictive modeling and large data analysis5 years‚Äô experience with statistical programming languages (for example, R, SAS)5 years‚Äô experience with SQL and relational databases (for example, DB2, Oracle, SQL Server)Expert in any scripting language (Python, PHP, Perl, etc.', 'For more information visit our website and follow GoodData on Twitter and LinkedIn., \\n\\n\\nJOB DESCRIPTION, \\n\\nAs a key member of our Consulting team within Professional Services, The Solutions Engineer will be the data engineer that helps guide our customers through their data product implementation.', '\"[Science and Technology on a Mission!, \\n\\nFor more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., We are looking for a Postdoctoral Researcher to perform research in the area of data analysis and machine learning with a goal to develop new techniques, analyze and steer multi-scale simulations in a large-scale parallel workflow.', 'Web analytics ‚Äì working knowledge of SiteCatalyst or Google Analytics\\n\\nModeling ‚Äì machine learning technique is a plus (i.e., Na√Øve Bayes, Random Forests, Deep Learning, Ensemble).', 'You have interacted with clickstream data (e.g., command of Google Analytics) and raw data ingested from paid marketing channels (e.g., Adwords, Facebook) and have derived insights from those data sources to positively-influence the business.', ')Working knowledge of cluster computing environments including Hadoop, Spark and HiveExperience with data visualization tools and techniquesWorking knowledge of multiple analytics and programming languages such as R, Python, SAS, Julia, Java, Scala or similarUnderstanding of relational databases and SQL, Desired Characteristics, Experience with multi-billion record datasets and leading projects that span the disciplines of data science and data engineeringExperience with television ratings and digital measurement tools (Nielsen, Rentrak, comScore, Omniture, etc.', ', Job Summary:\\n\\n, As a Data Scientist, you will:\\n\\n, Use emerging tools and technology to develop analytical models and automation in music planning, music research, and other areas of the company\\n\\nCommunicate complex solutions to a variety of stakeholders in easily understandable language\\n\\nBe a contributing member of a scrum team that voluntarily accepts work\\n\\nWrite code that meets standards and delivers desired functionality using agreed upon technology\\n\\nDemonstrate passion about using data assets to optimize systems and products across iHeartMedia\\n\\nUse and extend open source software to deliver solutions to iHeartMedia business partners Present solutions and ideas to other team members, IT leadership, and business leaders\\n\\nEmploy a pragmatic approach to evaluate new algorithms and technologies for positive impact within iHeartMedia\\n\\n, Requirements:\\n\\n, 5+ years of commercial experience in data science\\n\\nA demonstrable understanding of machine learning theory\\n\\nExtensive experience with Python and/or R\\n\\nDemonstrated experience with SQL\\n\\nExceptional communication and presentation skills are a requirement\\n\\nProgramming experience in JavaScript or Java for use in reading existing code or building prototypes (you do not have to have experience building production applications)\\n\\nMS in Applied Mathematics, Statistics, or Computer Science - PhD desired\\n\\n, Bonus:\\n\\n, Data Engineering/Data Wrangling\\n\\nExperience with Tensorflow, BigQuery, Tableau\\n\\nExperience with Google Cloud Platform or Amazon Web Services\\n\\n, Location\\n\\n, Position Type\\n\\n, The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.', 'DOD Secret Clearance preferred]\"\\n\"[\\nCB\\n]\"\\n\"[Science and Technology on a Mission!, \\n\\nFor more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., We have multiple openings for Postdoctoral Research Staff Members to engage in the research, design, and deployment of machine learning and statistical methods to solve important data and science problems stemming from the Laboratory\\'s mission spaces.', 'Experience managing various tagging and tracking platforms such as Adobe Marketing Cloud (Omniture), Tealium, Google Analytics, etc.', 'Experience with Google and Adobe analytics.', 'All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.', 'Experience in Google Cloud Services strongly preferred.', 'Includes agency management, budget allocation, SME curation, publishing assets into the campaign and the appropriate IBM tracking systems.', '\"[\\n\\nUnderstand the ad ecosystem including how an ad gets monetized\\n\\nFamiliar with DFP, Google Analytics\\n\\nFamiliar with spreadsheet tools such as Excel, Google Sheets\\n\\nFamiliar with data visualization tools such as Tableau, Data Studio\\n\\nAble to write code in SQL\\n\\nCurious and numerical minded\\n\\nAbility to work cross-functionally with different teams with varying technical levels\\n\\nGreat interpersonal skills\\n\\nBachelor‚Äôs Degree, \\n\\n2 years of working experience in an analyst/quantitative role\\n\\nExperience with pulling reports and data out of DFP\\n\\nFamiliarity with Salesforce\\n\\nExperience in BigQuery\\n\\nAttention to details\\n\\nExperience writing automation code in Python/R/AppScripts etc., \\n\\nCreate a robust system of revenue reporting\\n\\nBe an expert on all things ads-related: how are we monetizing our inventory?', 'Manage multiple tasks/projects and deadlines simultaneously to meet internal and client data needs\\n, QUALIFICATIONS, Bachelor‚Äôs degree required\\nAdvanced knowledge of reading and writing SQL queries\\nTableau, Excel and PowerPoint experience and strong presentation skills required\\nKnowledge of Hub Spot, CRM integration, Survey Monkey and Google Analytics\\nExcellent communication, facilitation, and interpersonal relations skills required\\n, Experience with project management tools and methodologies required.]\"', 'Build algorithms, tools, custom solutions, and new technologies from diverse and large-scale data sets to enhance comScore‚Äôs measurement products, or contribute to new products.', 'Connect with us on Twitter, Facebook, Instagram and LinkedIn or watch a video., Allstate generally does not sponsor individuals for employment-based visas for this position., \\n\\nEffective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.', 'Expert in Google Analytics and Tag Manager: you‚Äôll need to be able to manage, maintain and advance the analytics stack, and also be able to turn requests from marketing or product office into actionable implementation plans, then manage the process and valide the implementation.', 'Eligible candidates are recent PhDs within five years of the month of the degree award at time of hire date., About Us, \\n\\nLawrence Livermore National Laboratory (LLNL), located in the San Francisco Bay Area (East Bay), is a premier applied science laboratory that is part of the National Nuclear Security Administration (NNSA) within the Department of Energy (DOE).', 'Process Management - Excellent at figuring out the processes to get things done, understands efficient work flows\\nLearning on the Fly - Learns quickly when facing new problems, relentless learner, open to change, improves, enjoys challenges and finding solutions\\n, \\n1-3 years of professional software development experience\\n1+ years working with big data sets\\nExperience with a host of tools including: Google Analytics, Adobe Analytics, Google Tag Manager and tag auditing tools such as ObservePoint.', 'Experience with Google Cloud Platform or related cloud services.', ', \\nPartner with Marketing Managers, Sales, and executives as a strategic thought partner to deliver key insights from web tracking metrics\\nStudy website behavior patterns to analyze and optimize business results and user experience\\nSynthesize data from multiple sources, developing assumptions where needed, to drive customer insights and strategy development\\nCoordinate with external partners and business stakeholders to develop actionable dashboards which present the end to end funnel metrics, contributing to the development of hypotheses and actions\\nCollaborate with Marketing to measure impact of website strategy across all campaign channels and to refine strategy driven by data-based insights\\nWork with stakeholders to develop learning plans with recommendations of analytics approaches, including A/B testing\\nEnsure site tagging is implemented properly to provide visibility to impact and value of various initiatives and releases\\n, \\n5-8 years of experience in web analytics decision support and website optimization\\nDeep subject matter expertise with Google Analytics and SQL; experience with Google AdWords, Google Webmaster tools and Google Tag Manager a plus\\nSolid understanding of Paid Search, SEO, and other digital marketing channels such as Affiliate, Social, and Display\\nStrong analytical and problem solving skills\\nExperience with Tableau (or similar data visualization tools such as Spotfire, PowerBI, QlikView, etc.)', 'That‚Äôs why:, Our infrastructure is in Google Cloud Platform,\\nFor research we leverage both Python and R,\\nOur ETL pipelines and production models are in Python and Scala.', ', How you will impact WestRock:\\n\\n, Works with stakeholders throughout WestRock to identify opportunities for leveraging data to drive business solutions\\n\\nAnalyzes large data sets and use programming languages such as Python, R, IBM SPSS Modeler to develop statistical and optimization models to drive business solutions.', 'Knowledge of distributed systems as it pertains to data storage and computing\\nStrong problem-solving skills and capability to understand and set direction for complex technology integration\\nExperience and/or interest in designing and building Artificial intelligence solutions using third party API‚Äôs such as Microsoft Azure, Amazon Machine Learning, Google ML, IBM Watson etc\\nExperience and/or interest in working with open source eco-system components such as Tensorflow, Scikit learn, Hadoop, Apache Spark, Apache Flume and Apache Kafka.', 'As part of an entrepreneurial team in this rapidly growing business, you will help shape the future of businesses of all sizes use technology to connect with customers, employees and partners., The Google Cloud Revenue Acceleration team (RevX) focuses on boosting business growth of Google Cloud using quantitative programs.', 'Represents T-Mobile at professional meetings, in professional societies and universities.', 'You will conduct original research and publish results in academic and industry conferences., \\n\\nRequirements, \\n\\nPhD in Statistics or a closely related field, or 5+ years of equivalent industry experience in A/B testing and digital experimentation\\n\\nStrong research interest and experience with design of experiments, randomized control trials, and inference, particularly aspects of high throughput testing such as multiple hypothesis testing, sequential testing, robustness, data mining of experiments\\n\\nExperience with Python and/or Java preferred\\n\\nSome experience in math education such as teaching, teaching assistantships, consulting, or conference talks, \\n\\nPhD in Statistics or a closely related field, or 5+ years of equivalent industry experience in A/B testing and digital experimentation, \\n\\nStrong research interest and experience with design of experiments, randomized control trials, and inference, particularly aspects of high throughput testing such as multiple hypothesis testing, sequential testing, robustness, data mining of experiments, \\n\\nExperience with Python and/or Java preferred, \\n\\nSome experience in math education such as teaching, teaching assistantships, consulting, or conference talks, \\n\\nSome of our public work:, \\n\\nPapers, \\n\\nStats Engine White Paper - http://pages.optimizely.com/rs/optimizely/images/stats_engine_technical_paper.pdf\\n\\nStats Engine Academic Paper - https://arxiv.org/abs/1512.04922, \\n\\nStats Engine White Paper - http://pages.optimizely.com/rs/optimizely/images/stats_engine_technical_paper.pdf, \\n\\nStats Engine Academic Paper - https://arxiv.org/abs/1512.04922, \\n\\nBlog Posts, \\n\\nBayesian vs Frequentist Statistics https://blog.optimizely.com/2015/03/04/bayesian-vs-frequentist-statistics/\\n\\nOptimizely‚Äôs Stats Engine https://blog.optimizely.com/2015/01/20/statistics-for-the-internet-age-the-story-behind-optimizelys-new-stats-engine/\\n\\nApproximate Counting and Statistical Significance https://medium.com/engineers-optimizely/approximate-counting-and-statistical-significance-two-great-ideas-that-dont-play-nice-2bd643287644#.6uyxiytlr, \\n\\nBayesian vs Frequentist Statistics https://blog.optimizely.com/2015/03/04/bayesian-vs-frequentist-statistics/, \\n\\nOptimizely‚Äôs Stats Engine https://blog.optimizely.com/2015/01/20/statistics-for-the-internet-age-the-story-behind-optimizelys-new-stats-engine/, \\n\\nApproximate Counting and Statistical Significance https://medium.com/engineers-optimizely/approximate-counting-and-statistical-significance-two-great-ideas-that-dont-play-nice-2bd643287644#.6uyxiytlr, \\n\\nConference Talks, \\n\\nCODE @ MIT 2016: A/B Testing in a Changing World\\n\\nINFORMS 2015: Can I Take a Peek?', 'Connect with NRG Energy on Facebook and follow us on Twitter @nrgenergy., \\n\\nJob Summary, \\n\\nNRG is seeking an Analyst, Data Analytics with excellent analytical and interpersonal skills to join our Asset Integration team in NRG‚Äôs Asset-Backed Demand Response (ABDR) business.', '\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA, \\n\\nWhether you\\'re on a consumer product (like Gmail, Search, Maps, Chrome, Android) or a business product (Google Ads, AdSense, Google Marketing Platform, Analytics), you take part in a complete marketing experience as you lead every facet of the product\\'s journey.', 'Familiarity with web analytics (Google Analytics, Site Catalyst), statistical packages (SAS, R), and visualization tools (Qlikview, Tableau).', 'Using your influencing and relationship-building skills, you provide Google-caliber client service, research and market analysis.', 'Building data visualizations, reports and presentations\\nWorking with evolving Hadoop and Spark technologies\\nWorking with evolving Google Cloud and Amazon Web Services (AWS) cloud technologies\\nDelivering solutions to customers including vision workshop, Proof of Concepts / Proof of Value and production implementation.', '\"[\\nOwn our data infrastructure and use Supermetrics and Google Spreadsheets to ensure uptime on all client reporting\\nBring new and innovative ideas to the table to help us become the best in the world at sharing insights with our clients; source new business intelligence tools like Tableau, Looker, Periscope, etc.', 'Cloud: Google Cloud(BigQuery/ML Engine/Google Dataflow/Google Dataproc, etc.)', 'Statistics (Bayesian methods, experimental design, causal inference)\\n\\nTableau, Looker\\n\\nGoogle Cloud Platform, At Square, our purpose is to empower ‚Äì within and outside of our walls.', 'The Weather Company (an IBM Business) is seeking a Data Engineer to utilize skills in DevOps and data management/engineering to work with architects, developers and other team members to design, build, and operationalize solutions for strategic enterprise data processing in geospatial data.', 'AWS, Google)\\n\\nExperience with managing, cleaning and normalizing large, multi-dimensional datasets\\n\\nKnowledge and experience with electronic health records (EHRs)\\n\\nKnowledge of clinical data standards and ontologies including ICD, SNOMED, UMLS, etc.', 'Identify opportunities to use data to drive enhanced business decision making and promote a data-driven culture\\n, \\nHands-on experience with Hadoop, Teradata (or other MPP RDBMS), MapReduce, Hive, Sqoop, Splunk, STORM, SPARK, Kafka and HBASE\\nExperience with end-to-end solution architecture for data capabilities including:\\nExperience with ELT/ETL development, patterns and tooling\\nExperience with BI tools - Periscope Data or equivalent tool (Tableau, etc.)', '\"[We do research differently here at Google.', 'Passion for Rockstar Games and our titles., \\n\\nExperience with Vertica, Splunk and Hadoop, an asset.', 'You listen to and translate Googler needs into high-level technical specifications, design and develop recommended systems and consult with Google executives to ensure smooth implementation.', 'thought leadership, articles, talks, competitions, certifications)\\n\\nEducate and coach both clients and team members on machine learning knowledge, practical mathematical modeling, simulation and optimization in multiple analytics platform, BENEFITS, ibm.com/employment/us/benefits/\\n\\nibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\\n\\nFinding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee\\'s strength and career aspirations\\n\\nDiversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\\n\\nibm.com/ibm/responsibility/corporateservicecorps/, Master\\'s Degree in Statistics, Mathematics, Engineering or related STEM fields\\n\\nAt least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\\n\\nAt least 5 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\\n\\nAt least 5 years of experience in data management and coding such as DB2, SQL, Hadoop, PhD in Statistics, Mathematics, Engineering or related STEM fields\\n\\nApplied knowledge on simulation and optimization\\n\\nExperience in visualization such as d3, Javascript, HTML, CSS]\"\\n\"[\\n\\nDeliver lectures and tutorials on scientific Python, SQL, probability, statistics (Bayesian and frequentist), machine learning, and data engineering.', '\"[Build, design and implement high impact data analytics and machine learning solutionsBring new ideas in machine learning software developmentLeverage industry knowledge and stay close to technology developments in the open-source communitiesCollaborate with cross-functional teamsAssist and drive the team by providing oversight., Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms\\nLeverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions\\nDrive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements, Solid foundation in SQL, data structures, algorithms, design patterns and strong analytical and problem-solving skillsExperience working with predictive modeling in SAS, Python, R or other2+ years of experience leading workstreams with significant experience leading components of data engagements and team sizes ranging from 3 to 10 resources.A strategic thinker who is proactive in providing valuable insights and strong leadership skillsExcellent communications and interpersonal skills, Experience in data management consulting or industry experience (master data, metadata, data architecture, data governance, data quality, data modeling) with experience including the following tools: Informatica, IBM, Oracle and Cloud MDM, Reltio, PIM, SAP BODS, etc.Experience with other visualization tools is a major plus, such as TableauAbility to work independently; lead small teams focused on specific work streams of larger projects.Strong oral and written communication skills, including presentation skills (MS Visio, MS PowerPoint).Strong problem solving and troubleshooting skills with the ability to exercise mature judgment.Eagerness to mentor junior staffBachelor‚Äôs Degree or 4+ years of equivalent professional experience, As used in this posting, ‚ÄúDeloitte‚Äù means Deloitte Consulting LLP, a subsidiary of Deloitte LLP.', 'We establish new, flexible and iterative approaches that only IBM can offer through our unique combination of skills, experience and capabilities, leveraging the proven roadmaps and frameworks we have developed across our 17 industries.', 'Above all, your work will influence the way people experience music., Build large-scale batch and real-time data pipelines with data processing frameworks like Scalding, Scio, Storm, Spark and the Google Cloud Platform.', 'We leverage the Google Cloud Platform (including Google Dataflow, Bigtable, and BigQuery) for processing data as well as build our own analysis tools.', 'Originally formed at Google in 2011, we became an independent company in 2015 with a strong group of investors including Nintendo, The Pok√©mon Company, and Alsop Louie Partners.', 'Python or shell scripting)\\n\\nPreferred experience working with either a Map Reduce or an MPP system\\n\\nPreferred experience working with cloud platforms such as AWS, Google Cloud Platform or MS Azure\\n\\nExperience to analyze data to identify deliverables, gaps, and inconsistencies]\"\\n\"[Your consulting projects will include integrating data in a virtual manner for operational and/or informational purposes - Integration of 100+ data sources for a Customer Service Multichannel IT Infrastructure; implementation of Logical Data Warehouses and Virtual Datamarts to enable modern Business Intelligence solutions, Integration Layers for Hadoop-based Data Lakes, and support for Agile Operational Reporting on a diverse Big Data infrastructure are just a few flavours of your future projects.', 'Prior experience with Google Analytics and web analytics platforms such as Adobe Analytics, Test & Target, Maxymiser preferred.', 'Built software with technologies like ElasticSearch, GraphQL, and Google Cloud Platform.', 'can hit the ground running and bring new analytical approaches not currently practiced by Hallmark.', ', Require Skills & Experience:, \\n\\nBachelor\\'s or Master\\'s degree in Electrical or Mechanical Engineer or Physics\\n\\nStrong experience with Apache Spark/Spark streaming\\n\\nExperience building out pipelines for API\\'s\\n\\nExperience in production level code\\n\\nExperience working in the cloud (AWS or Google)\\n\\nKafka experience a plus, \\n\\nBenefits:, \\n\\n$160,000 - $180,000\\n\\nNew amazing office\\n\\nFull medical, dental, vision]\"\\n\"[\\n\\nWork with your team to determine product direction and customer needs\\n\\nDevelop and improve the service layers that connect the data backend to web apps\\n\\nShare knowledge, methodologies and best practices amongst the product engineering team and other teams\\n\\nParticipate in a team-wide on-call rotation to keep the systems ticking along\\n\\nMentor Software Engineers and Interns, \\n\\nBachelor\\'s or Master‚Äôs degree in Computer Science, related field and 5+ years of software development experience\\n\\nExceptional experience in programming with Java.', ', \\n\\nBachelor Degree in Data Science, Information Systems, Computer Science, Economics, Mathematics or similar\\n\\n2+ years of experience as a Business/Financial Analyst, BI Engineer or Data Analyst preferably with exposure to large complex data sources\\n\\nProficient in SQL and Microsoft Excel\\n\\nProven analytical and quantitative skills and an ability to use data and metrics to back up assumptions, develop business cases, and complete root cause analyses\\n\\nQuick learner with a strong data-driven and quantitative focus when solving problems\\n\\nKnowledge of fundamental relational database technology and terminology\\n\\nProficient in converting large datasets into actionable business insights\\n\\nExperience using business intelligence reporting and visualization tools such as Tableau, Looker, Cognos, Domo, or others\\n, \\n\\nExperience in payments, billing and subscriptions\\n\\nExperience with analytical software (Python, R) and solid grasp of common statistical methods and applications (A/B testing, probability, regression)\\n\\nExperience working with databases such as AWS Redshift\\n\\nAdvanced understanding of data analysis and visualization techniques\\n\\nFamiliarity with Google Analytics, web analytics, and funnel conversion concepts\\n]\"\\n\"[Responsible for analytic data needs of the business unit.', 'Additional responsibilities include, but are not limited to: participating in the activities and discussions of various Board advisory committees and task forces; serving as the Board‚Äôs representative in relevant stakeholder meetings; and working cooperatively with Arizona Department of Education staff as directed., \\n\\nKNOWLEDGE, SKILLS AND ABILITIES (KSAs):, \\n\\nKnowledge Required:,  Knowledge of data and statistical analysis Knowledge of sound research practices General understanding of the Arizona public education system, \\n\\nSkills Required:,  Skilled in presenting highly effective written, visual and oral presentations on complex data to a wide variety of audiences Skill in Microsoft Office and Google Suite products, including Microsoft Excel and Google Sheets Knowledge and capable ability in one or more of the following: SPSS, SAS, or R Skilled in working on multiple complex projects simultaneously Skilled in working in high pressure environments Skilled in detailed oriented reports Skilled in analyzing and developing complex policy in a variety of areas Skilled in interpreting and applying federal and state codes and regulations, \\n\\nAbilities Required:\\n\\n,  Ability to perform and analyze complex calculations associated with technical properties of educational assessments and accountability measures Ability to develop and articulate potential policy recommendations in the areas of school accountability, assessment and research Ability to work collaboratively with stakeholder groups and other state agencies Ability to perform detailed work with a high degree of accuracy, \\n\\nSELECTIVE PREFERENCE:,  Master degree or doctorate in Education, Educational Administration, Educational Leadership, Research and Development.', 'Experience linking multiple data platforms with data visualization tools (e.g., Tableau)\\n\\nExperience with Public Cloud Platforms (AWS, Azure, Google Cloud Platform)\\n\\nAdvanced knowledge of data management tools including SQL/RDBMS, NoSQL (e.g.', '\"[Must Have:, \\nOracle DBA\\nDatabase Design and System Analysis\\nData Security\\nBackup and Recovery\\nChange Control Management\\nDatabase Testing\\n, Good to Have:, \\nGigaSpaces XAP\\nGigaSpaces InsightEdge\\nCloud Computing (Amazon AWS, Microsoft Azure or Google GCP)\\nIn-Memory Databases (other than GigaSpaces like Redis, etc.)', '\"[\\naccess to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\na chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\\nparticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\\n, \\nExperience with statistical analysis, modeling and simulation\\nExperience programming in Matlab, R, Python, or other statistical and mathematical language\\nAbility to interpret results and disseminate results to a non-technical audience\\nAbility to work closely with people of various quantitative and qualitative backgrounds\\nAbility to explore academic research and apply and modify it to meet the needs of the client\\nTS/SCI clearance\\nBA or BS degree in mathematics, statistics, operations research, or other quantitative field\\n, \\nKnowledge of human factors methods is a plus\\nPossession of excellent analytic skills\\n]\"\\n\"[Develop in-depth knowledge of several Staples business processes and systems environment\\nWork closely with key business partners to understand critical, complex, data-driven business and operations challenges, and then apply analytical methods to solve them ‚Äì resulting in a significant, positive impact on the Staples‚Äô bottom-line.', '\"[Note: By applying to this position your application is automatically submitted to the following locations: Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA; Portland, OR, USA; Boulder, CO, USA, \\n\\nAs a Solutions Architect with a core focus on Machine Learning (ML), you\\'ll help prospective customers and partners understand the power and value of the ML capabilities of Google Cloud by explaining technical features, designing architectures, building proof-of-concept work and publishing advanced ML solutions.', 'All employment decisions at Dell are based on business needs, job requirements and individual qualifications, without regard to race, color, religion or belief, national, social or ethnic origin, sex (including pregnancy), age, physical, mental or sensory disability, HIV Status, sexual orientation, gender identity and/or expression, marital, civil union or domestic partnership status, past or present military service, family medical history or genetic information, family or parental status, or any other status protected by the laws or regulations in the locations where we operate.', 'Experience with Starcraft II and PySC2, and OpenAI Gym a plus.', 'Additionally, the analyst will be called upon to work directly with school leaders to interpret and act on their data, and to collaborate across all departments within the organization., \\n\\nESSENTIAL JOB FUNCTIONS:, \\n\\nClean, manipulate, organize and analyze student and school performance data, \\nPrimarily using R, write and maintain scripts to clean and organize raw data sets\\nCreate cross-sectional and longitudinal data sets from raw data files\\nCreate systems for assuring data quality and accuracy\\nCreate visualizations to help users understand and explore data\\nRespond to organizational requests for data analysis\\nEnsure consistency between data analyses, Google-based tools, and Tableau dashboards\\n, Manage infrastructure for processing large data sets for use in NV data tools and analyses, \\nMaintain repository of R scripts for automated overnight data processing and incorporate new analyses and descriptives as needed\\nSupport the integration of additional data sources into New Visions data warehouse and data tools\\nSupport the operationalizing of robust data quality assurance within data infrastructure\\n, Collaborate with internal and external colleagues to infuse New Visions tools, structures and strategies with a data-driven approach, \\nCollaborate with data users to understand their needs, build tools, and conduct analyses to support them\\nSupport schools and network leaders in launching tools and analyzing data within tools to make evidence-based decisions\\nProvide analysis to Management Team, cross-network meetings, and other collaborative structures\\nDevelop mechanisms for collecting feedback and modifying analyses and data tools to reflect internal and external data priorities\\n, REQUIRED EDUCATION AND EXPERIENCE:, \\nMasters degree in public administration, public policy, education, statistics, economics, psychology, sociology, or related social science field.', '2-4 years of relevant data science experience; comScore or other media measurement experience can be included.', 'One of:\\n\\nExperience or interest in controlling physical systems using Machine Learning\\n\\nComputational Neuroscience modeling experiences\\n\\nInterest and ability to make fundamental advances in ML\\n\\nInterest at the intersection of computer vision and language\\n\\nStrong understanding of classical ML techniques, \\n\\n#LI-post]\"\\n\"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.', 'Experience with Distributed Data platforms (HDFS, Elasticsearch, Splunk, Casandra).', 'Experience with AWS and Google Cloud Platform.', 'Founded by MIT roboticists who had the vision of making practical robots a reality.', ', Understand the capabilities of our current system and enhance it to support the capabilities of this new pipeline\\nWork with other groups within the organization to set up and configure big data clusters and assist with data volumetrics as well as hardware and software needs\\nResearch, design and assist in building tools that can be utilized to analyze the data by internal users and support staff\\nMaintain systems to ensure they are highly available\\n, 3+ years of current Java development experience\\nProven experience with a range of big data architectures, including Hadoop, HBase or other big data frameworks\\nExperience building large scale distributed data processing systems\\nSolid understanding of data structures, algorithms & object-oriented design concepts\\nA passion for big data technologies and a flexible, creative approach to problem solving\\nExcellent communication skills\\n, Experience with languages such as Python/Perl\\nExperience developing software using agile methodologies\\nWorking knowledge of development tools such as debuggers, memory profilers, and performance analysis\\n, Apply Now]\"\\n\"[Located in Pleasanton, this predictive analytics start-up that uses machine learning models and their client\\'s CRM data to provide sales and marketing insights is looking for a hands-on contractor with expertise in Hadoop and Java to join their team for up to 18 months., In this role, you\\'ll be working very hands-on with both the Hadoop and Spark ecosystems, Java, and Google\\'s Cloud Platform to support the big name clients of this company.', '\"[Responsible for following the defined agile development processes including attending the required meetings with contribution towards the successful completion of the sprints..Collaborates with product management and customer delivery teams to ensure product requirements are clear on what customers expect and what the delivery teams should set as the right expectations with the customers.Communicate rigorously within the squad on goals, ongoing progress, milestones, and any issues.Support and follow the overall product architects, delivery architects, to drive and establish the architecture decisions and designs for the product.Leverage the DevOps team to ensure product can be automatically built, deployed, and tested using a CI/CD pipelines across all of the release cycles from dev to production.Mentor and develop required skills of other junior product developers., Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.Experience applying machine learning and predictive analytic techniques to large, complex data sets specializing in event data processingExperience with Machine Learning frameworksExpert in coding hands on in Python and RExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processingProven ability to develop resilient code (best practice error handling) that performs and scales for large enterprise needsDeep expertise in developing REST-based API\\'s (json/yaml), Micro-services with RDBMS and NoSQLBachelor\\'s degree in Computer Science or equivalent with specialization Machine Learning, Understanding of Public and Private Cloud Provider services, usage and delivery paradigmsWorking knowledge of cloud technologies and architectures, including Virtualization, APIs, Micro-services and Containers.5+ years experience delivering enterprise-class cognitive applications2+ years experience developing in Python and modern web-based languagesExcellent verbal and written communication abilities: must effectively communicate with technical and non-technical teamsHigh attention to detail and proven track record in taking ownership, driving results and moving with speed to implement ideas in a fast-paced online environmentWillingness to roll up your sleeves and do whatever is necessaryAbility to process and manage multiple priorities, Ph.D or Masters in Computer Science/Artificial Intelligence with specialization in Machine Learning.Knowledge of IT Service Management and IT Operations Management processes, tools and technologiesKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment modelsExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storageExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.,  Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.', \"If you‚Äôre searching for a company that‚Äôs dedicated to your ideas and individual growth, recognizes you for your unique contributions, fills you with a strong sense of purpose, and provides a fun, flexible and inclusive work environment ‚Äì apply now., \\n\\nSAP'S DIVERSITY COMMITMENT\\n\\nTo harness the power of innovation, SAP invests in the development of its diverse employees.\", 'If you require an accommodation due to a disability, please contact Ericsson at hr.direct.dallas@ericsson.com or (866) 374-2272 (US) or (877) 338-9966 (Canada) for further assistance., \\n\\nPrimary country and city: United States (US) || || Plano || Consulting&SysInt]\"\\n\"[\\n\\nLead team in designing analytic solutions that meet customer needs\\n\\nEnhance existing analytic solutions to ensure quality, and performance\\n\\nSelect and implement appropriate measurements, and scoring metrics to evaluate performance of existing algorithms\\n\\nSelect and implement industry machine learning algorithms to enhance or compete with existing algorithms\\n\\nIntegrate Data from multiple sources to create a common operating picture\\n\\nPresentations to internal and external customers\\n\\nIdentifying and Implementing data visualization for analysis, presentation, and end-user UI needs\\n\\nDuties will also include feature engineering, classifier optimization, event forecasting, and anomaly detection\\n\\nData processing, cleansing, and validating both existing and incoming data, \\n\\nPython and good working knowledge of numpy, scikit-learn, pandas, scipy, matplotlib\\n\\nExperience in applying machine learning techniques to time series and geospatial data\\n\\nStrong statistical background in areas such as statistical testing, regression, and probability\\n\\nGood interpersonal skills and communication with all levels of management\\n\\nBachelors in Mathematics or related discipline with 6+ years of data science industry experience\\n\\nAble to multitask, prioritize, and manage time efficiently\\n\\nUS Citizenship and an active Public Trust clearance, \\n\\nAlgorithm performance scoring\\n\\nData Visualization of multi-source, multi-dimensional data, and analytic results in both real-time and for presentations\\n\\nMS in Computer Science, Physics, Mathematics, or other related discipline with 5+ years of industry experience of the data science field\\n\\nFamiliarity with database / data file system such as PostgreSQL, Kudu, HDFS\\n\\nStrong Google-Fu\\n\\nExperience with time series event forecasting\\n\\nWide breadth of machine learning algorithm experience and posses understanding of which problems those ML algorithms solve\\n\\nUp-to-date on latest industry trends; able to articulate trends and potential clearly and confidently]\"\\n\"[Req.', 'Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \\n\\nPredictive Science is looking for a Data Analyst who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results.', 'Experience with the Google Cloud Platform.', 'Perform statistical analyses and build machine learning solutions to support Google Cloud business needs.', 'Experience with data instrumentation, interpretation and visualization tools (ETL Tools, Splunk, Tableau).', 'Master\\'s degree in Engineering, Mathematics, Computer Science, Supply Chain or related field., \\n\\nCompany Summary, Position Summary]\"\\n\"[\\n\\nGather, document, and communicate requirements effectively to ensure appropriate implementation of solutions and processes\\n\\nDevelop effective problem statements and drive to resolution, \\n\\nPerform as-is and to-be analysis, \\n\\nServes as a data steward, ensuring accurate and timely data capture, \\n\\nPlan and manage projects; anticipate and mitigate risk, document decisions, manage change, \\n\\nCompose effective cross-team and inter-departmental communications, \\n\\nEnsure continuous improvement in quality of data and deliverables, \\n\\nCollaborate with cross-functional teams to enable and promote Enterprise adoption of Master Data Platforms, \\n\\n5 years of data analyst experience\\n\\nBachelor of Science degree in STEM (Science, Technology, Engineering or Math)\\n\\nProject Management experience\\n\\nExperience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\\n\\nExperience manipulating and analyzing large datasets, \\n\\nExperience utilizing SQL to develop queries or profile data OR programming experience in applications or databases\\n\\nExperience manipulating and analyzing large datasets, \\n\\nConcentration in Computer Science, Computer Engineering, or related field strongly preferred\\n\\nUnderstands NI\\'s products and how NI engages customers is strongly preferred\\n\\nSelf-Starter, high level of ownership, proactive nature, problem-solving skills\\n\\nKeen eye for detail and precision\\n\\nStrong technical skills, comfortable working with technical teams (Excel, PIM IBM, Datawarehousing, SQL Queries)\\n\\nSolution driven - strong analytical skills to identify, analyze and solve problems given ambiguous information\\n\\nStrong personal organizational and project planning and management skills\\n\\nTeamwork skills essential; sense of humor required\\n\\nExcellent English communication skills - verbal and written]\"\\n\"[Qualys is seeking a Data Analyst with experience in financial systems and data management and interest in helping automate reporting and financial analysis.', 'Self-motivated, work well both independently and as part of an agile team., \\n\\nPreferred Experience:, \\n\\nMaster‚Äôs degree required in a quantitative discipline such as Mathematics, Statistics, Economics, Engineering, Operations Research, Computer Science\\n\\nPreferred experience with console development for current platforms\\n\\nHave a clear understanding of Big Data tools mainly being Splunk, Hadoop, and Spark\\n\\nExperience with Visualization tools and platforms., \\n\\nCrystal Dynamics is an EOE and M/F/D/V employer.]\"', 'Through analyzing large volume of data both from Twitter users and Twitter advertisers, you‚Äôll help Twitter grow revenue globally and in scale., \\n\\nYou are able to:, \\n\\nBecome an expert on the data sources and systems at Twitter.', 'Experience architecting and developing end-to-end enterprise scale Big Data analytical solutions in serverless environments such as Google Cloud Platform\\n\\nExperience with Cloud Dataflow, BigQuery, Hadoop/Spark, and Tableau\\n\\nExperience implementing ETL processes in Big Data analytical solutions using a variety of sources (Text, databases, JSON, XML, etc..)\\n\\n2-3 years of experience in statistical and database languages (e.g., Python, R, advanced SQL)\\n\\n2-3 years of experience working with Big Data, data mining or machine learning, data visualization to draw actionable insights\\n\\n3+ years of experience programming in Java and Unix shell scripts\\n\\n2-3 years of experience with Agile and Scrum development\\n\\nFamiliar with Apache BEAM SDK\\n\\nWorking knowledge of basic financial concepts: P&L, margins, pricing, etc.', '\"[\\nAccess to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\nA chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\\nParticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\\n, \\n2+ years of experience with one or more scripting or scientific languages, including Python, R, C++ or Java\\n2+ years of experience in working with a wide range of predictive and decision models and tools for developing such models\\n2+ years of experience with Big Data programming technologies, including Hadoop, Spark, MapReduce, Accumulo, Cassandra, HBase, R, Mahout, Pig, or Hive\\n2+ years of experience with applying various machine learning techniques and understanding the key parameters that affect their performance\\nExperience with Microsoft Excel and Access\\nKnowledge of relevant statistical measures, including confidence intervals, significance of error measurements, and development and evaluation data sets\\nAbility to obtain a security clearance\\nBS degree\\n, \\nExperience with using statistical software applications, including SAS, R, MATLAB, SPSS, or Stata\\nExperience with developing statistical and simulation models\\nExperience in one or more natural language processing topics, including tagging, syntactic parsing, word sense disambiguation, topic modeling, contextual text mining, and application of deep learning to NLP\\nExperience with developing experimental and analytic plans for data modeling processes, use of excellent baselines, and determine cause and effect relationships accurately\\nBS degree in Operations Research, Data Science, Applied Mathematics, CS, Engineering, or a related technical field preferred; MS degree in Operations Research, Data Science, Applied Mathematics, CS, Physics, Statistics, Engineering, or a related technical field a plus\\n]\"\\n\"[OVERVIEW, \\n\\nAs a member of our R&D organization, your work will directly and rapidly impact our award winning Conversant One-to-One Relationship Engine.', \"We're developing Cloud ML on Google Cloud Platform, in close partnership with a number of teams across the company.\", 'Partner with customers to build the best strategy to increase profitability while respecting business rules by leveraging various Google offerings.', '\"[\\n5+ years of experience with Big Data, systems, including Hadoop, Hive and Pig\\n5+ years of experience with ETL tools including NiFi and StreamSets\\nExperience with Java\\n3+ years of experience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services\\nSecret clearance\\nBA or BS degree\\n, \\nExperience with Agile software development\\nPossession of excellent oral and written communication skills\\nBS degree in CS, Computer Information Systems, Information Systems, or a related field\\n]\"\\n\"[You will lead and guide technical aspects of small- and medium-sized project delivery through the entire project lifecycle ‚Äì from requirements gathering, analysis, design, development, testing, deployment, audit and post-production support.', ', Secret clearance is required\\n\\nBachelor\\'s degree required, additional years of experience may be substituted for a degree\\n10 years of professional experience is required, including 2 years of supervisory experience\\n\\nMust be technically savvy\\nMust have at least 1 year of experience with data analytics\\nMust have a strong knowledge of statistics and the ability to translate statistical reports into easy-to-read formats\\n\\nAbility to complete tasks under tight deadlines\\n, Experience with Google Analytics strongly desired\\nMarketing experience\\nState Department experience\\n\\n]\"\\n\"[Who we are:, \\n\\nOver ten years ago, we launched AppFolio(NASDAQ: APPF) to revolutionize the way small and medium-sized businesses grow and compete.', 'Experience with A/B and multivariate testing\\n\\nAdvanced Google Analytics and Google AdWords certified\\n\\nPositive attitude and entrepreneurial spirit, \\n\\nPreferred:, \\n\\nYou have familiarity with audience, attribution, and optimization solutions such as Google Audience / Adometry, Google Optimize, Adobe Target, Oracle and Adobe Audience Managers.', 'Splunk offers the chance to work with cutting-edge technology in a collaborative, exciting, and fast-paced environment., \\n\\nResponsibilities: I want to and can do that!, \\n\\nPartner with Splunk‚Äôs product managers and internal teams to address complex business data questions and provide insightful analysis and strategic recommendations to both technical and non-technical colleagues.', 'Please submit any online presence you may have (Twitter, Facebook, Fan pages made because of you), and if you are a DIY enthusiast, whether you think you are a good one or not, that means a lot to us, and we would love to hear about it when you send us your information!]\"', '#CJ]\"\\n\"[The Google Cloud team helps companies, schools, and government seamlessly make the switch to Google products and supports them along the way.', 'Experience developing in AWS, Google cloud, or Azure (Azure preferred).', 'PhD from an accredited college/university is preferred\\n\\nAbility to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\\n\\nSolid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\\n\\nFluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\\n\\nAbility to travel up to eighty percent of the time; US Citizenship is required, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.', 'Our work helps Google Assistant understand and speak with users, helps self-driving cars move safely, and helps Google Images and Geo understand the content of images among other cases across the company.', ', Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\\n, Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\\n, Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\\nProficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\\nAbility to digest and explain complex ideas to a diverse group of stakeholders\\nMust be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\\nExperience with digital media measurement and reporting platforms preferred as well as programming languages\\nExperienced in effective dashboard designing with a focus on customizing to client needs\\nAbility to work under pressure and manage multiple priorities\\nStrong communication and presentation skills equally capable of interacting with peers and senior leaders\\nMust be a team player but also have the ability to work independently]\"\\n\"[We are looking for you - dynamic, best-in-class talent - to join the Initiative team as a Senior Analyst, Analytics.', 'In addition to troubleshooting on the customer side, we work with Sales, Product and Engineering teams within Google to develop better tools and services to improve our products based on the evolving needs of our users.', 'Are you self-motivated and have a passion for analytics, search and display advertising, and advanced campaign management?, \\n\\nPureCars is looking for an analytics-driven Digital Analytics Analyst to plan, implement, and analyze digital marketing campaigns in Google Analytics / Analytics 360 across our customers.', 'Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.', 'Familiar with popular machine learning and artificial intelligence packages provided by Amazon AWS, Microsoft or Google (such as Azure, Sagemaker, GCP).', 'Hadoop, Spark or Vertica) is required\\n\\nMinimum of 1-2 years implementing solutions in a cloud environment (AWS, Azure or Google) Prior experience mentoring & leading technical teams of junior data scientists where you were responsible for providing project estimates for your work stream and assigning tasks to other team members\\n\\nExcellent written and oral communication skills; must be capable of effectively articulating technical concepts to non-technical audiences\\n\\nMust have an undergraduate (BS) or postgraduate (MS/Ph.D.)', 'Experience with Dataflow, Google PubSub or other queuing software beneficial\\n\\nGood experience of parsing data formats such as XML/JSON and using 3rd party API‚Äôs\\n\\nExperience with Curl / similar beneficial\\n\\nSolid Python programming skills.', 'Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud Platform.', 'Google drive suite services (Google Docs, Google Sheets, etc.).', 'Experience working across functions and influencing teams\\n\\nContinuous improvement mindset\\n\\nExperience with data modeling tools (e.g., SAP PA, Python, R, SAS, MS-Azure)\\n\\nExperience with business intelligence and data visualization tools (such as from Power BI, Google Analytics, Tableau, Domo, Qlikview)\\n\\nData integration experience including extract, transform, load (ETL) processes\\n\\nExperience with databases and complex data queries\\n\\nGreenbelt certified\\n\\nStrong organizational skills\\n\\nSelf-motivated and independent\\n\\nExcellent oral and written communication skills\\n\\nAbility to work in a rapidly changing environment\\n\\n, Location: St. Paul, MN\\n\\n, Sales Territory: N/A\\n\\n, Travel: May include up to 10% domestic/international\\n\\n, Relocation: Is not authorized\\n\\n, Must be legally authorized to work in country of employment without sponsorship for employment visa status (e.g., H1B status).]\"', 'Need to be close to a major airport\\nSalary: Entirely depends on skill-level and location (wide range), \\n\\nEveryday Responsibilites:, \\nWork with clients‚Äô software architects and engineers to provide technical solutions w/ company‚Äôs technologies\\nConsult with clients on how to integrate a new technology stack\\nDevelop software in Scala, Kafka, Akka, Spark, and other reactive platforms\\nInvolvement in the pre-sales process\\nDevelop training curriculum for clients\\n, Required Qualifications:, \\n4+ years of JVM-based languages/systems\\nExpert-level development experience in Java & Scala\\nExperience working with at least one of the following technologies (Spark, Kafka, Akka)\\nExperience in and knowledge of big data batch streaming architectures\\nExperience working with Distributed Architecture technologies\\nStrong interest in adopting new technologies and evangelizing them\\nAbility to be client facing (strong written and oral communication skills)\\nExperience leading/advising software development teams\\n, **US Citizen or Green Card Holder only**]\"\\n\\n\"[At IBM Global Business Services (GBS), we partner with Fortune 1000 clients to deliver real business value by bringing together the world‚Äôs largest consulting practice with industry-leading research capability, enriching business consulting with advanced research, analytics and technology, and teaming on all phases of engagement to plan, build, and implement advanced business solutions.', 'The Supply Chain Research group at Coyote Logistics is responsible for designing, selling, and implementing Coyote‚Äôs emerging portfolio of non-transactional supply chain services.', 'Skilled in SQL and Google Analytics.', \"We represent the voice of Google's users and many of our partners globally, sharing insights with the larger Google organization to enable exceptional customer and product experiences.\", 'Preferably including DoubleClick, Google Analytics, AdWords and Google Tag-Manager and stream data into environments such as BigQuery\\n\\nResponsible for the management of multiple processes and applications, performance reporting and error checking\\n\\nResponsible for the management of all data created within client applications, the structure of data held and the views of data created\\n\\nResponsible for recommending the correct technologies to be used and in the most cost effective manner\\n\\nResponsible for the design and creation of data led strategies which provide clients with opportunities to leverage their data for greater insight or performance\\n\\nProvide thought leadership with regards to best practice and use of the google cloud platform, BS Degree\\n\\nData Engineering/ BI Development/ Data Warehousing experience.', 'Provide domain expertise around public cloud and enterprise technology, and effectively promote Google Cloud with customers, at conferences, and online.', '\"[\\nyou grok data and revel in analyzing it\\nvery hardworking\\nexcited to disrupt online advertising\\nfascinated to learn more analysis techniques\\ndetail oriented\\nself-motivator who contribute effectively with limited supervision\\nenjoy sifting through large amounts of data\\n, \\nRetrieve and analyze data from cloud storage\\nIdentify key questions, problems, and KPIs to improve the experience of our users\\nHelp develop effective and scalable data models in our production environment and develop, build, and maintain a user-friendly version our production data in our data warehouse\\nProactively develop site performance reports and analysis such as segmentation analysis; highlight observations and business context to deliver actionable recommendations to business leads, not just data\\nParticipate in the design, set up, and evaluation of A/B and multivariate testing\\nProvide access to data through dashboards and other analytical tools to empower your team through self-service\\nAutomate insights through alerting and anomaly detection\\nEnsure quality and timeliness of deliverables that meet expectations while balancing business needs with the appropriate level of analytical rigor\\n, \\nExpert proficiency in python and web analytics tools including Omniture and Google Analytics\\nOutstanding organizational skills and dedication to quality and integrity\\nThe ability to work collaboratively acting as a subject matter expert within a team environment to help define and meet measurement criteria and goals\\nExperience building tools and automated processes to extract, clean, and distill data in a procedural language of your choice such as Python, Julia or R\\nAn understanding of A/B testing and other forms of statistical analysis using statistical packages similar to R, SAS, or Pandas\\nExperience with analytical visualization tools such as Tableau, Looker, D3.js or similar tools\\n, \\nData modeling, ETL and data pipeline development experience\\nAdvanced degree in statistics or other quantitative field\\n, \\nPython, C++, Django, React.js\\nApache Kafka, Nginx\\nPostgreSQL, MySQL, Aerospike, Druid, Bigtable\\nGCP, Linux, Kubernetes, Dockers, New Relic, Elasticsearch, Kibana\\n]\"\\n\"[Position Overview:, \\n\\nThe Climate Corporation‚Äôs mission is to help the world‚Äôs farmers sustainably increase their productivity with digital tools.', 'Cloud Computing Experience (e.g AWS, Google Cloud, Azure).', ', Experience with AWS and Google Cloud Platform.', 'Reporting to the Director of Data Management and working closely with the numerous stakeholders on both the Program and Development teams, the individual in this role is responsible for understanding our schema inside and out; understanding our existing data; understanding the universe of available data; and ultimately for turning data into reliable, trustworthy stories for all levels within the organization., Reporting (50%):, Produce reports on-demand for C-level, program, and development staff\\nReactively and proactively provide analytics from Google Analytics\\nRepresent reports visually using tools like Google Data Studio or others\\nBe innovative and at-times experimental about sharing data using various clever means to keep the stories interesting\\nSummarize and translate analytics\\nTease out trends in the data that might not be immediately obvious\\nWork with teams in each region to understand unique trends; facilitate sharing of best practices for data use across organization\\nKeep abreast of advances in analytics and data visualization\\nOccasionally attend relevant events, meetups, and conferences\\nBe forward-thinking - critical thinking about data is key!', '\"[Data Engineer Consultant, \\n\\nAs a Data Engineer for Slalom Consulting, you\\'ll work in small teams to deliver innovative solutions on Amazon Web Services, Azure and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other big data related technologies.', 'RPC, REST, JSON, XML, SOAP)\\n\\nExperience with NoSQL databases and key-value stores, such as Cassandra, Redis, \\n\\nExperience with recommender, or search/ranking systems\\n\\nExperience with Kafka and Yarn or Mesos\\n\\nExperience with AWS services (Athena, Glue, Redshift, Kinesis) or Google cloud services (BigQuery, BigTable)\\n\\nBA/BS or above in Computer Science or a related field]\"\\n\"[\\nBuild scalable and reliable near real time data pipeline on cloud (AWS and GCP) that collects, transforms, loads and curates data from various internal and external data sources\\nBuild a scalable distributed data store that will be central source of truth\\nOwn data quality for the pipelines you build and make them auditable\\nBuild self service tools that helps our data consumers to extract, analyze and visualize data faster\\nEvaluate new technologies and build prototypes for continuous improvements in Data Engineering\\nPartner with Infrastructure and Engineering teams to ensure instrumentation, logging and monitoring is in place\\nImplement Machine learning algorithms\\n, \\nExtensive experience in using big data technologies such as Spark, Kafka, Hadoop, HBase and Hive or their equivalents\\nExperience with AWS and/or GCP\\n5+ years of experience with Java, Scala and Python\\n5+ years of experience with SQL (MySQL, Redshift, etc)\\n3+ years of experience in building and monitoring near real time scalable ETL pipelines\\nExperience with shell scripting\\nExcellent written and verbal communication skills\\nBS or MS in Computer Science or related technical field\\n, \\nExperience with Machine learning algorithms will be a huge plus.', ', \\n\\nExperience training machine learning models in a cloud computing environment such as: Amazon EC2, Google Cloud Platform, Microsoft Azure, etc.', ', 3+ years of hands on experience with building productionized data ingestion and processing pipelines using Java, Spark, Scala, Python\\n\\n2+ years of hands on experience designing and implementing production grade data warehousing solutions on large scale data technologies such as Teradata, Oracle or DB2\\n\\nExperience of large scale Data Migration from on premise to cloud data warehouses\\n\\nExpertise and excellent understanding of Snowflake Internals and integration of Snowflake with other data processing and reporting technologies\\n\\nExcellent presentation and communication skills, both written and verbal\\n\\nAbility to problem solve and architect in an environment with unclear requirements\\n, Bachelor\\'s degree in Computer Science, Engineering, Technical Science or 3+ years of technical architecture and build experience with large scale solutions\\n\\nMinimum 1 year of experience in architecting large-scale data solutions, performing architectural assessments, crafting architectural options and analysis, finalizing preferred solution alternative working with IT and Business stakeholders\\n\\nExperience in building data ingestion pipeline using Talend, Informatica\\n\\nExperience in working with AWS, Azure and Google data services\\n\\nExperience with dev-ops tools\\n\\nPrior experience in working with a consulting firm in client facing projects.]\"', 'Excellent communication skills\\n\\nSelf-motivated, proactive, and able to work cooperatively in a team environment, \\n\\nAdditional consideration given to candidates who bring experience with, or understanding of:, \\n\\nManaging and manipulating large data sets\\n\\nC#, Java, .Net, Tomcat\\n\\nNetworking and/or mobile systems (TCP/IP stack, cellular, Wi-Fi, Android, iOS)\\n\\nSecurity (SIEM, UEBA, VPNs)\\n\\nCloud deployment system (AWS, Azure, Google) and/or microservice architectures\\n\\nSplunk, Splunk MLT a plus, \\n\\nWho We Are:\\n\\n\\nFor over 17 years, we‚Äôve worked with a simple philosophy: help the connected world move more smoothly, seamlessly and productively.', 'Interact cross-functionally with a wide variety of leaders and teams, and work closely with Engineers and Product Managers to identify opportunities for design and to assess improvements for Google products.', \"We're providing users around the world with great search results every day, but at Google, great just isn't good enough.\", ', 6+ years of experience in one or a combination of the following: reporting, analytics, or modeling; or a Masters degree or higher in a quantitative field such as applied math, statistics, engineering, physics, accounting, finance, economics, econometrics, computer sciences, or business/social and behavioral sciences with a quantitative emphasis and 4+ years of experience in one or a combination of the following: reporting, analytics, or modeling\\n\\n2+ years of design, implementation and governance experience with Artificial Intelligence, Natural Language Processing or Machine Learning architecture\\n\\n2 + years of experience using quantitative machine learning techniques\\n\\n2 + years of text analytics experience\\n\\n2+ years of Python experience, Extensive knowledge and understanding of research and analysis\\n\\nStrong analytical skills with high attention to detail and accuracy\\n\\nExcellent verbal, written, and interpersonal communication skills\\n\\n2+ years of experience with H2O software or Keras with TensorFlow\\n\\n2+ years of statistical modeling experience\\n\\nExperience with Spark, Hive and Kafka\\n\\nCloud computing experience, Knowledge and/or experience with the following:\\nCommon NLP techniques, such as, \\n\\no Pre-processing (tokenization, part-of-speech tagging, parsing, stemming)\\n\\no Semantic analysis (named entity recognition, sentiment analysis)\\n\\no Modeling and word representations (RNN / ConvNets, TF-IDF, LDA, Word2Vec), \\nWorking with data science workbench solutions (Dataiku, IBM DSX, Domino), \\n\\nAll offers for employment with Wells Fargo are contingent upon the candidate having successfully completed a criminal background check.', 'Transition data storage to Cloud environments (Google or Azure).', 'Deep understanding of relational database technologies and database development techniques, Experience working in a version-controlled (Git) development environment is strongly preferred\\n\\nFamiliarity with media data sets (Nielsen, comScore, Adobe Analytics, social platforms, etc.)', ', Bachelor‚Äôs degree in marketing, business, finance or other quantitative field., Over three years of marketing analytics experience., Proficient at Excel, PowerPoint and Word, Tableau., Experience with statistical packages such as SAS and reporting packages., Experience with using web analytics tools such as Google Analytics., Experience with using CRM data from Salesforce., Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.', 'Creative problem solver, ability to handle multiple projects, and strong work ethic needed\\n, Preferred:, Previous experience in an eCommerce or Logistics/Supply Chain management environments\\nAzure Machine Learning Studio or comfortable working in cloud hosted environments (AWS, Google Cloud, etc)\\nActive Kaggle user\\nStrong statistical analysis background]\"\\n\"[Data Scientist - 23258, \\n\\nData Science - USA Tampa, Florida, \\n\\nThe Nielsen Company is the largest global measurement company in the world with unique measurement technologies, assets, and data that make it one of the most interesting and challenging places for a measurement or data scientist to work.', 'And our teams are dedicated to helping our customers ‚Äî developers, small and large businesses, educational institutions and government agencies ‚Äî see the benefits of our technology come to life., Facilitate deep technical discussions with customers, partners, and Googlers.', \"Employees have the opportunity to gain invaluable experience and make a significant impact on the business outcomes of our clients and our company., \\n\\nOver the past years, Maven Wave has received the following awards and accolades:, \\n\\nGoogle Cloud North America Services Partner of the Year, 2018\\n\\n#21 Best Workplaces in Chicago, FORTUNE, 2018\\n\\nGreat Place To Work Certification, Great Place to Work, 2017 & 2018\\n\\nFast Fifty, Crain's Chicago Business, 2014, 2015, 2016, 2017, 2018\\n\\n101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR), 2014, 2015, 2016, 2017, 2018\\n\\nTop Google Cloud Partner, Clutch, 2017\\n\\nFastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine, 2016, 2017\\n\\nTop IT Services Companies, Clutch, 2015\\n\\nGoogle Global Rising Star Partner of the Year 2015, \\n\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions.\", \"You'll continuously explore and experiment with our advanced suite of products, partner tools, and third party applications to build and deploy cloud solutions that address customer use cases, all the while sharing valuable feedback with our product teams as you develop complex architectures, standard methodologies, and key strategies., \\n\\nGoogle Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.\", \"You will have the opportunity to analyze large datasets in a collaborative team work environment providing daily challenges and ongoing learning., Hallmark‚Äôs Data Scientist perform data analyses to derive insight, patterns and correlations from Hallmark's big data that includes vast amounts of consumer data, store data, product sales data, and other relevant data.\", 'Led by scientific experts from MIT, Harvard, Mayo Clinic and UCSD, and successful drug developers, informaticians, and company builders, Engine is working on multiple programs and therapeutic areas and growing rapidly across US and Asia., The Bioinformatics & Data Scientist will analyze multi-dimensional biological and genomics data, enhance algorithms and develop novel methods for the utilization in Engine‚Äôs analytics platform that combines advanced system biology analytics with genomics data science and machine learning for accelerated drug discovery and biomarker identification.', 'Experience with Google Suite (Docs, Sheets, Slides, etc.', 'We also implement metrics to track the impact of new product experiments and more generally find ways to make very large scale data approachable to guide our decisions., Twitter has very large and complex datasets.', 'Experience with integration, and analysis of data from multiple sources using tools like: Hive, Impala, Rstudio, Splunk, etc.', '\"[At Google, we work at lightning speed.', 'Then I have the right opportunity for you!, \\n\\nThe Company:, \\n\\nOur Google-backed client has recently closed 30M in funding, located in the Bay Area specializes in autonomous vehicles.', 'You will also collaborate closely with Engineers, Program Managers and other stakeholders to implement model-based solutions, measure the effectiveness of programs, and drive customer growth and success., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.', \"So, bring your creativity and pioneering spirit to KPMG Lighthouse., \\n\\nKPMG is currently seeking a Director to join our KPMG Lighthouse - Center of Excellence for Advanced Analytics., \\n\\nResponsibilities:, \\n\\nLead workshops, innovation sessions with clients, multi-disciplinary, and cross-functional teams to identify business opportunities and artificial intelligence solutions utilizing processes and best practices to plan, lead, and execute delivery of artificial intelligence engagements across different areas (risk management, financial services, mergers and acquisitions, and public policy)\\n\\nLead in a fast-paced and dynamic environment utilizing virtual and face-to-face interactions; Manage complex workstreams, expectations, budgets, deliverables, and multiple responsibilities using structured approaches for operational excellence and communicating results to executive level audiences\\n\\nWork with clients to discover data sources, and create data requests; Lead the ETL process to ingest structured data and annotation processes to enrich unstructured data; Leverage a variety of data sources (social media, news, internal/external documents, images, video, voice, emails, financial data and operational data)\\n\\nLeverage a variety of tools and approaches to solve complex business objectives, from Statistical Natural Language Processing, Information Retrieval/Extraction, Machine Learning/ Deep Learning, Image Processing, Rules Engines, Knowledge Graphs and Semantic Search\\n\\nPlan and manage engagement objectives and key deliverables using analytics processes to mitigate risks in data, modeling, validation and delivery while working with team members to capture assumptions, risks, and develop approaches to mitigate issues\\n\\nRefactor, deploy, and validate models; work with clients iteratively to validate performance metrics, and sample output to drive towards a business-first solution utilizing APIs, platforms, containers, multi-threading and distributed processing to achieve throughput goals, \\n\\nQualifications:, \\n\\nMinimum of ten years of experience leading teams of at least ten data scientists, engineers, and other data & analytics professionals, including business development, requirements gathering, people development, and quality management using analytics and software development processes for natural language processing, machine learning on unstructured data, and/or information retrieval; Multidisciplinary backgrounds\\n\\nMaster's degree from an accredited college/university in Computer Science, Engineering, or related fields; PhD from an accredited college/university is preferred\\n\\nAbility to work with the business to understand business goals to create an artificial intelligence solution and an accompanying business case that meets the business objectives and business constraints; With expertise in delivering projects using leading processes including strong knowledge of data discovery, cleaning, model selection, validation and deployment\\n\\nUnderstanding of data preparation, machine learning, deep learning, natural language processing, and development practices (testing, code design, complexity, and code optimization); Ability to discuss mathematical formulations, alternatives, and impact on modeling approach\\n\\nFluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly; Work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\\n\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.\", 'Technical Experience and Expertise:\\n\\nBig data technologies such as Hive, Hadoop, MapReduce, PIG, Google BigQuery, Oozie, etc.', 'Experience with Java, SQL and NoSQL databases, data analytics (such as pattern recognition & change detection) is highly desired., \\n\\nRequisition ID: 25608, For Benefits Information, click http://hrweb.mit.edu/benefits, MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.', '\"[Analyze information from various sources to identify options and communicate recommendations\\n\\nPresent information that summarizes overall application or technology status and trends for business level review\\n\\nReview the work of others to provide design or programming recommendations and guide work to completion\\n\\nMentor and coach others to enhance professional and technical skills\\n\\nAnalyze requirements for software programs or application enhancements\\n\\nCreate detailed programming specifications\\n\\nWrite or modifies code for complex software programs, components or applications\\n\\nSupport and clarify direction in times of change to minimize confusion or disruption to business processes\\n\\nReview documentation and ensure standards are being met\\n\\nOn-call hours and limited travel may be required, Bachelor\\'s degree in an Information Technology discipline or related field (Computer Science, Software Engineering) and six years of work experience designing, programming, and supporting software programs or applications\\n\\nInstead of a degree, eight years of related work experience designing, programming, and supporting software programs or applications may be accepted, In-depth knowledge of computer coding/programming languages and software development concepts in a large IT environment\\n\\nAn understanding of Kafka, NiFi, Spark Streaming and IoT architectures and concepts\\n\\nExperience in developing applications in Spark\\n\\nHortonworks or Cloudera certification\\n\\nFamiliarity with capabilities within AWS, Azure, or Google Cloud Services\\n\\nHands on experience with HBase, Cassandra, or other NoSQL database\\n\\nUnderstanding of version control systems, particularly GIT\\n\\nIn-depth knowledge of data structures, data management practices, system interaction patterns and interfaces\\n\\nIn-depth knowledge of vendor software integration and interaction patterns\\n\\nAdvanced analytical, technical troubleshooting, diagnosing and problem-solving skills\\n\\nNegotiation skills and ability to influence others by educating and sharing information\\n\\nInterpersonal skills and ability to motivate and inspire others to achieve goals and accomplish work\\n\\nCoaching skills and ability to assist others in learning new technical and professional capabilities\\n\\nListening, verbal and written communications skills with the ability to translate technical information into understandable terms to a variety of audiences\\n\\nPresentation skills and ability to present information in various ways to meet audience needs\\n\\nUses a variety of techniques to demonstrate product expectations and prevent production problems, Annual gainshare bonus of up to 30% of your salary; Progressive rewards each of us with an annual bonus based on company performance\\n\\n401k which includes dollar-for-dollar company match of up to 6%\\n\\nDedication to work/life balance which includes flexible work arrangements and tools to support your lifestyle\\n\\nCommitment to IT innovation through initiatives like our Business Innovation Garage where professionals can test new ideas, technology and prototypes\\n\\nDynamic company culture that encourages engagement, supports Employee Resource Groups, values your input and embraces a relaxed atmosphere\\n\\nOnsite gym and wellness programs with discounts & rewards\\n\\nHealthcare onsite and standard benefits (medical, dental, vision)\\n\\nRelocation assistance to Northeast Ohio or Colorado Springs available\\n\\nLearn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\\n\\nLearn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk, Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\\n\\nLearn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk]\"\\n\"[Where good people build rewarding careers., Think that working in the insurance field can‚Äôt be exciting, rewarding and challenging?', \"Actively partner and develop effective relationships with related groups in eCommerce management, eMarketing, product and tech to facilitate and manage efforts across teams to turn insights into practice on the site., Qualifications\\n\\n4-year Degree in Marketing, Finance, Economics, Mathematics or related areas of study\\n\\n4+ years experience working in data analytics or related areas\\n\\n2+ years experience using web analytics tools such as Adobe Analytics/Omniture, Google Analytics, or similar\\n\\nProficient in web analytics fundamentals and website measurement strategy, \\n\\nKnowledge of data modeling (using SQL, Python, and/or Excel) to support our S&OP team's demand planning process\\n\\nAbility to construct custom queries using web analytics tools\\n\\nGood knowledge eMarketing activities such as SEM/SEO, remarketing/retention, targeted display, affiliates, etc.\", 'Job Description includes:\\n, Experience in defining Data standards, Data governance and lineage, and Data migration between data base technologies\\n\\nDefine standards for data tagging into a data lake following industry best practices\\n\\nDefine Metadata standards\\n\\nGuide programs related to data standardization, data stewardship and master data management\\n\\nAbility to work with large amounts of data: facts, figures, and number crunching\\n\\nFamiliarity with establishing Master Data Management and Reference Data repositories\\n\\nFacilitate data meetings\\n\\nBuild data assessment metrics\\n\\nFamiliar with ETL/ELT best practices in the creation of the database\\n\\nWorking knowledge of message queuing, stream processing, and highly scalable big data stores\\n\\nDevelop and drive data governance, quality and analytics initiatives are executed successfully to provide appropriate data, information & analysis to various business functions/departments\\n\\nCommunicate effectively, both orally and written, to varied levels of the organization to include technical personnel, business managers, and senior leadership, Required Experience, Data architecture experience; experience including but not limited to metadata management, reference and master data management, data warehousing and business intelligence management and document and content management\\n\\nBreadth in established and emerging data technologies\\n\\nStrong critical thinking and problem solving skills\\n\\nExperience with relational SQL and NoSQL databases\\n\\nAbility to conceive and portray the big data picture\\n\\nAbility to astutely operate in the organization: well respected and influential, able to emphasize methodology, modeling, and governance, technologically and politically neutral, articulate, persuasive, and a good salesperson, and enthusiastic, Education Requirements, Bachelor‚Äôs Degree (preferred Master‚Äôs) in Computer Science, Information Systems, Data Analysis, Systems Engineering, Applied Mathematics/Statistics, Operation Research, or other physical science/engineering fields, Desired Requirements, Experience with Big Data solutions\\n\\nHands on experience working with AWS products (S3, Redshift, EC2, RDS, Aurora, Glacier), certifications recommended\\n\\nData intelligence (i.e., data mining and profiling) Data governance to establish guidelines and processes for a data management program for the enterprise is a plus\\n\\nData Analytics\\n\\nKnowledge/familiarity with DAMA and the Data Management Body of Knowledge, Security Clearance Level, Must be able to obtain and maintain a US Department of Defense SECRET Security Clearance]\"\\n\"[\\nAnalyze information from various sources to identify options and communicate recommendations\\n\\nPresent information that summarizes overall application or technology status and trends for business level review\\n\\nReview the work of others to provide design or programming recommendations and guide work to completion\\n\\nMentor and coach others to enhance professional and technical skills\\n\\nAnalyze requirements for software programs or application enhancements\\n\\nCreate detailed programming specifications\\n\\nWrite or modifies code for complex software programs, components or applications\\n\\nSupport and clarify direction in times of change to minimize confusion or disruption to business processes\\n\\nReview documentation and ensure standards are being met\\n\\nOn-call hours and limited travel may be required, \\nBachelor\\'s degree in an Information Technology discipline or related field (Computer Science, Software Engineering) and six years of work experience designing, programming, and supporting software programs or applications\\n\\nInstead of a degree, eight years of related work experience designing, programming, and supporting software programs or applications may be accepted, \\nIn-depth knowledge of computer coding/programming languages and software development concepts in a large IT environment\\n\\nAn understanding of Kafka, NiFi, Spark Streaming and IoT architectures and concepts\\n\\nExperience in developing applications in Spark\\n\\nHortonworks or Cloudera certification\\n\\nFamiliarity with capabilities within AWS, Azure, or Google Cloud Services\\n\\nHands on experience with HBase, Cassandra, or other NoSQL database\\n\\nUnderstanding of version control systems, particularly GIT\\n\\nIn-depth knowledge of data structures, data management practices, system interaction patterns and interfaces\\n\\nIn-depth knowledge of vendor software integration and interaction patterns\\n\\nAdvanced analytical, technical troubleshooting, diagnosing and problem-solving skills\\n\\nNegotiation skills and ability to influence others by educating and sharing information\\n\\nInterpersonal skills and ability to motivate and inspire others to achieve goals and accomplish work\\n\\nCoaching skills and ability to assist others in learning new technical and professional capabilities\\n\\nListening, verbal and written communications skills with the ability to translate technical information into understandable terms to a variety of audiences\\n\\nPresentation skills and ability to present information in various ways to meet audience needs\\n\\nUses a variety of techniques to demonstrate product expectations and prevent production problems, \\nAnnual gainshare bonus of up to 30% of your salary; Progressive rewards each of us with an annual bonus based on company performance\\n\\n401k which includes dollar-for-dollar company match of up to 6%\\n\\nDedication to work/life balance which includes flexible work arrangements and tools to support your lifestyle\\n\\nCommitment to IT innovation through initiatives like our Business Innovation Garage where professionals can test new ideas, technology and prototypes\\n\\nDynamic company culture that encourages engagement, supports Employee Resource Groups, values your input and embraces a relaxed atmosphere\\n\\nOnsite gym and wellness programs with discounts & rewards\\n\\nHealthcare onsite and standard benefits (medical, dental, vision)\\n\\nRelocation assistance to Northeast Ohio or Colorado Springs available\\n\\nLearn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\\n\\nLearn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk, Learn more about all Cleveland has to offerhttps://www.youtube.com/watch?v=56p2ENKC1Bw\\n\\nLearn more about all Colorado Springs has to offer https://www.youtube.com/watch?v=CDa2S6IwbGk]\"\\n\"[Data Engineer- Solution Design, \\n\\nData Engineers will report into MapR‚Äôs Professional Services Organization.', 'Twitter is an equal opportunity employer.', 'Use of Google Analytics and other analytic and statistical tools to provide in-depth statistical analyses to leverage data when making business decisions\\n\\nCommunicate insights to key internal stakeholders and executive leadership team\\n\\n\\n, Communicate insights to key internal stakeholders and executive leadership team\\n, Education:, \\nBachelor\\'s Degree Required (Concentration in a quantitative field preferred including Business, Engineering, Math, Statistics, Economics, Operations Research)\\\\\\nMaster\\'s Degree Preferred]\"\\n\"[Position Description, \\n\\nConsults with internal organizations on global strategic initiatives or multi-business initiatives in two or more functional business areas\\n\\nDevelops and directs one or more work streams of a cross-functional project to achieve desired results\\n\\nDevelops tools that that support decision making and business cases\\n\\nDrives the execution of multiple business plans and projects\\n\\nEnsures business needs are being met\\n\\nIdentifies and influences stakeholders\\n\\nPromotes and supports company policies, procedures, mission, values, and standards of ethics and integrity\\n\\nProvides supervision and development opportunities for associates, \\n\\nMinimum Qualifications, \\n\\nBachelor of Science or Bachelor of Art and 3 years\\' data analytics experience OR 5 years\\' data analytics experience OR Master of Science or Master of Art and 1 years\\' data analytics experience., \\n\\nAdditional Preferred Qualifications, 1 year\\'s experience leading project teams to solve problems.', ', Supports all aspects of data on-boarding, data cleansing, analytics, data interpretation and maintaining the analytic data warehouse., Consults with internal stakeholders on data requirements., Will work with unstructured data sets to identify information that can be used for predictive modeling/analytics, Implements best practices to deliver scalable marketing analytics in partnership with the segment analysts., Performing other duties as assigned or apparent., Qualifications, experience and personal specification, Google Analytics (or similar) guru & comfort with large record data sets\\nStrong quantitative and analytic ability with attention to detail.', 'For more information, visit www.weatherford.com and connect with Weatherford on LinkedIn, Twitter, YouTube and Facebook., \\n\\nWeatherford delivers innovative technologies and services designed to meet the world‚Äôs current and future energy needs in a safe, ethical, and sustainable manner.', 'They will have an appetite for learning new technology with an eye for the value it can create., \\n\\nResponsibilites:, \\n\\nWork closely with in-house subject matter experts to thoroughly understand the business domain and use that knowledge to help define, design and implement machine learning systems\\n\\nHelp define project goals and timelines\\n\\nEvaluate new architectures for feature extraction to optimize and extend machine learning models\\n\\nTake ownership of text analysis, image and form recognition projects\\n\\nCreate systems for evaluating model accuracy and anomaly detection\\n\\nWork with development team to put models into product and scale them properly, \\n\\nRequired Skills/Qualifications:, \\n\\nDevelopment languages including Python, R and Javascript\\n\\nMachine learning frameworks such as Tensorflow and Keras\\n\\nData Science algorithms such as decision trees, linear regression, clustering, word embeddings\\n\\nCloud ML resources like Google Cloud Platform\\n\\n.NET Experience is a plus\\n\\nOCR Experience is a plus\\n\\nExperience implementing successful machine learning systems\\n\\nCreativity and willingness to be open and share ideas]\"\\n\"[\\nExperience with machine learning algorithms and development on Cloud platforms\\nExperience with Python, R, and Java\\nAbility to manipulate, integrate, and analyze large and complex data sets using SQL and no-SQL database platforms\\nAbility to provide non-technical users with data-driven tools for implementing machine learning into workflows, as needed\\nBA or BS degree\\n, \\nExperience with health data sets, including electronic health records, clinical data, and claims data a plus\\nExperience with developing machine learning, deep learning or natural language processing unstructured text data\\nExperience with leading technical project teams\\nMA or MS degree\\n]\"\\n\"[Engage with Actuaries in order to develop innovative BI solutions containing actuarial methodologies to drive business decisions across all of Actuarial and Underwriting.', 'Experience with cloud analytics platforms such as Microsoft Azure/AWS/Google Cloud Platform.', \"Experience in using statistical analysis and data science to drive corporate decision making\\n\\n5+ years of experience preferred\\n\\nBachelor‚Äôs degree in business, data science or other quantitative discipline; Masters degree preferred, Dell offers:, \\n\\nOpportunity to work with a strong brand at one of the world's largest IT solutions providers\\n\\nDynamic, challenging, international work environment\\n\\nA team with a high level of energy, integrity and motivation to win\\n\\nExciting internal career opportunities\\n\\nA commitment to diversity and inclusion\\n\\nCompetitive compensation including bonus plans & a great benefit package\\n\\nAn individual professional development plan, Company Description, \\n\\nWith more than 100,000 team members globally, we promote an environment that is rooted in the entrepreneurial spirit in which the company was founded.\", 'If you are a Senior Engineer or Manager, looking for a step up and the chance to really make an impact on businesses across the nation, this could be the role for you., \\n\\nThe Role:, \\n\\nAs Analytics Engineer Manager, your responsibilities will include:, \\n\\nMentor and lead data engineers\\n\\nParticipate in strategic discussions for continued advancement of data infrastructure\\n\\nDesign, build and launch robust data pipelines and platform to ingest data and deployment of ML products/model\\n\\nDesign, build and launch highly scalable analytic tools\\n\\nPartner with other teams and intern stakeholder to gather requirements, \\n\\nYour Skills & Experience:, \\n\\nBachelor\\'s degree or high qualification in Computer Sciences or relevant degree\\n\\nProduction level code in Python is a must\\n\\nStrong commercial experience in Spark and Kafka is essential\\n\\nExperience with Google Cloud Platform or AWS is a must\\n\\nStrong communication skills\\n\\nDemonstrable ability to work with real-time data sets and reducing latency, \\n\\nBenefits:, \\n\\nSalary is $150,000 - $180,000, + bonus + equity]\"\\n\"[Senior Data Engineer, \\n\\nSan Francisco Bay Area, CA, \\n\\n$160,000 - $180,000 + Bonus + Equity + Benefits, \\n\\nFeel that your everyday work is not making a big impact on people\\'s lives?', 'For additional information on BlackRock, please visit www.blackrock.com | Twitter: @blackrock | Blog: www.blackrockblog.com | LinkedIn: www.linkedin.com/company/blackrock., Job Description:, Data Science at BlackRock:, \\n\\nIn February 2018, BlackRock announced the creation of a new central Data Science team in order to accelerate innovation and technology in artificial intelligence, and to have firm-wide impact using data science to solve strategic problems.', 'PREFERRED EXPERIENCE:, PREFERRED EXPERIENCE:, \\n\\nTechnical Expertise ‚Äì Experience with modeling tools & platforms (like MiniTab, R, Python, IBM SPSS, SAS or other), data management/data mining skills, visualization techniques and descriptive statistics to solve complex problems required.', 'degree in communications, journalism, mathematics, business administration or a related field preferred\\nFour to six years managing data analytics\\nAdvanced experience with Excel, Google Analytics/Omniture and native and aggregated social analytics platforms, including Sprout Social and Simply Measured\\nExperience working with CRM systems, including Salesforce, to interpret data\\nExperience working with content management systems, including Drupal\\n]\"\\n\"[\\nBachelors\\' degree in relevant field\\n3+ years of experience with data analysis and data interpretation with Army and/or DOD data sources\\nApplicant must be a U.S. citizen and have an active SECRET security clearance\\n, \\nExperience with Oracle and Microsoft Suite of software applications, highly desired\\nProject Management Institute Professional (PMP), a plus\\n]\"\\n\"[o Gain understanding of business processes in their assigned business unit.', 'Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \\n\\nPredictive Science is looking for a Chief Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them stand-up, manage, or take their data science practice to a whole new level.', 'We can only do that by understanding how people connect with those who mean the most to them., We are seeking innovative individuals who are energized by solving data mysteries; people who see the thought of bringing unknown or unexploited data to the Hallmark environment is a career high.', ', You have 3 years‚Äô experience and working knowledge of Lambda and Kappa architecture in a cloud environment (AWS, Google, Azure)\\n\\n, You have a deep understanding of SDLC, Agile methodologies, metadata, data modeling, and designing databases\\n\\n, Working knowledge on Linux/Unix Operating systems\\n\\n, Strong scripting skills - Python (a huge plus), Bash , Shell etc.', 'Leverage data to guide Analyst Relations leads to maximize amplification of IBM messages.Develop a keen understanding of how to build credible and impactful relationships with key influencers and leading industry analysts.', \"To learn more about Hill's and Colgate, please visit http://www.hillspet.com and http://www.colgatepalmolive.com, or find us on LinkedIn, Facebook, Twitter and YouTube., \\n\\nLocation: Topeka, Kansas, United States\\n\\nRelocation Assistance Offered Within Country\\n\\n# 62547, \\n\\nThe focus of the Data Scientist role is to analyze large amounts of complex raw and processed information to find patterns that will improve our understanding of the relationship between nutrition and health/wellbeing.\", 'Alternatively, summarize and critique a machine learning paper you have read that you found interesting., \\n\\n**Although cover letters are optional for most job applications at Google (as noted on the website), it is a mandatory component for this application.', 'Deep experience or knowledge in foundational information management arenas, such as Master Data Management, Data Governance, Modern Data Architecture, and Data Integration\\nExperience in Data Architecture/Modeling, ETL, Data Quality and MDM tools, including IBM Infosphere and Microsoft SQL Server Integration Services, Data Quality Services, and Master Data Services\\nExperience in architecting and implementing emerging technologies/tools, such as AWS, Hadoop, Cloudera, and/or Hortonworks, to address predictive analytics and unstructured data use cases\\nExperience in designing and implementing Next Generation Architecture solutions incorporating Big Data, NoSQL, Cloud-Based Analytics, and Real-Time Analytics\\nExperience in working with large volumes of data from disparate data sources across complex business processes and functions\\nMust have strong leadership and interpersonal skills to resolve problems in a professional manner, lead working groups, negotiate, and create consensus\\nMust be able to astutely operate in and navigate through client organizations\\nMust have strong written/oral communication and presentation skills\\nMust be highly self-motivated, entrepreneurial, humble, and curious\\n, Location, \\nWork remotely from home, your favorite coffee shop, or HatchWorks.', ', The Retail Marketing Analytics team develops and drives the advancement of the marketing data and analytics strategy for Hallmark Retail.', \"In this role, you'll be involved with product marketing strategy from beginning to end., \\n\\nGoogle has been at the forefront of data analytics and AI innovations and BigQuery is one of the most innovative and disruptive product offerings from Google in the data management space.\", 'In this role, you‚Äôll be responsible for driving product marketing for Google BigQuery and other data analytics solutions.', 'Splunk, PagerDuty, DataDog or Graphite), \\n\\nData Architecture & Governance, Zillow Group is owned, fueled and grown by innovators who help people make better, smarter decisions around all things home.', 'Comp Science, Math, Engineering) or related experience\\n\\n2+ years of collective experience in data engineering, data analysis, data warehousing, data integration or business intelligence, in a similarly sized organization\\n\\n2+ years of experience architecting, building and administering big data and real-time streaming analytics architectures in both on premises and cloud environments (AWS, Azure, Google) leveraging technologies such as Hadoop, Spark, S3, EMR, Aurora, DynamoDB, Redshift, Neptune, Cosmos DB\\n\\n1+ years of experience architecting, building and administering large-scale distributed applications\\n\\n1+ years of experience with Linux operations and development, including basic commands and shell scripting\\n\\n2+ years of experience with execution of DevOps methodologies and Continuous Integration/Continuous Delivery within a large scale data delivery environment\\n\\nSoftware development experience in least two or more of following languages: Java, Python, Scala, Node.js\\n\\nExpertise in usage of SQL for data profiling, analysis and extraction, Preferred Qualifications:, \\n\\nMaster‚Äôs Degree in a technical field (e.g.', 'Cloud ‚Äì AWS, Azure, Google, Languages/Libraries ‚Äì Python, Java, Scala, Spark, Kafka, Hadoop, HDFS, Parquet.', ', ABOUT EXPRESS SCRIPTS, \\n\\nAdvance your career with the company that makes it easier for people to choose better health., \\n\\nExpress Scripts is a leading healthcare company serving tens of millions of consumers.', 'Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world.]\"', 'X was formerly known as Google[x]., Partner cross-functionally with software engineers, aerospace engineers, flight operations/business teams to design, develop and deliver data pipelines that drive scalable operational excellence\\nDefine data sources and implement a customized real time, reliable system\\nMonitor, validate and maintain data pipelines to ensure consistent performance\\n, \\nBachelor\\'s degree in Computer Science, Mathematics, related technical field or equivalent practical experience\\n5 years of experience in data engineering in a cloud based environment\\nExperience with data analysis tools (such as SQL, PLX and with data processing algorithms such as Flume, MapReduce)\\nCoding experience with one or more of the following languages: Java, C++, Python, Go and/or JavaScript\\n, \\nExperience developing pipelines using Google proprietary backend and frontend tools\\neCommerce experience]\"\\n\"[\\n\\nWork with others to define, and propose for approval, a modern data platform design strategy and matching architecture and technology choices to support it, with the goals of providing a highly scalable, economical, observable, and operable data platform for storing and processing very large amounts of data within tight performance tolerances.', ', Key Responsibilities:\\n\\n, Build and validate large-scale batch and real-time data pipelines with Big Data Technologies such as Talend Real-Time Big Data Platform, Python, Spark, Hadoop, Hive, Pig, Redshift, Snowflake, NoSQL DB on AWS/Google Cloud\\n\\nEvaluate, configure and implement new technologies, methodologies and architecture design patterns to build data processing ETL pipeline\\n\\nDesign and Develop processes for data discovery, modeling, mining and archival\\n\\nCollaborate with data analytics team to ensure the integrity and availability of the data necessary for the business analytics & reporting\\n\\nThink strategically & bring new ideas to build the ETL pipeline architecture and how to scale it with the business as it grows\\n\\nBuild reusable components and framework to speed up the data pipeline development\\n\\nProvide guidance/ directions to the data engineers team and implement best practices as well as standards across all the data pipelines\\n\\n, Education & Technical Experience Requirements:\\n\\n, Bachelor‚Äôs in computer science, science, or similar field of study\\n\\n8+ years of Data Warehousing, OLAP, SQL Queries, ETL/ELT design and development experience\\n\\n3+ years of experience with AWS services including S3, Redshift, EMR, Lambda and RDS\\n\\n3+ years of solid experience in developing and performance tuning the data pipeline with Hadoop, Hive, Spark, Talend Big Data Platform\\n\\n3+ years of experience in programming languages such as Python, Scala, R, Java or C#\\n\\n2+ years of experience with parallel computing, batch processing, and stream processing using tools such as Kinesis or Kafka\\n\\n2+ years of experience in columnar databases such as RedShift, Snowflake as well as NoSQL databases such as MongoDB, DynamoDB\\n\\nSelf-starter and highly motivated to add value to the team and platform using innovations around data and data solutions\\n\\nExperience in dealing with the structured, semi-structured and unstructured datasets\\n\\nExcellent communication skills to collaborate with the data engineering, analytics and science teams\\n\\nExperience in Social Media Datasets such as Twitter, YouTube, Facebook, Instagram is a plus\\n\\nExperience in Google Clickstream, DFP, or Adobe Analytics datasets is a plus\\n\\nExperience in dealing with the Media content subscription-based datasets is a plus\\n\\nExperience in creating restful API‚Äôs is a plus\\n\\nExperience in AI, machine learning and statistics is a plus\\n\\nExperience in Media and Entertainment Industry is a plus\\n\\n, _]\"\\n\"[\\n3 years of experience with Big Data, systems, including Hadoop, Hive, and Pig\\nExperience with ETL tools, including NiFi and StreamSets\\nExperience with Java\\nExperience with using Cloud services, including Amazon Web Services (AWS), Azure, or Google Cloud\\nTop Secret clearance\\nBA or BS degree\\n, \\nExperience with Agile software development\\nPossession of excellent oral and written communication skills\\nBS degree in CS, Computer Information Systems, Information Systems, or a related field\\n]\"\\n\\n\"[Are passionate about working on cutting edge, high profile projects and are motivated by delivering solutions on an aggressive schedule\\nAren‚Äôt satisfied with status quo, insatiably curious, and regularly look for creative ways to solve problems and help your team meet commitments\\nLove learning new technologies and sharing them with your team\\nHave a keen interest in using any and all appropriate tools, especially Cloud-based and Open Sourced, to solve the problem at hand\\nHave strong verbal and written communication skills, and enjoy participating in dynamic, face-paced collaborations with customers, vendors, and other engineering teams to solve complex business problems together\\nUse your experience and leadership skills to motive your teammates to deliver high quality results in a fast-paced work environment\\n, Work within a team of like-minded professionals to design, build and deploy critical business and mission data-centric applications in a production environment\\nDesign and implement appropriate data extraction, transform, and load (ETL) processes to properly prepare data, ensuring data quality and accuracy, for consumption by business and mission applications\\nIdentify, retrieve, manipulate, relate and/or exploit multiple structured data sets from various sources\\nDesign and implement data storage, sharing, and dissemination environment, ensuring support for all relevant agency and community policies\\nEngineer suitable data management and governance procedures and provide production support when required\\nDesign and develop automation workflows, perform unit tests and conduct reviews to make sure your work is rigorously designed, elegantly coded, and effectively tuned for platform performance, and assess the overall quality of all delivered components\\n, Master\\'s Degree preferred, or a Bachelor‚Äôs degree and 4 years‚Äô experience, or 10 years of specialized experience\\nMinimum 4 years‚Äô experience working on complex data/database projects as a data analyst, data architect, or database engineer\\nTS Clearance with ability to obtain an SCI and CI poly\\n, Certified Data Management Professional (CDMP), Microsoft Certified Solutions Associate (Business Intelligence) or equivalent certification(s) strongly desired\\nExperience building n-tier web-based applications using SQL and non-SQL back-ends\\nExperience with large-scale data processing tools, such as Spark, NiFi, Hadoop, Kafka, etc.', 'Using analytical rigor and statistical methods, you mine through data to identify opportunities for Google and our clients to operate more efficiently, from enhancing advertising efficacy to network infrastructure optimization to studying user behavior.', 'Experience with Google Analytics is a plus\\n\\nStrong technical aptitude and a willingness to learn and adapt to new and evolving technologies\\n\\nExcellent communication skills\\n\\nTeam Skills: facilitation, presentation & group dynamics, \\n\\nMuch has changed since our start in 1912, but the important things remain the same.', 'in Computer Science, Informatics, Mathematics, Electronic/Electrical Engineering or other relevant field with an emphasis on data analytics.Experience with big data technologies such as Hadoop, Apache Spark, NoSQL databases.Strong computer science grounding, with knowledge of data structures, algorithms and computer architectures.Proficiency developing in one or more languages such as C++, Python or Java.Self-starting, requiring minimal supervision with strong problem-solving skills.Excellent communication and teamwork skills., \\n\\nDESIRED QUALIFICATIONS:, Hands-on experience with Cloud environments, such as AWS, Google Cloud, or AzureExperience with Cloudera, Job Function\\n\\n, R&D, ___________________________________________________________________________________, \\n\\nPrivacy Statement, \\n\\n***Keysight is an Equal Opportunity Employer.', 'Experience working with Journey, Voice of the Customer and operational data sources such as Splunk is preferred\\nExperience working with Web and native Mobile app data\\n\\nExperience applying aggregations, segmentation, statistics, clustering, to complex business problems.', 'Accepted file types are Microsoft Word (DOC or DOCX), PDF, HTML, or TXT., In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States.', 'Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, The following is required to be considered for this role:, Bachelor‚Äôs degree in Business or quantitative field (Data Science, Statistics, Analytics, Economics, Mathematics, Computer Science).', 'TrueCar offers a specialized digital marketplace and private targeted incentive solutions to help make that spend more efficient, while at the same time providing exclusive savings to the 6M+ consumers who visit our car buying service sites\\n\\n, ABOUT THE JOB:\\n\\n, Serve as the champion in data visualization techniques, analytics, dashboard design, and best practices for information delivery\\n\\nOwn all aspects of analytics, reporting, design, and optimization insights for our all of our TrueCar OEM affinity partners\\n\\nBuild, maintain and iterate on Tableau data visualizations\\n\\nSupervise creation of all visual reports in Tableau for internal and external clients that summarize findings clearly and effectively\\n\\nCollaborate with data engineering team to design data pipelines for Tableau Server\\n\\nLead data analysis projects from the research phase to production\\n\\nDevelop analytics and reporting capabilities for new OEM and Partner programs using Tableau and PowerPoint as they launch\\n\\nTrack and measure optimization efforts using Google Analytics or Redshift/SQL\\n\\nUnderstand program results from key marketing and product initiatives and articulate the key drivers of program success or needs for improvement\\n\\nLeverage insights created by the OEM Partner & OEM team into actionable recommendations to improve program performance\\n\\nMust be well-spoken and comfortable with presenting to an executive audience\\n\\nAnalyze digital marketing campaigns and provide cost analysis\\n\\n, WHAT YOU NEED:\\n\\n, 3 - 5+ years‚Äô experience working in an analytics role\\n\\nA passion for using data visualization to tell complex data stories\\n\\nAbility to communicate complex ideas to any audience, ranging from teammates to business executives\\n\\n3+ years of profession experience creating Tableau dashboards\\n\\nExperience with publishing and maintaining workbooks on Tableau Server\\n\\n3+ years of experience with database software (RedShift, Hive, SQL, MYSQL, ‚Ä¶)\\n\\nExperience with statistical programming software (Spark, R, Python preferred)\\n\\nProficiency with Tableau Desktop and Server\\n\\nBachelor‚Äôs Degree in Statistics, Data Science, Economics, CS, Engineering or related field\\n\\nStrong analytical background, with experience identifying trends and key takeaways from data\\n\\nAbility to analyze, organize, and integrate large amounts of complex data into clear and concise presentations and status reports\\n\\nOutstanding attention to detail and time-management skills\\n\\nExpert knowledge in Excel and PowerPoint required\\n\\nExperience tracking web metrics using Google Analytics\\n\\n, NICE TO HAVE:\\n\\n, Passion for the automotive and internet industries\\n\\n]\"\\n\\n\"[EBSCO Information Services (EIS) provides a complete and optimized research solution comprised of e-journals, e-books, and research databases ‚Äî all combined with the most powerful discovery service to support the information needs and maximize the research experience of our end-users.', '\"[Define database physical structure and functional capabilities, security, back-up, and recovery specifications.Install database systems by developing flowcharts; applying optimum access techniques; coordinating installation actions; document actions.Map data elements from client systems to target application for ingestion and processingMaintain database performance by identifying and resolving production and application development problems; calculating optimum values for parameters; evaluating, integrating, and installing new releases; completing maintenance; answering user questions., Bachelors degree and 5 years total relevant experience or equivalentAt least 3 years‚Äô experience as Data Analyst.As per TO2 of the contract, one of the discriminating factors for selecting the deployment architecture alternative shall be:Data acquisition, data processing and data lifecycle managementThe contractor should be able understand the selected alternative for data architecture, and help in mapping data from SSA systems to the IBM Counter Fraud Management Solution (ICFM) in the pre-production and production environments.Good communication skills, and problem solving abilities., Do you have what it takes to be mission critical?, \\n\\nWe are always looking for team members that have what it takes to be mission critical.', 'Familiarity with Google Cloud Platform (e.g.', 'At TMS, we‚Äôre the agency AND the client!, \\n\\nWhat you‚Äôll do:, \\nEstablish reporting processes and implement regular reporting on all marketing initiatives\\nAnalyze and interpret data into thoughtful market strategy\\nAcquire and manage data from both primary and secondary sources\\nIdentify, analyze, and interpret trends and correlation in large data sets\\nExplore correlation and regression models in data sets\\nManage and design reporting dashboards for Executive view\\nAssess the performance of tests, updates, and strategic optimizations, Requirements:\\n\\n, 2 years of experience as a data analyst or business data analyst\\nMust have an advanced user understanding of Microsoft Excel and PowerPoint\\n\\nProficient with Excel Tables and Pivot tables\\nProficient knowledge of Power Pivot, Power Query, and Power\\nStatistical modelling experience\\nBachelor‚Äôs degree, related advanced degree a plus\\nAbility to work under pressure with ambiguous or competing priorities\\nKnowledge in website analytics tools such as Google Analytics\\nProficient computer skills, Microsoft Office Suite (Word, PowerPoint, Outlook, and Excel)\\nExcellent analytical and time-management skills\\nStrong project management skills with ability to supervise multiple projects\\nExperience in Salesforce Marketing Cloud is a plus\\nExperience in the mortgage industry is a plus, Proficient with Excel Tables and Pivot tables\\nProficient knowledge of Power Pivot, Power Query, and Power\\n]\"\\n\"[It‚Äôs Time For A Change‚Ä¶, \\n\\nYour Future Evolves Here, \\n\\nEvolent Health has a bold mission to change the health of the nation by changing the way health care is delivered.', 'Education\\n\\n\\nBachelors or above in Operations Research, Math, Statistics, Computer Science, Physics and Economics\\n]\"\\n\"[\\n5+ years of experience\\nPredictive modeling (eg: neural networks, logistic regression, variable reduction, imputation)\\nStatistical Analysis with R, Python, or other scripting language\\nLinux command line (eg: Bash, AWK, Perl, Sed)\\nFamiliar with RDBMS concepts\\nData visualization (eg: ggplot, Python, Splunk, Tableau, Excel)\\nProven quick self-directed learner\\nGood communication skills\\nTeam Player\\nBA or BS in Math, Computer Science, Engineering, Physics, or a related field\\nExposure to the areas of AI, ML, and Data Science with an ability and desire to grow\\n, \\nMachine learning libraries (eg: Tensor Flow, Keras)\\nHadoop (Hive, Impala, MapReduce)\\nCloud (AWS, Azure)\\nIT Infrastructure Engineering exposure\\nRegular expressions\\nInfrastructure components (e.g.', 'Deep understanding of digital advertising industry and Google‚Äôs ad product suite in particular ad serving and yield management expertise.', 'Create automated systems to track performance metrics\\n\\nIdentify and troubleshoot any issues or discrepancies\\n\\nProject coordination and management - manage multiple high priority tasks/projects simultaneously\\n\\nTrack project performance, specifically to analyze the successful completion of short- and long-term goals, \\n\\nIntegrate data from others sources into the system\\n\\nConsistently maintain and improve the system, \\n\\nData Science / Statistics / Quantitative / Mathematics / Economics background\\n\\nMust have experience with Google Sheets, Excel, Tableau, SQL, Google Forms, Google Slides and/or PowerPoint\\n\\nKnow at least one script language, such as Python or JavaScript\\n\\nFamiliarity with database engines, such as SQL Server, \\n\\nPossess strong communication skills, and specifically an ability to take a complex problem and explain it very simply\\n\\nBe a teamplayer who enjoys cross-functional collaboration with colleagues and teams worldwide\\n\\nBe a technical expert - not only fix issues as they arise, but be a proactive adviser to your manager and the Global Security team\\n\\nBe driven and self-taught - seek solutions, identify gaps, create solutions and solve problems independently\\n\\nPossess high integrity - you will be responsible for handling and safeguarding sensitive data, and encounter potential exposure to incident reports.', 'Experience with, MATLAB or a similar mathematical programming language is desirable., Experience or research work related to satellite orbits is particularly, desirable., MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.', 'Getting the answers you need to solve a problem from Google, finding the right person to ask, or digging deep technically\\nMentoring junior developers.', 'AspenTech‚Äôs customer list (over 1700 companies) includes the world‚Äôs leading companies such as ExxonMobil, Shell, Dow Chemicals and BASF.', '\"[\\nLanguages: Python\\nBatch and Stream Processing with Beam, Data Bricks, Dataflow, Kinesis, BigTable\\nData Warehousing: BigQuery, Google Storage\\nExperience building and managing efforts in both batch and streaming data processing pipelines with technology like Beam, Spark, etc.', '), Caffe/TensorFlow/Keras/etc, Hadoop, Spark, PigExperience providing direct support to analystsExperience building models and tools to help analysts understand data and answer intelligence questionsExperience using Data Science libraries in Python or R: tidyverse, NumPy, SciPy, PandasFamiliarity with commercial and open source data science software: IBM SPSS Modeler, SAS, KNIME, RapidMiner, StatisticaFamiliarity with software development (Scala, C#, Java, JavaScript, etc.', 'Knowledge of Google BigQuery and Java/Scala is a plus.', 'Learn more about Splunk careers and how you can become a part of our journey!, Splunk is looking for highly motivated college students to join our team.', 'Experience with Java (Python a plus)\\n\\nExposure to cloud based technologies like Google Cloud Platform, AWS.', ', A few reasons why this is the #BestJobEver, \\niD Tech has been voted a Top Workplace by the Bay Area News Group 8 times!', 'Familiarity with visualization software and techniques (including Jupyter Notebook, Google Cloud Datalab).', 'MIT Sloan Management Review says that in many organizations, there is a consistent disconnect between data scientists and the executive decision makers ‚Äì that‚Äôs why it‚Äôs time for a new role ‚Äì the data translator., \\n\\nHighmark Health‚Äôs Pharmacy Services Team has identified this exciting new role to play a critical role in bridging the technical expertise of data engineers and data scientists with the operational expertise of our Pharmacy frontline business staff., \\n\\nThe incumbent helps to ensure that the deep insights generated through sophisticated analytics translate into impact at scale in the Pharmacy organization.', \"You won't accept anything less than helping our dealer customers measure the success of their digital campaigns against their business goals with easy to understand dashboards and reports., \\n\\nResponsibilities Include:, \\n\\nOperate as the subject matter expert on web analytics, tagging, audience and attribution technologies\\n\\nWork with a variety of software platforms, including Google AdWords, Google Analytics, Google Tag Manager, Bing Ads, DSPs, PPC and social media platforms\\n\\nWork with internal clients and stakeholders to understand, design, and implement analytics solutions tailed to our customers\\n\\nImplement best practices to address customer and product analytics and reporting needs via dashboard and custom report templates\\n\\nTrack, prioritize, and manage analytics implementation initiatives across multiple teams; act as primary lead for analytics/tracking implementation efforts\\n\\nPartner with your product and development peers to develop processes to improve audience data capture and improve data collection capabilities\\n\\nManage testing and debugging of analytics/tagging code\\n\\nAssist in reporting and ad-hoc analysis of data with performance teams\\n\\nAssist peer groups in the development of, and reporting on, additional KPIs and metrics illustrating the success of customers' digital campaigns, \\n\\nQualifications, \\n\\nRequired:, \\n\\nBA/BS in Marketing, Business, Computer Science, Finance, Statistics or related field\\n\\n5+ years of professional experience in data analytics using and implementing solutions like Google Analytics / Analytics 360, Firebase, and similar.\", 'PIE engineers regularly participate in discussions with the most senior leaders at Twitter to understand how experimentation can further increase the rate of innovation.', 'Splunk, PagerDuty, DataDog or Graphite), \\n\\nOther AWS technologies (e.g.', 'As a software engineer, you will work on a specific project critical to Google‚Äôs needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve.', '\"[5-10 years‚Äô experience with Application/ System support, development and design\\n\\nExperience with IBM database management systems\\n\\nTechnical skills with DB2, QMF and SQL\\n\\nDemonstrated project management and communication skills\\n\\nStrong analytic skills, focus on problem determination and solving\\n\\nAbility to write technical and operational management documentation, 5-10 years‚Äô experience with Application/ System support, development and design\\n\\nExperience with IBM database management systems\\n\\nTechnical skills with DB2, QMF and SQL\\n\\nDemonstrated project management and communication skills\\n, Strong analytic skills, focus on problem determination and solving\\n\\nAbility to write technical and operational management documentation]\"\\n\\n\"[First San Francisco Partners is a business advisory and enterprise information management (EIM) consultancy dedicated to helping companies leverage their data to improve strategic decision-making, reduce risk, create operational efficiencies and fuel unprecedented business success.', 'Microsoft SQL Server Reporting Services, Visual Studio\\nTableau 10.5.5\\nMS Excel, Google Sheets\\nETL solutions using SSIS, PGAgent\\nAgile Development Methodology, Github, Jira, Fresh Service\\n, Location: Waltham, MA, \\n\\nAbout StudentUniverse\\n\\n, StudentUniverse is a Boston-based technology company that provides exclusive travel discounts, rewards, and experiences for students, faculty and youth (18-25).', 'Find us on Facebook at www.facebook.com/gettyimages and Twitter at https://twitter.com/GettyImages., \\n\\nGetty Images is an equal opportunity employer and strongly supports diversity in the workplace.]\"', ', \\nETL: Apache Airflow\\nContainer: Docker/Kubernetes\\nAPI: gRPC/Tensorflow Serving/Flask(REST)\\nDatabase: Google Datastore/MySQL/Google Spanner\\nDistributed Processing: Apache Beam/Apache Spark\\nMachine Learning: Tensorflow/Keras/Scikit-Learn, etc.', 'Additional specific qualifications include:, \\nExperience architecting, implementing and successfully operationalizing large scale data solutions in production environments using Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, EMR, Kinesis, BigQuery, DataProc, Azure Data Lake, etc.', 'Google Analytics, etc.', 'in Computer Science or a related technical field, or equivalent experience\\n\\n2+ years of experience in either data infrastructure or backend systems\\n\\nStrong understanding of SQL\\n\\nBroad knowledge of the data infrastructure ecosystem\\n\\nExperience with Hadoop or other MapReduce-based architectures\\n\\nExperience working with large data volumes\\n\\nGood understanding of one or more of the following: Scala, C++, or Java, \\n, Scalding\\n\\nFull Stack Development\\n\\nPresto or Hive\\n\\nSpark, \\n, Applicants will be considered for this role at all levels from SWE I to Senior SWE depending on qualifications., \\n\\nÔªøWe are committed to an inclusive and diverse Twitter.', ', Alternate Location:, Employment Opportunities, XTO Energy/ExxonMobil is an Equal Opportunity Employer.', '\"[Science and Technology on a Mission!, \\n\\nFor more than 60 years, the Lawrence Livermore National Laboratory (LLNL) has applied science and technology to make the world a safer place., Research, design, implement and apply a variety of advanced data science methods in multiple application areas (such as material science, high energy physics, predictive medicine, cybersecurity, climate modeling) in a collaborative scientific environment.Identify and define moderately complex problems stemming from national security applications; scope, plan, and propose advanced analysis methodologies; collect and analyze data; and document results in technical reports and peer-reviewed publications.Consult with programmatic sponsors and funding agencies and foster research collaborations with academia and industry.Author grant proposals, including proposal presentations and preparation of proposals.Perform other duties as assigned., Conduct independent research projects to establish future research directions.Lead small to mid-sized projects in advanced data science methodologies and tools and their application to mission-related science, serving as a primary technical contact., Ph.D. in Computer Science, Statistics, Machine Learning, Mathematics or related field or the equivalent combination of education and related experience.Experience working in a collaborative, multidisciplinary, scientific environment and contribute to diverse application areas.Broad experience developing, implementing, and applying advanced statistical and machine learning models and algorithms.Demonstrated research ability, as documented by publications, reports, and presentations.Broad analytical and problem-solving skills necessary to craft creative solutions and solve complex problems with limited direction.Comprehensive programming skills in at least one prototyping language Python/R/MATLAB, as well as one of C/C++/Fortran to enable high-dimensional data analysis on high performance computing (HPC) platforms.Proficient verbal and written communication skills to effectively collaborate in a team environment, to present and explain technical information, document work, prepare and present proposals and research papers, and provide advice to management., Record of successful proposal writing and program development, and experience leading research and development in support of programs or R&D.', '\"[\\nPrimarily using R, write and maintain scripts to clean and organize raw data sets\\nCreate cross-sectional and longitudinal data sets from raw data files\\nCreate systems for assuring data quality and accuracy\\nCreate visualizations to help users understand and explore data\\nRespond to organizational requests for data analysis\\nEnsure consistency between data analyses, Google-based tools, and Tableau dashboards\\n, \\nMaintain repository of R scripts for automated overnight data processing and incorporate new analyses and descriptives as needed\\nSupport the integration of additional data sources into New Visions data warehouse and data tools\\nSupport the operationalizing of robust data quality assurance within data infrastructure\\n, \\nCollaborate with data users to understand their needs, build tools, and conduct analyses to support them\\nSupport schools and network leaders in launching tools and analyzing data within tools to make evidence-based decisions\\nProvide analysis to Management Team, cross-network meetings, and other collaborative structures\\nDevelop mechanisms for collecting feedback and modifying analyses and data tools to reflect internal and external data priorities\\n, \\nMasters degree in public administration, public policy, education, statistics, economics, psychology, sociology, or related social science field.', '\"[Experience - Consulting experience and client interaction on challenging projects\\n\\nEducation & Training - Ongoing learning and development opportunities\\n\\nNetworking & Professional Development - IBM leadership and peer networking opportunities\\n\\nSupportive and dynamic team work environment\\n\\nCompensation ‚Äì our employees enjoy a competitive compensation package, Natural language processing by helping to understand the complexities of unstructured data\\n\\nHypothesis generation and evaluation by applying advanced analytics to weigh and evaluate a panel of responses based on only relevant evidence\\n\\nDynamic learning by helping to improve learning based on outcomes to get smarter with each iteration and interaction.', 'Together, we are on a quest to change banking for good., \\n\\nManager, Data Engineer, We are seeking a leader to help build Capital One‚Äôs next generation of data products and capabilities., \\n\\nOn any given day you will:, \\n\\nProvide guidance to business and tech partners on best methods to engineer data processes\\n\\nBuild data pipeline frameworks to automate high-volume and real-time data delivery\\n\\nDevelop applications from ground up using a modern technology stack such as Scala, Spark, Java, Postgres, Python, Angular JS, and NoSQL\\n\\nEngineer capabilities and pipelines for big data and machine learning solutions\\n\\nWork directly with Product Owners and customers to deliver data products in a collaborative and agile environment, Responsibilities:, \\n\\nLead and engineer sustainable data driven solutions with current new data technologies to meet the needs of our organization and business customers\\n\\nRecruit, manage, and retain a team of talented engineers\\n\\nInfluence peer teams and leadership to ensure our technology culture is one where engineers proudly do their best work every day\\n\\nRaise the bar for technical excellence\\n\\nMaster new technologies rapidly as needed to progress varied initiatives\\n\\nBreak down complex data issues and resolve them\\n\\nUnderstand complex multi-tier, multi-platform systems, Basic Qualifications:, \\n\\nBachelor‚Äôs Degree or military experience\\n\\nAt least 3 years of backend software engineering experience\\n\\nAt least 1 year of experience in cloud technologies AWS, Azure or Google Cloud, Preferred Qualifications:, \\n\\nMaster\\'s Degree\\n\\n1+ years of People Management experience\\n\\n1+ years of machine learning experience\\n\\n3+ years of experience with Agile engineering practices\\n\\n3+ years of experience with the Big Data stack EMR, Spark, Databricks\\n\\n3+ years of experience in at least one scripting language Python, Perl, JavaScript, or Shell\\n\\n3+ years of experience with UNIX/Linux, Capital One will not consider sponsoring a new qualified applicant for employment authorization for this position.]\"', ', \\nData mining, data reduction*\\nClassification (Decision Tree, clustering, bagging, boosting, logit regression)\\nPrediction (Neural Network) & validation (cross validation)\\n, \\nUtilization of statistical programming tools (R,SAS, SciPy), coding languages (Python, Java, C++), and Google tools (BigQuery*, TensorFlow)\\nComfortable with data retrieval and processing with SQL and NoSQL\\nSolid understanding of relational and non-relational database technology, cloud based data lake, ETL, data pipeline\\nUnderstanding of code version management system\\n, \\nSome management experience, enjoys mentoring, managing direct reports\\nHighly collaborative individual with great communication skill\\nDevelop communication styles focusing on technical details for non-technical audiences\\n, \\nDegree / equivalent experiences in applied quantitative field (Statistics, Mathematics, Econometrics, Engineering or CS).', ', JOB SPECIFIC KNOWLEDGE, SKILLS, AND EXPERIENCE, Bachelor‚Äôs degree in a highly analytical field such as marketing analytics, mathematics, economics, finance, information systems, or statistics\\n3+ years of experience providing data insights to a marketing team\\nExperience with creating predictive statistical models\\nExperience writing SQL, MySQL, and Python scripts\\nKnowledge of SAS, R, or another language with statistical capabilities\\nExperience utilizing data from a variety of internal and external sources including, but not limited to: Google AdWords and Analytics, Microsoft Dynamics CRM, Marketing automation platforms, AWS, third-party databases, etc.', 'Previous experience using web analytics tools (Google Analytics, etc.)', 'Ability and willingness to learn structured and unstructured data systems\\n\\n\\nExperience in developing business requirements for instrumentation with Google Analytics; ability to instrument in Google Tag Manager a plus\\n\\n\\nProficiency in effective report/dashboard design and standards\\n\\n\\nFamiliarity with data preparation, processing, classification, and forecasting\\n\\n\\nFamiliarity with the software product lifecycle\\n\\n\\nAbility to write SQL and create data visualizations\\n\\n\\nExperience with Amazon S3, Redshift, Athena, Google Tag Manager, Google Analytics, Google Big Query, Tableau, or JavaScript, are big pluses!', 'Predictive Science is helping companies such as Verizon, NFL, Neiman Marcus, Dell, VMware and many others unlock the power of their data by creating algorithms that are changing the world., \\n\\nPredictive Science is looking for a Data Scientist who can work with Fortune 1000 companies and other companies around the world to help them take on challenging data problems that can provide high impact results.', 'AWS Kinesis/Lambda, GC Pub/Sub)\\nCloud infrastructure devops to support deployment and data management\\nExcellent communication skills both written and verbal\\n, Python, Javascript, Node.js, MongoDB, BigQuery\\nInfrastructure management on Amazon Web Services and Google Cloud Platform\\nDocker container deployment on Kubernetes\\nRESTful Web Service API development\\nMobile development in Android and iOS\\nExperience in games or fast paced company such as growth phase startup\\nGit, GitHub, Perforce, Jenkins, Splunk]\"\\n\"[\\nWork with computational and research scientists to understand common analysis use cases and data access needs.', 'Experience deploying high-performance data backends in the cloud with Amazon Web Services, Heroku, Google Cloud Platform, or a similar service.', 'As a multidisciplinary national laboratory, Argonne offers an exciting campus atmosphere in which to collaborate on interdisciplinary projects developing solutions to complex scientific and engineering problems on the world‚Äôs largest parallel supercomputers., Position Requirements\\n\\n\\n, Minimum bachelor‚Äôs degree in Bioinformatics, CS, or Biology\\n\\nFluency in scientific programming languages\\n\\nExperience with bioinformatics analysis techniques and tools\\n\\nFamiliarity working in a Unix environment\\n\\nExperience on high performance computing platforms and newer GPU systems\\n\\nExperience processing NGS sequence data, familiarity with bacterial genomics, or demonstrated work in microbiology\\n\\nKnowledge of artificial intelligence across machine learning, deep learning and statistics\\n\\nStrong analytical and problem-solving skills\\n\\nUnderstanding of computational algorithms to support DNA sequence alignment, small nucleotide polymorphism detection, gene expression quantification and/or small molecule (drug) structure\\n\\nExperience working on protected health information including electronic health records\\n\\nFamiliarity with regulatory policies and procedures surrounding electronic protected health information required\\n\\nAbility to write research publications\\n\\nConsiderable collaborative skills, including the ability to interact well with external and internal collaborators\\n\\nUnited States citizenship is a requirement on some projects\\n\\nAbility to think independently and innovatively to develop exceptional technical solutions required, As an equal employment opportunity and affirmative action employer, Argonne National Laboratory is committed to a diverse and inclusive workplace that fosters collaborative scientific discovery and innovation.', 'Experience with Amazon S3 and EC2 or Google cloud technologies as well as with raw data management and archiving.', '\"[With demand sensing, OM Partners is breaking through some boundaries of classical demand forecasting.', 'Develop integrated reporting dashboards using data visualization tools like Spotfire, Crystal Xcelcius, Tableau\\n\\nProvide digital asset tagging instructions for website development and digital adverting content\\n\\nUnderstanding of the analytics discipline: including process, best practices, tools and techniques\\n\\nSolid presentation and client facing skills\\n\\nExcellent project management and implementation skills\\n\\nService/client oriented\\n\\nExcellent verbal and written communication skills\\n\\nVersed in a range of industries, pharmaceutical and/or healthcare experience a plus, \\n\\nBA/BS degree required; MBA a plus\\n\\n3 - 5 years of experience in digital marketing analytics and database marketing\\n\\nDigital analytics (Adobe, Google Analytics, Webtrends, DoubleClick, Atlas, etc.', 'on-time and in-budget delivery.Experience with BI / Big-data solutions (Splunk / Hadoop) is a plusExperience with Microservice development in SpringCloud is a plusExperience with Angular development is a plus.Experience in and understanding of a wide variety of telemetric processes (governance, measurement, etc.', 'Experience troubleshooting and taking responsibility for small features, from design to user delivery\\nEnthusiasm for the field and professional development/improvement outside the day to day job\\n2+ years of experience in report development using various reporting tools like Tableau, Power BI, OBIEE\\n, Skills and Abilities, \\nExperience with connecting and integrating with at least one of the platform - Google Cloud, Microsoft Azure, Amazon AWS and/or various Data providers, like - Facebook or Tweeter, API integration and Big Data technologies (Hadoop, Map Reduce)\\nExpert level knowledge in at least 2 of these technologies - Relational Databases, Analytical Databases and NoSQL databases\\nExpert knowledge in SQL development\\nExpertise in building data integration and preparation tools using cloud technologies (like Snap logic, Google Dataflow, Cloud Data prep, Python etc.)', 'Ability to adapt to evolving business requirements and objectives in a fast-paced environment, \\n\\nBachelor‚Äôs degree in Marketing, Business or equivalent relevant experience\\n\\nMinimum of 1-2 years experience working with consumer databases and exposure to data-driven marketing programs\\n\\nAdvanced skills with Excel, Visio, and PowerPoint\\n\\nExperience with online tracking and reporting tools such as Google Analytics, DoubleClick DART, and Omniture\\n\\nProficiency with SQL\\n\\nExperience with Marketing Automation Platform, Marketo is preferred\\n\\nReport creation experience with business intelligence tools (e.g.', \"At IBM and The Weather Company, we're strongly committed to the advancement of open Internet standards and applications.\", 'You are smart, quick, and creative: an engineer who will dig into the system and find various ways to improve it., \\n\\nSet the direction and be the primary executor with the goal of making Animoto‚Äôs data easily consumable, highly actionable, and available to the widest number of internal users\\n\\nArchitect, design, and develop Animoto.com‚Äôs data infrastructure to support the wide variety of application and analytical needs\\n\\nDesign and implement dimensional data models and systems that scale\\n\\nPartner with product, engineering, and data analysts to explore structured and unstructured data to leverage business insights, \\n\\nBachelors degree in CS or equivalent work experience\\n\\nSolid experience in languages like Ruby or Python\\n\\nStrong experience with SQL\\n\\nExperience with Splunk or other Elasticsearch tools\\n\\nFamiliarity with ETL and BI concepts, \\n\\nComfortable with AWS (Redshift, Athena, etc)\\n\\nComfortable working in application code when needed\\n\\nFamiliarity with Looker, \\n\\nBe a part of a thriving engineering team that includes opportunities to collaborate with teams across the organization including, product, design, and marketing.', \"Develops responses to legislative requests including fiscal notes., \\nDevelops queries in TRS' IBM Cognos database to extract data for use in spreadsheets, models, dashboards, and summaries that support decision-making.\", 'Assisting in the design and distribution of an Enterprise-wide Dimensional data warehouse., \\n\\nhad some exposure to query writing using SQL\\n\\nwill have a demonstrable affinity for logical thought\\n\\nwill have a desire to work independently on individual tasks, while functioning as part of a team\\n\\nwill have a desire to assist others, both as an interpreter and provider of data\\n\\nwill have a demonstrable desire to continually learn and be able to apply new information\\n\\na background or education in accounting is preferred but not required]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: Boulder, CO, USA; Mountain View, CA, USA, \\n\\nAt gTech‚Äôs Users and Products team (gUP), our mission is to help users get the most out of Google.', 'Strong desire to combine rich business acumen and explore various data sources to uncover hidden trends and opportunities for the organization\\nAble to provide a GitHub or coding portfolio of prior advanced analytics, data science, computer programming and statistical work and projects\\nSelf-directed, detail & team oriented with highly developed problem solving and analytical skills\\nExcellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\\n, Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.', \"Mathematics, Statistics, Finance, Economics)\\n\\nExemplary stakeholder management & ability to effectively communicate complex analyses to internal and external stakeholders at all levels\\n\\nProgram management experience with focus on process and detail\\n\\nSubstantial experience with analytical tools and techniques, data management and stewardship\\n\\nContagious intellectual curiosity\\n\\n\\nJob Segment: Analytics, Data Analyst, SAP, ERP, Product Development, Management, Data, Technology, Research, Customer Insights, Data Warehouse, Machine Learning, \\n\\nJob Segment: Analytics, Data Analyst, SAP, ERP, Product Development, Management, Data, Technology, Research, Customer Insights, Data Warehouse, Machine Learning, \\n\\nSAP'S DIVERSITY COMMITMENT\\n\\n\\nTo harness the power of innovation, SAP invests in the development of its diverse employees.\", \"For additional information on BlackRock, please visit www.blackrock.com | Twitter: @blackrock | Blog: www.blackrockblog.com | LinkedIn: www.linkedin.com/company/blackrock., Job Description:, The Digital Wealth Platform and Sales Technology team's mission is to dramatically transform BlackRock‚Äôs current retail distribution strategy and performance around the globe, by enabling the sales team to deepen and expand their relationships with Financial Advisors & Home Offices by leveraging data to provide thoughtful analytics and by delivering cutting edge technology tools & applications to the sales force.\", 'Collaborates with the team in order to improve the effectiveness of business decisions through the use of data and machine learning/predictive modeling\\nCommunicates findings to data science team and small cross-functional teams to ensure models are well understood and incorporated into business processes\\nWorks with various business customers and leaders to ensure the projects will meet their business needs\\nTakes leadership in Hallmark Analytics community by educating and training other analytics and non-analytics staff on various analytics and data science techniques.', 'You will partner with Google and vendor engineering teams to shape and develop REWS‚Äô data architecture.', 'Natural language processing experience preferred\\n\\nShiny, Spyre, Flask, WebDev and prototyping experience preferred\\n\\nJupyterHub, Sun Grid Engine, Google Cloud Platform, AWS experience preferred\\n\\nExperienced in data science methodologies and techniques, e.g.', \"Most importantly, you‚Äôll work and collaborate with a nimble, autonomous, cross-functional team of makers, breakers, doers, and disruptors who love to solve real problems and meet real customer needs., \\n\\nThe person we're looking for:, \\n\\nhas a sense of intellectual curiosity and a burning desire to learn\\n\\nis self-driven, actively looks for ways to contribute, and knows how to get things done\\n\\nis deliriously customer-focused\\n\\nvalues data and truth over ego\\n\\nhas a strong sense of engineering craftsmanship, takes pride in the code they write\\n\\nbelieves that good software development includes good testing, good documentation, and good collaboration\\n\\nhas great communication and reasoning skills, including the ability to make a strong case for technology choices, Basic Qualifications:, Bachelor‚Äôs degree or Military ExperienceAt least 1 year of experience with leading big data technologies such as Spark, Cassandra, Hadoop, HDFS, PostgreSQL, Redshift, and MongoDBAt least 2 years of professional experience with data engineering concepts, \\n\\nPreferred Qualifications:, 2+ years experience with AWS cloud2+ years of experience in Java, Scala, or Python2+ years of experience with Unix/Linux systems with scripting experience in Shell, Perl or Python2+ years of experience building data pipelinesAt least 1 year of Cloud (AWS, Azure, Google) development experienceExperience with Streaming and/or NoSQL implementation (Mongo, Cassandra, etc.)\", 'Prior familiarity with programs involving Chatbots, Machine Learning, API.AI, and IBM Watson is REQUIRED\\n\\nAbility to lead digital transformation in a traditional Business Process.', 'As an intern, you will work on a real project (or a few) and have an opportunity to enjoy our dynamic, startup-like environment., \\n\\nYou will experience Splunking and what defines our culture while honing the skills which separate our development teams from others.', 'The Google-backed company is expanding their engineering efforts to enable more precise weather forecasting.', 'Exact dates are yet to be determined., \\n\\nAbout the Program:\\n\\nThe Google AI Residency Program is a 12-month role designed to advance your career in machine learning research.', '\"[\\nDesign, execute, and evaluate complex analyses of structured and unstructured data to solve complex business problems using cutting edge statistical techniques\\nAdroitly navigate the tradeoffs between speed and feature completion, in order to deliver the right solution in the right time\\nImport, clean, and analyze a variety of datasets in order to generate ad-hoc analyses and build long-running data products\\nWork with our Associate Chief Health Officer, Chief Product Officer, and Engineering teams daily to provide decision support\\nBuild production data processes for risk segmentation, member cohorting, and risk assessment\\nDocument and simplify complex processes and tools\\nDesign reports and dashboards to steer our value-driven business lines, including traditional and non-traditional success metrics Work with our clinical operations team to design robust evaluation models\\nMentor and build a team of both direct reports and cross-functional partners across the organization - encouraging growth in both individual and company-wide data maturity\\nOwn our vendor relationships with top clinical data providers and analyst groups\\n, \\nYou enjoy doing whatever it takes to execute on complex projects\\nYou have 3+ years of experience in a highly operational data science role\\nYou are a strong SQL programmer, with experience navigating and cleaning messy data at scale\\nYou demonstrate expertise across a range of data analysis, data visualization and machine learning toolsets (Python, R, SAS, SPSS, Scala, matplotlib, ggplot Hadoop, Spark)\\nYou have good applied statistics skills (hypothesis testing, experimental design)\\nYou have hands-on experience using machine learning techniques to solve real-world problems\\nYou have deep familiarity with a BI tool like Tableau, Looker, QlikView, Periscope, Mode, etc\\nYou have experience in a high growth technology company\\nYou have worked with healthcare data (administrative or clinical)\\n, \\nDeep expertise in one or many domains of healthcare data, including claims processing, EHR data, HIE/CCD data, HEDIS measures, Stars, RaF scoring, and risk segmentation\\nMaster\\'s Degree or PhD in Epidemiology, Mathematics, Statistics, Biostatistics/Bioinformatics or a related field\\nD3.js, seaborn, bokeh or other advanced data visualization experience\\nExperience building data workflows on Google Cloud Platform\\nMedical economics, actuarial, or finance/revenue cycle background\\n, \\nA resume and/or LinkedIn profile\\nA short cover letter and link to any public portfolio or previous data analyses and visualization work\\n]\"\\n\"[\\n35 GB of data ingest per day, supporting over 510\\n, \\n4 TB Microsoft SQL Server based data warehouse\\n1.5 TB production Cassandra cluster\\n, \\nApply machine learning to optimize ad selection for\\n, \\nDevelop algorithms to take into account hundreds of\\n, \\nInterface with the Business Intelligence team to\\n, \\nInterface with Product Engineering team to ensure\\n, \\nInterface with Product Management to develop\\n, \\nSuggest and implement integration of first and third\\n, \\nOperationalizing the data science process ‚Äì\\n, \\nPhD in CS/Math/Statistics or equivalent experience\\nExpert in machine learning methodologies\\n, \\nFamiliar with Bayesian statistics\\nAB testing, design of experiments\\nHands-on experience with R/Weka,\\n, \\nFamiliarity with the digital media / advertising\\n, \\nBe an excellent communicator and a leader able to\\n, \\nNativeX offers competitive, performance based pay\\n, \\nTraditional benefits including Health, Dental and\\n, \\nGenerous time off including paid time off starting\\n, \\nOngoing growth and development opportunities\\n, \\nWork in an entrepreneurial, energetic work\\n]\"\\n\"[Data Scientist - 16008, \\n\\nTechnology and Engineering - USA Needham, Massachusetts, \\n\\nUnderstanding marketing effectiveness is critical to the success of businesses across all verticals.', 'gUP builds innovative solutions that take user experience and engagement with Google to the next level, supporting users across products, countries, cultures, incomes, and identities.', 'We are one of the top-20 largest content publishers on the Internet according to comScore, a leading Internet measurement company, and reach more than 30% of the U.S. population every month.', 'We are looking for candidates who are ambitious, self-assured, possess strong can-do attitude, and want to be a part of a world-class team\\n\\n, Why you‚Äôll want to come work here:\\n\\n, Competitive salary (commission/bonus based on type of role), 4 weeks paid time off, great benefits (medical, dental, vision, FSA), 401K match\\n\\nGift matching, volunteer for vacation program, and endless community involvement opportunities\\n\\nNamed to Forbes‚Äô Fast Tech 25 and Fortune‚Äôs Change the World List; we are growing and offer incredible opportunity for advancement\\n\\nTremendous company culture and office perks as well as a new cutting-edge new headquarters completed in 2018\\n\\n, Stay up to date on everything Blackbaud, follow us on Linkedin , Twitter and Facebook .', 'Additionally, we apply IBM‚Äôs global expertise and local capabilities through our unique global delivery network combined with our teams in over 170 countries to provide our clients with an integrated approach to business design and execution, and turning strategies into actions.', \", THE ROLE:, \\n\\nPerform deep data research across multiple departments providing key metrics and insight\\n\\nCommunicate actively and effectively with analytical peers, business partners, and executive leadership, \\n\\nDrive end-to-end analytics: identify a problem, derive a solution, present your findings and finally drive a change in the business with quantifiable value\\n\\nWork closely with Financial Planning and Analytics to support monthly financial reporting & annual planning\\n\\nSupport Business Development team to make informed pricing decisions with new partners\\n\\nSupport Marketing Public Relations team to produce marketing that help the world see the service we provide our valued customers, \\n\\nREQUIREMENTS/CHARACTERISTICS:\\n, \\n\\nAnalytically driven\\n\\nExcellent time management and prioritization skills\\n\\nIntellectually curious & exhibits ability and desire to learn above and beyond what‚Äôs asked\\n\\nStrong communication and organizational skills\\n\\nAbility to thrive in a fast pace environment\\n\\nBachelor's degree in Math, Finance, Economics, Stats or other quantitative field\\n\\nRecent Grad to 2 years of professional experience in another analytical role\\n\\nHands on experience with MS PowerPoint, Excel, Tableau (or other visualization tool) and Google Big Query (or SQL) preferred, \\n\\nCare (for everyone): We show compassion and contribute to the well-being and growth of those around us.\", 'Site Engagement/Site Experience Analytics including tagging to help drive product management\\n\\nKnowledge of Social Listening/Analytics - especially across YouTube\\n\\nExcellent knowledge of web analytics tools including Google Analytics and/or Adobe Analytics\\n\\nAdvanced proficiency of Excel, along with other MS office products (Word, Powerpoint, Outlook).', 'Highly proficient in MS Excel and/or Google Sheets.', 'This means we offer these great perks to help keep our team healthy, productive and happy:, Health, dental and vision coverage\\nLife insurance, short-term, and long-term disability paid for by the company\\n401(k) plan offered with employer match\\nHigh-end hardware to work with\\nLearning and career growth prospects\\nPaid Holiday and Time Off\\nReferral bonus program\\nOpportunities for profit sharing, bonuses and ownership\\nAbility to working with bleeding edge technology right here in AZ\\nFast paced Startup Culture]\"\\n\"[IBM Global Business Services (GBS) is hiring a Data Scientist for our Cognitive & Analytics Consulting Practice.', 'Extensive experience working with AWS, Google components.', 'Deep data science skills, at the interface between computer science and statistics, MS or equivalent experience with evidence of impact in data science applied to real life problems in a research setting ideally within a clinical research environment\\n\\n1 to 5 years of experience post MS or PhD\\n\\nNatural language processing experience preferred\\n\\nPython and R experience required\\n\\nJupyterHub, Sun Grid Engine, Google Cloud Platform, AWS experience preferred\\n\\nExperienced in data science methodologies and techniques, e.g.', 'Job Candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process., Accenture is committed to providing veteran employment opportunities to our service men and women., Job Type: Full-time]\\n\"[\\nSpark, working in RDDs and DataFrames/Datasets API (with emphasis on DataFrames) to query and perform data manipulation\\nSpark Structured Streaming\\nExperience building large scale Spark applications, ideally with either Batch processing and/or Streaming processing\\nScala would be ideal but a solid knowledge of Java is also acceptable\\nExperience in SparkSQL (Broadcast Joins)\\nExperience with cloud computing platforms, we use AWS (Kinesis, S3, Lambda, DynamoDB)\\nHas experience with ANSI SQL relational database (Oracle, SQL, Postgres, MySQL)\\n, \\nLinux common working knowledge, including navigating through the file system and simple bash scripting\\nGeneral knowledge of distributed systems and distributed data processing frameworks\\nExperience with Storm, Kafka, or Cassandra is a plus\\nKnowledge about agile software processes\\n]\"\\n\"[\\nOwn relevant source systems analysis activities spanning multiple source systems including the MySQL databases that underpin our service, cloud based email delivery systems, Google analytics, Amazon Marketplaces and enterprise systems such as NetSuite financials and Laboratory Information Systems.', \"You work with Engineers, Product Managers, Sales Associates and Marketing teams to adjust Google's practices according to your findings.\", \"You'll build large scale batch and streaming pipelines across many product lines and datasets, with frameworks like Apache Beam, Storm, and Google Cloud Platform, enabling us to build high impact features for the next generation our indoor location platform.\", 'Experience analyzing data from 3rd party providers: Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, etc.', 'Come help us make Twitter the best place for finding what the world is saying, live!', 'This team manages the automation of reporting and processes, creation of data pipelines and database management, development of powerful technical solutions to empower staff and other robust data engineering solutions at Hallmark.', ', For eligible employees]\"\\n\"[\\n\\nIndependently identify appropriate data science techniques and methodologies that will be used to support comScore‚Äôs cross-platform measurement products, and answer technical and business questions.', 'IQVIA, Symphony, MMITDeep knowledge in and experience with at least two of GSK U.S. Pharma relevant commercial areas, Primary Care (particularly Respiratory), Specialty (Immunology, Oncology), VaccinesSustained functional leadership of teams, and success in achieving high-performing team levelsRecent experience in managing onshore/ offshore analytics workbench and data management vendorsOutstanding communication and presentation skills as evidenced through impactful senior management presentations, conference presentations, and/ or publications\\n, Understanding of the business impact of diversity & inclusionProven and advanced collaboration skills, and cultural sensitivityStrong business acumenDemonstrated ability to influence senior commercial leadership and confidently defend informed recommendationsAbility to work effectively across a matrix environment and influence without formal authorityAbility to lead through change and inspire agility/flexibility amongst teamExperience fostering personal development of direct reports\\n, Why GSK?', 'gPTO partners closely with gTech‚Äôs Support, Professional Services, Product Management, and Engineering teams to innovate and simplify our Ads products and build the productivity tools ecosystem for gTech users., The Customer Experience Lab conducts customer experience research on advertisers who are using Google‚Äôs Marketing Solutions.', 'You will play a key role in the architecture, design and development of the data pipeline using Big Data Technologies on AWS/Google Cloud.', '\"[The Google Cloud Platform team helps customers transform and evolve their business through the use of Google‚Äôs global network, web-scale data centers and software infrastructure.', 'Come make a difference at Ochsner Health System and discover your future today!', 'AWS, Google) and on-premise deployments\\nWorking knowledge of containers (e.g.', 'U.S. Citizen with a TS/SCI clearance]\"\\n\"[Dell provides the technology that transforms the way we all work and live.', 'X was formerly known as Google[x]., Contribute expertise in physical sciences and machine learning to cross-disciplinary projects.', 'Daily maintenance of database infrastructure, mainly checking daily / nightly scheduler jobs, backup/recovery and replication\\n\\nUnderstand business objectives and design services that couple business logic with code components for scalability and reusability\\n\\nProficient in designing efficient and robust ETL workflows\\n\\nCreate, or support creation of, required reports in response to business user needs\\n\\nMonitor and report for critical production data systems\\n\\nSupport multiple data Systems in a production environment, including DSS, OLTP, NOSQL and Big data services\\n\\nAble to work with Cloud Computing environments\\n\\nProactively monitor as well as troubleshoot problems escalated by the business / QA / Analytics / Development team in a timely manner\\n\\nRespond to and resolve SQL database access and performance issues\\n\\nCandidate will be on-call and maybe required to work over weekend at times, and will be part of a team in automating daily tasks using automated out-of-box solution or Shell/Perl scripting., \\n\\nData Engineer Requirements:, \\n\\n3-4 years‚Äô experience related to ORACLE DB Administration on Unix/Linus in a mid-to-large-scale computing environment\\n\\nStrong understanding of database structures, concepts, principles, and practices\\n\\nExperience in AWS or Google Cloud Computing Environment\\n\\nStrong Working knowledge of any NoSQL systems such as Cassandra, MongoDB or DynamoDB and Elasticsearch\\n\\nWorking knowledge of Big Data system such as Hadoop, MapReduce, Hive or Spark along with Resource management using YARN or Mesos\\n\\nProficient in Python, Java and/or R\\n\\nExperience in migrating from RDBMS to NoSQL systems\\n\\nStrong SQL (ANSI or other standard SQL) writing skills is a must\\n\\nUnderstanding of UNIX/Linux/Perl or bash Shell scripting language\\n\\nAbility to architect highly scalable distributed systems\\n\\nHands-on experience with PySpark or PyTorch\\n\\nWorking knowledge of Apache Kafka or AWS SQS with Kinesis Data Firehose\\n\\nWorking knowledge of in-memory computing systems such as Redis, NuoDB, VoltDB or GridGain]\"\\n\"[This Data Engineer will join other extremely passionate engineers who share a common interest in distributed systems, performance, scale, and solving problems with software and data.', 'You want to be a part of creating a culture within a small team\\n\\nYou strive for simplicity even for complex problems, We are the fastest growing health information site on the planet, and the 2nd largest health site in the US (per comScore)!', 'Experience with Kafka and Yarn or Mesos\\n\\nExperience with AWS services (Athena, Glue, Redshift, Kinesis) or Google cloud services (BigQuery, BigTable)\\n\\nBA/BS or above in Computer Science or a related field\\n\\nExperience with NoSQL databases and key-value stores, such as Cassandra, Redis\\n]\"\\n\"[\\n\\nBuild and improve NLP/ML models at hearth of AgentIQ product\\n\\nBuild and improve infrastructure to support NLP/ML modeling, experimentation and deployment\\n\\nTake ownership of NLP/ML trainer tools and data processing pipelines\\n\\nBrainstorm and prototype algorithmic improvements\\n\\nDevelop customer specific and general machine intelligence\\n\\nContribute to deploying/monitoring/debugging models in production\\n\\nTake ownership of NLP/ML trainer tools and data processing pipelines\\n\\nCollaborate with platform teams on developing new tools and features needed for NLP/ML development and deployment\\n\\nCreate and maintain documentation\\n\\nProvide internal training on applicable topics\\n, \\n\\nPassion for improving ML/NLP models and making them more robust and scalable\\n\\nThrive in a diverse, dynamic environment that leverages multiple tools and languages\\n\\nThe ability to communicate effectively with thoughtfulness and maturity\\n\\nMake technology decisions that are best for the business of Agent IQ\\n\\nExperience building large, production-quality NLP, speech, or deep learning systems\\n\\nStrong software engineering and interpersonal skills\\n\\nAbility and desire to quickly pick up on new topics and techniques\\n\\nAbility to take an idea from conception and prototyping to deployment in production\\n\\nMasters degree or equivalent in ML/NLP or related field\\n, \\n\\nAWS/GCP hosted infrastructure\\n\\nLinux\\n\\nPython\\n\\nTensorflow\\n\\nNode.js\\n\\nDocker\\n\\n, \\n\\nCompetitive salary + equity\\n\\nFull medical/dental/vision benefits\\n\\nUnlimited PTO policy\\n\\nTons of snacks in the office and all-you-can-drink coffee\\n\\nConvenient office within a 3 minute walk from BART/Muni Underground\\n\\nGoogle apps, Dropbox, Drive, Slack, Mac (or PC) everything\\n\\nAgent IQ swag\\n\\nCommuter benefits\\n\\nGreat teammates]\"\\n\"[At Capital One, we‚Äôre building a leading information-based technology company.', ': No\\nTravel: Yes, 25 % of the Time]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Seattle, WA, USA, \\n\\nAs a Cloud Data Engineer, you will guide customers on how to ingest, store, process, analyze and explore/visualize data on the Google Cloud Platform.', ', Data Analytics:, Very proficient in Google Search and other search engines.', 'Prior experience with IBM Guardium Big Data Intelligence/SongarG tooling., \\n\\n\\nIncumbency:\\n\\n\\nThis position will have an 18-month incumbency period, beginning on the effective date of the position, which must be met before the employee can post for any other lateral State Farm position.', 'Altair ProductDesign firmly advocates a user-centered, team-based design approach, and utilizes proprietary simulation and optimization technologies to help clients bring innovative, profitable products to market faster., \\n\\nDescription:, \\nSupport Quality Engineering for data analysis\\nMaintain Quality internal document databases to store and retrieve data\\nPerform data collection and stratification from all internal and external sources\\nUse Microsoft Office software to create reports, templates and PowerPoint presentations\\nAssist Management to write procedures, meeting preparation and presentations\\nSupport Quality Projects utilizing World Class Manufacturing methodology\\n, Requirements:, \\nSupporting technical Quality Team at multiple manufacturing facilities to capture and process control internal/external quality performance data and presenting it in a user friendly format\\nThe data will be used at the department level, plant level and division level to lead the team toward contiuous quality improvements\\nThis position will be challenged with continuously identifying systems and methods for quicker and easier sharing of complex data from various sources and operating systems\\n, Requirements:, \\nTechnical BS Degree\\nSQL knowledge & strong knowledge of data collection systems with the ability to interface multiple electronic data sources into to a front end reporting system (QlikSense)\\nExpert skills with Microsoft Office applications\\nStrong communications - verbal & written\\nProblem solving will be critical for the standardization and communization of multiple data collection systems\\nKnowledge of the Industry 4.0 methodology and Google Suite operating systems is preferred\\nAutomotive manufacturing experience preferred\\n, Driving and Travel Requirements:, \\nMay be required to drive a company car - valid drivers license and clean driving record required\\nPrevious supplier interface and leadership experience is a plus\\n]\"\\n\"[\\nCollaborate with cross functional teams to analyze and optimize game systems and features.', '), Google Cloud Platform, SQL-sever and postgres,)\\n\\nFluency in statistical analysis, data visualization, data mining and cleansing, machine learning, etc.', ', Experience architecting, implementing and successfully operationalizing large scale data solutions in production environments using Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, EMR, Kinesis, BigQuery, DataProc, Azure Data Lake, etc., Experience building performant data models at scale for Hadoop/NoSQL ecosystem of data stores to support different business consumption patterns off a centralized data platform., Experience creating data pipelines using Spark/MR/ETL processing, including Java, Python, Scala, Talend; for data analysis of production Big Data applications., Experience industrializing data lakes or real-time platforms for an enterprise enabling business applications and usage at scale., Experience designing and implementing relational data models working with RDBMS and understanding of the challenges in these environments., Responsibilities, \\n\\nThe candidate will work closely with other professionals within various departments to develop data solutions to support the business.', '\"[\\n\\nAnalyze traditional, social and digital media data using qualitative and quantitative research methods\\n\\nLeverage data to develop new insights with the goal of improving planning, deliverables, growth and efficiency\\n\\nIdentify trends and insights from data to generate actionable insights\\n\\nHelp develop internal processes and lead the analytic group in the management of projects and resources\\n\\nJointly develop business cases with account leads that clearly show impact of campaigns and initiatives on business objectives as well as ROI\\n\\nManage, organize, and clean data effectively and efficiently while reducing manual reporting and data redundancy\\n\\nUse data visualization skills and tools to analyze, package and communicate reports to key stakeholders, both internally and to external clients, \\n\\nAbility to translate data into insights that help clients understand audience needs and behavioral drivers\\n\\nHighly versed in analytic methodologies and modeling\\n\\nExcellent oral and written communication skills, specifically the ability to convey research findings in a concise and effective manner\\n\\nAbility to work individually and in a team setting\\n\\nAbility to remain organized, driven, and focused on multiple projects at a time\\n\\nAbility to meet deadlines and adapt quickly to new projects\\n\\nProject/time/client management skills\\n\\nStrong presentation and data visualization skills\\n\\nEnthusiastic, eager, and curious]\"\\n[Overall 8+ Years of experience in IT industryAtleast 4 years experience in SplunkVery good knowledge and working experience in Big Data Hadoop / No SQL3+ years\\' experience with Splunk in developing text mining use casesIntegrating Splunk with Big Data Hadoop for log storageIntegration with variety of external data sourcesThe ability to design Splunk reports and dashboards using complex data elementsFamiliarity of a Web Based application environmentLinux shell scripting/Regex experience would be highly preferableSplunk certifications is a plus.]', 'Strong organizational skills and the ability to operate independently are required.US Person, Spreadsheet tools, e.g., MS ExcelDatabase systems (SQL and NO SQL based)Communication and visualizationDescriptive statistics and exploratory data analysisLanguages: R, Python, HTML, Javascript, SQL, C/C++Knowledge of business planning / financial management, applied analytics, and manufacturing operations, preferably in an Aerospace application.Strong continuous improvement background, such as Lean Six Sigma training preferredDemonstrated ability to learn new programs and approach new problems in an efficient methodical manner]\\n\\n\"[Use quantitative methodology and data insights to influence the direction of our product development and business decisions\\n\\nPartner with our product teams to define goals and identify key metrics for existing features and new releases\\n\\nUse data to discover and evaluate new product opportunities\\n\\nMine our underlying data for trends in user behavior\\n\\nIdentify gaps in our existing data infrastructure and develop corresponding solutions\\n\\nDevelop data sets to empower operational and exploratory analyses\\n\\nCollaborate cross-functionally with Product, Data Science, Engineering, Marketing, and Customer Success to design, execute and iterate on product experiments\\n\\nWork with business intelligence tools such as Heap, Tableau, or Google Analytics to classify user populations and identify product usage trends\\n\\nDive deep into raw data sets to identify user behaviors\\n\\nBuild connectors between our existing data sets, business intelligence tools, and other systems to provide an integrated view of user behavior\\n\\nDive deep into a raw data set to identify behavioral inflection points, and propose experiments to influence our users to a desired outcome\\n\\nWork cross functionally to construct, monitor, and measure a usability experiment\\n\\nBuild a culture where we ask data-driven business questions, and update our company and product strategies based on the answers, Proven experience with using quantitative analysis to influence business and product decisions\\n\\nThe ability to clearly and effectively communicate the business impact & results of complex analyses\\n\\nMinimum of 3 years experience writing production datasets OR building internal/production data tools for ETL, experimentation, or exploration in Python\\n\\nBachelor\\'s degree in Computer Science, Engineering or related field, or equivalent training, fellowship, or work experience\\n\\nA solid grasp of common statistical applications and methods (experimentation, probabilities, regression)\\n\\nExperience in software engineering a plusExperience in predictive modeling in big data environment is a plus\\n\\n\\nOUR COMMITMENT TO DIVERSITY AND INCLUSION: At Hearsay we believe that diverse teams are the best teams.', 'You like a fast-paced & fun environment, believe in Twitter‚Äôs mission in the world and want to be a core actor in pushing it forward.', 'Cloud ‚Äì AWS, Azure, Google, As used in this posting, ‚ÄúDeloitte‚Äù means Deloitte Consulting LLP, a subsidiary of Deloitte LLP.', 'We have data stretching back before the existence of Google.', 'Salesforce and Google Cloud Platform experience preferred.Good experience of parsing data formats such as XML/JSON and using 3rd party API‚ÄôsSold Python programming skills - experience scheduling/automating scriptsStrong analytical and problem-solving skills, strategic thinker and visionary, self-motivatedProven ability to work cross functionallyAn understanding of how data can benefit the wider business, and how to translate technical requirements to non-technical stakeholdersPrevious experience and successful track record of learning new tools and technologiesGood time management and ability to work on concurrent assignments with different priorities - Ability to work in a fast-paced, iterative development environment with short turn-around times\\n, 3+ years experience with schema design and dimensional data modeling (marketing attribution)Data Rock Star.', 'Schedule, facilitate and provide training in support of compliance auditing activities., Demonstrated experience with Splunk, creating scripts to pull identified data from Splunk on an ongoing or recurrent basis; and monitoring application and server logs to ensure continued logging to Splunk., Demonstrated experience coding/scripting in one or more of the following: Perl, Python, HTML, SQL, or JavaScript., Working knowledge of appropriate analytic methods and methodological tools in one or more of the following areas, a.)', '\"[\\nMaster‚Äôs Degree in GIS, Computer Science, Statistics or related\\n, \\n2+ years of experience and strong understanding of GIS technology (knowledge of ESRI ArcGIS technology stack and Arc Objects)\\n, \\nPython: 2+ years experience with Python or other scripting languages (Python strongly preferred)\\nSQL: 2+ years experience and a demonstrated proficiency in data extraction, analysis and scripting tools, preferably PostgreSQL, Google BigQuery\\n, \\nStatistics: firm understanding of statistical inference and some experience using stats in business settings\\nResearch: Experience with empirical research; ability to understand technical papers; general curiosity\\nMachine Learning: Understanding of different ML techniques and fundamentals of model building / execution\\n, \\nClient Management: Ability to problem solve and empathize with key stakeholders\\nOwnership: Ability to own a problem with little oversight\\nOrganization: Ability to manage multiple workstreams and priorities with various stakeholders\\nExcellent interpersonal, written, and oral communication skills\\nSelf-starter, energetic and motivated contributor\\n, \\nExperience with PyGIS, PyQGIS, and/or QGIS\\nExperience with GitHub for collaboration and version control\\nExperience with data visualization tools (e.g., Tableau, Power BI, D3.js , Highcharts)\\nShell, Linux, Bash\\n, \\nCompetitive pay and stock option grants\\nFully-covered healthcare (no premiums, co-insurance, etc.', ', The goal of Cloud ML is to innovate and deliver the best AI tech to impact the world via Google Cloud.', 'AWS, Azure, Google Cloud etc.)', 'to ensure data is quickly and reliably available in all contexts\\n\\nPrepare technical documentation to include as-built design, requirements, and Standard Operating Procedures\\n\\nInterface with the broader Forcepoint data science team about analytic opportunities and accomplishments in the field to drive the evolution of the Forcepoint UEBA platform\\n\\nProvide technical briefings to customer leadership and Forcepoint corporate leadership as required\\n\\nCoordinate tasks and activities with various groups within Forcepoint, the government or partners\\n\\n, Required Skills & Experience:\\n\\n, Minimum of bachelors in computer engineering, computer science, information security, or equivalent with 5 years of technical work experience\\n\\nExperience writing modular and reusable code in Python\\n\\nFacility in scripting and troubleshooting application errors in Linux/Unix environments\\n\\nExperience with the ETL: cleaning, transforming, and ingesting large datasets\\n\\nExperience with full Software Development Life Cycle (SLDC) from requirements through to testing and deployment\\n\\nPossess strong analytical, verbal, and technical written communication skills\\n\\nMust be able to coordinate collaboratively across traditional engineering disciplines and effectively engage with customers\\n\\nMust be eligible to work in the U.S.\\n\\n, Nice to have:\\n\\n, Prior technical experience in large enterprises\\n\\nExperience with Apache NiFi and high volume ETL tasks\\n\\nIntegration experience with data stores such as Elasticsearch, PostgreSQL, Splunk, ArcSight, Cloudera, etc.', 'www.precima.com, Alliance Data participates in E-Verify., Check us out ‚Äì LoyaltyOne on Stack Overflow | LinkedIn | Glassdoor | Facebook |Twitter | Blog | Instagram]\"\\n[ Be an expert in business analysis, used to researching across business functions, subsidiaries and partners, complex and integrated business systems.', 'At Splunk, we‚Äôre committed to our work, customers, having fun and most importantly to each other‚Äôs success.', 'For more information about Toole Design, visit our website (www.tooledesign.com), follow us on Twitter (@tooledesign), or like us on Facebook (www.facebook.com/TooleDesignGroup).]\"', 'Hallmark‚Äôs mission is to inspire people everywhere ‚Äúto live a caring, connected life full of meaningful moments‚Äù.', ', Act as a focal point for vetting requirements and prioritizing work streams for data solutions with business and IT partners., Ensure adherence to approach of using self-service data solutions to enable others to be successful in data wrangling, data blending, and data delivery via services., Develop business data catalogs and data marketplaces on top of next generation data platforms., Transition data storage to Cloud environments (Google or Azure)., Coordinate the build and maintenance of data pipelines and services for use by multiple business areas.', 'AWS, Azure, Google Cloud) environment., A cover letter is required to apply to this position.', 'Maintain existing algorithms, tools, solutions, and methodologies contributing to comScore‚Äôs existing measurement products.', 'Responsibilities:\\n\\n\\n, Work with clients across many levels: C-Level, Vice-President, IT, Analytics and Business Users\\n\\nLeverage experience to apply elements of the Cross-Industry Standard Process for Data Mining (CRISP-DM)\\n\\nDefine key business problems from starter conversations, gather and analyze relevant data, conduct advanced transformations and integrations, identify suitable algorithmic approaches, conduct proper evaluations and stage outputs for operational deployments\\n\\nTranslate complex technical findings, conclusions and recommendations in compelling written and oral delivery formats, often to non data science personas\\n\\n, BENEFITS, ibm.com/employment/us/benefits/\\n\\nibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\\n\\nFinding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee\\'s strength and career aspirations\\n\\nDiversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\\n\\nibm.com/ibm/responsibility/corporateservicecorps/, At least 5 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\\n\\nAt least 5 years of experience in project management for external consulting engagements\\n\\nAt least 5 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\\n\\nAt least 5 years of experience data management and coding such as DB2, SQL, Hadoop\\n\\nAt least 3 years of experience in visualization such as d3, Javascript, HTML, CSS, Advanced degree in a technical field\\n\\nAt least 7 years of documented, provable experience in strategy consulting, application of data science, text analytics, visualizations and optimization modeling\\n\\nAt least 7 years of experience in project management for external consulting engagements\\n\\nAt least 7 years of experience in advanced analytics tools such as R, SPSS, Python, SAS\\n\\nAt least 4 years of experience in visualization such as d3, Javascript, HTML, CSS]\"\\n\\n\"[Must possess an active TS/SCI clearance with a CI polygraph.', 'Splunk, PagerDuty, DataDog or Graphite)\\n\\nData Architecture & Governance, Experience with:, \\n\\nOther AWS technologies (e.g.', \"You're equally at home explaining your team's analyses and recommendations to executives as you are discussing the technical trade-offs in product development with engineers., Research at Google addresses the most challenging problems in computer science, machine learning and other related fields.\", \", Bachelor's degree in Computer Science/Analytics or equivalent experience and minimum 5 years of data analytics / business analytics experience strongly preferred\\n\\nExperience with standard clickstream analytics tools such as Adobe Analytics, Omniture, Google Analytics\\n\\nExperience with SQL for querying and reporting against large scale data sets\\n\\nProven ability to manage stakeholder communications\\n\\n\\n, Adobe Analytics toolset ‚Äì Workspace, Data Warehouse, Report Builder, Ad Hoc Analysis\\n\\nExperience with Redshift, Hive, Spark, Python and other tools which allow analysis and enable queries on large datasets in Hadoop and AWS\\n\\nExperience in digital analytics supporting large healthcare, e-commerce or financial services web sites\\n\\nDemonstrated knowledge of healthcare products, benefits, claims, and/or customer service or related experience is a plus\\n\\n\\n, Problem solver with excellent analytical skills and ability to turn data into information and insights\\n\\nStrong communication and presentation skills with ability to create and deliver presentations and reports for senior management\\n\\nShould be resourceful, work well under pressure, and able to keep up in a fast-paced environment.\", 'Express Scripts is a VEVRAA Federal Contractor.]\"', 'Find iStock on Facebook, Twitter, Instagram and LinkedIn, or download the iStock app where you can easily search, save and share superior images to create standout visual communications.', 'video ads) to improve results for our most critical business priorities\\n\\nWe evaluate the impact of ads on new Twitter users, determining how to show them ads in order to maximize their long-term usage of the product\\n\\nWe are responsible for measuring the results of all experiments on Twitter ads, Experience using data intelligently to optimize product performance\\n\\nExperience performing analysis on raw event data in modern data warehouse systems\\n\\nDeep understanding of data platforms in which you‚Äôve previously worked\\n\\nGood understanding of how to grow and shape data tools and datasets to improve data-driven decision making\\n\\nAbility to thrive in an unstructured environment, working autonomously on a strong team to find opportunity and deliver business impact\\n\\nGood understanding of (one or more of the following): Python or R, \\n, Past experience in adtech\\n\\nPhD or MS in computer science, machine learning, or statistics\\n\\nGood understanding of (one or more of the following): Java, Scala, or C++\\n\\nInteresting side projects or Kaggle competition results, \\n, We are committed to an inclusive and diverse Twitter.', ', Success in this role will require the development of strong working relationships and interactions with customers, senior leaders, engineering teams, product management and other marketing groups across Google., Google Cloud helps millions of employees and organizations empower their employees, serve their customers, and build what‚Äôs next for their business ‚Äî all with technology built in the cloud.', \"AWS, Azure, GCP, \\n\\n\\nRequired Education:\\n\\n, Bachelor's or higher degree in Computer Science, Engineering, Mathematics, Statistics, Econometrics or equivalent discipline and 6 years of relevant experience, \\n\\n\\nDesired Education:\\n\\n, Industry or University Data Analytics / Data Science Certifications, Raytheon is an Equal Opportunity/Affirmative Action employer.\", 'We are looking for data scientists to research and analyze correlations between advertiser CSAT survey data and key data systems to determine key drivers, opportunities, and trends., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.', 'Work with data warehousing team to design optimal data architecture for BI tools\\n\\nWork as a client contact for analytics, partnering with various departments to identify priority dashboards and reports to better serve the company\\n\\nDesign and build dashboards and automated reports with embedded visualizations\\n\\n, Qualifications:\\n\\n, Minimum of 4 years of experience\\n\\nProven track record of identifying and highlighting key insights, signals, and trends deep within the underlying data\\n\\nWell-rounded individual with the ability to write code to query and transform both unstructured and structured data\\n\\nExperience publishing reports using visualization and presentation tools\\n\\nShould enjoy generating actionable insights by mining and modeling data and be passionate about answering challenging questions and telling stories with data and visualizations\\n\\nSelf-motivated, attentive to detail, and driven to continuously improve analytics skill set\\n\\nSQL, SAS, Python, Big Query, Google Analytics, Excel, and Tableau\\n\\nSPSS and/or R\\n\\nBachelor degree in Mathematics, Statistics, Econometrics, Actuarial Science or related quantitative discipline\\n\\n, _]\"\\n\"[Our Data Scientists are pioneers in building the next generation of retail interconnected experience for homedepot.com by leveraging Artificial Intelligence and Statistics.', \", In this role you are the Google Engineer working with Google's most strategic Cloud customers.\", 'Experience with a RDBMS (IBM DB2, Netezza, MySQL a plus).', '\"[\\n\\nWork with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business solutions\\n\\nGenerate reports and analysis on key product metrics\\n\\nDevelop custom data models and algorithms to apply to data sets\\n\\nHelp identify and assess metrics and KPIs that can be tracked to measure impacts and business outcomes\\n\\nActively involved in the development of our analytics tools for A/B testing, segmentation, funnel analysis, and other analytics needs, Excellent problem solving and communication skills\\n\\nStrong statistics and mathematical fundamentals\\n\\nFamiliar with reporting and analytics platforms and tools such as Looker, Google Analytics, and Excel\\n\\nFamiliar with our cloud computing platform, AWS, B.S.', 'and business transformationMeet travel requirements, up to 50%, SET YOURSELF APART: Preferred Skills: , Exceptional presentation skills ‚Äì ability to convey technology and business value propositionsStrong Data Management Technology backgroundValue based constructs5 years of experience interacting with clients of all levels to review expected outputs, applicability to business challenges, and model measurementWell connected with cutting-edge analytics techniques and be confident about how to apply them to generate insights and recommendations3 years of experience guiding the data formulation process and exploratory data analysis5 years of experience guiding and managing a team of practitioners to execute analytics solutions, both onshore and offshoreProven ability to manage multiple simultaneous work streams and shift / adjust resources to achieve optimal resultsEvidence of thought leadership in defining innovative analytics within multiple complex applications spanning marketing, risk, and cost reductionExcellent communication skills to drive thought-provoking dialogs with senior clients, Professional Skill Requirements, Proven ability to build, manage and foster a team-oriented environmentProven ability to work creatively and analytically in a problem-solving environmentDesire to work in an information systems environmentExcellent communication (written and oral) and interpersonal skillsExcellent leadership and management skills, OUR COMMITMENT TO YOU, Your entrepreneurial spirit and vision will be rewarded, and your success will fuel opportunities for career advancement.You will make a difference for some pretty impressive clients.', 'Proficiency with Google Analytics, Adobe Analytics, Test & Target, Maxymiser preferred.', 'Preferred: Knowledge of popular ad serving technologies and supporting analytical and research tools (Doubleclick, Atlas, comScore, Compete, etc.)', ', Locate duplicates and assist in implementing means to prevent duplication\\nConstantly promote and apply best practices in data management\\nSpot check existing common reports and correct filtering or returned data errors\\nHelp identify and purge vestigial data\\n, Become deeply familiar with the data structures and mechanisms at Facing History\\nRecognize data that is unnecessary or not actionable and develop strategies to eliminate it\\nAssist in creation and maintenance of systems maps and schema\\nIdentify areas for improvement in data storage and analysis\\nCross-train teammates and be transparent with expertise\\nIdentify data conflicts and misalignment and coordinate with the team on plans for improving data quality\\nIdentify redundancies\\n, 3-5 years of experience required in analytics\\nGoogle Analytics experience required\\nSalesforce experience strongly preferred but not required\\nEU privacy compliance law (GDPR) understanding preferred but not required\\nGoogle Data Studio experience a plus\\nHubSpot experience a plus\\n, Qualified candidate must be:, Very detail-oriented with a focus on accuracy; this cannot be overstated for someone in an analyst role\\nA strong communicator, both written and oral, and be comfortable with phone outreach on occasion\\nComfortable both producing and interpreting data\\nAble to work collaboratively and at the same time be able to work independently for long periods of time\\nResponsive and respectful to all requests but pragmatic around priorities\\nFlexible and agile in approach as needs change and evolve\\nWilling to experiment with and learn new technologies, and to share best practices]\"\\n\"[\\nAnalyze and generate actionable insights from structured and unstructured data\\nAnalyze BBYO\\'s progress in meeting accountability goals\\nData sleuthing and data set management: regularly query database for internal and external stakeholder requests, solving data mysteries and creating data resources for analysis.', 'The ideal candidate has extensive experience building and implementing complex data solutions in the Cloud (AWS, Microsoft, and/or Google).', 'We‚Äôre looking for people who bring an inquisitive mind to solve complex data issues and have all the necessary tools to take it to the next level., WHO WE ARE:, The Data Engineering and Reporting team under Category Solutions provides data enablement solutions across Hallmark Greetings.', 'science, engineering, economics, finance, statistics, or similar)., \\n\\n4+ years of work experience involving quantitative data analysis and complex problem solving (preferably focused on consumer-facing internet products)., \\n\\nComplete command of SQL, Excel, and either Python or R, along with some experience with Tableau and/or Mode., \\n\\nExtensive experience directly querying multi-terabyte-sized data sets (with Hive and Presto) including clickstream data (like Google Analytics), third party data (like Facebook) and raw data ingested from non-standard platforms., \\n\\nA strong understanding of concepts, terminology, and measurement issues related to web analytics along with a history of applying advanced analytical approaches to derive insights from the data., \\n\\nStrong written, verbal, and visual communication skills to concisely communicate in a way that provides context, offers insights, and minimizes misinterpretation., \\n\\nThe skills to work cross-functionally and push business partners to focus on realistic goals and projects., Zillow Group is owned, fueled and grown by innovators who help people make better, smarter decisions around all things home.', '\"[Working at MIT offers opportunities, an environment, a culture ‚Äì and benefits ‚Äì that just aren‚Äôt found together anywhere else.', 'Google BigQuery a plus.', 'Experience in API Gateways (IBM Datapower, Apigee)\\n\\nExperience with microservice and event driven architectures\\n\\nFamiliarity with Lambda and Kappa architectures for data intensive applications\\n\\nShows passion for hands-on work in the data engineering and data management space with a focus to bring them together to control at scale while improving data provisioning and consumption velocity\\n\\nExcellent organizational, communication, influence and execution skills]\"\\n\"[At Capital One, we‚Äôre building a leading information-based technology company.', 'Building on software and sensor technology developed at Google, Waymo is now launching the world‚Äôs first fully self-driving transportation service that will take members of the public from A to B at the touch of a button., \\n\\nWaymo takes an integrated approach to building the world‚Äôs first self-driving car, with researchers, product managers, and technical program managers working side by side.', 'Google Analytics, Omniture, Chartbeat, Crimson Hexagon) and traffic patterns, as well as Social Media analytics platforms (i.e.', 'Passion about machine learning and a desire to constantly learn as the field evolves., \\n\\nBA/BS degree in Computer Science, Machine Learning, or related technical field., \\n\\n2-5 years of relevant work experience with machine learning or data science., \\n\\nProficiency in R, Python, and/or Scala., \\n\\nExperience with problems and projects that depart from your average academic or Kaggle project and address real-world issues like severe class imbalance., \\n\\nUnderstanding of machine learning techniques in high-dimensional spaces including kernels, ensembles, regularization, dimensionality reduction, and clustering., \\n\\nSuperior verbal and written communication skills, ability to convey rigorous mathematical concepts and considerations to non-experts., \\n\\nPassion about machine learning and a desire to constantly learn as the field evolves., \\n\\nSecureworks (A Dell Technologies Company) is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.', 'Experience extracting data from both conventional databases (via SQL) and Hadoop data clusters (via Hive or similar language)]\"\\n\"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.', 'Experience in Geospatial analytics is preferred\\n\\nPreferred Tech and Prof Experience\\n\\n\\nDevOps & automation: Kubernetes, Git, Github, Jenkins, Terraform,Chef,Docker\\n\\n\\nExperience in designing, running and troubleshooting Hadoop/SPARK clusters\\n\\nBIGDATA: HBase, spark, hive, elastic search\\n\\n\\nCloud: IBM Cloud, AWS, S3, Swagger\\n\\n\\nStrong understanding of Linux OS core principles, performance and tuning\\n\\n\\nStrong programming skills in the following languages: Python, Scala, SQL, Java, bash, c++\\n\\n\\nExperience with Analytics : SPARK, python, scala, Jupyter notebooks\\n\\n\\nStrong knowledge of RDBMS management and application development: Postgres, MySQL, DB2\\n\\nEO Statement\\n\\nIBM is committed to creating a diverse environment and is proud to be an equal opportunity employer.', 'Strong knowledge of cloud-based object storage/processing platforms (AWS or Google).', 'Optimize data within Google Forms\\n\\nDesign surveys or advise teams on survey development to ensure proper data capture\\n\\nEnsure the integrity of data within the system\\n\\nBuild predictive models to identify future trends and patterns\\n\\nDevelop process maps and training plans for the team\\n\\nDevelop, monitor, evaluate and manage metrics (OKRs, KPIs, etc.)', 'PhD from an accredited college/university is preferred\\n\\nAbility to apply artificial intelligence techniques to achieve concrete business goals; ability to work with the business to understand available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Provide assistance, and resolve problems, using solid problem-solving skills, verbal/written communication\\n\\nUnderstanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Understanding of development practices such as testing, code design, complexity, and code optimization\\n\\nFluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\\n\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.', 'The Business Intelligence Data Analyst is responsible to support all CMS Marketplace users, who consume MIDAS Data and ensures the highest levels of customer satisfaction and provides thought leadership focusing on value-based design through the implementation and adoption of SAS solutions to empower analytics., \\n\\nMore About the Role:\\n\\n\\nChantilly, VA, \\n\\nThe Business Intelligence Data Analyst will perform the following duties:, \\n\\nCreates data modules in SAS and IBM COGNOS to fuse together many sources of data including relational databases, Hadoop-based technologies, Microsoft Excel, Flat files and so on and refine data by creating calculations, defining filters, and updating metadata for detail analysis of data.', '[Expert in enterprise data tranformation including data warehouse and data lake rationalization.Proven expertise in using combinations of supervised and unsupervised machine learning algorithms, predictive models, and statistical algorithms to provide insights into client datasets.Must be familiar with current link analysis and risk analysis tools.Deep knowledge of Data Science including Google Analytics and metrics, statistical analysis, machine learning and natural language processing, and data science, analytics, modeling and integration.Experience planning, organizing, facilitating, and collecting data from focus group and research/usability testing sessions.Data segmentation and data flow modeling.Knowledge of and experience working with Hadoop and Cloudera.Executing descriptive analyses, ranging from identifying product opportunities to understanding user behaviorExperience/expertise with Natural Language Processing (NLP), graph theory, Scala, and machine learning.Demonstrated ability building innovative data products (e.g., Artificial Intelligence, real-time services, such as personalization and commerce graphing using Big Data platforms with real-time data ingestion and processing).Establishing big data reporting and enterprise analytics platforms to analyze increasingly larger and more complex data sets.Skills at Identifying and correcting data quality issues and establishing a data governance framework to enforce data standards and improve accuracy using integrated internal and external disparate data sources., Developing machine-learning algorithms to improve predictions.Develop highly optimized, scalable automatic case matching logic on microservice/container technology.]', ', Qualifications, Education:, Bachelor‚Äôs degree, preferably in marketing, advertising, finance, business or a related field\\n, Work Experience:, 3+ years of analytical experience, media/advertising industry a bonus\\n, Skills:, Strong proficiency across the following platforms: Excel, PowerPoint, SQL, Tableau, Google Analytics, DoubleClick DCM, Python, & VBA\\nProficient in Microsoft suite of products particularly PowerPoint and Excel, including advanced knowledge of PivotTables and complex formulas\\nAbility to digest and explain complex ideas to a diverse group of stakeholders\\nMust be able to collaborate across teams to produce strong insights to advance reporting and client deliveries\\nExperience with digital media measurement and reporting platforms preferred as well as programming languages\\nExperienced in effective dashboard designing with a focus on customizing to client needs\\nAbility to work under pressure and manage multiple priorities\\nStrong communication and presentation skills equally capable of interacting with peers and senior leaders\\nMust be a team player but also have the ability to work independently]\"\\n\"[Responsibilities for this role include, but are not limited to:, \\n\\nBuilding complex data sets from multiple data sources, both internally and externally.', \"Research and develop analysis, forecasting and optimization methods to improve the quality of Google's user facing products; example application areas include ads quality, search quality, end-user behavioral modeling and live experiments.\", 'Familiarity with user funnel and digital marketing performance tracking\\nPerfect and automate more advanced analytic requirements, including LTV, lead scoring and financial modeling\\n, \\nProficiency in Excel and SQL required\\nWe prefer someone who has experience with Python and Google Analytics\\n0 to 3 years of work experience in a data focused role\\nPrior experience at a growth stage startup or software company a plus\\nBachelor‚Äôs Degree or equivalent experience required\\nWe love a strong Giphy game\\n]\"\\n\"[We are looking for an enthusiastic and technology-proficient Data Analyst who will work with terabytes of raw data, eliminate outliers, and share insights and KPIs based on the data analysis., \\n\\nResponsibilities:, \\n\\nParticipate in the design and development of analytical applications using an in-house data visualization product\\n\\nCreate dashboards, SQL optimization\\n\\nWork with terabytes of raw data and eliminate outliers, Strong knowledge of any data visualization product, creating dashboards, and SQL optimization\\n\\nExperience working with terabytes of raw data\\n\\nStrong knowledge of basic statistics for data analysis\\n\\nUnderstanding the best practices in data quality and quality engineering\\n\\nExperience with version control systems, Git in particular\\n\\nDesire and ability for quick learning of new tools and technologies, \\n\\nWill be a plus:, \\n\\nKnowledge of internals (queries, transformations, data connectors)\\n\\nKnowledge of Unix-based operating systems (bash/ssh/ps/grep etc.)', \"Data is already at the heart of both our ads & subscription businesses and you will be core to our ongoing growth., \\n\\nOur Stack, \\n\\nCustom, high-performance client-side javascript streams data from each users‚Äô browsers into our systems\\n\\nIt is collected/enriched by OpenResty/Nginx\\n\\nStreamed into fluentd\\n\\nStreamed to kinesis & elasticsearch\\n\\nEvents pushed to Google Analytics, exported to BigQuery, \\n\\nRequirements:, \\n\\n3-5+ years software engineering experience, specifically with:\\n\\nStreaming systems (ideally Fluentd and/or Logstash)\\n\\nElasticSearch & Kibana\\n\\nSpark, Vowpal Wabbit, Mahout\\n\\nAWS, Docker (ideally docker-compose/convox/ECS)\\n\\nRuby, OpenResty/Lua, Elixir/Erlang, R and/or Python\\n\\nStrong blend of technical and creative skills\\n\\nExperience working closely with engineering teams, researchers and business leaders\\n\\nStrong communication, and demonstrated ability to contribute to multiple projects, team goals and deadlines\\n\\nDetail oriented, analytical, and experienced with web technologies\\n\\nExperience working with distributed development teams and over communicating about progress and challenges to hit business goals\\n\\nAn insatiable appetite to transform education through data., \\n\\nStreaming systems (ideally Fluentd and/or Logstash)\\n\\nElasticSearch & Kibana\\n\\nSpark, Vowpal Wabbit, Mahout\\n\\nAWS, Docker (ideally docker-compose/convox/ECS)\\n\\nRuby, OpenResty/Lua, Elixir/Erlang, R and/or Python, \\n\\nAbout Chegg:, \\n\\nAs the leading student-first connected learning platform, Chegg's Student Hub makes higher education more affordable and more accessible, all while improving student outcomes.\", '\"[\\naccess to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\na chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\\nparticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\\n, \\nExperience in working with R and Python\\nExperience in working with Tableau and Microsoft packages\\nAbility to develop, test, and implement a data, as needed\\nAbility to work with data workflow via SQL queries\\nAbility to work with Java and MATLAB\\nAbility to obtain a security clearance\\nScheduled to obtain a BA or BS degree in Winter 2018 or Spring 2019\\n]\"\\n\"[Take data driven decisions through experimentation.', 'In addition, the Partnerships team supports Google‚Äôs own product teams with essential partnerships to help power Google‚Äôs user experiences in search, maps, travel, shopping, payments and more., Deliver yield management consulting, execution and outstanding results.', 'You can also follow us on LinkedIn, Instagram, Twitter and Facebook., Data is more than stats to our Business Development and Strategic Planning team‚Äîit‚Äôs a story waiting to be told.', 'Extensive experience directly querying multi-terabyte-sized data sets (with Hive and Presto) including clickstream data (like Google Analytics), third party data (like Facebook) and raw data ingested from non-standard platforms.', 'You preferably have experience with data pipeline tools like Apache Beam or even our open source API for it, Scio Experience with XGBoost, TensorFlow, or Google Cloud Platform is also a plus.', \"Our goal is to organize and produce data that's thoughtful, useful to sales teams and widely accessible., The Go-to-Market Operations (GtM) team ensures Google's complex and ever-evolving Ads business runs smoothly.\", 'You like a fast-paced & fun environment, believe in Twitter‚Äôs mission in the world and want to be a core actor in pushing it forward., \\n\\nWhat You‚Äôll Do:, \\n\\nYou will work with our team of experts in machine learning and software engineering to build powerful and scalable models and surface the most relevant content on Twitter.', 'You will formulate machine learning approaches and automate predictions while paying attention to the customer journey., Who You Are: You have a strong aptitude of performing large-scale data analysis, managing real world \"noisy\" data within an eCommerce platform; experience with Google Cloud Platform, Google Analytics, and Google Big Query, At least 4 years of experience with Data Analysis, Predictive Analytics, or Machine Learning, At least 2 year or experience with at least one programming language, such as Java or Python, etc., At least 2 year of experience with at least one statistics/data analysis package, such as Python or R, At least 2 year of experience working within a Retail or eCommerce company]\\n\"[Under general direction and minimal supervision perform data extraction and query data for ad hoc analyses and reports.', 'In this role you will have a very unique opportunity to work hand-in-hand with customers and Google engineers to shape the future of ML on Google Cloud.', '\"[\\n\\nBachelor\\'s degree from four year college or university; or two years related experience and/or training; and two plus years of experience; or equivalent combination of education and experience\\n\\nDemonstrated curiosity for analysis with large data sets, an attention to detail and an unparalleled work ethic\\n\\nExperience with Google Analytics, Adobe Analytics, Adobe Target and data management platforms strongly preferred.', 'Continuous Monitoring of A/B Tests\\n\\nCODE @ MIT 2014: Can I Take a Peek?', 'You will provide actionable insights and recommendations on all analytic and financial activities for area of business including agile ad hoc analysis and long term Project-based production of business insights., \\n\\nIn addition to these core functions, your additional responsibilities will be to:, \\nCollaborate with both internal stakeholders and external vendors involved in project definition, design and planning\\nDevelop hypotheses, gather data, brainstorm strategic options and create recommendations around strategic initiatives\\nOwn and rationalize marketing, web data and information across the organization\\nOperate as a visualization lead and Subject Matter Expert across the organization\\nCollect, Analyze and Synthesize complete information from disparate sources into a clear and compelling story in visualizations\\nBuild key success metrics to evaluate the impact of various projects, improvements and services that we provide\\nDevelop tactical analysis of our online business to strategically analyze current planning resources and develop actionable analysis, Required Qualifications:\\n\\n, Experience with range of Advanced Analytics techniques; statistical analysis skills; SQL, Tableau, Alteryx and other ETL/ELT knowledge and experience\\nGoogle Analytics, A/B testing and multivariate testing\\nStrong desire to tell analytical journeys and stories through the use of visualization tools\\n, \\nPreferred Qualifications:, \\nAbility to effectively build relationships across the business at all levels\\nCreative thinker who is intellectually curious with a demonstrated passionate about learning\\nSelf-starter, entrepreneurial, high-energy who can take initiative in a fast-moving environment\\nProficient in various programming languages, including SQL, R, and Python (and others)\\nDevelop critical business analysis skills - ability to hone in on real business impact and sorting through anecdotal reasoning, comfortable working with analysts and quantitative analysis\\nProvide strong technical understanding of current and emerging internet technologies and the operations of a commercial Website\\nFunction as a highly effective leader in a matrix environment given the role of serving various business partners on the enterprise and business unit teams\\nIdentify and model data to support personalization across digital channels; collaborate with product management, development, digital marketing, and data science to implement and enhance personalization efforts.', 'business analytics preferred\\n4+ year‚Äôs analytics experience, e-commerce preferred\\n, Special skills required:\\n\\n, Data enthusiast with strong analytical, technical and communication skills\\n, Advanced technical abilities including SQL, excel and clustering methods to extract insights across multiple databases\\nData visualization tools such as Tableau, Power BI\\nWorking knowledge of one or more of the following platforms:\\n\\nWeb analytics tool (Adobe Site Catalyst or Google 360 Premium),\\nCRM platform\\nLoyalty platform\\nA/B testing platform\\nEmail marketing platform (SalesForce Marketing Cloud is preferable)\\nAbility to utilize both internal and syndicated data systems and access, interpret and draw accurate conclusions to make a case for a plan of action or decision.', \"You will manage and coordinate testing, analysis, and improvement of our Google Analytics implementations and be instrumental in guiding our customers through successful setup and deployment., \\n\\nYou know you're the right candidate if you're passionate about implementing industry-leading best practices and design in your tagging and analytics measurement strategies.\", '\"[\\n\\nDesign a Business Intelligence and Analytics strategy to enable tracking of business goals and reporting on business performance at scale, \\n\\nBuild relationships with cross-functional stakeholders globally, gather requirements and deliver reporting/analytics solutions to meet those requirements, \\n\\nDevelop and lead a team of high performing Business Analysts, \\n\\nDrive smart, informed decision-making and deliver on implementation of a world class BI function for Global Security, with strong synergies across Facebook, \\n\\nCollaborate on conceptualization and development of centralized tools (including dashboards) that the Global Security Leadership and teams can use to extract data/insights in an automated manner, \\n\\nApply deep understanding of data flows and data definitions to creatively address complex issues, \\n\\nUnderstand Global Security/Physical Security Industry trends, and use these to inform analytics approaches, \\n\\nApply your expertise in business analysis, data visualization and data-mining to tell the story behind numbers and derive actionable insights for Global Security leadership, \\n\\nIdentify and analyze the most important metrics across program areas, \\n\\nBe able to conduct predictive analysis and be able to articulate implications for the business, \\n\\nDeliver presentations that are succinct and crisp, with a balance of high-level insights for executives, and detailed enough view for core teams, \\n\\nImprove reporting efficiency and standardization, \\n\\nBachelor‚Äôs degree, \\n\\n8+ years of experience in Business Intelligence and/or Analytics, with experience of taking on roles with increasing responsibility, \\n\\n5+ years of Management experience and managing team size of 5+ analysts, report writers, etc., \\n\\nExperience in startup(s) as well as enterprises who have created solutions at scale, \\n\\nKnowledge of BI best practices/methodologies, \\n\\nExperience with relational structures, SQL, data warehouse and reporting techniques, \\n\\nExperience with data visualization tools, \\n\\nExperience leading programs from definition through interpretation and execution, \\n\\nAnalytical experience solving problems using data to provide practical business insights, \\n\\nCommunication experience including presentation experience, \\n\\nMaster\\'s Degree in an analytical field or business]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA, \\n\\nWhether you\\'re on a consumer product (like Gmail, Search, Maps, Chrome, Android) or a business product (Google Ads, AdSense, Google Marketing Platform, Analytics), you take part in a complete marketing experience as you lead every facet of the product\\'s journey.', '\"[Google\\'s software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another.', \"We're constantly refining our signature search engine to provide better results, and developing offerings like Google Instant, Google Voice Search and Google Image Search to make it faster and more engaging.\", '\"[\\naccess to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\na chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\\nparticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\\n, \\nExperience with machine learning, data mining, statistics, or graph algorithms in an academic environment or internship\\nExperience with using R, Perl, Python, SAS, or SPSS for data analysis\\nKnowledge of an object-oriented language, including Java, C++, C#, or Python\\nKnowledge of Hadoop, MapReduce, or HDFS\\nAbility to obtain a security clearance\\nBA or BS degree\\n, \\nMA or MS degree preferred; PhD degree a plus\\n]\"\\n\"[\\nSolid understanding of machine learning algorithms and principles\\nStrong hands-on coding skills including prototyping languages such as Python and Java\\nGreat team player with excellent communication skills\\nMS or PhD in Computer Science, Electrical Engineering, Statistics, or equivalent fields with strong mathematical background\\nExperience with probabilistic models, time series, deep neural networks, supervised and unsupervised learning, natural language processing.', 'Continuous Monitoring of A/B Tests, \\n\\nCODE @ MIT 2014: Can I Take a Peek?', ', Ochsner Health System endeavors to make our site accessible to all users.', \"If you want to contribute on an incredible array of the biggest and most complex projects in the digital space, consider a career with Accenture Digital., Qualifications and SkillsBasic Qualifications , Bachelor's degree in Computer Science, Engineering, Technical Science or 3 years of IT/Programming experience.Minimum 2+ years of designing, implementing large scale data solutions operating in production environments using Spark, Hadoop and NoSQL ecosystem on premise or on Cloud (AWS, Google or Azure) using many of the relevant technologies such as Nifi, Spark, Kafka, HBase, Hive, Cassandra, Impala, GraphDB etc.Minimum 1 year of architecting data and building performant data models at scale for Hadoop/NoSQL/GraphDB ecosystem of data stores to support different business consumption patterns (using technologies such as Hive, Impala, Cassandra, HBase, Neo4j, DataStax Graph).Minimum 1+ years of Spark data processing using Java, Python, Scala; for data curation and analysis of large scale production deployed solution.Minimum 1 year of data integration, curation in a ‚ÄòBig Data‚Äô environment, using Talend Big Data Integration or Informatica BDE; for data curation and analysis of large scale production deployed solutions.Minimum 2 years designing and implementing relational or data warehousing models working with RDBMS (e.g.\", 'A career at Hallmark means you get to make a big impact and create something that can make a genuine difference.', 'Advanced experience with Google Analytics.', 'Mentors data scientists in pioneering techniques and business acumen, \\nRequired Qualifications:, \\n\\nCloud solution implementation experience with Azure Data Lake and Spark preferred\\n\\nMinimum 8 years hands-on experience with SQL\\n\\nAt least one year of experience in scripting languages such as Python\\n\\nDemonstrated experience in a cloud-based -computing environment such as AWS, Azure, or Google Cloud Platform\\n\\nBig data processing techniques, preferred\\n\\nCan work independently in ambiguous environment, \\n\\nAbout Logic20/20.', '\"[Data Scientist, Self Serve Ads, \\n\\nWho we are:, \\n\\nThe SSA team is responsible for driving global initiatives for Twitter\\'s self serve advertisers.', 'As a Twitter Data Engineer you will build datasets and make them accessible to our partner teams by writing great production code to simplify the complexity.', 'All other revenue cycle management as assigned by supervisor\\n, Minimum two to three years of experience with revenue cycle functions; experience in healthcare financial analysis, revenue cycle processes, denials, and cash applications strongly desired\\nAbility to demonstrate problem-solving, analytical, oral and written communication skills, and the ability to interact professionally with a diverse group\\nAbility to engage in multiple initiatives simultaneously while working in a dynamic environment subject to impromptu changes in schedules and priorities\\nExperience with data analysis and modeling to enable operational processes\\nProficient in Microsoft Office applications, including Visio, Word, Excel, Access, and Powerpoint\\nStrong initiative ‚Äì establish goals and take responsibility for meeting them within defined timelines\\n, Revenue Cycle functions & financial analysis: 3 years (Required)]\"\\n\"[Track in-game behaviors/metrics and provide analysis and recommendations for product changes and/or enhancements\\nPerform data analysis to support the operation and development of games\\nUnderstand marketing and game metrics and apply knowledge to identify analytical requirements that drive business profitability\\nWork with cross-functional teams to develop scheduled and ad hoc reports from a variety of sources for operations, marketing, and game design\\nAnalyze in-game monetization to identify opportunities for improvement\\nAnalyze marketing campaigns to determine efficiency and potential for optimization\\n, A Bachelor‚Äôs degree in data analytics, statistics or related field, with a heavy statistics orientation\\n3+ years relevant work experience\\nVery strong knowledge of one or more statistical tools such as R, Stata, SAS or Minitab\\nStrong knowledge of Excel, PowerPoint and SQL (experience with MySql and Vertica syntax preferred)\\nExperience applying data mining techniques (i.e., classification, clustering, association mining, forecasting), statistics and information retrieval methods to large data sets\\nAbility to write queries, pull and manipulate data sets and perform data analysis based on large data sets\\nExperience analyzing data from a variety of sources and types, both internal and external\\nSelf-starter, able to work independently with a wide degree of latitude and creativity\\nStrong interpersonal and communication skills\\nStrong problem solving and analytical skills\\nSolid quantitative background\\nProven track record in presenting complex results to users in an understandable manner\\n, Tableau\\nGoogle Analytics\\nThe mobile and online game industry\\nFree to play MMO games\\n, Please make sure that the durations of your education and employment on your resume are included in month/year format\\nSalary will be commensurate with experience\\nOnly highly qualified candidates need apply and only candidates that meet the degree requirements will be considered\\nApplicants must be legally able to work in the U.S. for KingsIsle]\"\\n\"[Data Analyst, Community Reach Center (CRC) is an Integrated Health Care and Trauma Informed Care Community that serves a metropolitan area in Denver, CO. Our 500 employees offer a wide variety of services to individuals and families in schools, day-treatment, residential, hospital, and correctional facilities., We are seeking a Data Analyst to join our team who is committed to enhancing lives every day.', 'The Data Scientist will be responsible for leveraging BJ‚Äôs wealth of data using advanced statistical methods., \\n\\nMajor Tasks, Responsibilities, and Key Accountabilities, \\n\\nExtract actionable insights from complex datasets using data mining, statistics, and database techniques to measure/understand/improve member acquisition/engagement KPIs\\n\\nApply Data Science methods along with project management skills to assist in developing new approaches to member acquisition, engagement and promotion\\n\\nWork cross functionally with stakeholders to ensure data-driven answers are provided and recommended\\n\\nBuild reports, dashboards, and other analytical tools to help communicate the state of business\\n\\nWorks with and streamlines established data warehouses, production data, and available tools to build strategic datasets in support of key initiatives\\n\\nEstablishes and systematically performs processes to assess and validate data accuracy, \\n\\nQualifications, \\n\\nWorking knowledge on machine learning and statistical methods (Supervised/unsupervised learning, Linear/logistic Regression, Random Forests, Lift Modeling, Linear/nonlinear Programming, Clustering, ARIMA, Neural Networks, Variable selection/feature engineering, hypothesis testing)\\n\\nExperience developing and productionizing machine learning models and application of statistical methods in Python(pandas/numpy/sklearn/scipy)\\n\\nExperience with data ETL in at least one of the following scripting language: Python/R/SAS/SQL\\n\\nExperience with Cloud computing environment preferred (AWS/Azure/Google Cloud)\\n\\nStrong analytics background with the ability to apply analytical skills to business problems\\n\\nMinimum 2 years of experience managing data science/analytics projects\\n\\nBachelor‚Äôs or Master‚Äôs degree in Computer Science, Mathematics, Statistics, Engineering or a related field, \\n\\nEnvironmental Job Conditions, \\n\\nMost tasks are performed while seated indoors at a personal computer.', 'From seeing the big picture through to implementing the tags and ensuring the quality of the data collected., Ensuring our business has the data required to grow our online sales business., Background in web analytics or digital marketing\\n\\nExperience deploying marketing and/or analytics tracking tools\\n\\nGood understanding of JavaScript, HTML, and CSS\\n\\nExperience of Tag Management tools, preferably Google Tag Manager or Adobe Dynamic Tag Manager, \\n\\nKnowledge of Python, SQL\\n\\nExperience of DSP\\'s and Digital Marketing Platforms\\n\\nExperience of Website Optimization]\"\\n\"[The Division of Pediatric Critical Care in the Department of Pediatrics, University of Utah School of Medicine has an immediate opening for a Business Analyst.', 'Follow Hawaiian‚Äôs Twitter updates (@HawaiianAir), become a fan on Facebook (Hawaiian Airlines), and follow us on Instagram (hawaiianairlines).', 'Our fast paced environment will require you to rise to the challenge and strive to exceed expectations\\n Enforce standards and best practices across all aspects of the platform/product\\n, You\\'ll need to have:, BA, BS, MS, PhD in Computer Science, Engineering or related technology field\\n 3+ years of relevant post-grad industry experience\\n Deep understanding of large scale distributed systems/databases\\n Solid understanding of different types of data models (relational, columnar, document based, key/value)\\n Experience/strong knowledge in Hadoop, Spark, and Large scale data processing\\n Experience building data pipelines and services and scaling them\\n Knowledge/Experience with web services, API design, OLAP/Business Intelligence, in-memory computing\\n Relentless focus on the quality and reliability needed for an infrastructure team]\"\\n[Hands on experience in implementing Data Lake and AWS Cloud DATA and Enterprise Data Warehouse SolutionsProviding Solutions for Big Data Platform infrastructure for across AWS VPCUnderstand GDPR lawsArchitect and standardize the way data is ingested, processed and exportedExpertise working with AWS and Other Cloud infrastructure:, Strong Database knowledge in Cloud based Database like RedShift, Snowflake etcMonitoring (CloudWatch, and ideally commercial solutions like DataDog, Splunk, PagerDuty)Identity Management & Security (e.g.', 'We advocate for users through partnerships with product areas at Google (and some Alphabet businesses), supporting Google‚Äôs consumer products ecosystem and enabling numerous launches for Google‚Äôs consumer products each year.', \"Experience with AI tools such as TensorFlow, IBM's OpenFlow, Dialogflow.\", 'People who are passionate about driving analytical thought within our customer teams and throughout the Hallmark Analytics community.', 'Knowledge of digital ad space or social media data preferred., We are committed to an inclusive and diverse Twitter.', 'Splunk flourishes with disruption and diversity.', 'Attempts through analysis to generate new, innovative ideas that optimize service delivery\\n\\nManages customer expectations throughout implementation process\\n\\n, Desired Qualifications\\n\\n, 2+ years of experience in field\\n\\nExperience with SQL coding and data analysis required\\n\\nExcellent written and verbal communication\\n\\nStrong customer service and interpersonal skills\\n\\nDetail oriented\\n\\nAbility to manage time and multiple tasks/projects efficiently\\n\\nBasic problem solving and conflict resolution\\n\\nPositive attitude centered on achieving high client satisfaction, both internal and external\\n\\nExperience with Blackbaud‚Äôs RE7/RENXT product is nice to have\\n\\n, Why you‚Äôll want to come work here:\\n\\n, Competitive salary (commission/bonus based on type of role), 4 weeks paid time off, great benefits (medical, dental, vision, FSA), 401K match\\n\\nGift matching, volunteer for vacation program, and endless community involvement opportunities\\n\\nNamed to Forbes‚Äô Fast Tech 25 and Fortune‚Äôs Change the World List; we are growing and offer incredible opportunity for advancement\\n\\nTremendous company culture and office perks as well as a new cutting-edge new headquarters completed in 2018\\n\\n, Stay up to date on everything Blackbaud, follow us on Linkedin , Twitter and Facebook .', 'Honesty, tenacity and consistency.Grow a deep technical interest in the spaces that IBM plays in.Be a person who thinks about bettering the world through your work in the technology sector., Bachelor‚Äôs Degree in Data Analytics, Data Science, Applied Math, EconomicsProven proficiency in analysis and visualization tools such as SQL, Tableau, and Excel.Expertise in writing and creating compelling data-based content and graphics, and presenting them in Word and PowerPoint.Experience with collaboration software tools such as Box, Zoom, Slack and Architect.Experience in social media analysis.Experience working in the tech sector and/or a passion for technology.Polish and presence to work with senior management.Excellent verbal and written communication skills.Unwavering attention to detail and excellence.Compassion and respect for fellow colleagues and clients.Entrepreneurial mindset, being able to operate in a highly visible and accountable role., Advanced Degree in the Engineering/Sciences, Math, Computer Science and/or MBA Strategy or JD.5+ years of work technology flavored experience in: Data Analytics, Market Research, Performance Marketing, Management Consulting, Strategy, Product Management, Communications, PR, or Graphic Design.Existing relationships with leading industry analysts/influencers in emerging technologies space.]', 'At Splunk, we‚Äôre committed to our work, customers, having fun, and most meaningfully to each other‚Äôs success.', 'Our team members follow an open approach to technology innovation and believe that technology is essential for human success., \\n\\nWhy work with us?, Life at Dell means collaborating with dedicated professionals with a passion for technologyWhen we see something that could be improved, we get to work inventing the solutionOur people demonstrate our winning culture through positive and meaningful relationshipsWe invest in our people and offer a series of programs that enables them to pursue a career that fulfills their potentialOur team members‚Äô health and wellness is our priority as well as rewarding them for their hard work, \\n\\nDell is committed to the principle of equal employment opportunity for all employees and to providing employees with a work environment free of discrimination and harassment.', '), \\n\\nRewards:, \\n\\nVoted 2018 IoT Company of the Year by Compass Intelligence\\n\\nWork with the Best and Brightest Talent\\n\\nStable, High Growth and Profitable Company\\n\\nComprehensive Benefits (Medical, Dental, Vision, 401K Plan)\\n\\nWellness Programs, Learning and Development Opportunities\\n\\nHappy Hours, Car Washes Onsite, Local Food Trucks, Fun Team Building Events\\n\\nEmployee Discounts on Spireon Products and Services\\n\\nSpireon Connections and Spireon University for ongoing learning and development]\"\\n[Experience in data analysis, including data preparation and modeling, with expertise in statistical approaches, operational analysisDemonstrated knowledge of software tools, including Microsoft Office products, business intelligence tools such as Tableau, data ingestion tools such as Talend, and analysis tools such as Stata, R, Matlab, and Splunk.General experience with data reporting, dashboard design, and other situational awareness tools.Experience with decision support and communicating results that inform data-driven decisions in military operation]\\n\"[Serve as technical lead in analysis and reporting efforts that support the Health Plan‚Äôs Clinical and Provider teams, programs and quality activities.', 'And just happen to be Google Ventures backed as well.', 'Experience using Google Analytics and Google Tag Manager is a plus.', \"Data Scientists work all across the organization to help shape Google's business and technical strategies by processing, analyzing and interpreting huge data sets.\", 'Working knowledge in the following technologies: Python, SQL, R, Alteryx, Microsoft Azure, IBM Watson, Tableau, etc.', 'Leverage Google Analytics and internal data to provide key insights by analyzing customer behavior.', ')., \\n\\nQuantitative research and analysis skills including competence with statistical software (Python preferred)., \\n\\nExperience with Google Suite (Docs, Sheets, Slides, etc.', \"You'll find us at over 150 locations across the USA; our most distinguished campuses include Stanford, UCLA, Princeton, and MIT.\", 'We are a late-stage startup backed by Capital G (Google Capital) where you will gain valuable experience in a fast-paced high-growth environment., \\n\\nResponsibilities, \\n\\nMine large scale and high dimensional data, identify patterns, and visualize trends\\n\\nCreate predictive models using supervised learning techniques to detect and stop the most sophisticated threats\\n\\nInnovate new semi-supervised and online learning techniques to enhance our threat detection capabilities and reduce nuisance false positives for our customers.', 'You have the technical competence to perform more advanced analytics:\\nCoding skills for analytics and data manipulation (SQL, R, Python, Pandas, Scala)\\nData visualization (such as Tableau, Qlik, D3, ggplot)\\nExperience performing analysis with large datasets in a cloud based-environment, preferably with an understanding of Google‚Äôs Cloud Platform\\nExperience training and tuning statistical and machine learning models with libraries/frameworks such as sci-kit learn, tensorflow, pytorch or similar\\nFamiliarity with experimentation and A/B testing\\nYou are capable of tackling very loosely defined problems and thrive when working on a team which has autonomy in their day to day decisions.', 'You can critically think through business problems and communicate to stakeholders the next., The Real Estate and Workplace Services (REWS) team creates inspiring spaces and innovative services that bring Google‚Äôs culture and values to life.', 'Providence does not discriminate on the basis of race, color, gender, disability, veteran, military status, religion, age, creed, national origin, sexual identity or expression, sexual orientation, marital status, genetic information, or any other basis prohibited by local, state, or federal law., Schedule: Full-time, Shift: Day, Job Category: Information Technology, Location: Washington-Renton, Other Location(s): Oregon-Portland, Oregon-Beaverton, Req ID: 194036]\"\\n\"[\\n, \\n\\nAct as a thought leader and mentor: teaching, training, and guiding using the latest ML tools, methods, and software integration techniques\\n\\nFacilitate or participate in business needs fulfillment through machine learning implementation ideation/discovery sessions with business stakeholders and subject matter experts, \\n\\nEstablish repeatable methods for the entire machine learning lifecycle (discovery/ideation to production hardening and launch)\\n\\nDocument and teach cloud technologies and machine learning tools to adjacent team members (data scientists, big data engineers, and architects)\\n\\nDocument architecture patterns for machine learning and data engineering pipelines and models, \\n\\nExperience with Amazon-AWS and Google Cloud ML toolsets\\n\\nExperience with Cloudera Big Data tools (Impala, Kudu, Parquet, HDFS, Sqoop, Flume, Spark, Kafka, Data Science Workbench, etc.)', 'Required Skills & Experience\\n, \\n\\nStrong python scripting skills\\n\\nExpertise in building out data pipelines and infrastructure\\n\\nFamiliarity with AWS\\n\\nExperience with distributed stream processing (Kafka, Spark), \\n\\nBenefits\\n, \\n\\nStrong equity package\\n\\nMedical/dental/vision\\n\\nMission-driven team]\"\\n\"[\\nSetting up new integrations with external data providers from around the world which often requires detective work, Google Translate-ing, working with meteorologists, and reverse engineering\\nBuilding reliable and resilient services, that report performance and quality metrics and trigger alerts when things go wrong\\nwriting services and utilities that rapidly ensure the quality of the data being received and transforms it into a usable form.', 'Experience with the Hortonworks sandbox environment]\"\\n\"[Data Engineer, \\n\\nAs a Data Engineer for Slalom Consulting, you\\'ll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.', 'Excellent written and verbal communication and interpersonal skills, able to effectively collaborate with technical and business partners\\n\\nStrong self-drive to teach, learn from, empower, and facilitate your team\\n\\nSense of humor (everyone says this, but we really mean it)\\n\\n\\nOUR COMMITMENT TO DIVERSITY AND INCLUSION: At Hearsay we believe that diverse teams are the best teams.', 'Specifically, you will lead the development of fraud detection algorithms and systems that protect Square and its customers from fraud and financial loss., \\n\\nYou will:, \\n\\nCreatively leverage both new and existing data to increase the effectiveness and efficiency of our risk infrastructure\\n\\nWork with engineers to design machine learning solutions that operate effectively at scale\\n\\nPartner with operatives to quickly respond to rapidly evolving threats\\n\\nApply good software development practices and actively contribute to production code\\n\\nHelp build the next generation of data products at Square, You have:, \\n\\n2-4 years of relevant industry experience\\n\\nA graduate degree in statistics, applied mathematics, computer science, physical sciences, or a similar technical field\\n\\nExperience developing and deploying machine learning / deep learning solutions\\n\\nThe versatility to communicate clearly with both technical and non-technical audiences\\n\\nA willingness to solve problems using whichever tool is most appropriate for the situation, \\n\\nTechnologies we use and teach:, \\n\\nPython (numpy, pandas, sklearn, xgboost, TensorFlow)\\n\\nMySQL, Hive\\n\\nJava\\n\\nGoogle Cloud Platform\\n\\nTableau, Looker, At Square, our purpose is to empower ‚Äì within and outside of our walls.', 'www.levyrestaurants.com]\"\\n\"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.', 'Your mission, should you choose to accept it, is to make sure the world understands the value of BigQuery and Google Cloud data analytics solutions.', 'in Computer Science, Math, Engineering or related quantitative field.Work experience with SQL, Teradata, Google Big Query and/or other comparable database systems.Expert knowledge of R, Python or other statistical computing programming languages., Knowledge of a variety of machine learning techniques (clustering, decision tree learning, artificial neutral networks, etc.)', \"Experience with computer scripting and programming\\n\\nExperience with human-subjects research and understanding of HIPAA\\n\\nExperience with ticketing systems\\n\\nExperience with statistical-analysis approaches\\n\\nExperience with statistical software in R/Python\\n\\n, THE SIMONS FOUNDATION'S DIVERSITY COMMITMENT\\n\\n\\n\\nMany of the greatest ideas and discoveries come from a diverse mix of minds, backgrounds and experiences, and we are committed to cultivating an inclusive work environment.\", 'Analyzes code to find causes of errors and revise programs as needed., Required Qualifications, \\n\\n4+ years of Extensive experience with designing, developing, and ongoing support of a data warehouse environments\\n\\n2+ years hands on experience with ETL tools like Informatica\\n\\n4+ years of experience in SQL\\n\\n2 years+ experience working with the Hadoop ecosystem and tools\\n\\nUnderstanding and experience with cloud platforms and technologies like Azure, AWS, Google Cloud is preferred\\n\\nExperience with Teradata, a major plus\\n\\nExcellent scripting and programming skills using python or any other programming language\\n\\nDemonstrated ability to understand data architectures and systems\\n\\nStrong communication and customer relationship skills.', 'Prior experience with Google DataFlow and/or Spark is a big plus.', 'Make Twitter-scale data more discoverable and easy to use for Data Scientists and Analysts across the company.', 'You will bring solid experience in implementing web analytics tools (Google Analytics/Adobe Analytics), the ability to leverage consumer data into insights, and a collaborative work ethic to the team!', '[Bachelor‚Äôs degree from an accredited college in an analytical disciplineExperience with parts of the data analytics pipeline, such as data collection, wrangling, cleaning, analysis, visualization, presentationExperience formulating and executing online researchWriting reports that follow logical guidelines (e.g., pyramid logic)Proven ability to think creatively about data analysisProven potential and/or desire to learn how to code using a scripting language such as Python or R and/or use APIs to access data and data analysis capabilities, Experience with open-source intelligence projectsExperience with machine learningExperience with consultingTeam player, enjoys working on a collaborative teamDetail-oriented with effective written and verbal communication skills with the ability to communicate at all levelsExperience with analytical tools such as Brainspace, Nuix, or TableauKnowledge of: aerospace and defense market, corporate finance, microeconomic factors associated with manufacturing]\\n[Bachelor‚Äôs degree from an accredited college in an analytical disciplineExperience with parts of the data analytics pipeline, such as data collection, wrangling, cleaning, analysis, visualization, presentationExperience formulating and executing online researchWriting reports that follow logical guidelines (e.g., pyramid logic)Proven ability to think creatively about data analysisProven potential and/or desire to learn how to code using a scripting language such as Python or R and/or use APIs to access data and data analysis capabilities, Experience with open-source intelligence projectsExperience with machine learningExperience with consultingTeam player, enjoys working on a collaborative teamDetail-oriented with effective written and verbal communication skills with the ability to communicate at all levelsExperience with analytical tools such as Brainspace, Nuix, or TableauKnowledge of: aerospace and defense market, corporate finance, microeconomic factors associated with manufacturing]\\n[Bachelor‚Äôs degree from an accredited college in an analytical disciplineExperience with parts of the data analytics pipeline, such as data collection, wrangling, cleaning, analysis, visualization, presentationExperience formulating and executing online researchWriting reports that follow logical guidelines (e.g., pyramid logic)Proven ability to think creatively about data analysisProven potential and/or desire to learn how to code using a scripting language such as Python or R and/or use APIs to access data and data analysis capabilities, Experience with open-source intelligence projectsExperience with machine learningExperience with consultingTeam player, enjoys working on a collaborative teamDetail-oriented with effective written and verbal communication skills with the ability to communicate at all levelsExperience with analytical tools such as Brainspace, Nuix, or TableauKnowledge of: aerospace and defense market, corporate finance, microeconomic factors associated with manufacturing]\\n\"[\\n\\nMaintain the Customer Experience big data visualization roadmap\\n\\nInterview key stakeholders from the Customer Experience team to identify their requirements for data visualization and reporting\\n\\nDocument stakeholder requirements, develop functional specifications, and design and deliver visualizations\\n\\nAct as a liaison between the Customer Experience team and the Data and Analytics team\\n\\nParticipate in bi-weekly meetings with the Data and Analytics team to ensure adherence to best practices\\n\\nDevelop SQL queries using Google BigQuery against Geotab‚Äôs big data environment\\n\\nUse Redash or Datalab for visualizations of data from existing datasets and create derivative datasets when required\\n\\nEnsure Geotab data standards are met by ensuring the the developed queries and dashboards coincide with the Customer Experience KPAs and KPIs\\n\\nMaintain released visualizations ‚Äî resolve issues and change requests as required\\n\\nKeep documentation up to date for all your areas of responsibility\\n\\nContinuous learningContribute to the Geotab staff blog on an annual basis, \\n\\nBachelor‚Äôs degree in Computer Science, Math, Statistics, Engineering or related field\\n\\nExperience working with big data environments and understanding techniques to extract value out of very large data sets\\n\\n4+ years‚Äô experience using SQL (experience with Google BigQuery an asset)\\n\\n2+ years‚Äô experience with data science tools (experience with Datalab, Python, Pandas, NumPy an asset)\\n\\n2+ years‚Äô experience creating high-quality dashboards and data visualizations for internal consumption (experience with Redash an asset)\\n\\nExperience with database design and writing queries\\n\\nFamiliarity with Customer Experience metrics an asset]\"\\n[Perform application design, code development and testing utilizing JavaScript and jQueryUtilizing Quadient Ignite; work with client input files to ensure data is appropriately formatted and cleansed prior to moving over to letter composition side of departmentDesign reusable components, frameworks and librariesReview code and provide feedback relative to best practices and improving performanceTroubleshoot production support issues post-deployment and come up with solutions as requireWork very closely with the application team and drive solutionsDesign, execute, and modify programs utilizing the appropriate technologyUnderstanding the ramifications of programs and logical order of operationsContribute to the upkeep and consistency of internal documentation related to issues, resolutions, usage topics, and trainingMaintain confidentiality regarding the information being processed, stored or accessedProof composition output against data following to ensure accuracy of letter text, images and variable fieldsAssist in resolving internal/external inquiries related to input/output requirements, intended usage, strategic planning, and alignment of these elements to internal checks, controls, and quality assuranceTrack quality defects and ensure they are resolvedProvide general hands-on demonstrations of common process, 4-year degree in Computer Science or related experienceMust have demonstrated proficiency with JavaScriptDevelopment and support skills in at least one of the following software packages: Quadient Ignite (preferred), Postalsoft / Firstlogic Business Objects, BCC, or Group 1 / Pitney BowesReferenceable examples of developing custom code for applicationsExperience in data migration and integrationExperience integrating business processes across disparate systems using 3rd party toolsExpertise on various APIsPositive and consultative demeanor and strong work ethicAbility to interact with technical and non-technical resourcesExcellent verbal and written communications skills]\\n\"[Data Analyst - Media Analytics - 11471, \\n\\nAnalytics - USA Stamford, Connecticut, \\n\\nThe Nielsen Company is a leading global information and measurement company that provides clients with a comprehensive understanding of consumers and consumer behavior., \\n\\nThis role will closely collaborate with Nielsen‚Äôs Media Analytics practice.', 'Experience understanding data from Google Analytics, Facebook Insights and other marketing dashboards.', \"Implement new, highly scalable platform components and tools leveraging machine learning and deep learning models to solve real-world problems in areas such as Speech Recognition, Natural Language Processing and Time Series predictions\\n\\nDemonstrating self-reliance to achieve goals collaboratively, \\n\\nBENEFITS, ibm.com/employment/us/benefits/\\n\\nibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\\n\\nFinding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee's strength and career aspirations\\n\\nDiversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\\n\\nibm.com/ibm/responsibility/corporateservicecorps, Strong programming skills and data structures, with proficiency in Python, R, Java or similar with related machine learning packages\\n\\nProficient in SQL\\n\\nExperience using Unix/Linux & the corresponding standard command line tools preferred\\n\\nDeep understanding of machine learning techniques for classification, & regression is preferred\\n\\nAbility to design or evaluate intrinsic & extrinsic metrics of your model‚Äôs performance which are aligned with business goals\\n\\nUsing NLP & ML techniques to extract structure from unstructured data\\n\\nAbility to come up with solutions to loosely defined business problems by leveraging pattern detection over large datasets\\n\\nDemonstrated ability to investigate & debug difficult problems\\n\\nStrong written and verbal communication skills.\", 'Expertise in delivering analytics projects using leading processes including expert knowledge of data discovery, cleaning, model selection, validation and deployment\\n\\nUnderstanding of data preparation, machine learning, deep learning, natural language processing; ability to discuss mathematical formulations, alternatives, and impact on modeling approach; Knowledge of development practices (testing, code design, complexity, and code optimization)\\n\\nFluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, Tensorflow); and experience with platforms such as Google Cloud, Azure, and AWS; Ability to pick up new languages and technologies quickly; Ability to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\\n\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.', 'Author technical and academic publications showcasing capabilities of comScore‚Äôs data assets to solve real world problems.', 'Awesome with Google Analytics, AdWords, and SQL?', ', Affirmative Action Policy Statement]\"\\n[Raytheon is an Equal Opportunity/Affirmative Action employer.', 'PhD from an accredited college/university is preferred\\n\\nAbility to apply artificial intelligence techniques to achieve concrete business goals while understanding available resources and constraints around data (sources, integrity, and definitions), processing platforms, and security; Ability to discuss mathematical formulations, alternatives, and impact on modeling approach and understanding of development practices (testing, code design, complexity, and code optimization)\\n\\nSolid experience performing data science from data discovery, cleaning, model selection, validation, and deployment; experience coding artificial intelligence methods using object-oriented programming in a software development process, and ability to restructure, refactor and optimize code for efficiency\\n\\nFluency in Python; Proficiency in AI related frameworks (NLTK, Spacy, Scikit-Learn, and Tensorflow); Experience with platforms (Google Cloud, Azure, and AWS); Ability to pick up new languages and technologies quickly and to work efficiently under Unix/Linux environment with experience with source code management systems like GIT; Ability to work with a variety of databases (SQL, ElasticSearch, Solr, Neo4j)\\n\\nAbility to travel up to eighty percent of the time; Applicants must be currently authorized to work in the United States without the need for visa sponsorship now or in the future, \\n\\nKPMG LLP (the U.S. member firm of KPMG International) offers a comprehensive compensation and benefits package.', 'Apply now., \\n\\nEOE/M/F/Veteran/Disability]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; Sunnyvale, CA, USA; Seattle, WA, USA; Kirkland, WA, USA, \\n\\nWhether you\\'re on a consumer product (like Gmail, Search, Maps, Chrome, Android) or a business product (Google Ads, AdSense, Google Marketing Platform, Analytics), you take part in a complete marketing experience as you lead every facet of the product\\'s journey.', 'At Splunk, we‚Äôre committed to our work, customers, having fun and most meaningfully to each other‚Äôs success.', \"This position will be responsible for building predictive analytics models using various machine learning techniques., \\n\\nLearning & Development Opportunities, \\n\\nThe employee will have the opportunities to lead a customer co-innovation project as a data scientist; to be able to directly interface with customer and understand the requirements, and to be able to apply leading-edge techniques to solve challenging high-value IoT business requirements., \\n\\nWork Experience, \\n\\nIdeally, the Candidate should have professional experiences in the following:, Data mining and machine learning techniquesStatistics, applied mathematics or operations research backgroundR, Python, SQL and other programming languages, \\n\\nEducation & Qualifications / Skills & Competencies, \\n\\nMaster or above degree in a related field is desirable, \\n\\nSAP'S DIVERSITY COMMITMENT\\n\\nTo harness the power of innovation, SAP invests in the development of its diverse employees.\", 'Implement new, highly scalable platform components and tools leveraging machine learning and deep learning models to solve real-world problems in areas such as Speech Recognition, Natural Language Processing and Time Series predictions\\n\\nDemonstrating self-reliance to achieve goals collaboratively, \\n\\nBENEFITS, ibm.com/employment/us/benefits/\\n\\nibm.com/press/us/en/pressrelease/50744.wss, Skill development: helping our employees grow their foundational skills and promoting internally\\n\\nFinding the dream job at IBM: navigating our company with the potential for many careers by channeling an employee\\'s strength and career aspirations\\n\\nDiversity of people: Diversity of thought driving collective innovation, ibm.com/ibm/responsibility/initiatives.html\\n\\nibm.com/ibm/responsibility/corporateservicecorps, Bachelor‚Äôs Degree in Statistics, Mathematics, Engineering or related STEM fields\\n\\nAt least 5 years of progressive experience with a broad set of technical stacks, hands-on Machine Learning and Big Data\\n\\nDeep expertise in building scalable with Machine Learning powered applications\\n\\nExpertise across a variety of data integration tools streamlining data across several big data solutions\\n\\nExperience in creating and managing capabilities and solutions for any one of the following:\\n\\nRisk, Legal, Fraud, Compliance Management\\n\\nRetail, Wealth and Private Banking\\n\\nMarketing Analytics\\n\\nQuantitative Financial Analytics\\n\\nDigital Customer Experience, Customer Care and Customer Journey Optimization, \\n\\nRisk, Legal, Fraud, Compliance Management\\n\\nRetail, Wealth and Private Banking\\n\\nMarketing Analytics\\n\\nQuantitative Financial Analytics\\n\\nDigital Customer Experience, Customer Care and Customer Journey Optimization, Master‚Äôs Degree in Statistics, Mathematics, Engineering or related STEM fields\\n\\nAt least 7 years of progressive experience with a broad set of technical stacks, hands-on Machine Learning and Big Data\\n\\nSales and or Pre-Sales experience]\"\\n\"[Senior Data Scientist, \\n\\nSanta Clara, \\n\\nA compelling opportunity has arisen to join a leading analytics business based in the South Bay, as a Senior Data Scientist with a core focus on Natural Language Processing and Linguistics., \\n\\nThe business was recently awarded the highest possible scores for corporate strategy, analysis, consulting and product roadmaps by a leading market research organization., \\n\\nReporting directly to the Director of Data Science, you will be joining an organization on a strong growth path, working with one of the most interesting and complex data sets available., \\n\\nYOUR ROLE AS SENIOR DATA SCIENTIST:, \\n\\nDocument classification - genre recognition - ads, spam, natural speech\\n\\nSentiment Analysis of linguistic data\\n\\nExtending insight extraction functions\\n\\nUnderstanding trends and theories in linguistic classification, \\n\\nSKILLS AND EXPERIENCE:\\n, Expert hands-on Python programming experience\\n\\nHands on experience with JavaScript & MySQL\\n\\nExtensive experience with NLP and Linguistics\\n\\nExceptional communication skills, \\n\\nDesirable Requirements:, \\n\\nHands-on experience with Hadoop, Cassandra, Spark\\n\\nStatistics or Data Visualization experience\\n\\nCross functional project management experience\\n\\nPrior experience working with overseas teams.', 'This means that Hallmark was a big data company before big data was even a ‚Äúthing.‚Äù We have data on millions of consumers and their purchases across tens-of-thousands of products across thousands of points of distribution.', 'Experience in cloud computing platforms such as Google Cloud Platform\\n\\nExperience with deep learning framework (ex: Tensorflow, Torch, etc)\\n\\nProven command of R or Python or Java\\n\\nExcellent interpersonal, verbal, and written communication skills - must be able to communicate complex ideas in both technical and user-friendly language.', 'This role collaborates heavily with their matrix partners in JetBlue‚Äôs IT, JetBlue Tech Ventures and external business partners., \\n\\nThe data engineer can change priorities and focus to meet business demands, excels when working on complex projects, is motivated to deliver results, and exhibits the JetBlue values of Safety, Caring, Integrity, Passion , and Passion., Design, develop and manage data management products from conception to retirementEnsure that the data engineering team delivers with consistency, high quality and predictabilityCreate and promote a work environment focused on engineering excellence to attract, develop and encourage a culture of technical innovationPartner with product management and marketing teams and help develop the product vision and roadmapCreate the JBTP data infrastructure and analytics environments, understand the data and provide support for key business decisionsParticipate in the DevOps practice as it pertains to data engineeringHelp establish frameworks, design and integration patterns as well as guide the software development performed by business partnersHelp manage a collection of external technology products used to deliver business productsPartner with JetBlue Tech Ventures to identify, monitor, learn, experiment and share information about emerging technology that is relevant to JetBlue Travel Products.Other duties as assigned, Bachelor‚Äôs Degree in Computer Science or related technical field or equivalent practical experience with demonstrated capability to perform job responsibilities through four (4) previous years of combined experience and educationThree (3) years‚Äô experience in an engineering roleGood understanding of software engineering environments and standardsDeep understanding of Internet technologies, protocols and methodologies for delivering web-based productsExperience managing Service Level AgreementsExperience interacting daily with people at different levels within the organization, including developing and maintaining ongoing relationshipsMust pass a ten (10) year background check and pre-employment drug testLegally eligible to work in the country in which the position is located, Experience maintaining a public profile and building relationships throughout the organizationFive (5) years‚Äô experience in technology rolesExperience in writing software in one or more languages such as Java, Python, Go and/or JavaScriptExperience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud Platform., Regular attendance and punctualityPotential need to work flexible hours and be available to respond on short-noticeWell-groomed and able to maintain a professional appearanceWhen working or traveling on JetBlue flights, and if time permits, all capable crewmembers are asked to assist with light cleaning of the aircraftOrganizational fit for the JetBlue culture, that is, exhibit the JetBlue values of Safety, Caring, Integrity, Passion, and Fun, Computer and other office equipment, Generally not required, or up to 10 pounds occasionally, 0 pounds frequently.', 'Experience with the following technologies is desired: Hadoop, AWS, Tableau or other OLAP cube/data visualization, Oracle database, Adobe Marketing Cloud (Omniture), Google Analytics, Clicktale, ExactTarget/Salesforce (or similar ESP)\\n\\nExperience coordinating and communicating with internal and external stakeholders.', 'Hadoop, Spark, Apache Beam, Flink), Understand trade offs among data formats such as CSV, JSON, Avro, Parquet\\n\\nExperience with stream processing technologies such as Apache Beam, Spark Streaming, Flink, Kafka Streams\\n\\nETL experience on AWS using EMR, Firehose, Lambda\\n\\nETL experience on Google Cloud using Dataproc, Cloud Functions, Dataflow\\n\\nExperience using a data warehouse such as Redshift or BigQuery\\n\\nFamiliar with messaging systems such as Kinesis, Kafka, PubSub\\n\\nFamiliar with automation tools such as Apache Airflow, Luigi, AWS Data Pipeline, \\n\\nCompetitive base salary plus meaningful equity\\n\\nComprehensive benefits (Medical, Dental, Vision, 401k)\\n\\nFlexible Paid Time Off, \\n\\nDaily catered lunches\\n\\nDog friendly office\\n\\nCollaborative, fun team]\"\\n\"[\\n\\nAs a result, Trianz is focusing on three important themes in our engagement model with clients., \\n\\nCrystallize business impact from a top management point of view\\n\\nHelp Clients achieve results from strategy-by making execution predictable through innovative execution techniques\\n\\nCreate a positive, enriching partnership experience in everything we do, \\n\\nCloud\\n\\nAnalytics\\n\\nDigitization\\n\\nInfrastructure\\n\\nSecurity, \\n\\nJob Description, \\n\\nStrong data engineer able to:, Create and maintain optimal data pipeline architecture,Assemble large, complex data sets that meet functional / non-functional business requirements,Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources,Work with stakeholders including Product, Data and Design teams to assist with data-related technical issues and support their data infrastructure needs,Experience building and optimizing data pipelines, architectures and data sets,A successful history of manipulating, processing and extracting value from large disconnected datasets., \\n\\nA plus:, Experience in creating reports and dashboards in Tableau., \\n\\nTechnologies we use:, \\n\\nDataswarm (data pipeline framework in Python), Hive, Presto, Python, Scuba (in-memory database), SQL, Oracle, Tableau, \\n\\nTrianz is growing above the average of the professional services industry.', 'Working knowledge of Google docs, calendars, and sheets.', 'Experience with source control solutions (ex git, GitHub, Jenkins, Artifactory) required\\nAt least 1 year of experience with big data and the Hadoop ecosystem (HDFS, SPARK, SQOOP, Hive, Impala, Parquet) required\\nExperience with Agile development methodologies and tools to iterate quickly on product changes, developing user stories and working through backlog (Continuous Integration and JIRA a plus)\\nExperience in any scheduling tools such as IBM Tivoli Workload Scheduler, Control M, AutoSys, etc required\\nWorking knowledge of Tableau ‚Äì a plus\\nAdvanced oral and written communication skills; must be a self-starter.', 'Save for your future: Through profit sharing, you share in the success of Hallmark.', \"From developing and maintaining our data centers to building the next generation of Google platforms, we make Google's product portfolio possible.\", '\"[ExxonMobil Research and Engineering Company is seeking ambitious and motivated candidates with Engineering, Applied Math, Computer Science or related experience and with an interest in applying data analytics to solve the world‚Äôs toughest energy problems to join our Modeling & Optimization team at the Clinton, NJ campus., Job Role Responsibilities\\n\\n, Knowledge and experience with distributed data processing environments, non-convex optimization, and numerical methods\\nCurious and analytical mindset\\nDemonstrated strong leadership skills\\nExcellent verbal and written communication skills\\nDesire and ability to grow into new process technology areas and learn new skills\\n, Expected Level of Proficiency\\n\\n, M.S./Ph.D.', 'Use of Google Analytics and other analytic and statistical tools to provide in-depth statistical analyses to leverage data when making business decisions\\n\\nCommunicate insights to key internal stakeholders and executive leadership team\\n\\n\\n, Communicate insights to key internal stakeholders and executive leadership team\\n, Education:, \\nBachelor\\'s Degree Required (Concentration in a quantitative field preferred including Business, Engineering, Math, Statistics, Economics, Operations Research)\\\\\\nMaster\\'s Degree Preferred]\"\\n\"[Execute and enhance recurring business performance reporting packages and data analyses;\\n\\nCreate SQL queries to facilitate extraction of data into reporting tools, such as Power BI;\\n\\nAnalyze existing complex systems to understand and document data elements, relationships, data flow, dependencies and their related interfaces;\\n\\nActively participate in cross-functional teams providing analysis expertise, offering original perspectives and challenging the conventional views;\\n\\nPerform other duties and assignments, as requested, Bachelor‚Äôs degree in Business Information Systems or equivalent related experience;\\n\\nProven record of data management skills and experience with SQL;\\n\\nAdvanced Microsoft Office knowledge and application skills;\\n\\nAbility to handle multiple assignments on a timely basis with a high degree of accuracy and attentiveness to details;\\n\\nEnthusiastic team player with a committed work ethic and strong problem-solving aptitude;\\n\\nHigh level of motivation and can-do attitude in a high-performance environment;\\n\\nExceptional personal and professional integrity and trustworthiness\\n\\nKnowledge of network marketing business operations strongly preferred]\"\\n\"[\\n\\nEfficiently prioritize to supplement day-to-day operations with data and processes that scale - provide teams with ad-hoc analysis, automated reports and dashboards, and self-service reporting tools that accurately reflect the health of their products and help them track their progress towards their goals.', \"Over the past years, Maven Wave has received the following awards and accolades:, \\n\\nGoogle Cloud North America Services Partner of the Year, 2018\\n\\n#21 Best Workplaces in Chicago, FORTUNE, 2018\\n\\nGreat Place To Work Certification, Great Place to Work, 2017 & 2018\\n\\nFast Fifty, Crain's Chicago Business, 2014, 2015, 2016, 2017, 2018\\n\\n101 Best and Brightest Companies to Work For, National Association for Business Resources (NABR), 2014, 2015, 2016, 2017, 2018\\n\\nTop Google Cloud Partner, Clutch, 2017\\n\\nFastest Growing Consulting Firms in North America (#11, #37), Consulting Magazine, 2016, 2017\\n\\nTop IT Services Companies, Clutch, 2015\\n\\nGoogle Global Rising Star Partner of the Year 2015, \\n\\nWe are looking for a skilled Big Data / Cloud Data Engineer to join our team.\", 'Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.', '1 to 2 years of experience on cloud platforms such as Google, AWS, or Azure, Education, 4-year degree in data science, data analysis, computer programming, healthcare or related field of study, or equivalent work experience.', 'Direct technically, and/or manage, within the broad mission of the group, activities of other research staff members and technical support persons., \\n\\nDemocratize AI by deploying AI Solutions easily for common business scenarios\\n\\nLeverage Powerful prebuilt AI models exposed as API services\\n\\nSimple REST APIs with .NET, Java, Python, Node SDKs\\n\\nTrain in the cloud and deploy anywhere model\\n\\nText Analytics and NLP services to the broader T-Mobile functional areas\\n\\nInnovation: Contributes designs to implement new ideas improving existing or new system/process/service directly supporting Business value drivers.', 'Our unique approach goes beyond the limitations of automation and offshoring to give you authentic, input and insight, from real people in real-world settings., \\n\\nThousands of the world‚Äôs leading digital brands ‚Äì including Google, Uber, Michael Kors, Amazon, Nike, Slack, and FOX ‚Äì rely on Applause to delight customers, increase their top line and innovate faster., \\n\\nApplause has a winning culture, fantastic benefits and tons of potential for career growth., Key Responsibilities:, \\nUses best practices to develop statistical machine learning techniques to build models that address business needs\\nUses effective project planning techniques to break down basic and occasionally moderately complex projects into tasks and ensure deadlines are kept\\nUses and learns a wide variety of tools and languages to achieve results (e.g., Python, Scala, R, SAS)\\nCollaborates with the team in order to improve the effectiveness of business decisions through the use of data and machine learning/predictive modeling\\nInnovates on projects by using new modeling techniques or tools\\nContributes on a wide variety of projects\\nExecutes on modeling/machine learning projects effectively\\nCommunicates findings to team and leadership to ensure models are well understood and incorporated into business processes\\nWorks with leaders to ensure the project will meet their needs\\nReviews and evaluates on appropriateness of techniques, given current modeling practices, to senior leadership\\n, Qualifications:, \\nHave completed at least a Bachelor‚Äôs degree in a quantitative field such as computer science, data science, mathematics, statistics, or physics.', 'Experience with Informatica, Talend and other data management systems\\nExperience operating in traditional and agile project models\\nExperience in developing and setup of MDM organization structures\\nTechnical expertise to include: Talend ESB, IBM IIB, IBM Informatica tools, J2EE, Exari, Drupal, Oracle, Microsoft SQL Server, MySQL, Subversion, Agile, DevOps and Java Based Workflow/BPM, and Office 365 including SharePoint\\n, About Octo Consulting Group, Inc., \\n\\nOcto Consulting Group (Octo) is an industry-leading, award-winning provider of digital services for the federal government.', 'And check us out at ipsy.com, @ipsyofficial on Snapchat, and @ipsy on Facebook, Instagram, YouTube, and Twitter.]\"', 'is strongly preferred (MBA a plus), Unlimited time off\\n\\nFlexible dress code\\n\\nKitchen stocked with snacks\\n\\nPet Insurance\\n\\nCatered meal on Fridays\\n\\nHealth, dental and vision benefits\\n\\n401(k) with a company match\\n\\nBoth paid maternity time and paid paternity time\\n\\nDog-friendly Fridays\\n\\n]\"\\n\"[Partner with Product and Engineering to proactively define what success means and ensure we‚Äôll have the data in place to measure against it\\n\\nDesign and analyze A/B multivariate tests to drive KPI improvement\\n\\nLeverage internal and external analytics tools (Looker, Adobe) and SQL (Redshift) to access, manipulate, and analyze complex data sets\\n\\nBuild data visualizations and cross-functional reporting that conveys key performance metrics, significant trends, and relationships across multiple data sources\\n\\nBe a resource for product owners and key stakeholders regarding data questions\\n\\nTranslate business hypotheses into data capture requirements and validate tracking and measurement\\n\\nCollaborate across multiple teams to understand business needs, analyze complex data, and clearly communicate recommendations\\n\\nMonitor web analytics KPIs to ensure site traffic and conversion funnels are performant, 2-4 years experience in an analytical role, preferably in e-commerce\\n\\nDemonstrated analytical and problem-solving skills\\n\\nProficiency in SQL a must\\n\\nAble to juggle multiple priorities at once, self-manage and self-prioritize\\n\\nAble to articulate complex technical problems to a non-technical audience Excellent communication skills\\n\\nTableau experience a plus]\"\\n\"[\\n\\nPerform recurring and ad hoc quantitative analysis to support day-to- day decision making\\n\\nSupport reporting and analytics such as KPIs, financial reports and creating and improving dashboards\\n\\nRecap and analyze business results versus plan and forecast on a weekly, monthly, quarterly and ad-hoc basis\\n\\nCollaborate with non-quantitative stakeholders across Pond5 to empower data-driven decisions (an important aspect of our work is evangelizing analytical concepts and quantitative thinking throughout the organization)\\n\\nContribute insights and drive innovation to help our team develop a 360-degree understanding of Pond5‚Äôs business\\n\\nHelp translate this understanding into visualizations, metrics, and goals\\n\\nInteract with and present data findings to senior management\\n\\nParticipate in strategy decisions and advise with regard to company goals, plans, and results, \\n\\nBS/BA in Mathematics, Statistics, Economics, Finance, Computer Science, or other quantitative areas of study\\n\\n2+ years of relevant work experience in analytical roles such as data science, business intelligence, corporate finance, investment banking, or quantitative consulting is preferred, though exceptional candidates without work experience will be considered\\n\\nAdvanced quantitative analysis skills in Excel and SQL required\\n\\nBasic understanding of e-commerce concepts and metrics such as traffic, conversion rates, CPA, LTV, revenue retention, channel/cohort analysis as examples, is strongly preferred\\n\\nExceptional problem solving and analytical skills\\n\\nHighly organized and detail oriented with exceptional communications skills; we value candor, constant feedback and constructive debate\\n\\nExperience with SQL, Google Analytics, Tableau Desktop, and ETL processes are preferred\\n\\nExperience using Python, R, VBA, macros, statistics or other programing / development are also nice to have, \\n\\nInternational team of 180 awesome people\\n\\nCompetitive compensation and benefits\\n\\nGenerous 401(k) program\\n\\nDaily office lunches\\n\\nEquipment needed for work\\n\\nLearn new things every day!]\"', 'Salesforce and Google Cloud Platform experience preferred.Good experience of parsing data formats such as XML/JSON and using 3rd party API‚ÄôsSold Python programming skills - experience scheduling/automating scriptsStrong analytical and problem-solving skills, strategic thinker and visionary, self-motivatedProven ability to work cross functionallyAn understanding of how data can benefit the wider business, and how to translate technical requirements to non-technical stakeholdersPrevious experience and successful track record of learning new tools and technologiesGood time management and ability to work on concurrent assignments with different priorities - Ability to work in a fast-paced, iterative development environment with short turn-around times, \\n\\nPreferred Experience:, \\n\\nExperience with statistical analysis of marketing initiatives, or a history of collaboration with data scientists for statistical analysis.', 'Experience with Java, SQL and NoSQL databases, data analytics (such as pattern recognition & change detection) is highly desired., Position will require candidate to acquire and maintain a Secret clearance., MIT Lincoln Laboratory is an Equal Employment Opportunity (EEO) employer.', 'We can‚Äôt wait to meet you., Arity.com Instagram Twitter LinkedIn, Allstate generally does not sponsor individuals for employment-based visas for this position., \\n\\nEffective July 1, 2014, under Indiana House Enrolled Act (HEA) 1242, it is against public policy of the State of Indiana and a discriminatory practice for an employer to discriminate against a prospective employee on the basis of status as a veteran by refusing to employ an applicant on the basis that they are a veteran of the armed forces of the United States, a member of the Indiana National Guard or a member of a reserve component.', 'Example: JOHN SMITH\\n\\nNOTE: Use correct grammar for Names with multiple cases.', 'Utilize tools such as Power BI, Excel, MS SQL, Salesforce, system monitoring tools, automated testing, Google Analytics, Google Search Console, and similar tools.', '3+ years of experience architecting, building and administering big data and real-time streaming analytics architectures in both on premises and cloud environments (AWS, Azure, Google) leveraging technologies such as Hadoop, Spark, S3, EMR, Aurora, DynamoDB, Redshift, Neptune, Cosmos DB\\n\\n4+ years of experience architecting, building and administering large-scale distributed applications\\n\\n3+ years of experience with Linux operations and development, including basic commands and shell scripting\\n\\n4+ years of experience with execution of DevOps methodologies and Continuous Integration/Continuous Delivery within a large scale data delivery environment\\n\\nSoftware development experience in least three or more of following languages: Java, Python, Scala, Node.js\\n\\nExpertise in usage of SQL for data profiling, analysis and extraction, Preferred Qualifications:, \\n\\n2+ years of experience with advanced analytics and machine learning concepts and technology implementations (Tensorflow, H20)\\n\\n3+ years of experience with NoSQL implementations (Mongo, Cassandra, HBase)\\n\\n3+ years of experience implementing serverless architecture leveraging AWS Lambda or similar technology\\n\\n2+ years of experience with data visualization tools such as Tableau and PowerBI\\n\\nExpert understanding of the Hadoop ecosystem (e.g.', 'Experience migrating a SQL Server DW to a cloud provider such as AWS, Google Cloud Services and Snowflake\\n\\nDemonstrated knowledge of Unix/Linux, object-oriented programing, relational database technologies, database performance and tuning, distributed computing tech (Hadoop, spark), RESTful API\\n\\nProven experience mentoring engineers in DW best practices and development\\n\\nHands-on proficiency with SQL, SSIS, and ETL jobs, including stored procedures\\n\\nHands-on proficiency in working with cloud services such as Amazon Web Services, Google Compute Engine, and Snowflake\\n\\nExperience with quality assurance and testing in a relational database environment.', 'Proven experience modeling large datasets in distributed databases such as Apache Cassandra\\n\\nKnowledge of at least one NoSQL database such as Neo4j, CouchDB, etc., \\nExperience with Platform-as-a-Service software such as Cloud Foundry or Kubernetes\\n\\nDemonstrated experience building cloud native applications in a public cloud such as AWS, Google Cloud or Azure\\n\\nExperience contributing to open source projects\\n\\nExperience with stream processing, e.g.', 'Python, Hive, Spark)\\n\\nWillingness to travel up to 50%, at peak times of projects, \\n\\nQualifications, \\n\\n3+ years of related work experience in Data Engineering or Data Warehousing\\n\\nHands-on experience with leading commercial Cloud platforms, including AWS, Azure, and Google\\n\\nProven experience with data warehousing, data ingestion, and data profiling\\n\\nProficient in SQL\\n\\nStrong aptitude for learning new technologies and analytics techniques\\n\\nHighly self-motivated and able to work independently as well as in a team environment\\n\\nUnderstanding of agile project approaches and methodologies\\n\\nProficient in a source code control system, such as Git\\n\\nProficient in the Linux shell, including utilities such as SSH, \\n\\nPreferred Experience, \\n\\nFamiliarity with implementing analytics solutions with one or more Hadoop distributions (Cloudera, Hortonworks, MapR, HDInsight, EMR)\\n\\nFamiliarity with streaming data ingestion\\n\\nProficient in Python and/or Java\\n\\nConsulting experience\\n\\nFamiliarity or strong desire to learn quantitative analysis techniques (e.g., predictive modeling, machine learning, segmentation, optimization, clustering, regression)]\"\\n\\n\"[As a key member of an Agile development and/or support team, the Senior Data Engineer performs technical design, development, modification, implementation, maintenance and support of applications using existing and emerging technologies such as Microsoft SSIS ETL, SQL Server, Data Warehousing and Data Integration.', 'Strong technical, communication, political and negotiation skills will be required., \\n\\nSkills required:, \\n\\nAbility to collect and aggregate data from multiple databases while validating the data integrity and accuracy\\n\\nSkilled Excel user with pivot tables, slicers, graphing, formulas, macros, & integration of data connectors\\n\\nData visualization & Business Intelligence tools systems such as Looker, EasyBi, Power BI, Tableau\\n\\nCoding languages such as VBA, Java, Ruby, C#, PHP, Python, HTML, JavaScript, SQL queries in both MySQL & MSSQL\\n\\nMonitoring tools such as Cloud Watch, Alertsite & Zabbix\\n\\nCode Repositories such at GitHub\\n\\nLog aggregation, analytics & monitoring tools such as Elastic & Splunk\\n\\nLinux & Windows system administration in cloud environments such as AWS, Applies advanced subject matter knowledge to solve complex business issues and is regarded as a subject matter expert.', '\"[Bachelor\\'s degree in computer science or engineering\\n\\nMaster\\'s degree in computer science or engineering, or MBA preferred\\n\\nEight (8) years or more of relevant IT experience with a variety of DW/BI technologies supporting the full software development life cycle\\n\\nFive (5) years or more of experience as a Data Integration Lead, managing large and complex environment, ideally in a multibillion dollar organization\\n\\nExperience managing production incident/change request backlog, performing initial triage of issues and resource allocation\\n\\nExcellent project management skills\\n\\nStrong verbal communication, interpersonal and listening skills\\n\\nStrong technical aptitude\\n\\nA team player, with a positive attitude and willingness to help and mentor others\\n\\nExpertise in Informatica & Microsoft Data Integration platform, IBM Netezza Analytical appliance, Oracle Golden Gate replication and SQL Server transactional database (expert level)\\n\\nKnowledge of data modeling tools preferred (intermediate level) preferred, \\n\\nBring collections and/or elements of legacy and new data together as part of a BI&A data integration architecture that adds value to the business\\n\\nCollaborate with BIA development teams, enterprise architecture and other IT application teams to define current and strategic future state data integration architectures\\n\\nContribute to the creation and implementation of new design patterns and standards for the data integration domain\\n\\nProvide leadership in the logical and physical design of analytical and reporting application systems, and ensure design is consistent and well integrated with existing conceptual, logical, and physical application architectures\\n\\nManage a team of data integration developers to guide the creation of ETL processes and support existing production jobs\\n\\nMaintain a depth of expertise with database security, data virtualization and replication as well as other complex technical tools and solutions, data access, transformation, design, modeling, metadata structures, data integrity, archiving/recovery, etc.', 'Including A/B and multivariate testing\\n\\nAbility to develop data driven targeted and segmented contact strategies\\n\\nProficient in digital analytics, including web analytics with tools like Adobe Analytics, Google Analytics and Webtrends\\n\\nExperienced in digital test design and implementation with current digital targeting tools (Adobe, Webtrends, X+1, etc.)', 'ZestFinance was founded in 2009 by Douglas Merrill and a team of former Google employees with the mission of making fair and transparent credit available to everyone., \\n\\nWe are committed to diversity in hiring, professional development, and everyday discussion.', 'click through rates, golden pathways, conversion analysis, and marketing effectiveness.Deliver quick turnarounds on dashboards, identify trends and/or issues within data sets, and make recommendations to influence business decisions and investments.Evaluate the effectiveness of marketing actions, recommend segmentation approaches and deliver actionable insights to improve customer lifetime value.Partner with IT, BI and Operations team to help identify and mend data gaps, source issues, and data inaccuracies.Present analytical results and insights to business partners to answer strategic questions and influence business decisions.Develop measurement plans/processes including multivariate A/B tests and experimental design to evaluate performance of marketing results., Bachelor degree in Mathematics, Computer Science or Marketing related quantitative field.Minimum of 2-3 years of experience in a data analytics capacity, experience with digital/online product strongly preferred.Understanding of relational database theory and proficiency in writing and understanding complex SQL code.Experience with Business Intelligence tools (Tableau, Alteryx & Cognos) and real time dashboard development.High proficiency in MS Excel and Web Analytics tools such as Adobe Analytics or Google Analytics.Working knowledge of Salesforce is a plus.Knowledge of statistical models and practical experience in predictive model development is a plus (R, Python, SAS, etc).Strong oral and written communicator with demonstrated experience translating analytics findings into business insights in order to influence business stakeholders to drive actionable decisions and optimize business performance.Excellent analytical and problem-solving skills with an exceptionally strong attention to detail.Curious, self-motivated thinker; always asks why and strives until the answer is clear.Strong organizational and time-management skills; ability to multi-task and prioritize responsibilities in line with business objectives, react to shifting priorities while adhering to deadlines.]', '\"[Note: By applying to this position your application is automatically submitted to the following locations: Seattle, WA, USA; New York, NY, USA; Mountain View, CA, USA; Pittsburgh, PA, USA, \\n\\nResearch in machine intelligence has already impacted user-facing services across Google including Search, Maps and Google Now.', 'Data-oriented personality]\"\\n\"[\\n8+ years of experience with data science or Cybersecurity\\nExperience with Python\\nExperience with SQL\\nKnowledge of data science and machine learning techniques\\nKnowledge of Cybersecurity concepts and trends\\nAbility to build presentations and present to large groups\\nTS/SCI clearance\\nBA or BS degree in CS, Mathematics, Engineering, Science, or Technology\\n, \\nExperience with Apache Spark\\nExperience with Hadoop, YARN, HDFS, Kafka, and Ambari\\nExperience with Elasticsearch, Logstash, and Kibana (ELK) stack\\nExperience with IBM Netezza, Tableau, and bash scripting\\nExperience with JIRA and working in an Agile environment\\nDHS Suitability clearance\\nApache Spark Developer Certification\\nCISSP, Security+, or other Cybersecurity Certification\\n]\"\\n\"[\\n\\nCollaborating with other developers (both data scientists and engineers) to design, research, integrate, and implement solutions, \\n\\nCollaborating with other analysts, product and client-facing stakeholders to determine the feasibility of specific client requests given our data and capability, \\n\\nCommunicating with team members, project management and business stakeholders to understand requirements and strategically implement robust software and machine learning design, \\n\\nIdentifying opportunities for improvement within existing software applications and frameworks, \\n\\nMandatory Qualifications:]\"\\n\"[At American Family Insurance, we‚Äôre driven by our customers and employees.', 'If a candidate requires work authorization for a location, Google will explore the available options on a case-by-case basis., Your application should show evidence of proficiency in programming and in prerequisite courses (e.g., machine learning, user-centered interfaces or applications, data science, mathematical analysis).', 'experience with these, or similar tools‚Äù portion of the post:\\n\\nAmazon ‚Äì Sagemaker, AMI‚Äôs, ML Solutions Lab\\n\\nGoogle ‚Äì BigQuery, Dataproc, Spanner., \\n\\nAmazon ‚Äì Sagemaker, AMI‚Äôs, ML Solutions Lab\\n\\nGoogle ‚Äì BigQuery, Dataproc, Spanner., \\n\\nPlease complete our online application process to be considered for this role., \\n\\nPenguin Random House is the leading adult and children‚Äôs publishing house in North America, the United Kingdom and many other regions around the world.', 'From Google Ads to Chrome, Android to YouTube, Social to Local, Google engineers are changing the world one technological achievement after another., Work with large, complex data sets.', 'Upon completing our initial assessments of these tools, you‚Äôll assist with the implementation and deployment of the solutions we collectively decide upon., Extract data from multiple data sources, such as SQL, MongoDB, Google Analytics, and other platform APIs, and load them into a centralized data warehouse to facilitate unified reporting.', 'We engage and develop people to their greatest potential., \\n\\nWork Collaboratively: We work together to achieve results by actively listening, seeking, understanding and creating solutions as a unified team driving toward one company, one culture, one brand., \\n\\nAchieve Results: We focus on winning by exceeding expectations and getting better ‚Äì everyone, every day., \\n\\nFor more information, visit www.massmutual.com or find us on Facebook, Twitter, LinkedIn, YouTube, Google+, Instagram and Pinterest., \\n\\nMassMutual is an Equal Employment Opportunity employer Minority/Female/Sexual Orientation/Gender Identity/Individual with Disability/Protected Veteran.', 'Diagnosis and Tuning experience, with Applications or Infrastructure Components\\nPredictive modeling (eg: Bayesian inference, time series forecasting, signal detection, queuing optimization, clustering, survival analysis)\\nSplunk Machine Learning Toolkit, Data visualization in Splunk\\nAbility to code in an Object Oriented Language such as Java or C++\\nData transformation and Conformal Mapping/Decomposition\\n]\"\\n\"[\\nWork with your team members (analysts, developers, project managers and data scientists) to understand the problem space and design a solution that meets the customer\\'s needs\\nWork directly with the customer to gain information and share results\\nProvide technical/analytics leadership\\nPerform data assessment, cleaning, and analysis\\nDevelop the analytics required for the solution\\nCreate production-ready code, test, document and deploy\\n, \\nMS or PhD in quantitative discipline (e.g.', \"), XSA or XS engine\\n\\nSAP UI5\\n\\nDevelopment in Cloud, Cloud Foundry including understanding of containers, microservices, \\n\\n#SAPIBSCareers, \\n\\nSAP'S DIVERSITY COMMITMENT, \\n\\nTo harness the power of innovation, SAP invests in the development of its diverse employees.\", 'Understanding of machine-learning and operations research\\n\\nExperience with Business Objects, Core Metrics, SQL, Google Analytics, or other analytical tools.', 'Prior experience in security is not a prerequisite for this position., From keeping Googlers safe and secure to managing disruptive events, the ability to anticipate, deter, detect, and act are the pillars of Google‚Äôs Global Security and Resilience Services (GSRS) team.', 'Experience developing advanced analytic queries using Spark, MapR, Splunk or Elk., \\n\\nEven better if you have:, \\n\\nMaster‚Äôs degree in Computer Science, Cybersecurity, Mathematics or equivalent.', 'Expert command of statistical analysis, algorithm development, and state-of-the-art tools and methodologies for data science\\n\\n5+ years creating predictive models using advance machine learning techniques\\n\\n2+ years managing a team of data scientists\\n\\nExpert command of SQL and R or Python as applied to data science\\n\\nExperience developing real-time production data pipelines\\n\\nExperience interacting with external clients is a plus, \\n\\nPerks and benefits:, \\n\\nPeople ‚Äì the best part of Zest\\n\\nRobust healthcare plans, matching 401K and unlimited vacation time\\n\\nDog friendly office with lounge areas, video games and gigantic jigsaw puzzles\\n\\nOn-site gym with yoga, salsa and other employee run fitness classes\\n\\nGenerous family leave policy (6 month maternity leave/3 month paternity leave)\\n\\nTuition reimbursement, conference allowance and Zest talks\\n\\nComplimentary massages, manicures, pedicures and more\\n\\nDaily catered lunches from LA‚Äôs best restaurants and fully stocked kitchen]\"\\n\"[\\n\\nAt least 3 years industry experience working as a full-time Data Scientist designing and implementing predictive models written in Python\\n\\nSeasoned in feature selection and feature engineering\\n\\nExperience training, tuning and optimizing ML models using scikit-learn\\n\\nExperience training, tuning and optimizing ML models using TensorFlow\\n\\nExperience defining, evaluating measuring the performance of competing models\\n\\nExperience partnering with ML Engineers to productionize models you have built, \\n\\nExperience building recommender systems\\n\\nExperience training models leveraging GPU driven frameworks\\n\\nExperience training models using Google Cloud ML or AWS SageMaker\\n\\nExperience optimizing models for production deployment\\n\\nExperience data mining using Splunk]\"\\n\"[\\nAdvanced degree in machine learning or related field, or equivalent experience\\nExperience applying machine learning techniques to real-world problems\\nComfort analyzing large, complex, high-dimensional datasets\\nAbility to quickly assess a problem both qualitatively and quantitatively\\nStrong passion for empirical research and answering hard questions with data\\nAbility to present results and describe techniques in both technical and non-technical contexts\\nStrong SQL skills\\nFluency in at least one scripting language, such as Python or Perl\\n3 - 6 years of professional experience\\n, \\nPh.D. in machine learning or related field\\nExperience with Hadoop, HDFS, Pig, Hive, Spark, Impala\\nSignificant experience using a statistical computing package such as Python/Pandas/Scikitlearn, R, or MATLAB\\n]\"\\n\"[We are seeking professionals who are well versed in scalable data mining, machine learning techniques, and love to build analytics models.', 'The engineer support and collaborate with our data engineers, researchers, report writers and data analysts., \\n\\nResponsibilities, \\n\\nImplement, secure and maintain the advanced data analytics platform\\n\\nImplement, secure and maintain the front-end interface to platform\\n\\nDesign, implement and automate data flows to and from the platform\\n\\nWork with partners and vendors on data integration projects\\n\\nCreate data models for analytics applications\\n\\nAssist in the Data Warehouse ETL design and implementation\\n\\nAssist in resolution of production issues and root cause analyses, \\n\\nTechnical Qualifications and Experience, \\n\\n3+ years with Python analytics platform, Python notebooks and Data Science libraries\\n\\n3+ years‚Äô experience with ETL tools: SSIS (preferred), Informatica, Talend\\n\\n3+ years‚Äô experience with RESTFul APIs and Web Services: JSON and XML\\n\\n3+ years‚Äô experience with RDMS databases: SQL Server, Postgres, Oracle\\n\\nStrong expertise in SQL scripting required\\n\\nStrong expertise in Python scripting required\\n\\nExperience integrating large datasets, many 100Gbs to several Terabytes required\\n\\nExperience with Linux and Windows Server Operating Systems required\\n\\nStrong expertise in a programming language such as Java/Scala or C# a big plus\\n\\nExperience with web front scripting such Javascript, HTML and CSS a big plus\\n\\nExperience supporting researchers in bioinformatics a big plus\\n\\nExperience with statistics, machine learning and deploying predictive models a big plus (R, Python, Matlab, Spark)\\n\\nExperience with SAS, administration and SAS language a plus\\n\\nExperience with public cloud a plus: AWS, Google Cloud, Azure\\n\\nExperience with Big Data technology a plus: Hadoop, Spark, AWS EMR, Hive, etc.', 'spatial pattern extraction and analysis in 2D and 3D)., Responsibilities:, Apply statistical analysis, pattern recognition, and machine learning ‚Äì along with domain knowledge and subject-specific models ‚Äì to solve science, engineering, and commercial problems.Contribute to all stages of data analytics or decision modeling projects, including problem formulation, solution development, and product deployment:Translate business-relevant scientific, engineering, and commercial problems into questions that may be address using data analytics.Design experiments and/or run simulations to generate new data in support of analytic studies.Retrieve and combine data from databases, data historians, and/or data lakes; there is a strong emphasis on programming, particularly using scripting languages.Perform exploratory data analysis for quality control and improved understanding.Rigorously and reproducibly build, analyze, and compare statistical and/or machine learning models.Contextualize the results and synthesize them with existing knowledge and/or domain-specific models.Deploy data-analytic products to end-users and/or document data-analytic results in technical reports., Requirements:, PhD in one of the following disciplines: Statistics, Computer Science, or Science or Engineering with significant experience in data analyticsExperience in Python, MATLAB, or R is requiredExcellent communication skills and experience working in a collaborative environment is requiredKnowledge of numerical methods for linear algebra and optimization is an advantageExperience in technical software development is an advantageExperience working in Linux and in a High Performance Computing environment is an advantagePrevious work experience in the oil and gas industry is an advantage, Alternate Location: United States: Houston, Texas || United States: Clinton, New Jersey || United States: Baytown, Texas, ExxonMobil is an Equal Opportunity Employer.', 'Expert user of Microsoft and Google office suites.', \"Maintain the latest knowledge in software and hardware products or services, trends, and identify best solutions to meet business requirements., \\n\\n\\nYou‚Äôll Bring These Qualifications:, \\n\\nMaster's degree in Computer Science, Computer Engineering, Information Technology or Engineering Management or related or equivalent., \\n\\nExperience/Skills: 2 years of experience in data analysis using SAS platform tools such as SAS Programming, EBI, Enterprise Guide, Enterprise Miner, SAS Visual Analytics and SQL; 2 years of development experience with IBM COGNOS Business Intelligence Platform; 2 years of experience to support users for development issues and provide guidelines to address the issues; experience analyzing big data using SAS and big data products such as Hive, Impala, HDFS, Spark, Hue and HBase; data analysis experience, with a combination of business and technical skills; experience in building BI Reports to meet customer requirements using IBM COGNOS & SAS Tools; experience automating operational processes using scripting languages such as Shell/Ruby/Python; experience working with Data warehouse., We‚Äôve been named a Best Place to Work by the Washington Post., Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives., We offer competitive benefits and learning and development opportunities., We are mission-oriented and ever vigilant in aligning our solutions with the nation‚Äôs highest priorities., For over 55 years, the principles of CACI‚Äôs unique, character-based culture have been the driving force behind our success., \\n\\nJob Location, \\n\\nUS-Chantilly-VA-VIRGINIA SUBURBAN, \\n\\nCACI employs a diverse range of talent to create an environment that fuels innovation and fosters continuous improvement and success.\", 'You manage individual project priorities, deadlines, and deliverables, adapting to changes and setbacks in order to manage pressures, demonstrating and applying theories through research efforts to develop new and improved products, processes, or technologies., As a Research Scientist on the Google Cloud AI and Machine Learning (ML) team, you will be working on innovating and delivering the most advanced machine learning techniques to impact the world via Google Cloud.', 'Bachelor‚Äôs Degree in a computer/database related field or equivalent professional experience., \\n\\nWhat you‚Äôll learn, \\n\\nAdvanced real-time processing concepts\\n\\nAdvanced data modeling\\n\\nGoogle Compute Platform tools and methods\\n\\nPioneer our use of graph databases]\"\\n\"[Data Engineer - Yahoo Sports\\n\\n\\n\\nA Little About Us:\\n\\n\\n\\nWe are sports fans.', '4+ years of experience applying IBM analytics software to business problems: SPSS Statistics, SPSS Modeler and SPSS Collaboration and Deployment Services\\n\\nMasters Degree or PhD in statistics, mathematics or closely related field]\"\\n\"[\\n\\nWork closely with the Embedded Data Scientists/Analysts to set up, maintain and optimize performance analysis of our various in-market experiments\\n\\nProvide test requesters with testing methodology and frameworks to create and monitor tests over time\\n\\nWork with experimentation tools team to improve & enhance tool capabilities\\n\\nDevelop traffic forecasts and size opportunities based on constraints and interpretation of data findings\\n\\nDefine, implement and standardize metrics, reports and dashboards leveraging Tableau or other data visualization tools\\n\\nDeliver key metrics, reports, dashboards and ad-hoc analyses with interpretation, contributing to the development of hypotheses and actions\\n\\nWork with Marketing and Product Managers to develop learning plans with recommendations of analytics approaches to address questions or validate hypotheses\\n\\nGenerate follow-up questions with stakeholders, refine data findings and interpret results to drive data-based insights\\n\\nCollaborate with internal and external partners to assist with data collection and reporting, \\n\\n7-10 years of experience in decision support and site optimization for an online/e-commerce business\\n\\nDeep knowledge of testing and web analytics\\n\\nConfident applying appropriate analysis methods of causal inference in both experimental and non-experimental situations\\n\\nSubject matter expertise with clickstream data, SQL & Hive is a must\\n\\nUnderstanding of complex web ecosystems, best practices and ability to put this knowledge into action\\n\\nAbility to tell stories with data, educate effectively, and instill confidence, motivating stakeholders to act on recommendations\\n\\nExcellent problem solving skills and end to end quantitative thinking\\n\\nOutstanding communications skills with both technical and non-technical colleagues.', 'Solid understanding of computer science fundamentals like algorithms and data structures\\n\\nFamiliarity with MySQL (or other RDBMS) is a nice to have\\n\\n, Big data technologies such as Hive, Hadoop, MapReduce, PIG, Google BigQuery, Oozie, etc.', 'Oracle\\n\\nBackground in Statistics\\n\\nData quality experience and familiarity with commercial data quality software\\n\\nExperience with Informatica or IBM Infosphere data quality tools\\n\\nFamiliarity with IBM Initiate, Workbench and/or Identity Management\\n\\nKnowledgeable of or experience with data warehouse, graphical presentation of large dataset\\n\\n, # of Openings:\\n\\n, Scheduled Weekly Hours:\\n\\n, T elecommuting Options:\\n\\n, Work Location:\\n\\n, Additional Work Locations:\\n\\n, CSRA is committed to creating a diverse environment and is an equal opportunity employer.', \"We are one of the World's Most 50 Innovative Companies according to MIT, and one of Forbes Most Promising Companies.\", 'Experience solutioning in public cloud environments: AWS (preferred), Google Cloud, Azure., GoDaddy is proud to be an equal opportunity employer.', ', \\n\\nResponsibilities, \\n\\nYou will design and develop Data life cycle management such as Ingestion, pipeline development, data at rest strategy, Archive and Migration solution\\n\\nWork with the Chief Architect and other engineering groups to align with company product design paradigm\\n\\nProvide design mentorship and review the work of other specialists\\n\\nAble to work with Nutanix Global (mainly India and USA) engineering and multi-functional team, \\n\\nQualifications and Experience, \\n\\nBS/MS degree in Computer science or equivalent (PhD degree a plus)\\n\\n8+ years of product platform development with 4+ years of data life cycle management\\n\\nExperience with building a data pipeline development framework\\n\\nHands-on development in at least one of the programming languages: Java, Python/Golang and C++\\n\\nKnowledge of storage/file system and its meta data\\n\\nStrong development experience in Linux/Unix OS platform\\n\\nHands-on experience working with version control / DevOps tools ‚Äì Git, Gerrit and Jenkins, \\n\\nPluses, \\n\\nUnderstanding of any of the cloud computing technology ‚Äì AWS / Google Cloud / Azure / VMWare\\n\\nKnowledge in any of the area such as - Splunk, Spark, Kafka, Elasticsearch and its component, Apache/Tomcat server, Flask framework is a plus\\n\\nExperience in Message Bus (RabbitMQ, Kafka), Elastic Search, Cassandra and Zookeeper.', 'Whether the answer is a bespoke solution to solve a unique problem, or a new tool that can scale across Google, everything we do aims to ensure our customers benefit from the full potential of Google products.', 'Ensure quality of implementation of Golden Gate replication from the source system to the PJM Information Warehouse / MOD., \\n\\nBS, Computer Science, Management Information Systems or equivalent work experience\\n\\nAt least 5 years of experience data warehousing concepts and support tools with data modeling and data structure design/supporting Oracle 11g/12c in an AIX/UNIX environment: SAP PowerDesigner / Erwin or other data modeling tool, Oracle Enterprise Manager (OEM) and Various Oracle development tools (SQL*Plus, Toad)\\n\\nAbility to produce high-quality work products with attention to detail\\n\\nAbility to visualize and solve complex problems\\n\\nAbility to apply analytical and mathematical solutions\\n\\nExperience with conceptual and logical data modeling including developing and maintaining data model diagrams (ERD), facilitating structured data modeling meetings\\n\\nExperience designing and building business intelligence architectures including data marts, data warehouses, and reporting and analysis applications\\n\\nExperience with MS Suite of Business Intelligence Tools including SSIS, SSRS, SSAS\\n\\nExperience with SQL Tools, such as SQL Navigator, TOAD, SQL*Plus\\n\\nExperience with Oracle 11g database management system, \\n\\nMS, Computer Science\\n\\nExperience with PJM operations, markets, and planning functions\\n\\nExperience with Alteryx and SAS Experience with visualization and reporting tools such as Tableau, SAS Visual Analytics, Qlik etc Experience in end to end delivery and lifecycle of analytical business solutions]\"\\n\"[The Day to Day:, \\n\\nOwn, improve, and document WP Engine‚Äôs business financial data models\\n\\nUnderstand requirements from both internal and external stakeholders, gather data from various data sources, conduct business analysis, and provide quantitative insights through creation of dashboards and visualizations\\n\\nWork closely with Finance to translate manual data analysis into automated analytics, resulting in faster more meaningful data extraction for users\\n\\nApplying statistical expertise to analyze large data sets to build models that highlight business needs/challenges\\n\\nDevelop and implement new ETL methods and/or tools to integrate new data sources\\n\\nAccessing data through SQL and other ETL processes to generate automated reports\\n\\nPerform technical analysis on data to measure underlying trends and behavior\\n\\nEnforcing data integrity and applying quality assurance best practices for data services\\n\\nConduct deep-dive data analysis for business insights and recommendation utilizing both established dashboard/visualization tools and ad-hoc querying of internal databases\\n\\nTrack and understand the economic and financial fundamentals of the Finance organization that are identified as part of overall company objectives, \\n\\nYour Expertise and Passion:, \\n\\n4-8 years of data oriented experience working in a fast-paced, hyper growth, start up environment\\n\\nKnowledge of SQL to write complex, highly-optimized queries across large volumes of data\\n\\nUndergraduate degree in Statistics, Economics, Mathematics, or Computer Science\\n\\nAbility to program in R, Python (preferred), or PHP\\n\\nExperience with ETL methods, data modeling, and automation\\n\\nPassion for reporting and analytics while working in an agile team to drive change\\n\\nMotivation to take ownership and work independently on multiple simultaneous projects\\n\\nExceptionally strong analytical and problem solving skills, combined with strong business acumen\\n\\nDesire to use analytical skills to drive better financial outcomes for the Finance organization\\n\\nBusiness Intelligence experience is a plus., Compensation (We offer market competitive salaries)\\n\\nStock Options (Every employee is an owner in the company)\\n\\nHealth Benefits (100% Paid Employee Medical, Dental, and Vision)\\n\\n401(k) (Make the most of retirement)\\n\\nLife and Disability Insurance (100% Paid Life, STD, LTD and AD&D)\\n\\nGenerous Vacation Time (Who doesn‚Äôt like time off)\\n\\nTransportation (Downtown parking or commuter reimbursement)\\n\\nLunch (Provided Monday ‚Äì Thursday)\\n\\nGym membership discount]\"\\n\"[Note: By applying to this position your application is automatically submitted to the following locations: San Francisco, CA, USA; New York, NY, USA, \\n\\nBusinesses that partner with Google come in all shapes, sizes and market caps, and no one Google advertising solution works for all.', 'Together with the team you will support customer implementation of Google Cloud products through: architecture guidance, best practices, data migration, capacity planning, implementation, troubleshooting, monitoring and much more., \\n\\nThe Google Cloud Platform team helps customers transform and evolve their business through the use of Google‚Äôs global network, web-scale data centers and software infrastructure.', 'S/He will be responsible for supporting product development for key ad sales research solutions and initiatives, and in addition to the team‚Äôs Product Managers, will also support the data needs of three Sr. Data Scientists., \\n\\nBuild distributed, high-volume data pipelines to power new product features based on analytics and machine-learning\\n\\nBuild applications that are AWS-ready\\n\\nIdentify and solve data pipeline issues as they arise\\n\\nServe as point between Advertising Science and MTS (IT/Cloud-Engineering department) in support of our data products\\n\\nDevelop, test, and maintain data architectures to ensure data availability\\n\\nWork closely with external product vendors to set up back-ends of Advertising Science products, BS/MS/PhD in a STEM field\\n\\nExperience building data pipelines from scratch and architected solutions for data science and analytics\\n\\nFluent in scalable cloud computing technologies (AWS, Google Cloud Compute, Azure).', ', Technical Experience and Expertise:\\n\\n, Big data technologies such as Hive, Hadoop, MapReduce, PIG, Google BigQuery, Oozie, etc.', ', Skills & Responsibilities:, Expert in data architecture development, data policy formation, data asset management, data modeling, and data taxonomy creation\\nMust be able to draw insights from structured and unstructured information\\nCompetent in information systems design and information visualization techniques\\nExcellent verbal and written communication skills\\nAbility to challenge and convince the various stakeholders involved in any project\\nWorking knowledge of usability design and data warehousing techniques\\nAbility to perform business domain analysis and business process modeling\\nProficient understanding of distributed computing principles\\nProficient with cloud data warehouse technologies, such as AWS RedShift and/or Google BigQuery\\nExperience with MySQL and PostgreSQL databases\\nGood knowledge of data warehouse querying tools, such as SQL, AWS QuickSight and Google Data Studio\\nGood knowledge of business intelligence tools, such as Jaspersoft and/or Tableau\\nAbility to solve any ongoing data issues that arise throughout the data processing lifecycle\\nKnowledge of various ETL techniques and frameworks, such as Matillion and/or Talend\\nExperience with integration of data from multiple data sources\\nExperience with integrating machine learning toolkits into data infrastructure\\nExperience with Big Data technologies to support future growth\\n, Success Criteria, Advanced Analytical Thinking and Problem Solving skills\\nSolid experience in architecture, advanced reporting and dashboards\\nExperience working with data warehouses is required\\nStrong SQL skills and experience with performance tuning are required\\n‚ÄúGet it done‚Äù attitude\\nSuperior Communication and Business-Technical Interaction skills\\nGood understanding of data modeling concepts and data relationships\\n, To qualify, you must possess the following skills:, Bachelor‚Äôs degree in computer science, management information systems, or a related discipline\\nMore than five years of experience in data architecture or minimum five to seven years of experience as data analyst, business intelligence analyst, or equivalent roles\\nProven experience with ETL tools\\nProfessional or educational experience in software development\\nExcellent communication and data analysis skills\\nExcellent knowledge of SQL, R, and Python for performing data transformation and analysis\\n, Zoro is an Equal Opportunity Workplace and an Affirmative Action Employer., All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status.]\"', 'Experience with data extraction, manipulation and blending across different data sources (Google Analytics, DoubleClick for Publishers, SQL Server, Snowflake, AWS, Salesforce, flat files, etc).', 'Knowledge of IT Service Management and IT Operations Management processes, tools and technologies\\n\\nKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment models\\n\\nExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storage\\n\\nExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processing\\n\\nExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.]\"', 'This role requires someone excited to advance a team through the transition from traditional data solutions to emerging data patterns., \\n\\nWhat you‚Äôll do:, \\nWork with business product owners to understand business requirements and use cases\\nCreate technical and business solutions architectures (logical and physical)\\nResolve questions during design and implementation of architecture\\nEvaluate tools for use case fit, perform vendor/tool comparisons and present recommendations\\nContribute to the capability roadmaps for data platforms\\nReview schemas, data models and data architecture for Hadoop and Teradata environments\\nPrototype solutions for specific use cases\\nAdvise peers and business partners on fit-for-use and technical complexities\\nPartner with other technical leaders for solution alignment with strategy and standards\\n, What you have:, \\nHands-on experience with Hadoop, Teradata (or other MPP RDBMS), MapReduce, Hive, Sqoop, Splunk, STORM, SPARK, Kafka and HBASE (At least 2 years)\\nExperience with end-to-end solution architecture for data capabilities including:\\nExperience with ELT/ETL development, patterns and tooling (Informatica, Talend)\\nExperience with BI tools (BusinessObjects, Tableau) and other visualization (D3)\\nExperience with Advanced Analytics (SAS, R)\\nExperience with Graph and In-memory databases\\nExperience with Machine Learning techniques and practices\\nExperience with Test Driven Code Development and SCM tools\\nFluent understanding of best practices for building Data Lake and analytical architectures on Hadoop\\nStrong scripting / programming background (Unix, Python preferred)\\nStrong SQL experience with the ability to develop, tune and debug complex SQL applications\\nExpertise in schema design, developing data models and proven ability to work with complex data is required\\nExperience in real time and batch data ingestion\\nProven experience in working in large environments such as RDBMS, EDW, NoSQL, etc.', 'We come from a background of companies like, YP, TiVo, CNET, AOL, comScore, BrightRoll, Walmart, Coca Cola and many we just picked up out of college.', 'Employment by Hallmark is contingent upon the signing of the Employment Agreement, signing of an agreement to arbitrate in connection with the Hallmark Dispute Resolution Program, completing Form I-9 Employment Eligibility Verification, passing the urinalysis drug screen, education verification and satisfactory reference and background checks., BASIC QUALIFICATIONS, The following is required to be considered for this role:, Bachelors degree in Computer Science, Engineering, Data Science, Mathematics, OR a degree with technology, analytics, or quantitative focused curriculum\\n5+ years of experience with database management and programming languages (SQL, Python, Java, .NET, C++, Java Script, Scala, Perl, or Ruby, etc)\\n3+ years of experience in numerous databases (Oracle, Teradata, MySQL, etc), Big Data platforms (Hadoop, Hive, Spark, etc) and/or Cloud-based platforms and ERPs (AWS, Azure, Google Cloud, SAP S4 Hanna, etc)\\n1+ years of experience with software/web development (including automation), data science and/or advanced statistical modeling, including predictive analysis, forecasting, regression, experimentation (multivariate is a plus), data mining, sequential/time-series, supervised and unsupervised models, etc\\n, PREFERRED QUALIFICATIONS, Your resume will stand out if you have:, Master‚Äôs or PhD in the above fields\\nExpertise with data visualization tools (including Tableau, Dash, RShiny, D3.js, Microstrategy, etc) and creating automated interactive dashboards and reports for business customers that are robust in knowledge and simplistic in usage\\nAbility to develop data models and data pipelines to enable analysts and data scientists access to a vast array of data sources from numerous locations\\nExpertise in computer programming, APIs, macro/function design and automation (Chron Jobs) in order to streamline statistical models and business processes for the organization\\nExpertise in software development, notably developing GUIs for non-technical staff members we have little to no experience with data and analytics, in order to collect data, conduct analysis, run simulations and other activities\\nStrong ability to communicate with analytics staff across the organization and develop innovative solutions to simplify their work processes and increase productivity\\nStrong ability to work with Senior Leadership across an organization to design and drive optimal data strategy across the company\\nExperience leading teams of data engineers, developers, data scientists, data analysts and/or others to develop robust technical solutions and software to optimize a business\\nAble to provide a GitHub or coding portfolio of prior data engineering, data science, computer programming and statistical work and projects\\nStrong desire to explore various data sources to uncover hidden opportunities for the organization\\nSelf-directed, detail & team oriented with highly developed problem solving and analytical skills\\nExcellent communication skills, both written and verbal, coupled with strong organizational, planning and interpersonal skills\\n, Hallmark believes in enriching the lives of our employees by offering benefit programs to help you:, Take care of you and yours: We offer comprehensive medical, dental and vision benefits, as well as discounts on elder care, child care, education assistance and adoption assistance.', 'You will contribute to Splunk‚Äôs privacy and compliance efforts.', '\"[\\n3 years of experience with Big Data, systems, including Hadoop, Hive and Pig\\nExperience with ETL tools including but not limited to NiFi and StreamSets\\nExperience with Java\\nExperience with using Cloud services, including AWS, Azure, Google Cloud or other Cloud services\\nAbility to obtain a security clearance\\nBA or BS degree\\n, \\nExperience with Agile software development\\nPossession of excellent oral and written communication skills\\nBS degree in CS, Computer Information Systems, Information Systems, or a related field\\n]\"\\n\"[1.', 'Come help us make Twitter the best place for finding what the world is saying, live!, \\n\\nRequirements:, \\n\\nExpertise in Deep Learning and NLP\\n\\nExperience with software engineering best practices\\n\\nMS or PhD in machine learning or equivalent work experience, Desired:, \\n\\nExperience using big data platforms such as Spark or Hadoop]\"\\n\"[\\nProven experience in computer vision and deep learning.', '\"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.', 'Detect data/analytics quality issues and implement bug fixes and data validation for prevention\\n\\nHelp understand our day to day operations for continuous improvement of production systems, \\n\\n2+ years experience with Big Data technologies (we‚Äôre hiring all experience levels)\\n\\nExperience with Scala/Java, Spark, Kafka, or demonstrated ability to pick up new technology quickly\\n\\nFundamental knowledge about databases and strong SQL skills\\n\\nFamiliar with Google Cloud ecosystem such as BigQuery, GCS, DataProc, etc\\n\\nEnjoys working collaboratively; CK‚Äôs values include empathy and helpfulness\\n\\nAble to estimate and meet deadlines\\n\\nExcellent verbal and written communication skills, \\n\\nExperience working with cloud technologies\\n\\nExperience scaling data throughput or building low latency streaming pipelines\\n\\nExperience solving for data quality]\"\\n\"[\\n\\nArchitect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake\\n\\nDesign, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights\\n\\nBe a technical leader for the team; guide technical and architectural designs for the major team initiatives; mentor junior members of the team\\n\\nBuild data expertise, and partner with data scientists and product engineers to define and standardize business rules and maintain high-fidelity data\\n\\nDefine and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently\\n\\nWork cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches, \\n\\n5+ years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science\\n\\nStrong software engineering skills and at least one scripting language (e.g., Python)\\n\\nProficient with relational databases and SQL\\n\\nFamiliarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred\\n\\nAbility to communicate technical concepts clearly and concisely\\n\\nIndependence and passion for innovation and learning new technologies, Data Warehousing for Business Intelligence Specialization]\"\\n\"[**THIS POSITION REQUIRES AN ACTIVE TS/SCI **, \\n\\nBI&A seeking DataEngineer with data transformation (ETL) experience working with latest industry tools., \\n\\nDUTIES ENTAIL:, Work with a teammate on data integration requirements.Write code on ETL platform to transform data to a suitable formats as defined by IC ITE initiatives.Add features to ETL platform to shorten timelines for future data integration efforts.Develop, maintain code, and integrate software into a fully functional software system.Participate in daily scum meetings, sprint retrospectives, and other agile processes.Work with external teams to validate data ingest.Provide and maintain documentation of system architecture, development, and enhancements., \\n\\nEDUCATION:, Bachelor‚Äôs Degree and 6 or more years‚Äô experience or Master\\'s Degree with 3 or more years\\' experience from an accredited course of study, in engineering, computer science, mathematics, physics or chemistry., \\n\\nREQUIRED EXPERIENCE:, 6+ years of software development experienceDemonstrated understanding of high scale cloud architectureLinux/Unix experienceObject Oriented programming languagePossess strong verbal and written communication skillsPossess strong analytical skills, with excellent problem solving abilities in the face of ambiguity, \\n\\nDESIRED EXPERIENCE:, Expertise in data ingestion, data transformation (ETL), and data modeling.Experience with Java, Ruby, or PythonExperience in Agile/SCRUM enterprise-scale software development3 years‚Äô experience working with batch-processing and tools (eg, Nifi, Midpoint, MapReduce, Yarn, Pig, Hive, HDFS, Oozie)1 year working with Restful web services Experience with code development, deployment, versioning, and build tools (eg, Eclipse, git, svn, maven, Jenkins)Experience working with tools in the stream-processing (eg, Storm)Experience developing applications that work with NoSQL stores (eg, ElasticSearch, Hbase, Cassandra, MongoDB, CouchDB)Working in cloud architecture with AWS EC2, RDS, S3, VPC, Elastic Search, \\n\\nBI&A is an Equal Opportunity Employer.', ', and\\n\\n, Only technical issues will be monitored through the below inbox:\\n\\n, recruiting.support@ imerys.com\\n\\n\\n\\nPLEASE DO NOT SUBMIT RESUMES OR APPLICATIONS TO THIS EMAIL, AS THEY WILL NOT BE REVIEWED.', 'More than a billion people rely on Google Maps services to explore the world and navigate their daily lives.', 'As a member of GSRS you will help develop a culture where safety, security and resiliency are integrated into every facet of Google, including the creative process.', 'We routinely deliver significant improvements to our revenue, and work in a close sync with our executive staff (including our COO & CFO) due to our direct impact on Twitter‚Äôs business., We‚Äôre looking for a key individual contributor to drive our advertising products forward.', 'and Ph.D are preferred)\\nStrong written and verbal communication skills\\n, Experience with sklearn, pandas, numpy or similar packages\\nFamiliarity with malware, host forensics, or network traffic analysis concepts\\nExperience with Linux command line and bash scripting\\nExperience with reverse engineering malware\\nExperience with AWS infrastructure\\nExperience with a deep learning frameworks such as TensorFlow, Theano, or MXNet\\nExperience with GPU-accelerated computing and hardware (e.g., NVIDIA DGX-1)\\nExperience using Hadoop and Spark\\nExperience using relational and non-relational databases\\nExperience with web frameworks to visualize large datasets\\n]\"\\n\"[\\nDesign and implement critical, highly scalable systems and algorithms to run analytics, workflow and machine learning\\nImprove Scalability, Reliability and performance of our Streaming Data Pipelines built on top of Kafka and Spark\\nHelp drive the Design and Architecture of next generation Cloud Machine Learning platform\\nDesign methods to derive Data Insights via efficient and effective feature learning for challenging problems\\n, \\nYou have experience designing and implementing large scale distributed systems for Stream and Batch processing\\nYour idea of fun is reading the Google Millwheel paper, and you get excited debating the merits of Flink versus Spark\\nYou have designed creative models to derive actionable insights from complex datasets\\nYou have a passion for creating new products, including being comfortable with ambiguity\\nBS/MS/PhD in Computer Science or equivalent work experience\\nStrong background in computer science algorithms\\nContributions to relevant open source projects is a plus\\n]\"\\n\"[Senior Data Scientist, Senior Data Scientists on our team partner with product managers, SMEs and our clients to form a cross-functional team driving optimization of precious healthcare resources.', 'Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc.', 'We desire someone with diverse experience and skills in data analysis, litigation support, statistical software, analytic programming languages (Python, R, Java, SAS), visualization software, and database management., \\n\\nRESPONSIBILITIES:, \\n\\nWork with client case teams to identify their needs and jointly develop solutions through leveraging all available analytic and visualization options\\n\\nConduct regular consultations with clients\\n\\nProvides regular status updates regarding assigned tasks\\n\\nEnsures successful completion of work, timeliness of deliverables, and quality control\\n\\nBuild experience in all available analysis and visualization software, Qualifications, \\n\\nEDUCATION & EXPERIENCE, \\n\\nBachelor‚Äôs degree or equivalent; 2+ years of experience using analytics tools, methods, and visualization software\\n\\nSignificant experience in one or more of the following tools is required:\\n\\nTableau Software\\n\\nIBM I2/EIA\\n\\nIBM Analyst Notebook\\n\\nDatabase (SQL Server, Oracle, PostgreSQL, MySQL)\\n\\nProgramming and/or scripting (Python, R, Java)\\n\\nNatural Language Processing\\n\\nNeo4j or other graph databases\\n\\nPalantir Gotham\\n\\nNexidia\\n\\nOther analytic and visualization tools, \\n\\nTableau Software\\n\\nIBM I2/EIA\\n\\nIBM Analyst Notebook\\n\\nDatabase (SQL Server, Oracle, PostgreSQL, MySQL)\\n\\nProgramming and/or scripting (Python, R, Java)\\n\\nNatural Language Processing\\n\\nNeo4j or other graph databases\\n\\nPalantir Gotham\\n\\nNexidia\\n\\nOther analytic and visualization tools, Background in Law Enforcement, Data Science, Investigations, Data Analysis, Computer Information Systems, or Statistics\\n\\nIndustry analytics/business intelligence knowledge including current industry trends, challenges, and data quality approaches\\n\\nDeep understanding of database, ETL, and analytics tools and concepts\\n\\nMust be able to work independently and prioritize work effectively, as well as to function as an effective team member in a local and virtual team development environment\\n\\nStrong analytical and problem solving skills with an unsurpassed attention to detail\\n\\nExcellent communication (written and verbal) skills\\n\\nExperience supporting federal agencies\\n\\nSQL experience is required, We‚Äôve been named a Best Place to Work by the Washington Post., Our employees value the flexibility at CACI that allows them to balance quality work and their personal lives., We offer competitive benefits and learning and development opportunities., We are mission-oriented and ever vigilant in aligning our solutions with the nation‚Äôs highest priorities., For over 55 years, the principles of CACI‚Äôs unique, character-based culture have been the driving force behind our success., \\n\\nJob Location, \\n\\nUS-Washington-DC-WASHINGTON DC, \\n\\nCACI employs a diverse range of talent to create an environment that fuels innovation and fosters continuous improvement and success.', ', 5+ years of hands-on experience with R, Microsoft Machine Learning, IBM I2, STATA, SPSS, S+, SAS Enterprise Miner or similar tools.', 'Communicate complex solutions to a variety of stakeholders in easily understandable language\\n\\nBe a contributing member of a scrum team that voluntarily accepts work\\n\\nWrite code that meets standards and delivers desired functionality using agreed upon technology\\n\\nDemonstrate passion about using data assets to optimize systems and products\\n\\nUse and extend open source software to deliver solutions to company‚Äôs business partners Present solutions and ideas to other team members, IT leadership, and business leaders\\n\\nEmploy a pragmatic approach to evaluate new algorithms and technologies for positive impact within the company\\n\\n, Requirements:\\n\\n, 2-5+ years of commercial experience in data science\\n\\nA demonstrable understanding of machine learning theory\\n\\nExtensive experience with Python and/or R\\n\\nDemonstrated experience with MSSQL\\n\\nExceptional communication and presentation skills are a requirement\\n\\nProgramming experience in JavaScript, C or C# for use in reading existing code or building prototypes (you do not have to have experience building production applications)\\n\\nExperience with Google Cloud Platform or Amazon Web Services, ElasticSearch\\n\\n, Bonus:\\n\\n, MS in Applied Mathematics, Statistics, or Computer Science\\n\\nData Engineering\\n\\nExperience with Tensorflow, BigQuery, Tableau\\n\\n, Location\\n\\n, Position Type\\n\\n, The Company is an equal opportunity employer and will not tolerate discrimination in employment on the basis of race, color, age, sex, sexual orientation, gender identity or expression, religion, disability, ethnicity, national origin, marital status, protected veteran status, genetic information, or any other legally protected classification or status.', 'Experience in analyzing data from business line data applications and data providers such as Google Analytics, Site Catalyst, Coremetrics, Adwords, Crimson Hexagon, Facebook Insights, Nielsen, Comscore, Simmons, MRI and etc\\nExperience in visualizing data to stakeholders in a simple and concise manner through visualization software such as ggplot, D3,Tableau Qlinkview, Periscope, Business Objects, or other similar software.', 'Programming / Scripting (Python, Java, C/C++, Scala, Bash, Korn Shell)\\n\\nLinux / Windows (Command line)\\n\\nBig Data (Hadoop, Flume, HBase, Hive, Map-Reduce, Oozie, Sqoop, Spark)\\n\\nCloud Platforms (AWS, Azure, Google Cloud Platform)\\n\\nData Concepts (ETL, near-/real-time streaming, data structures, metadata and workflow management)\\n\\nData Integration Tools (Ab Initio, DataStage, Informatica, SSIS, Talend)\\n\\nDatabases (DB2, HANA, Netezza, Oracle, Redshift, Teradata, Vertica)\\n\\nMarkup Languages (JSON, XML, YAML)\\n\\nCode Management Tools (Git/GitHub, SVN, TFS)\\n\\nDevOps Tools (Chef, Docker, Puppet, Bamboo, Jenkins)\\n\\nTesting / Data Quality (TDD, unit, regression, automation)\\n\\nSolving complex data and technology problems\\n\\nLeading technical teams of 2+ consultants\\n\\nAbility to design components of a larger implementation\\n\\nExcellent communication to narrate data driven insights and technical approach\\n\\nMust reside in the San Francisco, CA bay area\\n]\"\\n\"[\\n\\nOwn the entire end-to-end execution from requirements gathering from key stakeholders to building scalable, efficient, and reliable data marts which provide our business partners with clarity into the complexities of our platform\\n\\nCreate maintainable, scalable data processing pipelines in PostgresSQL, Python, and other data processing language in the data platform running in AWS\\n\\nDefine, develop, and operate functional data marts/cubes with common open source and SaaS based data processing and management tools like embulk, airflow, rundeck, Spark, Informatica, etc.', 'Investigating, recommending and implementing data ingestion and ETL performance improvements\\n\\nDocument data ingestion and ETL program designs, present findings, conduct peer code reviews\\n\\nDevelop and execute test plans to validate code\\n\\nWork in a collaborative, agile environment, \\n\\nRequirements:, \\n\\nBachelor\\'s degree in a technical or quantitative field with preferred focus on Computer Science or Information Systems\\n\\n4+ years experience building complex ETL programs with one of the following Informatica, DataStage, Spark, Dataflow, etc\\n\\nExpert in data extraction experience\\n\\n3+ years experience developing complex SQL\\n\\nExperience using Cloud Storage and computing technologies such as BigQuery, RedShift, Snowflake\\n\\nExperience configuring and developing big data solutions in a Cloud environment (AWS, Microsoft, or Google)\\n\\n3+ years experience programming in Python, and/or Java\\n\\n3+ years with UNIX shell scripting\\n\\n2+ years experience with Git\\n\\n2+ years experience in data quality testing; adept at writing test cases and scripts, presenting and resolving data issues\\n\\n2+ years experience developing complex technical and ETL programs within a Hadoop ecosystem (Hadoop, YARN, Hive, Pig, Sqoop, Spark)\\n\\n2+ years implementing and programming data ingestion and ETL programs with large datasets (10+ Terabyte analytical environment)\\n\\nExperience with integration of data from multiple data sources\\n\\nExperience developing and implementing streaming data ingestion solutions\\n\\n3+ years working with relational database technologies\\n\\n3+ years investigating, recommending and implementing solutions that resolve data quality issues\\n\\nDemonstrated independent problem solving skills and ability to develop solutions to complex analytical/data-driven problems\\n\\nDemonstrated experience developing data analytics solutions within AWS and/or Google Cloud Platform\\n\\nMust be able to communicate complex issues in a crisp and concise fashion to multiple levels of management\\n\\nExcellent interpersonal skills necessary to work effectively with colleagues at various levels of the organization, \\n\\nCheck out our Data Team!]\"', 'and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.Minimum 1 year of experience securing Hadoop/NoSQL based modern data platforms on-premise or on AWS, Google, Azure cloud.Minimum 1 year of Re-architecting and rationalizing traditional data warehouses with Hadoop, Spark or NoSQL technologies on premise or transition to AWS, Google clouds.Experience implementing data preparation technologies such as Paxata, Trifacta, Tamr for enabling self-service solutions.Experience integration enterprise data management toolsets (e.g.', 'Dell‚Äôs team members are committed to serving our communities, regularly volunteering for over 1,500 non-profit organizations.', 'Individual file size attachment limit is 10 MB., In compliance with the Immigration Reform and Control Act of 1986, Hallmark Cards, Inc. and its subsidiary companies will hire only individuals lawfully authorized to work in the United States.', \"Master's Degree or Ph.D. in Operational Research, Mathematics, Engineering, Statistics, Econometrics or related field - Preferred\\nExperience with Big Data technologies like Hadoop, Spark, Hive, NoSQL, etc., and Cloud technologies (Google Cloud, Azure, etc.)\", 'You love database and visualization solutions like SQL, Google Data Studio, and Tableau.', 'Write complex ETL processes and frameworks for analytics and data management\\n\\nImplement large-scale real-time streaming data processing pipelines\\n\\nWork inside a team of industry experts on cutting-edge Big Data technologies to develop solutions for deployment at a massive scale, \\n\\nRequirements:, \\n\\nHadoop v2, MapReduce, HDFS on Google Cloud\\n\\nBuilding stream-processing systems, using solutions such as Storm or Spark-Streaming\\n\\nBig Data querying tools, such as Pig, Hive, and Impala\\n\\nIntegration of data from multiple data sources\\n\\nSpark, Scala, Java, Python, Bash, BigQuery, Azkaban, Airflow, and Dataflow\\n\\nNoSQL databases, such as HBase, Cassandra, MongoDB\\n\\nMessaging systems Kafka, RabitMQ, etc., \\n\\nWhat will be a plus:, \\n\\nKnowledge of Unix-based operating systems (bash/ssh/ps/grep etc.)', 'Will accept Bachelor‚Äôs Degree in Mathematics/Statistics plus equivalent experience.Minimum Years of Experience: 3 to 5 years., Google Suite and Microsoft Office, with advanced Microsoft Excel.Working knowledge of SQL.', 'If you have ever worked for the Central Intelligence Agency (CIA), you are not eligible for employment at the Peace Corps in any capacity, and you should not apply for employment.', 'Amazon, Cisco, Google, Microsoft, SAP and other leading businesses are all part of the MapR ecosystem.', 'and governance solutions for modern data platforms that use Hadoop and NoSQL on premise or on AWS, Google and Azure cloud.', 'Knowledge of machine learning platforms such as Amazon, IBM Watson, Azure, Google Predict, BigML\\nStrong trouble-shooting skills.', ', \\nMachine learning experience required\\nNatural language processing experience preferred\\nShiny, Spyre, Flask, WebDev and prototyping experience preferred\\nJupyterHub, Sun Grid Engine, Google Cloud Platform, AWS experience preferred\\nExperienced in data science methodologies and techniques, e.g.', 'Expert in Oracle\\n\\nBackground in Statistics\\n\\nData quality experience and familiarity with commercial data quality software\\n\\nExperience with Informatica or IBM MDM Infosphere data quality tools\\n\\nFamiliarity with IBM MDM InfoSphere 11.5 (or initiate), Workbench and/or Identity Management\\n\\nKnowledgeable of or experience with data warehouse, graphical presentation of large dataset\\n\\n, # of Openings:\\n\\n, Scheduled Weekly Hours:\\n\\n, T elecommuting Options:\\n\\n, Work Location:\\n\\n, Additional Work Locations:\\n\\n, CSRA is committed to creating a diverse environment and is an equal opportunity employer.', 'Twitter Analytics, Facebook Insights, Instagram Insights, Hootsuite, Shareablee)\\n\\nExperience with BI tools (ex.', 'Extensive SQL query and R/Python script development experience\\n\\nGeneral consulting skills including: analysis and problem solving, written and verbal communication, and team collaboration\\n\\nBachelor‚Äôs Degree in a technical field such as Computer Science, Engineering from a four-year-college or university\\n, 2+ year of experience with equivalent Amazon Web or Google Cloud Platform services\\n\\nExperience with NoSQL environments such as Azure Cosmos DB, MongoDB or Cassandra\\n\\nHistory of working successfully with cross-functional engineering teams\\n\\nUnderstanding of advanced analytics, machine learning\\n\\nExperience with IoT based solutions\\n\\n]\"\\n\"[Are you excited about being in a start-up and being in the cyber security industry?', 'Experience implementing customer installations with tag management systems such as Google Tag Manager and similar.', 'For more about Forcepoint, visit www.Forcepoint.com and follow us on Twitter at @ForcepointSec.', 'Hallmark does not generally provide sponsorship for employment.', '\"[Note: By applying to this position your application is automatically submitted to the following locations: Boulder, CO, USA; Mountain View, CA, USA, \\n\\nAt gTech‚Äôs Users and Products team (gUP), our mission is to help users get the most out of Google.', 'It is an exciting time to be in the Greetings business at Hallmark!, WE ARE LOOKING FOR:, Hallmark is in the midst of a data revolution and we need a talented data engineer to join our team.', 'The Senior Data Analyst position is ideal for a motivated and highly capable self-starter with sharp technical and business acumen., Other Duties:, Serve as the subject matter expert in working with multi-touch attribution and media mix modeling agency\\nAssist in the creation of a data warehouse by identifying data streams and database requirements\\nUse SQL queries and stored procedures to develop reports pertaining to web analytics, marketing campaign performance, customer interactions and other business and marketing performance metrics\\nManage SQL queries and stored procedures\\nDevelop, deploy and manage the implementation of data visualization and reporting tools including Tableau\\nCreate automated reports from various databases\\nMine data and provide intensive analysis of customer and business data and offer actionable insights\\nCreate ROI campaign tracking\\nAnalyze variance in terms of actual vs forecasted metrics across sales and service (on macro and micro levels)\\nAnalyze trends in terms of marketing and business operations\\nGather and confirm user requirements for various analytics projects\\n, Qualifications:, Minimum 7 years‚Äô experience in data analysis\\nProficient in use of SQL server\\nExpert knowledge of Tableau or similar data visualization tools\\nExpert knowledge of Excel and other statistical tools such as SAS\\nExtensive experience with budgeting and forecasting\\nExtensive knowledge of marketing and web analytics including Google Analytics\\nProficiency in SSIS is preferred\\nStrong analytical and problem solving skills\\nKnowledge of multi-touch attribution and predictive modeling principles\\nEffectively multi-task with planning and efficiency\\nStrong email marketing analysis capability\\n, We believe that taking care of employees is an important step in creating a positive workplace and a successful company.', 'Learn more about Splunk careers and how you can become a part of our journey!, \\n\\nThe Data Scientist role involves working on all the stages of the data science pipeline, including acquiring and understanding the data, modeling various algorithms, performing evaluation of the performance of algorithms, and also implementing these solutions in a commercial product either as standalone code or in existing ML frameworks like Spark/MLlib., \\n\\nYou will become an expert on the product data, including how it is collected and processed\\n\\nYou will explore the data and answer questions about the data to improve our understanding of the potential of the data\\n\\nYou will closely interact with product management and engineering to derive requirements for what solutions should be implemented in the product\\n\\nYou will rapidly prototype, and evaluate statistical and machine learning solutions\\n\\nYou will collaborate with engineering to implement these solutions in production\\n\\nYou will communicate your results and explain your solutions to technical and non-technical stakeholders, \\n\\nYou have experience with Python scikit-learn, Spark/MLlib, or an equivalent framework ‚Äì required\\n\\nYou have the ability to code in Python, Java or Scala - required\\n\\nYou have the ability to evaluate and tune statistical and machine learning solutions ‚Äì required\\n\\nYou have experience working with large datasets, preferably using tools like SQL, Spark, Hadoop, MapReduce, Pig, or Hive ‚Äì preferred, \\n\\nA constant stream of new things for you to learn.', '\"[\\n3+ years of experience as a data scientist\\nExperience with building statistical models and developing machine learning algorithms\\nExperience with data visualization\\nExperience with managing data scientist team\\nExperience with programming languages, including Python, R, Scala, or Java\\nExperience with Big Data technologies, including HDFS, Hadoop, or Spark\\nExperience with manipulating data and ETL in parallel processing and distributed compute environments\\nExperience with designing and executing machine learning models and applications\\nTS/SCI clearance\\nMA or MS degree\\n, \\n2+ years of experience as a developer in Java, Python, R, or similar high-level languages\\n2+ years of experience with designing novel data analytic methods and workflows, including full data pipelines from raw data through analysis results\\n2+ years of experience in managing disparate data sources with varying data structures of content and preparing these for data science and machine learning applications\\nExperience in working with Big Data storage, processing, and computation, including one or more of the following: Accumulo, Spark, Storm, Kafka, or MapReduce\\nAbility to both manage and manipulate large data sets, develop data science approaches, and manage data science tasks\\nAbility to leverage a wide variety of data science capabilities and languages\\nAbility to exhibit flexibility, initiative, and innovation when dealing with ambiguous and fast-paced situations\\n]\"\\n\"[Responsible for following the defined agile development processes including attending the required meetings with contribution towards the successful completion of the sprints..Collaborates with product management and customer delivery teams to ensure product requirements are clear on what customers expect and what the delivery teams should set as the right expectations with the customers.Communicate rigorously within the squad on goals, ongoing progress, milestones, and any issues.Support and follow the overall product architects, delivery architects, to drive and establish the architecture decisions and designs for the product.Leverage the DevOps team to ensure product can be automatically built, deployed, and tested using a CI/CD pipelines across all of the release cycles from dev to production.Mentor and develop required skills of other junior product developers., Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.Experience applying machine learning and predictive analytic techniques to large, complex data sets specializing in even data processingExperience with Machine Learning frameworksExpert in coding hands on in Python and RExperience with Big Data architectures including Spark/Hadoop, HDFS, analytical processingProven ability to develop resilient code (best practice error handling) that performs and scales for large enterprise needsDeep expertise in developing REST-based API\\'s (json/yaml), Micro-services with RDBMS and NoSQLBachelor\\'s degree in Computer Science or equivalent with specialization Machine Learning, Understanding of Public and Private Cloud Provider services, usage and delivery paradigmsWorking knowledge of cloud technologies and architectures, including Virtualization, APIs, Micro-services and Containers.5+ years experience delivering enterprise-class cognitive applications2+ years experience developing in Python and modern web-based languagesExcellent verbal and written communication abilities: must effectively communicate with technical and non-technical teamsHigh attention to detail and proven track record in taking ownership, driving results and moving with speed to implement ideas in a fast-paced online environmentWillingness to roll up your sleeves and do whatever is necessaryAbility to process and manage multiple priorities, Ph.D or Masters in Computer Science/Artificial Intelligence with specialization in Machine Learning.Knowledge of IT Service Management and IT Operations Management processes, tools and technologiesKnowledge of CI/CD processes, DevOps toolchains, blueprint, template and/or container based deployment modelsExperience with multiple Cloud services, including vmWare, IBM Cloud, AWS, MS Azure, Google Cloud beyond compute and storageExperienced with Jira / Confluence, GitHub, Travis, TestRails, GoCD.,  Experience as a Cognitive Data Scientist for large-scale enterprise cognitive applications.', '), with a minor (or equivalent experience) in Computer Science, or Software engineering\\n2-3 years‚Äô experience with programmatic data analysis (preferably using R); experience with time series analysis/forecasting or customer analytics a plus\\nExperience working with real-world datasets, including joining disparate data sources, record linkage, data cleaning/reshaping/management, and descriptive data analysis; data visualization and automated reporting skills (such as RMarkdown or Shiny) a plus\\nExperience writing relational database queries (preferably using Postgres SQL)\\nExposure to web analytics (such as Google Analytics or Adobe Analytics) and e-commerce fundamentals a big plus\\nStrong verbal and written communication skills: able to produce professional-quality, insightful deliverables, and experience communicating analysis and insight to all levels of an organization\\nExperience managing project ambiguity, complexity, and interdependencies in a methodical way\\nExcellent attention to detail and a systematic approach to problem-solving, with strong data intuition\\n, Founded in 2012, IXIS is rooted in innovative processes for data-driven digital experience and strategic online planning.', \"Strong knowledge of randomForest, nnet, svm, PMML and glmnet packages., \\n\\n#LI-MC1, \\n\\nCompany Summary, \\n\\nZeta is a data-driven marketing technology innovator whose SaaS-based marketing cloud helps 500+ Fortune 1000 and Middle Market brands acquire, retain and grow customer relationships through actionable data, advanced analytics and machine learning., \\n\\nFounded by David A. Steinberg and John Sculley (former CEO of Apple and Pepsi-Cola) in 2007, the company's highly-rated ZetaHub technology platform has been recognized in Gartner's Magic Quadrant for Digital Marketing Hubs (February 2017) and in its Magic Quadrant for Multichannel Campaign Management (April 2017), competing with offerings from Oracle, IBM, Salesforce and Adobe., \\n\\nOperating on four continents with 1,300+ employees, the company is headquartered in New York City, with Centers of Excellence in Silicon Valley, Boston, London, and Hyderabad, India.\", '\"[Epic Care is seeking a Medical Systems Data Analyst to join our team to develop or apply mathematical or strategical theory and methods to collect, organize, interpret and summarize numerical data to provide useable information as directed by the Chief Administrative Officer., JOB DUITES INCLUDE BUT ARE NOT LIMITED TO:, In collaboration with others, develop and maintain databases and data systems necessary for projects and department functions.', 'In every decision that you influence, you will see the product improve and be more valuable to Twitter users., \\n\\nWe are trying to improve Twitter.', \"preferred\\n\\nComfortable working in a GNU Linux/Unix environment\\n\\nEffective communication skills, focusing on presentation of technical information to non-technical team members\\n\\nAdept in cross-team collaboration, with the ability to work autonomously, as well as with colleagues at all levels in the organization\\n\\nPrevious travel industry experience is a plus, \\n\\nSAP'S DIVERSITY COMMITMENT\\n\\n\\nTo harness the power of innovation, SAP invests in the development of its diverse employees.\", ', As a data engineer, you will:\\n\\n, Run and support a production enterprise data platform\\n\\nDesign and develop data models\\n\\nWork with languages like Java, Python, Go, Bash, and SQL\\n\\nBuild batch and streaming data pipelines with tools such as Spark, Airflow, and cloud-based data services like Google‚Äôs BigQuery, Dataproc, and Pub/Sub\\n\\nDevelop processes for automating, testing, and deploying your work\\n\\n, About You\\n\\n, To thrive in this role, you are excited about data and motivated to learn new technologies.', '\"[The team is responsible for placing each and every ad that Twitter serves.', 'Founded by Murali Aravamudan and Venky Soundararajan, Ph.D., nference is led by a multidisciplinary team of serial entrepreneurs from the tech and biotech worlds and Ph.D‚Äôs in Biology/Genomics from Massachusetts Institute of Technology (MIT) and Harvard Medical School.', 'Our goal is both to support your growth and development while empowering you for a successful start to your career., \\n\\nAs a Machine Learning Intern you will be responsible for ‚Ä¶, \\n\\nAchieving data science and software engineering goals set by you and your mentor\\n\\nLearning about Splunk, both the product and the company\\n\\nWorking and socializing with the other interns as well as full-timers, Minimum Qualifications:\\n\\n, Strong interest in state-of-art Machine Learning techniques.', 'Supporting the Analytic‚Äôs automated batch processes running on a combination of Cloudera Data Science Workbench (CDSW) and IBM SPSS Modeler in a Linux environment.', '\"[Bachelor\\'s degree preferably in Computer Science, Statistics, or Mathematics or equivalent experience\\n\\n5-8 years experiences in data analysis required\\n5 or more years hand on experience writing complex SQL\\nGeneral knowledge of Netezza and/or Oracle databases\\n\\nWorking experience with Informatica Analyst and IBM Information Governance Catalog\\nStrong analytical and problem-solving skills, Performs data analysis, gap and impact analysis for medium to large sized assignment (with med/large number of data elements, one-to-multiple sources, business impact, and visibility).', 'Hallmark is looking for someone like you., People rely on us to help them connect and express their emotions through products and services that enrich lives every day.', 'Identify impact and opportunities to reuse data structures through services oriented architecture (Data as a Service ‚Äì Daas)\\n\\nLeading data engineering teams for large BI, Cloud and / or ERP projects, \\n\\nPreferred Skills:, \\n\\nFocus in Oil & Gas with Hadoop technology stack\\n\\nAWS, MS Azure and other Cloud RDBMS experience is a PLUS\\n\\nExperience with Enterprise Architecture Tools (Mega, Troux, IBM, Opentext etc)\\n\\nData Archiving, Disaster Recovery and DBA, \\n\\nProfessional Skills:, \\n\\nEagerness to contribute in a team-oriented environment\\n\\nAbility to work creatively and analytically in a problem-solving environment\\n\\nDesire to work in an information systems environment\\n\\nExcellent leadership, communication (written and oral) and interpersonal skills]\"\\n\"[Data Engineer Consultant, \\n\\nAs a Data Engineer for Slalom Consulting, you\\'ll work in small teams to deliver innovative solutions on Amazon Web Services, Azure, and Google Cloud using core data warehousing tools, Hadoop, Spark, Event Stream platforms, and other Big Data related technologies.', 'We‚Äôre inspired by a noble mission that‚Äôs shared by Raytheon employees around the globe and an inclusive culture that empowers employees and celebrates their contributions.', \"You anticipate how decisions are made, persistently explore and uncover the business needs of Google's key clients and understand how our range of product offerings can grow their business.\", 'Understanding of PKI and PKI/E using CAC, SSL/TLS, OpenSSL, NSS\\n\\nNetwork and System Monitoring: Nagios/Icinga2, Splunk, Elastic Search, LogStash, Kibana, syslog, syslog-ng, rsyslog, snmp\\n\\nServer/Node Provisioning: Red Hat Kickstart, Windows Imaging Format (WIM), Cobbler, PXE, Packer, CloudFormation, SaltStack, Puppet, Chef, Ansible\\n\\nFirewalls: IPTables, FirewallD, MS Forefront, AWS VPC, AWS Security Groups, AWS NACL\\n\\nNetwork/OS Troubleshooting utilities:TCPDump, WireShark, nslookup, netstat, watch, htop, strace, route, ifconfig\\n\\nCloud/IaaS/PaaS and Virtualization Technologies:VMware (vSphere, vCenter, ESXi, Fusion), Vagrant, VirtualBox, Virtualization using Hypervisors type 1-2 KVM/XEN, RHEV, Open Stack, Hyper-V, AWS (EC2, C2S, S3,VPC), Microsoft Azure\\n\\nCND Tools for log-based telemetry: Splunk, NMap, TCPdump, WireShark, Elastic Search, LogStash, Kibana\\n\\nICD 503 Security Compliance:eEye Retina, McAfee Enterprise Policy Orchestrator (ePO), Host Based Security System (HBSS), XCCDF, STIG, SRR, Security Checklists, SCAP compliance tools such as openSCAP, ACAS and commercial Nessus, HubbleStack\\n\\nKnowledge of static and dynamic vulnerability analyses tools such as: Threadfix, HP Fortify, SonarQube, OWASP ZAP, Arachni, Amazon Inspector, CoreOS Clair, Twistlock, OpenScap, \\n\\nKnowledge of pentesting platforms such as: Kali, BurpSuite]\"\\n\\n\"[As a Research Scientist on the machine learning team, you will be helping to build the core machine learning building blocks upon which computer vision, speech, and other application specific API‚Äôs can be built.', 'Together, we are on a quest to change banking for good., \\n\\nSenior Data Engineer, We are seeking a leader to help build Capital One‚Äôs next generation of data products and capabilities., \\n\\nOn any given day you will:, \\n\\nProvide guidance to business and tech partners on best methods to engineer data processes\\n\\nBuild data pipeline frameworks to automate high-volume and real-time data delivery\\n\\nDevelop applications from ground up using a modern technology stack such as Scala, Spark, Java, Postgres, Python, Angular JS, and NoSQL\\n\\nEngineer capabilities and pipelines for big data and machine learning solutions\\n\\nWork directly with Product Owners and customers to deliver data products in a collaborative and agile environment, Responsibilities:, \\n\\nLead and engineer sustainable data driven solutions with current new data technologies to meet the needs of our organization and business customers\\n\\nRecruit, manage, and retain a team of talented engineers\\n\\nInfluence peer teams and leadership to ensure our technology culture is one where engineers proudly do their best work every day\\n\\nRaise the bar for technical excellence\\n\\nMaster new technologies rapidly as needed to progress varied initiatives\\n\\nBreak down complex data issues and resolve them\\n\\nUnderstand complex multi-tier, multi-platform systems, Basic Qualifications:, \\n\\nBachelor‚Äôs Degree or military experience\\n\\nAt least 3 years of backend software engineering experience\\n\\nAt least 1 year of experience in cloud technologies AWS, Azure or Google Cloud, Preferred Qualifications:, \\n\\nMaster\\'s Degree\\n\\n1+ years of machine learning experience\\n\\n3+ years of experience with Agile engineering practices\\n\\n3+ years of experience with the Big Data stack EMR, Spark, Databricks\\n\\n3+ years of experience in at least one scripting language Python, Perl, JavaScript, or Shell\\n\\n3+ years of experience with UNIX/Linux, Capital One will not consider sponsoring a new qualified applicant for employment authorization for this position.]\"', 'Work closely with other functional teams, including Software Engineering, Product Management, Data Operations, Client Accounts Managers, and Sales Teams to develop and maintain the methodologies contributing to comScore‚Äôs cross-platform measurement services.', 'Google Research & Machine Intelligence teams are actively pursuing the next generation of intelligent systems for application to even more Google products.', \"Synthesize information to make it useful and available to partners and sales teams, and analyze it to understand how features impact clients and Google's ads business.\", 'Working on an advanced analytics platform that combines wider market, artificial and human intelligence to highlight the value to both new and existing clients of how it can make their marketing targeting more efficient and effective, increasing ROI across all communication channels\\n\\nUsing your advanced analytics backgrounds in R/SAS, Python, SQL, Adobe Analytics and knowledge of DMPs/DSPs to aggregate and integrate multi-channel data and predict customer behaviors based on their engagement with advertising/marketing and purchasing trends\\n\\nConsult with the client as well as with wider stakeholders and teams internally to maximize the product, develop it further, and meet their data goals, \\n\\nYOUR SKILLS AND EXPERIENCE:, \\n\\nIn order to be successful in this role you must have:, \\n\\nA degree in a numerate discipline such as Math, Stats, Economics or similar\\n\\nProven capabilities in building and managing advanced analytics and data science teams who build predictive models including audience modelling and machine learning\\n\\nStrong quants background in SAS/R, SQL/Python and knowledge of web analytics tools including Adobe Analytics, Google Analytics, DMPs/DSPs\\n\\nAbility to engage with a wide variety of stakeholders at different levels, delivering insights and recommendations, \\n\\nBENEFITS:, \\n\\nAs a VP Advanced Analytics, you can expect to earn up to $250,000 + benefits (depending on experience)]\"\\n\"[Senior Technical Product Manager, Analytics, \\n\\nWhy Zynga, \\n\\nOur mission at Zynga is to connect the world through games by building games around core social experiences to deliver deep player engagement, organic acquisition and long term retention.', 'Experience working with cloud databases and/or distributed computing platforms, and their query interfaces, such as SQL, Hive, Spark, Google Cloud BigQuery or Dataproc.', ', OM Partners is a software and consulting company focused on Supply Chain Planning.', 'Expert in Microsoft Excel and Powerpoint (or equivalent)\\n\\nExperience with website reporting tools, such as Google Analytics, Adobe Analytics, or similar.', 'Survey tools such as Survey Monkey & Web Analytics such as Google Analytics.', 'Experience with Modeling Techniques (linear regression, logistic regression, decision tree), Query Languages (SQL, Python), Automation (SQL Stored Procedures, SSIS, APIs), Reporting (Excel, .Net, MicroStrategy), prior management of a project in which a relational database was built and utilized for analysis, Google Analytics, and Data Mining experience\\n, Ingram Micro Inc. is committed to creating a diverse environment and is proud to be an equal opportunity employer.', 'While placing those ads we decide how best to balance user experience, advertiser results, and Twitter revenue.', 'Google BigQuery and Google Cloud Platform experience preferred.', 'Minimum of 5+ years experience working in a quantitative analysis/data analytics, managing and/or coaching one or more analysts\\n\\nExperience working with relational databases, such as SQL\\n\\nStrong communication skills to be able to work with clients and present to C-level executives\\n\\nSolid project management methodology background, including schedule, scope, issue and risk management experience, change management, strategic planning and analysis\\n\\nPresent experience or proficiency with data related projects\\n\\nProficient analytical, problem solving and quality delivery experience\\n\\nProven expertise with advanced analytics and data mining tools and programming languages such as SAS, IBM/SPSS, R, Python, and SQL\\n\\nFamiliarity with BI/data visualization tools such as Tableau and Qlikview\\n\\nHands-on experience with multivariate analytic techniques such as linear and logistic regression, decision tree, cluster and factor analysis, time-series forecasting methods, SVM models, and neural nets\\n\\nNoSQL (preferred): HBase, Cassandra, Accumulo, Mongo, Neo4j, etc.', 'We are highly profitable and expanding quickly\\niD Tech is a national leader in youth, STEM education\\n, Our Company.', 'From timeline ranking to ads ranking to new user on-boarding, recommendation systems are prevalent at Twitter.', '\"[\\n\\nIdentify opportunities to operate the marketplace more efficiently, working closely with business, product, and engineering leaders\\n\\nBuild multivariate models to arrive at inferences or predict future behavior\\n\\nDevelop algorithms that match owners with providers or solve other customer needs\\n\\nDesign and analyze A/B user tests and marketplace experiments, often in partnership with product managers\\n\\nDeploy machine learning models at scale, writing production code in collaboration with machine learning platform engineers, \\n\\nSQL\\n\\nPython or R\\n\\nGoogle Analytics or similar user funnel analytics tools\\n\\nTableau, Looker, or similar data visualization tools\\n\\nData-informed decision making with rigorous split testing.', 'You will be expected to focus on results, be a self-starter and demonstrate success in using analytics to drive the understanding, progression and excellence in product and operations., Google creates products and services that make the world a better place, and gTech‚Äôs role is to help bring them to life.', 'Over 50,000 students attended our programs last year, and that number continues to grow rapidly!, \\n\\niD Tech is committed to fostering a diverse work environment and proud to be an equal opportunity employer.', ', Google Analytics (or similar) guru & comfort with large record data sets, Strong quantitative and analytic ability with attention to detail., Strong problem solving ability including generating hypotheses, conducting root cause analysis and developing actionable recommendations., Willingness to do detailed work as well as higher level strategic analysis., Effective verbal and written communication skills with the ability to clearly and concisely articulate information to diverse audiences., Ability to build strong relationships with cross-functional teams and become a trusted business partner., Results oriented with the ability to organize and independently manage multiple projects simultaneously., Effective time management and prioritization skills including estimating appropriate time for tasks and deliverables, creating focus, eliminating roadblocks and consistently meeting deadlines., Strong decision making skills by incorporating a combination of analysis, experience and judgment., Qualifications, Bachelor‚Äôs degree in marketing, business, finance or other quantitative field.', 'Experience with behavioral / click-stream data (Adobe Analytics, Google 360) and extracting processed data from the applications with SQL- extending beyond the front-end of the application a must.', ', In particular, you can expect to:, Implement your own digital analytics/web analytics tool kit and definite processesOrganize data trends and look at ways to unlock new consumer data sourcesBuild out a team of digital analysts and BI analysts, while working collaboratively with the existing marketing team, as well as Product, Tech and OperationsAnalyze data and deliver insight on site and media campaign performance, solving problems around pixel trackingPerform A/B testing and multivariate testing, \\n\\nYour Skills and Experience, Bachelor\\'s Degree requiredWorking experience in a digital analytics or web analytics leadership positionWorking experience in analyzing data from digital platforms (Google Analytics, Adobe Analytics, DMPs, attribution tools, DCM)Experience in implementing web analytics toolsStrong client management and strategy delivery skillsDeep knowledge of cross-channel digital marketing campaignsExperience working collaboratively with marketing operations and technology teamsAbility to pitch findings and ideas to stakeholdersWorking exposure to R or Python preferred, \\n\\nSALARY AND BENEFITS, \\n\\nThe successful candidate will secure a salary of $180,000 - $200,000 and benefits depending on experience]\"\\n\"[VP Advanced Analytics\\nGlobal Consultancy\\nNew York City\\n$200,000 - $250,000 + benefits, \\n\\nAre you a \"\"purple unicorn\"\" with an entrepreneurial mindset who possesses not only a technical background in advanced analytics with the ability to predict customer behaviors across multiple channels and platforms, but also have a solid background in media analytics?', 'Lead the data science aspect of multiple engagements at the same time\\nWork on complex data sets from some of the world‚Äôs largest organizations\\nWork in a multi-disciplinary environment mixing highly skilled people in data science, data engineering and design\\nBuild strong links with the academic world and constantly share ideas and stay ahead of the curve on the latest methods\\nHelp grow and shape an elite team of world-class data scientists\\n, Requirements, \\nDeep experience in statistical modeling, machine learning and deep learning techniques/frameworks\\nProven record of applying data science methods to business problems\\nStrong presentation and communication skills, with a knack for explaining complex analytical concepts to people from other disciplines\\nProgramming experience in at least 2 of the following language: R, Python, Scala\\nEducated to a PhD level in the field of Computer Science, Machine Learning, Applied Statistics or Mathematics\\nTeam leadership, mentoring and project management skills]\"\\n[Required Skills: , - 4+ years as a Data Scientist, - Machine Learning, - Python/R and Google Cloud Platforms (or any other Cloud Platforms), Educational Qualification: , Bachelor‚Äôs Degree, or equivalent work experience., Job Type: Full-time, Salary: $150,000.00 to $210,000.00 /year, Experience:, Machine Learning: 1 year (Preferred)Google Cloud Platform: 1 year (Preferred)Python: 1 year (Preferred), Education:, Bachelor\\'s (Required), Work authorization:, United States (Required)]\\n\"[\\nMS/PhD in a quantitative field e.g., Physics, Astronomy, Chemistry, CS, Math or have worked in Data Science, Quantitative Research or Software Development for 5 years.', 'Experience in data integration automation via Google DataFlow, Apache Beam, Spark, AWS EMR, etc.', '\"[\\naccess to online and onsite training in data analysis and presentation methodologies, and tools like Hortonworks, Docker, Tableau, and Splunk\\na chance to change the world with the Data Science Bowl‚Äîthe world‚Äôs premier data science for social good competition\\nparticipation in partnerships with data science leaders, like our partnership with NVIDIA to deliver Deep Learning Institute (DLI) training to the federal government\\n, \\n8+ years of experience with data science and analytics\\nExperience with analytics project management\\nE xperience with federal health market and finance agencies\\nExperience with using R or Python to analyze data and create data-driven visualizations\\nKnowledge of machine learning, data mining, and statistics\\nAbility to integrate data environments, including SQL, HDFS, or Hadoop into analytics workflows\\nAbility to create reports and present findings based on statistical analysis and develop persistent monitoring applications for statistical or machine learning processes\\nAbility to obtain a security clearance\\nMA or MS degree in Mathematics, Statistics, or CS\\n]\"\\n\"[As a SENIOR DATA SCIENTIST within our Personalized HealthCare (PHC) function you will work with meaningful data to generate impactful evidence and insights on our molecules/ medicines and patients, that support R&D, advance scientific and medical knowledge, and enable personalized patient care and access., You will collaborate with peers within the function and across the organization to develop evidence generation strategies, identify evidence gaps and data sources, design and execute studies, and implement analyses to address molecule and disease area questions.', 'A Masters degree in Computer Science, Mathematics or related technical field is a plus., \\n\\nExperience architecting and developing end-to-end enterprise scale Big Data analytical solutions in serverless environments such as Google Cloud Platform, \\n\\nExperience with Cloud Dataflow, BigQuery, Hadoop/Spark, and Tableau, \\n\\nExperience implementing ETL processes in Big Data analytical solutions using a variety of sources (Text, databases, JSON, XML, etc..), \\n\\n2-3 years of experience in statistical and database languages (e.g., Python, R, advanced SQL), \\n\\n2-3 years of experience working with Big Data, data mining or machine learning, data visualization to draw actionable insights, \\n\\n3+ years of experience programming in Java and Unix shell scripts, \\n\\n2-3 years of experience with Agile and Scrum development, \\n\\nFamiliar with Apache BEAM SDK, \\n\\nWorking knowledge of basic financial concepts: P&L, margins, pricing, etc., \\n\\nPrior experience in financial modeling is a plus., \\n\\nExcellent oral and written communication skills, including the ability to communicate complex findings in a structured and clear manner to a non-technical audience]\"\\n\"[Build data expertise and own data quality for all data pipelines you build\\n\\nTrack events that are critical to drive business values\\n\\nWork with new data models that provide intuitive analytics\\n\\nMove data from large scale data warehouse and data storage both internally and externally\\n\\n Develop new systems and tools to enable folks to consume and understand data faster\\n\\nUse your expert coding skills across a number of languages from Python, Java and PHP\\n\\nWork across multiple teams in high visibility roles and own the solution end-to-end, \\n\\n2+ years of Java and/or Python development experience is necessary\\n\\n2+ years of SQL (mySQL, Hive, etc) experience is required\\n\\n3+ years of experience with dimensional data modeling & schema design in Data Warehouses\\n\\n2+ years of experience in ETL design, implementation and maintenance (Pentaho, Elastic Search)\\n\\n100% passionate for reliable data pipelines and intuitive user interfaces\\n\\nAbility to write well-abstracted, reusable code components\\n\\nExcellent communication skills including the ability to identify and communicate data driven insights\\n\\nBS or MS degree in Computer Science or a related technical field]\"\\n\"[Build comprehensive summary presentations to executive and technical teamsStrong analytical, planning, and organizational skills with an ability to manage competing demandsStrong experience in data exploration and visualization with large data sets, MS in Computer Science, Computer Engineering or Bachelors with equivalent experience is requiredExperience in Java, C, C++ a plusExperience and solid understanding of Scala, Spark, TeraData, SQL & SQL-like languagesStrong Hadoop skills (hive, spark, scala)Good coding skills to clean data sets for ingest and tool development (i.e.', 'Our Data Management Platform (DMP) is now ingesting thousands of GB\\'s of data from our online marketing sources:\\n, \\n\\nDisplay Advertising\\n\\nSocial Advertising\\n\\nEmail marketing\\n\\nOnline Job Postings\\n\\nCareer Web Sites\\n, Display Advertising, Social Advertising, Email marketing, Online Job Postings, Career Web Sites, Amongst many other things, Symphony Talent will be using this data to produce the following:, \\n\\nMulti source attribution analytics\\n\\nPredictive Analytics\\n\\nClient facing Analytics - via our SaaS portal\\n\\nIntegration with external vendors and clients (Google, Facebook, Twitter, Indeed etc)\\n, Multi source attribution analytics, Predictive Analytics, Client facing Analytics - via our SaaS portal, Integration with external vendors and clients (Google, Facebook, Twitter, Indeed etc), About the Role:\\n\\n\\nWe are looking for a \"\"generalist\"\" engineer, that will primarily be responsible for collecting, storing, processing, and analyzing huge sets of data.', 'Informatica DQ), 1+ years of experience working with Agile development methodologies]\"\\n\"[Guide business and technical stakeholders in the collection and analysis of key data related Cyber Security metrics\\n\\nCollaborate with a wide range of stakeholders to establish qualitative analysis on metrics depicting key trends and messages to communicate to targeted audiences\\n\\nBuild and maintain dashboards for executive & senior leadership reporting, providing critical Cyber Security metrics trending and forecasting information, summarized as appropriate for executive and senior levels consumption\\n\\nProduce ad-hoc Security metrics reporting in a concise and consistent manner\\n\\nCreate data platforms and manage Cyber Security metrics tools\\n\\nProactively identify opportunities for optimization in the data collection\\n\\nPartner with stakeholders to turn analyses into opportunities to detect and mitigate future security risk\\n\\nCoordinate the GS budget activities including tracking and coordination with IT PMO to drive appropriate sourcing and investments decisions, Education:\\n\\nA university degree\\n\\nCertifications such as CISM, CISSP, ISO27001 or trainings in the domain of Information Security are considered as a plus, \\n\\nA university degree\\n\\nCertifications such as CISM, CISSP, ISO27001 or trainings in the domain of Information Security are considered as a plus, \\n\\nExperience:\\n\\nMinimum of 3+ years managing, analyzing and reporting on large datasets\\n\\nExposure to Cyber Security metrics, key performance indicators (KPIs) and key risk indicators (KRIs)\\n\\nVery good understanding of Information Security management reporting processes\\n\\nPrevious experience in a corporate security organization is highly preferred\\n\\nGood knowledge of Information Security processes, procedures and controls\\n\\nProven track record in managing multiple projects\\n\\nExperience in interfacing with multiple levels of management\\n\\nKnowledge of Splunk and ServiceNow is a plus, \\n\\nMinimum of 3+ years managing, analyzing and reporting on large datasets\\n\\nExposure to Cyber Security metrics, key performance indicators (KPIs) and key risk indicators (KRIs)\\n\\nVery good understanding of Information Security management reporting processes\\n\\nPrevious experience in a corporate security organization is highly preferred\\n\\nGood knowledge of Information Security processes, procedures and controls\\n\\nProven track record in managing multiple projects\\n\\nExperience in interfacing with multiple levels of management\\n\\nKnowledge of Splunk and ServiceNow is a plus, \\n\\n Other skills:\\n\\nExcellent analytical & organizational skills\\n\\nProactive, consultative and business-minded\\n\\nAbility to work independently\\n\\nStrong communication skills\\n\\nVery good interpersonal skills\\n\\nAbility to deliver data-driven conclusions effectively\\n\\nCritical mindset ‚Äì challenges status quo, \\n\\nExcellent analytical & organizational skills\\n\\nProactive, consultative and business-minded\\n\\nAbility to work independently\\n\\nStrong communication skills\\n\\nVery good interpersonal skills\\n\\nAbility to deliver data-driven conclusions effectively\\n\\nCritical mindset ‚Äì challenges status quo]\"\\n\\n\"[About Bill.com, \\n\\nBill.com is the leading business payments network, with 3 million members paying and getting paid over $52 billion per year.', '\"[Security is at the core of Google\\'s design and development process: it is built into the DNA of our products.', 'They will also filter and clean the data, identify and analyze trends along with working with data engineers and scientists to ensure identified trends are implemented to enable JetBlue Travel Products to become a digital disruptor., \\n\\nThe Data Analyst can change priorities and focus to meet business demands, excels when working on complex projects, is motivated to deliver results, and exhibits the JetBlue values of Safety, Caring, Integrity, Fun, and Passion., Build and prototype analysis pipelines in order to provide insights at scale.Make business recommendations with effective presentations of findings at multiple levels of stakeholders through visual displays of quantitative information.Develop comprehensive understanding of data structures and metrics, advocating for changes that will improve product adoption and customer conversion.Run live experiments that drive key product decisions.Work with data engineers to embed the research into production pipelines.Partner with product management and marketing teams to identify opportunities, envision and design technology products.Assist with creating the data infrastructure and analytics environments.Participate in the DevOps practice as it pertains to data team.Partner with JetBlue Tech Ventures to identify, monitor, learn, experiment and share information about emerging technology that is relevant to JetBlue Travel Products.Other duties as assigned., Bachelor‚Äôs Degree in Computer Science or related technical field or equivalent practical experience with demonstrated capability to perform job responsibilities through four (4) previous years of experience and education.One (1) years‚Äô experience in an Analyst role.Good understanding of software engineering environments and standards.Experience managing Service Level Agreements (SLA‚Äôs) Interacting daily with people at different levels within the organization, including developing and maintaining ongoing relationships.Pass a ten (10) year background check and pre-employment drug test.Legally eligible to work in the country in which the position is located.Proficient in Python with numpy, pandas.Proficient with Jupyter notebooks, Datalab notebooks.Proficient in linear algebra and statistics.Familiar with DataStudio, Looker, Tableau.Familiar with basic SQL for structured and unstructured data.Familiar with cloud technologies, SAAS, IAAS.Familiar with ML concepts., Maintaining a public profile and building relationships throughout the organization.Three (3) years‚Äô experience in technology roles.Experience in writing software in one or more languages such as Java, Python, Go and/or JavaScript.Experience architecting, developing software, or internet scale production-grade Big Data solutions in virtualized environments such as Amazon Web Services, Azure and Google Cloud Platform., Regular attendance and punctuality.Potential need to work flexible hours and be available to respond on short-notice.Well-groomed and able to maintain a professional appearance.When working or traveling on JetBlue flights, and if time permits, all capable crewmembers are asked to assist with light cleaning of the aircraft.Organizational fit for the JetBlue culture, that is, exhibit the JetBlue values of Safety, Caring, Integrity, Passion, and Fun., Computer and other office equipment., Generally not required, or up to 10 pounds occasionally, 0 pounds frequently.', '*\\n]\"\\n[Establish overall approach to data strategy with given clients, including the ability to see growth potential within existing accountsOversee the design and management of research projectsUse foresight to build and provide value to clientDevelop and maintain all client relationshipsEnsure that all clients have a long-term Measurement Roadmap in place, leveraging best-in-class internal and external toolsEnsure appropriate staffing levels against staff planEffectively articulate the applications of media research tools and resourcesProvide staff with all the necessary tools and training to improve upon existing expertiseEnsure client service teams have fully optimized their media plans and developed rich and well thought out campaign strategiesWrite POVs on industry topicsSupport new business pitches, Data Visualization: Tableau, Omniscope, PowerBIWeb Analytics: Omniture, Google Analytics, WebtrendsAd Servers: DoubleClick, MediaMind, PointRoll, AtlasSyndicated Measurement: comScore, Nielsen, CompeteAd Effectiveness Research: comScore, Millward Brown Digital, Dimestore, Vizu, Research NowMicrosoft Office: Excel, Word, PowerPointFamiliarity with SAS, SPSS, R, Python a plus, Bachelors or advanced degree in Statistics, Economics, Business, Math, or Sciences is preferredMinimum of eight years‚Äô experience preferredExperience managing a mid-to-large size teamStrong analytic and problem solving skillsExcellent written, oral, and presentation communication abilitiesAbility to foster collaborative relationships with other cross-functional teamsAbility to manage and prioritize competing projects and deliverables]\\n\"[\\nExperience with using Tableau to aggregate and analyze data collected from various sources\\nExperience with the Microsoft program suite\\nAbility to synthesize and communicate organizational performance clearly based on information from disparate sources through oral and written formats\\nAbility to communicate information to senior executives for decision making purposes\\nTS/SCI clearance with a polygraph\\nBA or BS degree\\n, \\nExperience with performance management and identifying and defining performance measures to support an organization\\'s mission and goals\\nKnowledge of overall IC agency processes and policies\\nAbility to execute projects and tasks with minimal guidance and supervision\\nPossession of excellent oral and written communication skills\\nPossession of excellent data gathering, analytical, and problem solving skills\\n]\"\\n\\n\"[\\n\\nPartner with e-commerce leadership and cross-functional analytics teams to increase the sophistication of our e-commerce analytics and reporting capabilities and tools\\n\\nUse Google Analytics to measure and understand consumer behavior on site, ranging from pathing and funnel analysis to product interaction; perform deep dive analyses to identify pain points within the online experience and partner with product team to share results and devise technology solutions and enhancements to improve\\n\\nEstablish executive dashboards to provide visibility into business performance and track progress on KPIs vs. goals; perform deep dives and build more sophisticated data models as needed to drive business prioritization and decision-making\\n\\nPrepare executive presentations, including e-commerce reporting, comprehensive business analyses, storylines to tie key strategic updates and action plans to financials & forecasts, and recommendations to senior management and the Board\\n\\nServe as a thought leader and partner for e-commerce merchandising and product teams\\n\\nManage and grow team of e-commerce data analysts, \\n\\nDevelop a test and learn methodology to optimize our product pricing to drive optimal product category mix, maximize sell-through and profitability, and deliver the best possible value to our customers\\n\\nPartner with Product, Engineering, and internal analytics teams to devise plan for site personalization and implement a test-and-learn approach; seek and manage external consultants and related technology partners as needed to deliver on our business goals\\n\\nEvaluate current processes & tools; identify opportunities to drive efficiencies and deliver stronger outcomes for the business and manage related cross-functional implementation plans\\n\\nImprove and help mature process optimization between e-commerce and internal client-facing teams, including Sales and Customer Success; develop synergies between departments surrounding our e-commerce offering, ensuring efficiencies in the processes related to selling and managing accounts\\n\\nServe as an e-commerce SME for clients, facilitating ongoing client business reviews, reporting, and related e-commerce analytics\\n\\nManage and build team to support business optimization and client-facing initiatives, 10+ years of experience in analytical roles with 5+ years in a business analytics, strategy and/or optimization-focused role in a technology environment preferred\\n\\nEntrepreneurial leader ‚Äì ability to develop and lead strategy while getting down in the weeds with the team to drive fast and effective execution with limited resources\\n\\nProven track record of taking ownership and driving results in an unstructured environment\\n\\nCollaborator who thrives on teamwork and has a demonstrated ability to accomplish goals by working cross-functionally; an evangelist who can get stakeholders on board with a plan and leverage cross-functional resources to get things done\\n\\nPlayer/Coach mentality and strong management skills; Experience recruiting and managing a high-performing team\\n\\nDesire to make an impact on business decisions with data; possess a balance of strong quantitative and analytical skills with a passion in business and leadership\\n\\nAppreciate the power of a data-driven environment and serve as a data evangelist to help grow and build a highly analytical culture around our e-commerce business and evolving needs\\n\\nResourceful and creative problem solver ‚Äì proven ability to tackle complex challenges with limited resources\\n\\nExpert with Excel and SQL\\n\\nBA/BS with strong academic record, preferably in Economics, Mathematics, Statistics, or other quantitative discipline preferred\\n\\nMBA from a top tier school or similar degree desired]\"\\n\"[Job Description\\n\\n, Major Job Responsibilities:\\n\\n, Works with internal business stakeholders and senior company management to define information needs, develop business cases and business intelligence reporting priorities\\n\\nDevelops and implements business intelligence solutions and plans, assesses cost and ensures the plan supports both strategic and near term needs\\n\\nProactively identifies future technology trends, challenges and impacts on the company\\'s strategic agenda\\n\\nCreates and communicates clear and compelling vision and strategy and communicates vision to staff and business stakeholders\\n\\nEvaluates and recommends new products, maintain knowledge of emerging technologies\\n\\nDevelops annual budgets, capital plans and system development plans and monitors performance against plans\\n\\nResponsible for supervising external consultants as needed\\n\\nIdentifies, builds, and maintains enterprise analytics and reporting assets, deliverables and technology solutions\\n\\nInterfaces with all business units and executive leadership to ensure access to business metrics in an easy to consume and highly visual fashion\\n\\nBuilds web based dashboards to report on key performance indicators\\n\\nBuilds web based self-service modules to allow staff to generate enterprise reports in an ad hoc fashion\\n\\nRegularly ensures that enterprise reports are accurate, rich in actionable content, and useful\\n\\nEnsures that uniform enterprise-wide design standards, style and conventions are maintained\\n\\nMaintains awareness of and participates in data quality assurance, governance, curation, meta-tagging and definition efforts\\n\\nTraining, mentoring and knowledge transfer with team members\\n\\n, Works with internal business stakeholders and senior company management to define information needs, develop business cases and business intelligence reporting priorities\\n\\n, Develops and implements business intelligence solutions and plans, assesses cost and ensures the plan supports both strategic and near term needs\\n\\n, Proactively identifies future technology trends, challenges and impacts on the company\\'s strategic agenda\\n\\n, Creates and communicates clear and compelling vision and strategy and communicates vision to staff and business stakeholders\\n\\n, Evaluates and recommends new products, maintain knowledge of emerging technologies\\n\\n, Develops annual budgets, capital plans and system development plans and monitors performance against plans\\n\\n, Responsible for supervising external consultants as needed\\n\\n, Identifies, builds, and maintains enterprise analytics and reporting assets, deliverables and technology solutions\\n\\n, Interfaces with all business units and executive leadership to ensure access to business metrics in an easy to consume and highly visual fashion\\n\\n, Builds web based dashboards to report on key performance indicators\\n\\n, Builds web based self-service modules to allow staff to generate enterprise reports in an ad hoc fashion\\n\\n, Regularly ensures that enterprise reports are accurate, rich in actionable content, and useful\\n\\n, Ensures that uniform enterprise-wide design standards, style and conventions are maintained\\n\\n, Maintains awareness of and participates in data quality assurance, governance, curation, meta-tagging and definition efforts\\n\\n, Training, mentoring and knowledge transfer with team members\\n\\n, Supervisory Responsibilities:\\n\\n, Direct management responsibilities in accordance with the ministry‚Äôs policies and applicable laws, including interviewing, hiring, training, planning, assigning and directing work, appraising performance, rewarding and disciplining staff, addressing complaints, and resolving problems\\n\\n, Member Responsibilities: The following responsibilities apply to any employee who is also a member of the religious organization:\\n\\n, Partnership Development: Build and retain a team of prayer and financial partners that will sustain them during their entire Wycliffe ministry according to the Wycliffe Partnership Development policy\\n\\nOrganizational Representative: Present the global ministry of Wycliffe and encourage interested individuals and churches to participate in this work\\n\\nMaintain an exemplary standard of ethics and conduct that reflects biblical principles\\n\\n, Partnership Development: Build and retain a team of prayer and financial partners that will sustain them during their entire Wycliffe ministry according to the Wycliffe Partnership Development policy\\n\\n, Organizational Representative: Present the global ministry of Wycliffe and encourage interested individuals and churches to participate in this work\\n\\n, Maintain an exemplary standard of ethics and conduct that reflects biblical principles\\n\\n, Minimum Skill Sets (KSAs):\\n\\n , Servant‚Äôs-heart attitude towards leadership and team relationships\\n\\nExcellent strategic vision and a global, enterprise mindset\\n\\nExceptional communication, leadership, and people management skills\\n\\nGood judgment with strong problem-solving and decision-making skills\\n\\nExceptional project management skills, including the ability to effectively utilize resources and manage multiple sub activities in a cross-functional environment\\n\\nExceptional technical acumen with current and relevant knowledge of BI practices and technologies\\n\\nGood understanding of corporate policies, practices, and organizations\\n\\nAbility to forge strong partnerships with vendors, business partners and internal customers\\n\\nAbility to meet deadlines and produce quality results under pressure\\n\\nHigh energy self-starter\\n\\nAbility to interact with all levels of management, c-suite executives\\n\\nExcellent interpersonal skills that fosters a positive and collaborative work environment\\n\\nProficient in business intelligence tools, developing and delivering scorecards, dashboards, trend data in partnership with the BI and Enterprise Architects\\n\\nStrong analytical and problem-solving skills\\n\\nFamiliarity with database design concepts including OLAP, OLTP, ESB, system integration and Big-Data\\n\\nFamiliarity with n-tier architecture, performance tuning, and application security\\n\\nSpiritual Bona Fide Occupational Qualification (BFOQ): Demonstrates desire and ability to support corporate Biblical and religious goals and participate in regular work related spiritual activities without mental reservation\\n, Servant‚Äôs-heart attitude towards leadership and team relationships\\n\\n, Excellent strategic vision and a global, enterprise mindset\\n\\n, Exceptional communication, leadership, and people management skills\\n\\n, Good judgment with strong problem-solving and decision-making skills\\n\\n, Exceptional project management skills, including the ability to effectively utilize resources and manage multiple sub activities in a cross-functional environment\\n\\n, Exceptional technical acumen with current and relevant knowledge of BI practices and technologies\\n\\n, Good understanding of corporate policies, practices, and organizations\\n\\n, Ability to forge strong partnerships with vendors, business partners and internal customers\\n\\n, Ability to meet deadlines and produce quality results under pressure\\n\\n, High energy self-starter\\n\\n, Ability to interact with all levels of management, c-suite executives\\n\\n, Excellent interpersonal skills that fosters a positive and collaborative work environment\\n\\n, Proficient in business intelligence tools, developing and delivering scorecards, dashboards, trend data in partnership with the BI and Enterprise Architects\\n\\n, Strong analytical and problem-solving skills\\n\\n, Familiarity with database design concepts including OLAP, OLTP, ESB, system integration and Big-Data\\n\\n, Familiarity with n-tier architecture, performance tuning, and application security\\n\\n, Spiritual Bona Fide Occupational Qualification (BFOQ): Demonstrates desire and ability to support corporate Biblical and religious goals and participate in regular work related spiritual activities without mental reservation\\n, Education & Experience:\\n\\n, Undergraduate degree, or equivalent experience in business analysis, new business development, business intelligence, data analytics and reporting\\n\\nThree years experience in information technology, information systems, data management, and/or business management\\n\\nBackground in designing and implementing leading Business Intelligence packages such as MSBI, MicroStrategy, Sisense, Pentaho, Tableau, etc.', 'E- Strong verbal, presentation, and written skills\\n\\nE- Strong critical thinking and creative problem solving skills\\n\\nE- Strong planning and organizational skills\\n\\nE- Familiarity with SQL, Oracle or other relational database software including manipulation of large data sets\\n\\nE- Proficiency in MS Office suite (Excel, Access, PowerPoint and Word) and/or Google Office Apps (Sheets, Docs, Slides, Gmail)\\n\\nE- Knowledge of statistical tests and procedures such as ANOVA, Chi-squared, Correlation, Regression, Student t-test, and Time Series\\n\\nP- Familiarity with Tableau , BI, Spotfire, or other data visualization software and techniques\\n\\nP- Proficiency with the SAS language and toolset (Enterprise Guide, Forecast Studio, etc.)', 'We want to maintain and increase our diversity so whoever you are and wherever you come from, if you are a great engineer we would be honored if you applied., \\n\\nWe are committed to an inclusive and diverse Twitter.', '\"[\\nExperience with applying advanced analytic techniques, including natural language processing and machine learning\\nExperience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\\nExperience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\\nSecret clearance\\nBA or BS degree\\n, \\nTS/SCI clearance preferred\\nBA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\\n]\"\\n\"[\\nExperience with applying advanced analytic techniques, including natural language processing and machine learning\\nExperience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\\nExperience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\\nSecret clearance\\nBA or BS degree\\n, \\nTS/SCI clearance preferred\\nBA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\\n]\"\\n\"[\\nExperience with applying advanced analytic techniques, including natural language processing and machine learning\\nExperience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\\nExperience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\\nAbility to obtain a security clearance\\nBA or BS degree\\n, \\nTS/SCI clearance preferred\\nBA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\\n]\"\\n\"[\\nExperience with applying advanced analytic techniques, including natural language processing and machine learning\\nExperience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\\nExperience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\\nAbility to obtain a security clearance\\nBA or BS degree\\n, \\nTS/SCI clearance preferred\\nBA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\\n]\"\\n\"[\\nExperience with applying advanced analytic techniques, including natural language processing and machine learning\\nExperience with building data products using any open source programming languages, including Python, R, TensorFlow, and ElasticSearch\\nExperience with scaling data products across distributable computing environments, including Hadoop, MapReduce, or MongoDB\\nAbility to obtain a security clearance\\nBA or BS degree\\n, \\nTS/SCI clearance preferred\\nBA or BS degree in CS, Computer Engineering, Systems Engineering, or a related field preferred; MA or MS degree a plus\\n]\"\\n[Apply a variety of analytical techniques to solve customer challenges to include data mining, statistical models, predictive analytics, optimization, risk analysis, and data visualizationPerform original research, development, test and evaluation, and demonstration of advanced analytic capabilitiesBuild and test prototypes in MITRE, government labs, and commercial cloud environmentsPerform independent reviews of contractor proposed architectures, designs and productsApply state of the art techniques, using multiple programming languages and development environments and open source code to drive advances in mission capabilities, Bachelor‚Äôs degree in data science or a related field (e.g.', 'Experience with a Business Intelligence Dashboards tool (Tableau, Google Data Studio, Superset, or similar)\\n\\nMath or Statistical Background, i.e., can you talk through Distribution functions (Binomial, non-normal, student t-test), linear and non-linear models\\n\\nExposure to A/B testing tools (Optimizely, Google Optimize, etc.)', 'Customer engagement reports & dashboards to support the Sales & Marketing team, pulling data from Google Analytics and our CMS & entitlement databases to show who is (or isn‚Äôt!)', 'You are driven and excited to face the challenges of building a robust and scalable data platform, \\n\\nRequirements:, \\n\\nStrong programming and algorithmic skills\\n\\nBackend development experience with a solid foundation in data pipelines, distributed systems, and large-scale data processing\\n\\nExtensive experience with Hadoop Hive, Spark, Presto, Pig, Parquet or similar technologies\\n\\nProficiency with Java or Scala\\n\\nProficiency with SQL (Relational, AWS Redshift, Hive, Presto etc)\\n\\nExperience with schema design and dimensional data modeling\\n\\nExperience in a custom or structured ETL, implementation and maintenance\\n\\nAbility in managing and communicating data warehouse project plans to internal clients, \\n, We are committed to an inclusive and diverse Twitter.', 'Curiosity that drives you to continually learn new things., \\n\\nBONUS, \\n\\nExperience with Google BigQuery.', 'There\\'s a good chance it reached you because of our technology., \\n\\nTaboola is the world\\'s leading content discovery platform, serving 360B recommendations to over 1B unique visitors each month on the web\\'s most innovative publisher sites, including NBC, USA Today, The Weather Channel, Tribune and Fox Sports., \\n\\nAbout You: You are a hyper-intelligent Data Scientist with a robust background in a big data environment., \\n\\nIn this Job: You will build complex Data Science solutions for large-scale product initiatives, scaling up to a Petabyte of data., \\n\\nRequirements:, \\n3+ years of experience as a Data Scientist, preferably in Big Data Environment\\n2+ years of programming experience in Java/Scala and/or Python\\nHadoop stack (HIVE, Pig, Hadoop streaming) and MapReduce\\nHBase or comparable NoSQL\\nSQL & database experience\\nExperience with Google products: Google Cloud Storage, Google Analytics and Google Big Query (a plus)\\nBachelor‚Äôs degree in quantitative or related field\\n, Responsibilities:, \\nDesign and build predictive customer behavior models for targeting and personalization\\nImplement Machine Learning and statistics-based algorithms for prediction and optimization, then deliver to production\\nBuild and maintain code to populate HDFS, Hadoop with log from Kafka or data loaded from SQL production systems\\nDesign, build and support algorithms of data transformation, conversion, computation on Hadoop, Spark and other distributed Big Data Systems\\n, #LI - AM1, \\n\\n#GD]\"\\n\"[\\n\\nHelp lead day to day project execution including developing advanced analytics solutions, creating client deliverables, and project management\\n\\nEfficiently manage data from disparate sources, distilling into datasets prepared for modeling\\n\\nCreate statistical models to support client projects, including marketing mix modeling, attribution, and purchase funnel analytics\\n\\nPrepare client facing material (example: PowerPoint slides and charts), distilling analytical insights effectively into stories for EI clients\\n\\nEffectively visualize data and analytical insights via Tableau and other mediums\\n\\nProactively lead development of standardized code and processes that can be easily used by the larger team\\n\\nSupport senior staff on thought leadership and development of new advanced analytics offerings for EI clients\\n\\nSupport senior staff in business development, including the scoping of projects and development of client proposals\\n\\nMentor other team members and provide training on analytical offerings throughout the organization, \\n\\n2+ years of professional experience in advanced analytics or related\\n\\nBachelor‚Äôs degree in Analytics, Economics, Mathematics, Statistics or related field\\n\\nAcademic background in econometrics or applied statistics and related technologies, including statistical concepts, (example: Time-Series Regression, Logistic Regression, Factor Analysis)\\n\\nExperience consulting business stakeholders to develop statistical solutions for business questions\\n\\nExperience managing workstreams against project deadlines\\n\\nComfortable with prepping and visualizing data in Microsoft Office (Excel and PowerPoint)\\n\\nExperience in statistical programming in R, SAS, or Python ‚Äì experience in more than one language is a preferred\\n\\nExperience with Tableau or other data visualization tools\\n\\nExcellent organizational and communication skills, coupled with the ability to adapt to new conditions, assignments and deadlines\\n\\nKnowledge of marketing, market research, and economics]\"\\n\"[\\n\\nLeverage data to perform intensive analysis across all areas of our business to drive growth strategies, including product development and rider engagement strategies\\n\\nGenerate ideas for exploratory analysis to shape future projects and provide recommendations for actions\\n\\nPerform time-series analyses, hypothesis testing, and causal analyses to statistically assess relative impact and extract trends\\n\\nBuild models to enhance understanding of user behavior and predict future performance of cohorts\\n\\nDesign experiments and interpret the results to draw detailed and actionable conclusions\\n\\nCreate dashboards and reports to regularly communicate results and monitor key metrics\\n\\nPresent findings to senior management to inform business decisions\\n\\nCollaborate with cross-functional teams across disciplines such as product, engineering, operations, and marketing\\n, \\n\\nMinimum 4 years of experience in a quantitative analysis role with emphasis on statistics\\n\\nBA/BS/MS in Math, Economics, Statistics, Engineering, Computer Science, or other quantitative field (advanced degrees are a plus)\\n\\nExcellent SQL skills and the ability to use tools such as Python, R, or Excel to work efficiently at scale with large data sets\\n\\nAdvanced knowledge of experimentation and statistical methods\\n\\nAbility to deliver on tight timelines and move quickly while maintaining attention to detail\\n\\nWork closely with cross-functional teams to execute on decisions\\n\\nSelf-driven with the ability to work in a self-guided manner\\n\\nSuperb communication and organization skills]\"\\n\"[\\n\\nIdentify, analyze and pinpoint trends and patterns in our data sets that we can leverage to further our growth\\n\\nCommunicate and present your findings to executives and key stakeholders\\n\\nWork closely with management to prioritize business and strategic objectives using a data-driven approach\\n\\nInteract with executives and managers to identify information needs based around the products and services we offer to track how they are being used by our clients\\n\\nDesign and improve our data collection and database designs to optimize efficiency and improve the data quality\\n\\nAcquire data from internal and external data sources that can be used to enhance our data sets and improve analysis, Masters in Computer Science, Mathematics, Statistics\\n\\n5+ years\\' experience in a data science or data analysis role\\n\\nWorking knowledge of mining and analyzing data sets to extract meaningful trends, producing meaningful and actionable reports\\n\\nExperience using statistical programming languages or toolkits for analyzing large, complex datasets\\n\\nTechnical proficiency with optimizing data collection, database design, data mining and modeling/analysis\\n\\nStrong analytical skills, attention to detail and accuracy\\n\\nExpert problem solving skills and creative thinking ability\\n\\nAbility to distill and present key findings to managers and other stakeholders (both technical and non-technical individuals)\\n\\nProject management skills with experience planning and coordinating full project lifecycle for data and research focused projects]\"\\n\"[\\n\\nApply data science and machine learning to threat intelligence, network situational awareness, intrusion detection and prevention, incident response, and malware analysis.', '\"[Who We Are:, \\n\\nAs data engineers, on the Revenue Data Platform, our mission is to build real-time and offline solutions to make data accessible and reliable while leveraging the largest-scale data processing technologies in the world at the Petabytes scale - and then apply them to the Revenue‚Äôs most critical and fundamental data problems., \\n\\nWhat You‚Äôll Do:, \\n\\nAs a member of the DataEng team, you will build and own mission-critical data pipelines that are ‚Äòsource of truth‚Äô for Twitter‚Äôs fundamental revenue data., \\n\\nYou will be a part of an early stage team and have a significant stake in defining its future with a considerable potential to impact all of Twitter‚Äôs revenue and hundreds of millions of users., \\n\\nYou will be among the earliest adopters of bleeding-edge data technologies, working directly with the Pipelines Infrastructure team to integrate your services at scale., \\n\\nYour efforts will reveal invaluable business and user insights, leveraging vast amounts of Twitter revenue data to fuel numerous Revenue teams including Ads Analytics, Ads Experience, Data Science, Marketplace, Targeting, Prediction, and many others., \\n\\nWho You Are:, \\n\\nYou have a deep expertise in distributed systems, database internals, and performance analysis; you are also experienced with Hadoop, Spark, Hive, Scalding, Parquet, or other similar technologies.', ', Responsibilities:, \\n\\nEnsure marketing campaign funnels and customer behavior flows are tagged and tracked accurately for reporting and analysis purposes\\n\\nSet up standard processes, data infrastructure, operational best practices across global marketing organization\\n\\nAnalyze data, identify trends, implement optimizations on a day to day basis across digital and offline marketing channels, building dashboards and delivering timely reports to support analyses\\n\\nDevelop recommendations for changes to investment and marketing strategy, optimize the efficacy of marketing spend based on quantitative analyses\\n\\nSupport product marketing, sales enablement, growth acquisition, and marketing automation seements on data needs and insights\\n\\nImplement technology in order to analyze sales funnel, lifetime value based on customer segmentation, \\n\\nEnsure marketing campaign funnels and customer behavior flows are tagged and tracked accurately for reporting and analysis purposes, \\n\\nSet up standard processes, data infrastructure, operational best practices across global marketing organization, \\n\\nAnalyze data, identify trends, implement optimizations on a day to day basis across digital and offline marketing channels, building dashboards and delivering timely reports to support analyses, \\n\\nDevelop recommendations for changes to investment and marketing strategy, optimize the efficacy of marketing spend based on quantitative analyses, \\n\\nSupport product marketing, sales enablement, growth acquisition, and marketing automation seements on data needs and insights, \\n\\nImplement technology in order to analyze sales funnel, lifetime value based on customer segmentation, \\n\\nQualifications:, \\n\\nStrong quantitative, analytical, and problem solving skills\\n\\n4+ years experience within business/marketing/data analytics\\n\\nExperience working in the Salesforce environment, understanding business products, journey flow and terminology\\n\\nExpertise in a query language such as SQL or equivalent\\n\\nExperience working with various digital advertising platforms, including but not limited to AdWords, Facebook, Google Analytics\\n\\nExperience in reporting on customer insights and LTV analysis\\n\\nWorking knowledge in Google Tag Manager\\n\\nWorking knowledge of ad trafficking/ad serving platforms including but not limited to Doubleclick etc.', 'Experience with statistical software or scientific computation software (e.g.,R, Matlab) is preferred\\n\\nHadoop or other comparable MapReduce experience is preferred\\n\\nExperience with hands-on coding from scratch is preferred\\n\\nExposure to Internet measurement data is a plus\\n\\nOnline advertising industry experience is a plus, LI-BM1\\n, MSJA]\"\\n\"[Spun out of Dell‚Äôs Digital Innovation Lab in 2013, Predictive Science has benefited from $40M in total R&D investment to become one of the fastest growing tech startups in the United States.', \"You are very experienced programming in Python, Java or R.\\nYou're familiar with tools like spaCy, scikit-learn, NLTK, Mallet, TensorFlow, PyTorch and all the others that didn't come up in our Google search.\", 'Experience with Google Analytics, Snowplow, and Salesforce a plus\\nWorked with data warehouses and DMPs\\nKnowledge and experience with SQL\\nShown an ability to translate raw data into compelling, insightful analysis\\n, \\nAnalogFolk started in 2008 and has expanded offices across the world (London, Sydney, New York, Portland, Hong Kong and Shanghai)\\nWe make interactive experiences that create value for people and brands.', 'Self-motivated, work well both independently and as part of an agile team., Preferred experience with console development for current platforms\\n\\nHave a clear understanding of Big Data tools mainly being Splunk, Hadoop, and Spark\\n\\nExperience with Visualization tools and platforms.]\"', 'Exposure to big data platforms, such as Big Query, Hadoop, AWS is a plus\\n\\nExposure to Google Machine Learning is a plus\\n\\nExperience with customer analytics concepts, such as CLV modeling, churn modeling, real-time customer evaluation, recommendation engine is a plus.', 'We build and maintain all aspects of what keeps our Googley workspaces operating seamlessly across multiple cities and regions globally.', 'Being a motivated self-starter, an evangelist for a data-driven culture, and desiring a deep understanding of customer needs., \\n\\nAbility and willingness to learn structured and unstructured data systems, \\n\\nExperience in developing business requirements for instrumentation with Google Analytics; ability to instrument in Google Tag Manager a plus, \\n\\nProficiency in effective report/dashboard design and standards, \\n\\nFamiliarity with data preparation, processing, classification, and forecasting, \\n\\nFamiliarity with the software product lifecycle, \\n\\nAbility to write SQL and create data visualizations, \\n\\nExperience with Amazon S3, Redshift, Athena, Google Tag Manager, Google Analytics, Google Big Query, Tableau, or JavaScript, are big pluses!, \\n\\nA Bachelor‚Äôs degree or advanced degree in a technical, business, or math-based field, \\n\\nExperience interacting with individuals at all levels, good time management, and solid communication skills., \\n\\nProven leadership ability to influence and inspire people indirectly, lead by example, and engage and effectively build multidisciplinary alliances, \\n\\nAbility to do some travel for planning and team meetings (20%) and frequently use web-based remote video and project collaboration tools, #LI-2KM, Pearson is an Equal Opportunity and Affirmative Action Employer and a member of E-Verify.', 'Additional responsibilities as needed by manager or supervisor., \\n\\n3 years of experience in an agency or in-house analytics role, ideally in marketing\\n\\nMasters Degree in relevant field\\n\\nStrong understanding of marketing and customer segmentation tactics\\n\\nExperience in one or more marketing channels (email, direct mail, FB), with understanding of how to measure & optimize\\n\\nIntermediate to advanced-level experience in Google Analytics or similar web analytics platform\\n\\nIntermediate to advanced-level experience in coding in Python and Javascript in order to assist in creating new data products that result out of work in predictive models, surveys, & A/B tests\\n\\nIntermediate to advanced-level experience in Excel and 3rd party measurement platform\\n\\nIntermediate to advanced-level experience in SQL and Tableau/other BI tools\\n\\nExperience setting up and distilling insights from experimental lift testing (Creative, A/B, segment)\\n\\nFamiliarity with correlation analysis, t-testing, and regression-based forecasting preferred]\"\\n\"[ESAC, Inc., a global provider of data management, informatics research and healthcare IT solutions to government, academic and research institutions is looking for a Software Engineer/ Senior Software Engineer who can contribute to our high-profile projects in the healthcare and bioinformatics domain.', 'Experience with Agile methodologies (Scrum)\\n\\nExperience working with large data processing platforms like Apache Beam, Apache Spark, or Apache Hadoop MapReduce (Google Cloud Dataflow a plus).', 'Intellectual curiosity and ability to handle high levels of ambiguity\\n\\nAbility to communicate complex statistical concepts and output to non-experts in both a written and verbal manner\\n\\nTechnical experience in SPSs, Big Query, Google Analytics, Excel and/or Tableau a plus\\n\\nBusiness insight\\n\\nAbility to work under pressure and within tight deadlines]\"\\n\"[A career in National Special Functions, within Internal Firm Services, will provide you with the opportunity to support service, sector, and market leaders deliver the unique PwC client experience to our clients.', 'We offer a highly competitive base salary and a comprehensive benefits program, including medical, prescription drug, dental, vision, 401(k) with company match, life insurance, paid time off, tuition assistance and an employee stock purchase plan., \\n\\nExpress Scripts is an equal opportunity employer/disability/veteran]\"\\n\"[What do we need?, \\n\\nYou to have an amazing personality and communication style.', 'Your contribution will be critical to helping Pairwise meet a set of aggressive targets and building a culture where science and engineering can be fun., Minimum of Bachelors degree in Computer Science, Engineering or related fields\\n\\nMinimum of 5+ years of experience (Masters or Doctoral thesis work counts as work experience)\\n\\nStrong track record of building and deploying modern engineering tools in the cloud (AWS, Azure, Google Cloud)\\n\\nProficiency with MySql, Postgres or noSQL technologies\\n\\nAdvanced Knowledge with Python or R and one object-oriented programming language\\n\\nDemonstrated ability to deliver tools in a cross functional environment\\n\\nExperience with building and maintaining APIs\\n\\nProficiency with data modeling and data architecture]\"\\n\"[\\nYou\\'ll work closely with our technology operations and engineering teams to understand business needs and design/maintain scalable data models.', 'You have 3 years‚Äô experience and working knowledge of Lambda and Kappa architecture in a cloud environment (AWS, Google, Azure)\\n\\nYou have a deep understanding of SDLC, Agile methodologies, metadata, data modeling, and designing databases\\n\\nWorking knowledge on Linux/Unix Operating systems\\n\\nStrong scripting skills - Python (a huge plus), Bash , Shell etc.']\n"
     ]
    }
   ],
   "source": [
    "def generate_corpus(sentence, words):\n",
    "    unique_description = []\n",
    "    res = []\n",
    "    for entry in words:\n",
    "       # entry = entry.strip()\n",
    "        for substring in sentence:\n",
    "           # print(substring)\n",
    "            if entry in substring:\n",
    "           # if (len(k) == len(words) ):\n",
    "                print ('entry --- ' + entry)\n",
    "                print ('substring --- ' + substring)\n",
    "\n",
    "                res.append(substring)\n",
    "            \n",
    "    unique_description = set(res)\n",
    "    unique_description = list(unique_description)\n",
    "    return unique_description\n",
    "      \n",
    "# Driver code\n",
    "sentence = ['python coder SQL in PayPal design', 'geeksforgeeks', 'SQL']\n",
    "words = ['PayPal','role']\n",
    "jd_rol_res_corpus = generate_corpus(jd_sentences,company_keyword_seed)\n",
    "print(jd_rol_res_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open('./company_corpus_V1.txt','w')\n",
    "\n",
    "word_list= []\n",
    "\n",
    "for i in jd_rol_res_corpus:\n",
    "    line = i \n",
    "    word_list.append(line) \n",
    "text_file.writelines(word_list)\n",
    " \n",
    "text_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
