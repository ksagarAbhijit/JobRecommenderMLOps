# -*- coding: utf-8 -*-
"""Task9_EvaluatingModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y__5fS1Ge0VDC6tjX2XUMKGIHK9ME4B3
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import gpt_2_simple as gpt2
from datetime import datetime
from google.colab import files
import pandas as pd
import tensorflow as tf
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import CountVectorizer
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize, word_tokenize
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))
import re

from nltk.util import ngrams 

from textblob import TextBlob

NGRAM = 2

re_stripper_alpha = re.compile('[^a-zA-Z]+')

sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')
from itertools import chain
from collections import Counter
import re
import math


def getModelOutput(Input_Job_title,Input_Skills,Input_Company_name,Input_Location):
  text_skills = run_Model('run1',Input_Job_title+ ' '+Input_Skills)
  
  text_role = run_Model('run2',Input_Job_title+ ' '+Input_Skills)
  
  text_aboutCompany = run_Model('run3',Input_Company_name +' '+Input_Location)
  
  output = 'SKILLS'+'\n'+text_skills + '\n\n'+ 'ROLES'+'\n'+text_role+ '\n\n'+ 'ABOUT COMPANY'+'\n'+text_aboutCompany
  return output

def run_Model(run_name, input):
  tf.reset_default_graph()

  sess = gpt2.start_tf_sess()
  gpt2.load_gpt2(sess, run_name=run_name)
  
  output = gpt2.generate(sess,
                         run_name=run_name,
                  prefix=input,
                  length=100,
                  temperature=0.7,
                  nsamples=1,
                  return_as_list=True
                  )
  output = output[0].replace(input,'')
  output = output.replace('\', \'','')
  output = output.replace('[\'','')
  output = output.replace('[','')
  output = output.replace(']','')
  output = output.replace('.,','.')
  output = output.replace('"','.')
  output = output.replace('"','.')
  output = re.sub('\s+',' ',output)
  output = re.sub('^,','',output)
  print( run_name, ' :: Output generated ')
  return output

cleaned_indeed_data = pd.read_excel('/content/drive/My Drive/JobDescriptionPrediction/Resources/Data/interim/cleaned_indeed_job_dataset.xlsx')

cleaned_indeed_data.columns

# INPUTS ::
def getInputs(index):
  inputs = []
  inputs.append(cleaned_indeed_data['Job_Title'][index])
  inputs.append(cleaned_indeed_data['Skill'][index])
  inputs.append(cleaned_indeed_data['Company'][index])
  inputs.append(cleaned_indeed_data['Location'][index])
  inputs.append(cleaned_indeed_data['Description'][index])
  return inputs

def tokenizestring(input):
  output = word_tokenize(str(input))
  output = [word for word in output if not word in stopwords.words()]
  return output

def generateResults(index):  
  inputs = getInputs(index)
  expectedoutput= inputs[4]
  modeloutput = getModelOutput(str(inputs[0]),str(inputs[1]),str(inputs[2]),str(inputs[3]))
  calculateCosineSimilarity(expectedoutput,modeloutput)


def calculateCosineSimilarity(expectedoutput,modeloutput): 

  
  expectedoutput_tokens = tokenizestring(expectedoutput)
  modeloutput_tokens = tokenizestring(modeloutput)


  expectedoutput_keywords = ' '.join(expectedoutput_tokens)
  modeloutput_keywords = ' '.join(modeloutput_tokens)

  
  cos_sim = generateCosineSimilary(modeloutput_keywords,expectedoutput_keywords)

  # print('---------------------------------------------------------------')
  # print('expectedOutput ::' , expectedoutput )
  # print('modeloutput ::' , modeloutput )
  # print('\n\n\n Cosine similarity :: ',cos_sim)
  return cos_sim
def generateCosineSimilary(input1,input2):

  input = [input1,input2]

  input1_vectorizer = CountVectorizer(input)
  input1_vectorizer.fit(input)
  vectors = input1_vectorizer.transform(input).toarray()
  
  cos_lib = cosine_similarity(vectors)
  return cos_lib[0][1]

def get_tuples_nosentences(txt : str, NGRAM ):
    """Get tuples that ignores all punctuation (including sentences)."""
    if not txt: return None
    ng = ngrams(re_stripper_alpha.sub(' ', txt).split(), NGRAM)
    return list(ng)
def cosine_similarity_ngrams(a, b):
    vec1 = Counter(a)
    vec2 = Counter(b)
    
    intersection = set(vec1.keys()) & set(vec2.keys())
    numerator = sum([vec1[x] * vec2[x] for x in intersection])

    sum1 = sum([vec1[x]**2 for x in vec1.keys()])
    sum2 = sum([vec2[x]**2 for x in vec2.keys()])
    denominator = math.sqrt(sum1) * math.sqrt(sum2)

    if not denominator:
        return 0.0
    return float(numerator) / denominator

def getSimilarityMatrix(index):
  res_df = pd.DataFrame()
  df = []
  # res_df = pd.DataFrame(columns = ['Job_Title', 'Skills','Company','Location','Expected Output', 'Model Output','Word_similarity', '2Gram Similarity','4Gram Similarity','6Gram Similarity','8Gram Similarity','10Gram Similarity'])
  inputs = getInputs(index)
  expectedoutput= inputs[4]
  modeloutput = getModelOutput(str(inputs[0]),str(inputs[1]),str(inputs[2]),str(inputs[3]))
  word_similarity  = calculateCosineSimilarity(expectedoutput,modeloutput)
  
  res_df['Job_Title'] = inputs[0]
  res_df['Skills'] = inputs[1]
  res_df['Company']= inputs[2]
  res_df['Location'] = inputs[3]
  res_df['Expected Output'] = inputs[4]
  res_df['Model Output'] = modeloutput
  res_df['Word_similarity']= word_similarity
  df.append(inputs[0])
  df.append(inputs[1])
  df.append(inputs[2])
  df.append(inputs[3])
  df.append(inputs[4])
  df.append(modeloutput)
  df.append(word_similarity)
  print('Word simi completed')
  print(df)
  ngram_sim = []
  loop = [1,2,4,6,8,10]
  for  i in loop:
    expOutputNGram  = get_tuples_nosentences(expectedoutput,i)
    modelOutputNGram  = get_tuples_nosentences(modeloutput,i)
    sim = cosine_similarity_ngrams(expOutputNGram,modelOutputNGram)
    ngram_sim.append(sim)
    df.append(sim)
  res_df['2Gram Similarity'] = ngram_sim[0]
  res_df['4Gram Similarity'] = ngram_sim[1]
  res_df['6Gram Similarity'] = ngram_sim[2]
  res_df['8Gram Similarity'] = ngram_sim[3]
  res_df['10Gram Similarity'] = ngram_sim[4]
  print('n gram completed')


  return df

