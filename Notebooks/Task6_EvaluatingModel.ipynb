{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task6_EvaluatingModel.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYWQoHeu2ku_","executionInfo":{"status":"ok","timestamp":1618123189840,"user_tz":-330,"elapsed":7868,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"013c5407-ae05-40ea-b19d-2a26a7625e3c"},"source":["%tensorflow_version 1.x\n","!pip install -q gpt-2-simple\n","import gpt_2_simple as gpt2\n","from datetime import datetime\n","from google.colab import files\n","import pandas as pd\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.feature_extraction.text import CountVectorizer\n","import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","STOPWORDS = set(stopwords.words('english'))\n","import re\n","\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","gpt2.mount_gdrive()\n","\n","from nltk.util import ngrams \n","\n","from textblob import TextBlob\n","\n","NGRAM = 2\n","\n","re_stripper_alpha = re.compile('[^a-zA-Z]+')\n","\n","sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n","from itertools import chain\n","from collections import Counter\n","import re\n","import math\n","\n","!pip install pipreqs\n","!pipreqs ./"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: pipreqs in /usr/local/lib/python3.7/dist-packages (0.4.10)\n","Requirement already satisfied: yarg in /usr/local/lib/python3.7/dist-packages (from pipreqs) (0.1.9)\n","Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from pipreqs) (0.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yarg->pipreqs) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (1.24.3)\n","ERROR: Failed on file: ./drive/MyDrive/TestFastAPI_v2.py\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pipreqs\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.7/dist-packages/pipreqs/pipreqs.py\", line 470, in main\n","    init(args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pipreqs/pipreqs.py\", line 409, in init\n","    follow_links=follow_links)\n","  File \"/usr/local/lib/python3.7/dist-packages/pipreqs/pipreqs.py\", line 138, in get_all_imports\n","    raise exc\n","  File \"/usr/local/lib/python3.7/dist-packages/pipreqs/pipreqs.py\", line 124, in get_all_imports\n","    tree = ast.parse(contents)\n","  File \"/usr/lib/python3.7/ast.py\", line 35, in parse\n","    return compile(source, filename, mode, PyCF_ONLY_AST)\n","  File \"<unknown>\", line 1\n","    !pip install uvicorn fastapi\n","    ^\n","SyntaxError: invalid syntax\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sOK67YBHKZXJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618123217844,"user_tz":-330,"elapsed":35863,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"fcc6fb9e-b77a-4134-82ca-aa2b2faf8f5f"},"source":["! cp drive/My\\ Drive/JobDescriptionPrediction/Resources/Model/* .\n","!tar -xvf  'checkpoint_run1.tar' -C .\n","!tar -xvf  'checkpoint_run2.tar' -C .\n","!tar -xvf  'checkpoint_run3.tar' -C .\n","# gpt2.copy_checkpoint_from_gdrive(run_name=\"/JobDescriptionPrediction/Resources/Model/run1\")\n","# gpt2.copy_checkpoint_from_gdrive(run_name=\"/JobDescriptionPrediction/Resources/Model/run2\")\n","# gpt2.copy_checkpoint_from_gdrive(run_name=\"/JobDescriptionPrediction/Resources/Model/run3\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["cp: -r not specified; omitting directory 'drive/My Drive/JobDescriptionPrediction/Resources/Model/T5-Aboutcompany'\n","cp: -r not specified; omitting directory 'drive/My Drive/JobDescriptionPrediction/Resources/Model/T5-Role'\n","cp: -r not specified; omitting directory 'drive/My Drive/JobDescriptionPrediction/Resources/Model/T5-Skill'\n","checkpoint/run1/\n","checkpoint/run1/checkpoint\n","checkpoint/run1/counter\n","checkpoint/run1/encoder.json\n","checkpoint/run1/events.out.tfevents.1617255936.c51996cb59be\n","checkpoint/run1/hparams.json\n","checkpoint/run1/model-3337.data-00000-of-00001\n","checkpoint/run1/model-3337.index\n","checkpoint/run1/model-3337.meta\n","checkpoint/run1/vocab.bpe\n","checkpoint/run2/\n","checkpoint/run2/checkpoint\n","checkpoint/run2/counter\n","checkpoint/run2/encoder.json\n","checkpoint/run2/events.out.tfevents.1617285150.0c4597a381ce\n","checkpoint/run2/hparams.json\n","checkpoint/run2/model-1000.data-00000-of-00001\n","checkpoint/run2/model-1000.index\n","checkpoint/run2/model-1000.meta\n","checkpoint/run2/vocab.bpe\n","checkpoint/run3/\n","checkpoint/run3/checkpoint\n","checkpoint/run3/counter\n","checkpoint/run3/encoder.json\n","checkpoint/run3/events.out.tfevents.1617284719.bbfb068a22bb\n","checkpoint/run3/hparams.json\n","checkpoint/run3/model-1000.data-00000-of-00001\n","checkpoint/run3/model-1000.index\n","checkpoint/run3/model-1000.meta\n","checkpoint/run3/vocab.bpe\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mL44FGFq3I2v","executionInfo":{"status":"ok","timestamp":1618123217845,"user_tz":-330,"elapsed":35855,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["def getModelOutput(Input_Job_title,Input_Skills,Input_Company_name,Input_Location):\n","  text_skills = run_Model('run1',Input_Job_title+ ' '+Input_Skills)\n","  \n","  text_role = run_Model('run2',Input_Job_title+ ' '+Input_Skills)\n","  \n","  text_aboutCompany = run_Model('run3',Input_Company_name +' '+Input_Location)\n","  \n","  output = 'SKILLS'+'\\n'+text_skills + '\\n\\n'+ 'ROLES'+'\\n'+text_role+ '\\n\\n'+ 'ABOUT COMPANY'+'\\n'+text_aboutCompany\n","  return output"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"J5ErRkdV-U6i","executionInfo":{"status":"ok","timestamp":1618123217846,"user_tz":-330,"elapsed":35852,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["def run_Model(run_name, input):\n","  tf.reset_default_graph()\n","\n","  sess = gpt2.start_tf_sess()\n","  gpt2.load_gpt2(sess, run_name=run_name)\n","  \n","  output = gpt2.generate(sess,\n","                         run_name=run_name,\n","                  prefix=input,\n","                  length=100,\n","                  temperature=0.7,\n","                  nsamples=1,\n","                  return_as_list=True\n","                  )\n","  output = output[0].replace(input,'')\n","  output = output.replace('\\', \\'','')\n","  output = output.replace('[\\'','')\n","  output = output.replace('[','')\n","  output = output.replace(']','')\n","  output = output.replace('.,','.')\n","  output = output.replace('\"','.')\n","  output = output.replace('\"','.')\n","  output = re.sub('\\s+',' ',output)\n","  output = re.sub('^,','',output)\n","  print( run_name, ' :: Output generated ')\n","  return output"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3JVxTTYB6ZC","executionInfo":{"status":"ok","timestamp":1618123224566,"user_tz":-330,"elapsed":42568,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["cleaned_indeed_data = pd.read_excel('/content/drive/My Drive/JobDescriptionPrediction/Resources/Data/interim/cleaned_indeed_job_dataset.xlsx')"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcztA4agBZEb","executionInfo":{"status":"ok","timestamp":1618123224566,"user_tz":-330,"elapsed":42565,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"031c2d08-db76-411c-96fd-65dfe5cba2b0"},"source":["cleaned_indeed_data.columns"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['JobID', 'Job_Title', 'Link', 'Queried_Salary', 'Job_Type', 'Skill',\n","       'No_of_Skills', 'Company', 'No_of_Reviews', 'No_of_Stars',\n","       'Date_Since_Posted', 'Description', 'Location', 'Company_Revenue',\n","       'Company_Employees', 'Company_Industry', 'python', 'sql',\n","       'machine learning', 'r', 'hadoop', 'tableau', 'sas', 'spark', 'java',\n","       'Others', 'CA', 'NY', 'VA', 'TX', 'MA', 'IL', 'WA', 'MD', 'DC', 'NC',\n","       'Other_states', 'Consulting and Business Services',\n","       'Internet and Software', 'Banks and Financial Services', 'Health Care',\n","       'Insurance', 'Other_industries'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"PCzdRMFA_NWC","executionInfo":{"status":"ok","timestamp":1618123224567,"user_tz":-330,"elapsed":42562,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["# INPUTS ::\n","def getInputs(index):\n","  inputs = []\n","  inputs.append(cleaned_indeed_data['Job_Title'][index])\n","  inputs.append(cleaned_indeed_data['Skill'][index])\n","  inputs.append(cleaned_indeed_data['Company'][index])\n","  inputs.append(cleaned_indeed_data['Location'][index])\n","  inputs.append(cleaned_indeed_data['Description'][index])\n","  return inputs"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezE0gJD_FNg8","executionInfo":{"status":"ok","timestamp":1618123224567,"user_tz":-330,"elapsed":42559,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["def tokenizestring(input):\n","  output = word_tokenize(input)\n","  output = [word for word in output if not word in stopwords.words()]\n","  return output"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"zYqwfLoJDYTa","executionInfo":{"status":"ok","timestamp":1618123224568,"user_tz":-330,"elapsed":42556,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["def generateResults(index):  \n","  inputs = getInputs(index)\n","  expectedoutput= inputs[4]\n","  modeloutput = getModelOutput(str(inputs[0]),str(inputs[1]),str(inputs[2]),str(inputs[3]))\n","  calculateCosineSimilarity(expectedoutput,modeloutput)\n","\n","\n","def calculateCosineSimilarity(expectedoutput,modeloutput): \n","\n","  \n","  expectedoutput_tokens = tokenizestring(expectedoutput)\n","  modeloutput_tokens = tokenizestring(modeloutput)\n","\n","\n","  expectedoutput_keywords = ' '.join(expectedoutput_tokens)\n","  modeloutput_keywords = ' '.join(modeloutput_tokens)\n","\n","  \n","  cos_sim = generateCosineSimilary(modeloutput_keywords,expectedoutput_keywords)\n","\n","  # print('---------------------------------------------------------------')\n","  # print('expectedOutput ::' , expectedoutput )\n","  # print('modeloutput ::' , modeloutput )\n","  # print('\\n\\n\\n Cosine similarity :: ',cos_sim)\n","  return cos_sim\n","def generateCosineSimilary(input1,input2):\n","\n","  input = [input1,input2]\n","\n","  input1_vectorizer = CountVectorizer(input)\n","  input1_vectorizer.fit(input)\n","  vectors = input1_vectorizer.transform(input).toarray()\n","  \n","  cos_lib = cosine_similarity(vectors)\n","  print('Word similarity :: ',cos_sim)\n","  return cos_lib[0][1]\n"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"tEqbS96rjlVg","executionInfo":{"status":"ok","timestamp":1618123224568,"user_tz":-330,"elapsed":42551,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["def get_tuples_nosentences(txt, NGRAM ):\n","    \"\"\"Get tuples that ignores all punctuation (including sentences).\"\"\"\n","    if not txt: return None\n","    ng = ngrams(re_stripper_alpha.sub(' ', txt).split(), NGRAM)\n","    return list(ng)\n","def cosine_similarity_ngrams(a, b):\n","    vec1 = Counter(a)\n","    vec2 = Counter(b)\n","    \n","    intersection = set(vec1.keys()) & set(vec2.keys())\n","    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n","\n","    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n","    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n","    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n","\n","    if not denominator:\n","        return 0.0\n","    return float(numerator) / denominator"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NVr_rAVlLbf","executionInfo":{"status":"ok","timestamp":1618123224568,"user_tz":-330,"elapsed":42547,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["def getSimilarityMatrix(index):\n","  res_df = pd.DataFrame()\n","  df = []\n","  # res_df = pd.DataFrame(columns = ['Job_Title', 'Skills','Company','Location','Expected Output', 'Model Output','Word_similarity', '2Gram Similarity','4Gram Similarity','6Gram Similarity','8Gram Similarity','10Gram Similarity'])\n","  inputs = getInputs(index)\n","  expectedoutput= inputs[4]\n","  modeloutput = getModelOutput(str(inputs[0]),str(inputs[1]),str(inputs[2]),str(inputs[3]))\n","  word_similarity  = calculateCosineSimilarity(expectedoutput,modeloutput)\n","  \n","  res_df['Job_Title'] = inputs[0]\n","  res_df['Skills'] = inputs[1]\n","  res_df['Company']= inputs[2]\n","  res_df['Location'] = inputs[3]\n","  res_df['Expected Output'] = inputs[4]\n","  res_df['Model Output'] = modeloutput\n","  res_df['Word_similarity']= word_similarity\n","  df.append(inputs[0])\n","  df.append(inputs[1])\n","  df.append(inputs[2])\n","  df.append(inputs[3])\n","  df.append(inputs[4])\n","  df.append(modeloutput)\n","  df.append(word_similarity)\n","  print('Word simi completed')\n","  print(df)\n","  ngram_sim = []\n","  loop = [1,2,4,6,8,10]\n","  for  i in loop:\n","    expOutputNGram  = get_tuples_nosentences(expectedoutput,2)\n","    modelOutputNGram  = get_tuples_nosentences(modeloutput,2)\n","    sim = cosine_similarity_ngrams(expOutputNGram,modelOutputNGram)\n","    ngram_sim.append(sim)\n","    df.append(sim)\n","  res_df['2Gram Similarity'] = ngram_sim[0]\n","  res_df['4Gram Similarity'] = ngram_sim[1]\n","  res_df['6Gram Similarity'] = ngram_sim[2]\n","  res_df['8Gram Similarity'] = ngram_sim[3]\n","  res_df['10Gram Similarity'] = ngram_sim[4]\n","  print('n gram completed')\n","\n","\n","  return df\n","  \n"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":454},"id":"8odqa8gbtcKD","executionInfo":{"status":"error","timestamp":1618123282910,"user_tz":-330,"elapsed":100886,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"231a50f2-1c12-4dfa-91bb-54823de8c2e9"},"source":["df = getSimilarityMatrix(0)\n","print(df)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Loading checkpoint checkpoint/run1/model-3337\n","INFO:tensorflow:Restoring parameters from checkpoint/run1/model-3337\n","run1  :: Output generated \n","Loading checkpoint checkpoint/run2/model-1000\n","INFO:tensorflow:Restoring parameters from checkpoint/run2/model-1000\n","run2  :: Output generated \n","Loading checkpoint checkpoint/run3/model-1000\n","INFO:tensorflow:Restoring parameters from checkpoint/run3/model-1000\n","run3  :: Output generated \n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-801acb595958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetSimilarityMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-26-054b0c5309e9>\u001b[0m in \u001b[0;36mgetSimilarityMatrix\u001b[0;34m(index)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mexpectedoutput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodeloutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetModelOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mword_similarity\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mcalculateCosineSimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectedoutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodeloutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mres_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Job_Title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-d96d71f8dccc>\u001b[0m in \u001b[0;36mcalculateCosineSimilarity\u001b[0;34m(expectedoutput, modeloutput)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mcos_sim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerateCosineSimilary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodeloutput_keywords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpectedoutput_keywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# print('---------------------------------------------------------------')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-24-d96d71f8dccc>\u001b[0m in \u001b[0;36mgenerateCosineSimilary\u001b[0;34m(input1, input2)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mcos_lib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Word similarity :: '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcos_lib\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cos_sim' is not defined"]}]},{"cell_type":"code","metadata":{"id":"E0kHyyyCGZ3v","executionInfo":{"status":"aborted","timestamp":1618123282900,"user_tz":-330,"elapsed":100871,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["generateResults(0)\n","generateResults(10)\n","generateResults(20)\n","generateResults(30)\n","generateResults(40)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQzW8_itjPBC","executionInfo":{"status":"aborted","timestamp":1618123282905,"user_tz":-330,"elapsed":100872,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSXA2YKhlzZw","executionInfo":{"status":"aborted","timestamp":1618123282906,"user_tz":-330,"elapsed":100869,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["def jaccard_distance(a, b):\n","    \"\"\"Calculate the jaccard distance between sets A and B\"\"\"\n","    a = set(a)\n","    b = set(b)\n","    return 1.0 * len(a&b)/len(a|b)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FYCZadCcjQrw","executionInfo":{"status":"aborted","timestamp":1618123282907,"user_tz":-330,"elapsed":100866,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["a = get_tuples_nosentences(\"Above is a bad example of four-gram similarity.\")\n","b = get_tuples_nosentences(\"This is a better example of four-gram similarity.\")\n","print(\"Jaccard: {}   Cosine: {}\".format(jaccard_distance(a,b), cosine_similarity_ngrams(a,b)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-4pl-SonfgJ","executionInfo":{"status":"aborted","timestamp":1618123282908,"user_tz":-330,"elapsed":100864,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K44jc-BdwiNx","executionInfo":{"status":"aborted","timestamp":1618123282910,"user_tz":-330,"elapsed":100862,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":[""],"execution_count":null,"outputs":[]}]}