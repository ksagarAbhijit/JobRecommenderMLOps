{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Task1_JobDescriptionDataCleaning.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_W62z03UE0xB","executionInfo":{"status":"ok","timestamp":1618120313771,"user_tz":-330,"elapsed":7323,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"4ed9dedb-fdfd-4698-ae8f-8eb10a2a0117"},"source":["!pip install logzero\n","import logzero         \n","from logzero import logger\n","from google.colab import files\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import nltk\n","nltk.download('punkt')\n","import re\n","from bs4 import BeautifulSoup\n","import gensim \n","from gensim.models import Word2Vec  \n","from nltk.tokenize import sent_tokenize, word_tokenize\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: logzero in /usr/local/lib/python3.7/dist-packages (1.7.0)\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"D2jbgrc_E1ft","executionInfo":{"status":"ok","timestamp":1618120313774,"user_tz":-330,"elapsed":7313,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"db4cc953-4e52-42e8-fef6-a79983aeaad5"},"source":["JobData = pd.read_csv(\"/content/drive/My Drive/JobDescriptionPrediction/Resources/Data/raw/indeed_job_dataset.csv\", index_col = None)\n","JobData.head(n=2)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Job_Title</th>\n","      <th>Link</th>\n","      <th>Queried_Salary</th>\n","      <th>Job_Type</th>\n","      <th>Skill</th>\n","      <th>No_of_Skills</th>\n","      <th>Company</th>\n","      <th>No_of_Reviews</th>\n","      <th>No_of_Stars</th>\n","      <th>Date_Since_Posted</th>\n","      <th>Description</th>\n","      <th>Location</th>\n","      <th>Company_Revenue</th>\n","      <th>Company_Employees</th>\n","      <th>Company_Industry</th>\n","      <th>python</th>\n","      <th>sql</th>\n","      <th>machine learning</th>\n","      <th>r</th>\n","      <th>hadoop</th>\n","      <th>tableau</th>\n","      <th>sas</th>\n","      <th>spark</th>\n","      <th>java</th>\n","      <th>Others</th>\n","      <th>CA</th>\n","      <th>NY</th>\n","      <th>VA</th>\n","      <th>TX</th>\n","      <th>MA</th>\n","      <th>IL</th>\n","      <th>WA</th>\n","      <th>MD</th>\n","      <th>DC</th>\n","      <th>NC</th>\n","      <th>Other_states</th>\n","      <th>Consulting and Business Services</th>\n","      <th>Internet and Software</th>\n","      <th>Banks and Financial Services</th>\n","      <th>Health Care</th>\n","      <th>Insurance</th>\n","      <th>Other_industries</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Data Scientist</td>\n","      <td>https://www.indeed.com/rc/clk?jk=6a105f495c36a...</td>\n","      <td>&lt;80000</td>\n","      <td>data_scientist</td>\n","      <td>['SAP', 'SQL']</td>\n","      <td>2</td>\n","      <td>Express Scripts</td>\n","      <td>3301.0</td>\n","      <td>3.3</td>\n","      <td>1.0</td>\n","      <td>[&lt;p&gt;&lt;b&gt;POSITION SUMMARY&lt;/b&gt;&lt;/p&gt;, &lt;p&gt;\\r\\r\\nThe ...</td>\n","      <td>MO</td>\n","      <td>More than $10B (USD)</td>\n","      <td>10,000+</td>\n","      <td>Health Care</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Data Scientist</td>\n","      <td>https://www.indeed.com/rc/clk?jk=86afd561ea8c6...</td>\n","      <td>&lt;80000</td>\n","      <td>data_scientist</td>\n","      <td>['Machine Learning', 'R', 'SAS', 'SQL', 'Python']</td>\n","      <td>5</td>\n","      <td>Money Mart Financial Services</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>15.0</td>\n","      <td>[&lt;p&gt;&lt;b&gt;What do we need?&lt;/b&gt;&lt;/p&gt;, &lt;ul&gt;&lt;li&gt;\\r\\r\\...</td>\n","      <td>TX</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0       Job_Title  ... Insurance Other_industries\n","0           0  Data Scientist  ...         0                0\n","1           1  Data Scientist  ...         0                0\n","\n","[2 rows x 43 columns]"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"0gm2ru_6MY7p","executionInfo":{"status":"ok","timestamp":1618120313777,"user_tz":-330,"elapsed":7312,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["JobData.rename(columns={JobData.columns[0]: 'JobID'}, inplace = True)\n","JobData['JobID'] = JobData['JobID'] +1"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Olh3Z0Ody1K","executionInfo":{"status":"ok","timestamp":1618120313779,"user_tz":-330,"elapsed":7309,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"585e4169-4a89-4f9f-e3e7-37a30b960e9d"},"source":["\"Checking for missing values\"\n","JobData.isnull().sum()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["JobID                                  0\n","Job_Title                              0\n","Link                                   0\n","Queried_Salary                         0\n","Job_Type                               0\n","Skill                                232\n","No_of_Skills                           0\n","Company                              104\n","No_of_Reviews                        962\n","No_of_Stars                          962\n","Date_Since_Posted                    104\n","Description                          302\n","Location                             252\n","Company_Revenue                     3698\n","Company_Employees                   2516\n","Company_Industry                    1889\n","python                                 0\n","sql                                    0\n","machine learning                       0\n","r                                      0\n","hadoop                                 0\n","tableau                                0\n","sas                                    0\n","spark                                  0\n","java                                   0\n","Others                                 0\n","CA                                     0\n","NY                                     0\n","VA                                     0\n","TX                                     0\n","MA                                     0\n","IL                                     0\n","WA                                     0\n","MD                                     0\n","DC                                     0\n","NC                                     0\n","Other_states                           0\n","Consulting and Business Services       0\n","Internet and Software                  0\n","Banks and Financial Services           0\n","Health Care                            0\n","Insurance                              0\n","Other_industries                       0\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"ZuYLvDS8KVyg"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"F5OfjWvrOANM","executionInfo":{"status":"ok","timestamp":1618120313782,"user_tz":-330,"elapsed":7309,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["JobDataCopy = JobData.copy()\n","# Deleting redundant columns\n","\n","def delete_redundancy(col):\n","  return JobData.drop(col, axis = 1, inplace = False)\n","\n","JobData  = delete_redundancy(['Link', 'No_of_Skills', 'No_of_Reviews', 'No_of_Stars', 'No_of_Stars', 'Company_Revenue', 'Company_Employees'])   # deleting company revenue and company employees due to large no of missing values\n","\n","\"Exclude last columns\"\n","JobData = JobData[JobData.columns[:10]]"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C8_FyxXUE_h6","executionInfo":{"status":"ok","timestamp":1618120313784,"user_tz":-330,"elapsed":7306,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"c3b51154-b99c-4fce-ab89-ef6b31635399"},"source":["JobData.nunique()    #checking count of unique values in all columns"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["JobID                5715\n","Job_Title            2314\n","Queried_Salary          6\n","Job_Type                3\n","Skill                4024\n","Company              2231\n","Date_Since_Posted      30\n","Description          4802\n","Location               51\n","Company_Industry       33\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yZVH7KvoFJdR","executionInfo":{"status":"ok","timestamp":1618120318949,"user_tz":-330,"elapsed":12466,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"f0bf95da-e493-49a3-d0f6-b2d952778328"},"source":["\n","# Cleaning the description text\n","def clean_description_text(text):         \n","   \n","    text = BeautifulSoup(text, \"lxml\").get_text()       #removing html tags\n","    text = text.replace('/', ' ')                       #removing forward slashes\n","    text = text.replace('\\n', ' ')                      #removing new lines\n","    text = re.sub(r'(x.[0-9])', '', text)               #removing special characters\n","    text = text.replace('\\r', ' ')\n","    text = text.lower()    #lower case the text         \n","    return text\n","\n","logger.info(\"-----Cleaning Job Description-----------\") \n","JobData['Description'] = JobData.astype(str).apply(lambda x: clean_description_text(x['Description']), axis=1)\n","logger.info(\"%s Cleaned Job Description \")                      "],"execution_count":16,"outputs":[{"output_type":"stream","text":["[I 210411 05:51:51 <ipython-input-16-cea299bc85a8>:13] -----Cleaning Job Description-----------\n","[I 210411 05:51:57 <ipython-input-16-cea299bc85a8>:15] %s Cleaned Job Description \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"R9eAF-Zn5CMk"},"source":["### Handling Input features"]},{"cell_type":"code","metadata":{"id":"pMmdVFdn0GzI","executionInfo":{"status":"ok","timestamp":1618120318951,"user_tz":-330,"elapsed":12465,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}}},"source":["#categorizing less frequent values into 'Other'\n","def bin_companyIndustry(df,column):\n","\n","  series = pd.value_counts(df[column])\n","  mask = (series/series.sum() * 100).lt(1)   # masks categroies with less than 1%\n","  df[column] = np.where(df[column].isin(series[mask].index),'Other',df[column])\n","  df[column] = df[column].fillna('Other')\n","  return df[column]\n","\n","JobData['Company_Industry'] = bin_companyIndustry(JobData, 'Company_Industry')"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"l4CPNPovcbsd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618120320547,"user_tz":-330,"elapsed":14056,"user":{"displayName":"CHANDRIKA","photoUrl":"","userId":"13931345100314558168"}},"outputId":"81af246d-ab05-416b-d43c-0b2f5abe21f6"},"source":["def clean_cols(df):\n","  df['Job_Title'] =df['Job_Title'].str.replace(r\"\\(.*\\)\",\"\")\n","  df['Job_Title'] =df['Job_Title'].str.replace(r\"Sr.\",\"Senior\")\n","  df['Job_Title'] =df['Job_Title'].str.lower()\n","  df['Job_Title'] = [re.sub('[^a-z0-9]+', \" \", text) for text in df['Job_Title']]\n","  df['Job_Title'] = df['Job_Title'].str.lower()\n","  df['Job_Type'] = [re.sub('[^a-z0-9,]+', \" \", text) for text in df['Job_Type']]\n","  df['Skill'] = df['Skill'].astype(str).str.replace('\\[|\\]|' , '')#convert list into strings\n","  #df['Skill'] = df['Skill'].str.replace(',','') \n","  df['Skill'] = df['Skill'].str.replace('\\'','')  # should we relace , ?? \n","  df['Skill'] = df['Skill'].str.lower()\n","  df['Location'] = df['Location'].fillna(df['Location'].mode()[0])\n","  \n","  df['Company_Industry'] = df['Company_Industry'].str.lower()\n","\n","clean_cols(JobData)\n","logger.info(\"%s Cleaned Job Description \")       \n","logzero.logfile(\"logdatacleaning.log\",maxBytes=1e6)\n","JobData.to_excel(\"cleaned_indeed_job_dataset.xlsx\", index=False)\n","JobData.to_pickle('cleaned_indeed_job_dataset.pkl')"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[I 210411 05:51:57 <ipython-input-18-3b6b6d53e7a8>:17] %s Cleaned Job Description \n"],"name":"stderr"}]}]}